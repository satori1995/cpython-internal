<!DOCTYPE HTML>
<html lang="zh-cn" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>CPython3.8 源码探秘</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/custom.css">
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="0.序言.html">0. 序言</a></li><li class="chapter-item expanded "><a href="1.CPython源码长什么样子？.html">1. CPython 源码长什么样子？</a></li><li class="chapter-item expanded "><a href="2.变量和对象，它们之间有什么区别和联系呢？.html">2. 变量和对象，它们之间有什么区别和联系呢？</a></li><li class="chapter-item expanded "><a href="3.Python对象有哪几种，我们可以从哪些角度进行分类呢？.html">3. Python 对象有哪几种，我们可以从哪些角度进行分类呢？</a></li><li class="chapter-item expanded "><a href="4.万丈高楼平地起，一切从PyObject开始.html">4. 万丈高楼平地起，一切从 PyObject 开始</a></li><li class="chapter-item expanded "><a href="5.详解PyTypeObject，Python类型对象的载体.html">5. 详解 PyTypeObject，Python 类型对象的载体</a></li><li class="chapter-item expanded "><a href="6.通过type和object之间的关联，进一步分析类型对象.html">6. 通过 type 和 object 之间的关联，进一步分析类型对象</a></li><li class="chapter-item expanded "><a href="7.当创建一个Python对象时，背后都经历了哪些过程？.html">7. 当创建一个 Python 对象时，背后都经历了哪些过程？</a></li><li class="chapter-item expanded "><a href="8.当调用一个Python对象时，背后都经历了哪些过程？.html">8. 当调用一个 Python 对象时，背后都经历了哪些过程？</a></li><li class="chapter-item expanded "><a href="9.再探泛型API，感受Python对象的设计哲学.html">9. 再探泛型 API，感受 Python 对象的设计哲学</a></li><li class="chapter-item expanded "><a href="10.Python对象的行为是怎么区分的？.html">10. Python 对象的行为是怎么区分的？</a></li><li class="chapter-item expanded "><a href="11.一个Python对象会在何时被销毁？.html">11. 一个 Python 对象会在何时被销毁？</a></li><li class="chapter-item expanded "><a href="12.深度解密Python的浮点数是怎么实现的？.html">12. 深度解密 Python 的浮点数是怎么实现的？</a></li><li class="chapter-item expanded "><a href="13.对象被销毁之后所占的内存一定会释放吗？解密浮点数的缓存池机制.html">13. 对象被销毁之后所占的内存一定会释放吗？解密浮点数的缓存池机制</a></li><li class="chapter-item expanded "><a href="14.浮点数支持的操作是怎么实现的？.html">14. 浮点数支持的操作是怎么实现的？</a></li><li class="chapter-item expanded "><a href="15.解密Python的复数是怎么实现的？它有什么用途呢？.html">15. 解密 Python 的复数是怎么实现的？它有什么用途呢？</a></li><li class="chapter-item expanded "><a href="16.Python的整数是怎么设计的，为什么它不会溢出？.html">16. Python 的整数是怎么设计的，为什么它不会溢出？</a></li><li class="chapter-item expanded "><a href="17.解密Python的小整数对象池.html">17. 解密 Python 的小整数对象池</a></li><li class="chapter-item expanded "><a href="18.两个Python整数之间是如何进行大小比较的？过程并不像我们想的那样简单.html">18. 两个 Python 整数之间是如何进行大小比较的？过程并不像我们想的那样简单</a></li><li class="chapter-item expanded "><a href="19.探究Python整数的加减法，感受大整数的运算哲学与魅力.html">19. 探究 Python 整数的加减法，感受大整数的运算哲学与魅力</a></li><li class="chapter-item expanded "><a href="20.Python的布尔值是怎么实现的，你对它的了解有多深呢？.html">20. Python 的布尔值是怎么实现的，你对它的了解有多深呢？</a></li><li class="chapter-item expanded "><a href="21.Python的None是怎么实现的？.html">21. Python 的 None 是怎么实现的？</a></li><li class="chapter-item expanded "><a href="22.深度解密Python切片的实现原理.html">22.深度解密 Python 切片的实现原理</a></li><li class="chapter-item expanded "><a href="23.bytes对象（字节串）是怎么实现的？解密它的内部原理.html">23. bytes 对象（字节串）是怎么实现的？解密它的内部原理</a></li><li class="chapter-item expanded "><a href="24.bytes对象都支持哪些操作，它们是怎么实现的？.html">24. bytes 对象都支持哪些操作，它们是怎么实现的？</a></li><li class="chapter-item expanded "><a href="25.通过bytes对象的合并，探究缓冲区的奥秘.html">25. 通过 bytes 对象的合并，探究缓冲区的奥秘</a></li><li class="chapter-item expanded "><a href="26.解密bytes对象的缓存池.html">26. 解密 bytes 对象的缓存池</a></li><li class="chapter-item expanded "><a href="27.详解bytearray对象的底层实现.html">27. 详解 bytearray 对象的底层实现</a></li><li class="chapter-item expanded "><a href="28.字符集和字符编码.html">28. 字符集和字符编码</a></li><li class="chapter-item expanded "><a href="29.Python是怎么存储字符串的？.html">29. Python 是怎么存储字符串的？</a></li><li class="chapter-item expanded "><a href="30.解密字符串的底层结构，它是怎么实现的？.html">30. 解密字符串的底层结构，它是怎么实现的？</a></li><li class="chapter-item expanded "><a href="31.字符串的intern机制是怎么一回事？.html">31. 字符串的 intern 机制是怎么一回事？</a></li><li class="chapter-item expanded "><a href="32.聊一聊字符串常见操作的源码实现.html">32. 聊一聊字符串常见操作的源码实现</a></li><li class="chapter-item expanded "><a href="33.列表是怎么实现的？解密列表的数据结构.html">33. 列表是怎么实现的？解密列表的数据结构</a></li><li class="chapter-item expanded "><a href="34.列表是怎么扩容的？.html">34. 列表是怎么扩容的？</a></li><li class="chapter-item expanded "><a href="35.解密列表的创建与销毁，以及缓存池长什么样子？.html">35. 解密列表的创建与销毁，以及缓存池长什么样子？</a></li><li class="chapter-item expanded "><a href="36.列表作为序列型对象都支持哪些操作，它们在底层是怎么实现的？.html">36. 列表作为序列型对象都支持哪些操作，它们在底层是怎么实现的？</a></li><li class="chapter-item expanded "><a href="37.列表都有哪些自定义方法，它们是怎么实现的？.html">37. 列表都有哪些自定义方法，它们是怎么实现的？</a></li><li class="chapter-item expanded "><a href="38.解密元组的实现原理.html">38. 解密元组的实现原理</a></li><li class="chapter-item expanded "><a href="39.聊一聊喜闻乐见的哈希表.html">39. 聊一聊喜闻乐见的哈希表</a></li><li class="chapter-item expanded "><a href="40.字典是怎么实现的，它的底层结构长什么样子？.html">40. 字典是怎么实现的，它的底层结构长什么样子？</a></li><li class="chapter-item expanded "><a href="41.什么是可哈希对象，它的哈希值是怎么计算的？.html">41. 什么是可哈希对象，它的哈希值是怎么计算的？</a></li><li class="chapter-item expanded "><a href="42.字典的key是怎么映射成索引的，索引冲突了又该怎么办？.html">42. 字典的 key 是怎么映射成索引的，索引冲突了又该怎么办？</a></li><li class="chapter-item expanded "><a href="43.哈希表是怎么删除元素的，能直接删除吗？.html">43. 哈希表是怎么删除元素的，能直接删除吗？</a></li><li class="chapter-item expanded "><a href="44.字典是怎么创建的，支持的操作又是如何实现的？.html">44. 字典是怎么创建的，支持的操作又是如何实现的？</a></li><li class="chapter-item expanded "><a href="45.字典的自定义方法是怎么实现的？.html">45. 字典的自定义方法是怎么实现的？</a></li><li class="chapter-item expanded "><a href="46.字典是怎么扩容的？它会经历哪些过程？.html">46. 字典是怎么扩容的？它会经历哪些过程？</a></li><li class="chapter-item expanded "><a href="47.身虽死，道未消，解密字典的缓存池.html">47. 身虽死，道未消，解密字典的缓存池</a></li><li class="chapter-item expanded "><a href="48.解密集合的实现原理.html">48. 解密集合的实现原理</a></li><li class="chapter-item expanded "><a href="49.集合支持的操作有哪些，它们是怎么实现的？.html">49. 集合支持的操作有哪些，它们是怎么实现的？</a></li><li class="chapter-item expanded "><a href="50.迭代器是怎么实现的？.html">50. 迭代器是怎么实现的？</a></li><li class="chapter-item expanded "><a href="51.Python源文件编译之后会得到什么，它的结构是怎样的？和字节码又有什么联系？.html">51. Python 源文件编译之后会得到什么，它的结构是怎样的？和字节码又有什么联系？</a></li><li class="chapter-item expanded "><a href="52.PyCodeObject拾遗.html">52. PyCodeObject 拾遗</a></li><li class="chapter-item expanded "><a href="53.一文让你搞懂pyc文件.html">53. 一文让你搞懂 pyc 文件</a></li><li class="chapter-item expanded "><a href="54.深度解密虚拟机的执行环境：栈帧对象.html">54. 深度解密虚拟机的执行环境：栈帧对象</a></li><li class="chapter-item expanded "><a href="55.名字空间：变量的容身之所.html">55. 名字空间：变量的容身之所</a></li><li class="chapter-item expanded "><a href="56.当查找一个变量时，虚拟机会进行哪些动作？.html">56. 当查找一个变量时，虚拟机会进行哪些动作？</a></li><li class="chapter-item expanded "><a href="57.虚拟机是怎么执行字节码的？背后都经历了哪些过程.html">57. 虚拟机是怎么执行字节码的？背后都经历了哪些过程</a></li><li class="chapter-item expanded "><a href="58.深入源码，进一步考察字节码的执行流程.html">58. 深入源码，进一步考察字节码的执行流程</a></li><li class="chapter-item expanded "><a href="59.局部变量是怎么实现静态查找的，它和local名字空间又有什么联系呢？.html">59. 局部变量是怎么实现静态查找的，它和 local 名字空间又有什么联系呢？</a></li><li class="chapter-item expanded "><a href="60.剖析字节码指令，以及Python赋值语句的原理.html">60. 剖析字节码指令，以及 Python 赋值语句的原理</a></li><li class="chapter-item expanded "><a href="61.流程控制语句if是怎么实现的？.html">61. 流程控制语句 if 是怎么实现的？</a></li><li class="chapter-item expanded "><a href="62.流程控制语句for、while是怎么实现的？.html">62. 流程控制语句 for、while 是怎么实现的？</a></li><li class="chapter-item expanded "><a href="63.异常是怎么实现的？虚拟机是如何将异常抛出去的？.html">63. 异常是怎么实现的？虚拟机是如何将异常抛出去的？</a></li><li class="chapter-item expanded "><a href="64.虚拟机是如何捕获异常的？.html">64. 虚拟机是如何捕获异常的？</a></li><li class="chapter-item expanded "><a href="65.函数在底层长什么样子？.html">65. 函数在底层长什么样子？</a></li><li class="chapter-item expanded "><a href="66.函数是怎么创建的，背后经历了哪些过程？.html">66. 函数是怎么创建的，背后经历了哪些过程？</a></li><li class="chapter-item expanded "><a href="67.函数在底层是如何调用的？.html">67. 函数在底层是如何调用的？</a></li><li class="chapter-item expanded "><a href="68.函数是如何解析位置参数的？.html">68. 函数是如何解析位置参数的？</a></li><li class="chapter-item expanded "><a href="69.函数是如何解析关键字参数的？.html">69. 函数是如何解析关键字参数的？</a></li><li class="chapter-item expanded "><a href="70.扩展位置参数和扩展关键字参数是如何解析的？.html">70. 扩展位置参数和扩展关键字参数是如何解析的？</a></li><li class="chapter-item expanded "><a href="71.闭包是怎么实现的？.html">71. 闭包是怎么实现的？</a></li><li class="chapter-item expanded "><a href="72.生成器是做什么的，为什么会有生成器？.html">72. 生成器是做什么的，为什么会有生成器？</a></li><li class="chapter-item expanded "><a href="73.源码解密生成器的实现原理.html">73. 源码解密生成器的实现原理</a></li><li class="chapter-item expanded "><a href="74.回顾Python的对象模型.html">74. 回顾 Python 的对象模型</a></li><li class="chapter-item expanded "><a href="75.class概念解析.html">75. class 概念解析</a></li><li class="chapter-item expanded "><a href="76.类型对象的初始化.html">76. 类型对象的初始化</a></li><li class="chapter-item expanded "><a href="77.自定义类对象的底层实现与metaclass.html">77. 自定义类对象的底层实现与 metaclass</a></li><li class="chapter-item expanded "><a href="78.彻底搞懂描述符.html">78. 彻底搞懂描述符</a></li><li class="chapter-item expanded "><a href="79.实例对象是如何创建的？.html">79. 实例对象是如何创建的？</a></li><li class="chapter-item expanded "><a href="80.实例对象的属性访问.html">80. 实例对象的属性访问</a></li><li class="chapter-item expanded "><a href="81.为什么实例在调用方法时会将自身传给self参数.html">81. 为什么实例在调用方法时会将自身传给 self 参数</a></li><li class="chapter-item expanded "><a href="82.模块是如何导入的？.html">82. 模块是如何导入的？</a></li><li class="chapter-item expanded "><a href="83.import机制的黑盒探测.html">83. import 机制的黑盒探测</a></li><li class="chapter-item expanded "><a href="84.import机制是怎么实现的？.html">84. import 机制是怎么实现的？</a></li><li class="chapter-item expanded "><a href="85.Python运行时环境的初始化，解释器在启动时都做了什么？.html">85. Python 运行时环境的初始化，解释器在启动时都做了什么？</a></li><li class="chapter-item expanded "><a href="86.激活Python虚拟机.html">86. 激活 Python 虚拟机</a></li><li class="chapter-item expanded "><a href="87.初识GIL、以及多个线程之间的调度机制.html">87. 初识 GIL、以及多个线程之间的调度机制</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">CPython3.8 源码探秘</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/satori1995/cpython-internal" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p>大家好，我是古明地觉，从今天开始我将和大家一起剖析 Python 解释器源码。</p>
<p>毫无疑问，Python 已经成为当下最主流的语言之一，如果你只是会用，那么很难和其他人拉开差距。但如果你知道 Python 解释器的底层原理，比如：</p>
<ul>
<li>列表、字典、生成器等数据结构是怎么实现的； </li>
<li>GIL 如何限制多线程只能同时使用一个核； </li>
<li>虚拟机是如何执行字节码的； </li>
<li>Python 的垃圾回收又是怎么一回事； </li>
<li>······</li>
</ul>
<p>那么你在面试的时候一定能让面试官眼前一亮，并且也能写出更好、更优雅的代码，这也是我们为什么要剖析 Python 解释器源码。可 Python 解释器的源码行数有五十多万行，该怎么入手呢？不用担心，本系列就来抽丝剥茧，带你近距离观察 Python 解释器这座宏伟大厦。</p>
<blockquote>
<p>注：官方 Python 解释器由 C 语言编写，我们称之为 CPython。想要读懂它，需要有一定的 C 语言基础，当然我也会给出详细的注释。</p>
</blockquote>
<p>本系列力求详细、精致，在介绍源码时会给出大量的注释和清晰的图表，并且我不仅仅会介绍源码实现，还会穿插大量的 Python 普通知识。因为 Python 解释器由 C 语言编写，想要读懂它，需要有一定的 C 语言基础。而本系列则确保，不管你 C 语言的水平如何，读了之后都能有所收获。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="cpython-源码结构"><a class="header" href="#cpython-源码结构">CPython 源码结构</a></h2>
<p>工欲善其事，必先利其器，在剖析源码之前，要先将它下载下来，并熟悉里面的结构。我们登录官网下载 CPython，本系列剖析的版本是 3.8.8，你可以点击此<a href="https://www.python.org/ftp/python/3.8.8/Python-3.8.8.tgz">链接</a>进行下载。</p>
<p>压缩包下载下来之后解压，即可得到整个 CPython 工程项目，我们看看它长什么样子？</p>
<p><img src="./images/1.png" alt="" /></p>
<p>以上便是 CPython3.8.8 源码结构，我们解释一下每个目录的作用。</p>
<p><font color="blue"><strong>Doc 目录</strong></font></p>
<p>存储 Python 文档的源文件（.rst），用于编译之后生成官方文档。</p>
<p><font color="blue"><strong>Grammar 目录</strong></font></p>
<p>负责定义 Python 的语法规则。</p>
<p><font color="blue"><strong>Include 目录</strong></font></p>
<p>包含 Python 所有公开的头文件，这些文件定义了 Python 的 C API，在编写扩展模块和嵌入式开发时会用到。</p>
<p><font color="blue"><strong>Lib 目录</strong></font></p>
<p>Python 的标准库，对于那些不影响性能的模块会用 Python 编写，然后放在 Lib 目录下面。</p>
<p><font color="blue"><strong>Modules 目录</strong></font></p>
<p>Python 的内置库，这些库都是用 C 编写的，编译之后会内嵌在解释器里面。我们举个例子：</p>
<pre><code class="language-python">import random, _random
import re, _sre
import io, _io
import ast, _ast
</code></pre>
<p>以 random 为例，它是用来生成随机数的，和性能密切相关。所以它的核心功能由 C 编写，编译之后内嵌在解释器里，模块名为 _random。只不过 Python 又封装了一个 random，在内部会导入 _random，像 re 和 _sre、asyncio 和 _asyncio 都是类似的关系。</p>
<p>Modules 目录里面实现了大量和性能相关的模块，比如 sys、time、gc 等等，我们后续再聊。</p>
<p><font color="blue"><strong>Objects 目录</strong></font></p>
<p>包含 Python 内置数据结构的底层实现，像字典、列表、元组、函数等，底层实现都定义在 Objects 目录中。</p>
<p><font color="blue"><strong>Parser 目录</strong></font></p>
<p>负责 Python 代码的编译，虽然 Python 是解释型语言，但也是要经过编译的。编译的结果为 PyCodeObject 对象，它里面包含了要执行的字节码，编译完之后会交给虚拟机执行。</p>
<p>所以 Python 解释器 = Python 编译器 + Python 虚拟机。</p>
<p><font color="blue"><strong>Python 目录</strong></font></p>
<p>Python 虚拟机的具体实现，字节码的执行、执行环境的管理等都在里面。</p>
<p><font color="blue"><strong>Mac 目录</strong></font></p>
<p>用于 Mac OS X 平台的特定工具和脚本。</p>
<p><font color="blue"><strong>Misc 目录</strong></font></p>
<p>包含各种杂项文件，如配置脚本、工具等。</p>
<p><font color="blue"><strong>PC 目录</strong></font></p>
<p>专为 Windows 平台编写的配置文件和特定扩展。</p>
<p><font color="blue"><strong>PCbuild 目录</strong></font></p>
<p>用于在 Windows 上编译 Python 的项目文件。</p>
<p><font color="blue"><strong>Programs 目录</strong></font></p>
<p>包含 Python 其它可执行文件（如 IDLE）的源代码。</p>
<p><font color="blue"><strong>Tools 目录</strong></font></p>
<p>包含用 Python 编写的各种脚本和工具，帮助开发和维护 Python。</p>
<p>以上就是 CPython 的源码结构，对它有一个基本的认识有助于我们后续的源码学习。</p>
<h2 id="解释器编译器虚拟机"><a class="header" href="#解释器编译器虚拟机">解释器、编译器、虚拟机</a></h2>
<p>我们上面说了，<font color="darkgreen"><strong>Python 解释器 = Python 编译器 + Python 虚拟机</strong></font>，当解释器执行 py 文件时都经历了哪些过程呢？</p>
<p><img src="./images/2.png" alt="" /></p>
<p>Read File、Scanner、Parser、Compiler 都是由 Python 编译器负责的，Code Eval 则由 Python 虚拟机负责。</p>
<p>因此 Python 虽然是解释型语言，但也有编译的过程。源代码会被编译器编译成 PyCodeObject 对象，然后再交给虚拟机来执行。而之所以要存在编译，是为了让虚拟机能更快速地执行，比如在编译阶段常量都会提前分配好，而且还可以尽早检测出语法上的错误。</p>
<p>而 Python 编译器和 Python 虚拟机组合起来，便是 Python 解释器。</p>
<p><img src="./images/3.png" alt="" /></p>
<p>如果你了解 Java，那么应该知道 Java 也有编译器和虚拟机。只不过 Java 的编译器和虚拟机是分开的，而 Python 则是整合在一起的。</p>
<p>不过在后续介绍 Python 源码的时候，我们暂不涉及 Python 编译器的部分，也就是 Parser 目录里面的代码不做分析，因为涉及到编译原理。而且编译这一过程也不是 Python 语言独有的，任何一门编程语言、当然还有 SQL 都会涉及到编译。所以探究 Python 代码的编译过程没太大意义，我们的重点是 Python 代码的编译结果，以及虚拟机是如何执行的？</p>
<h2 id="小结"><a class="header" href="#小结">小结</a></h2>
<p>本文就说到这里，赶快下载 Python 3.8 源码，来和我一起学习 Python 吧（ヾ(◍°∇°◍)ﾉﾞ）。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="python-中一切皆对象"><a class="header" href="#python-中一切皆对象">Python 中一切皆对象</a></h2>
<p>在学习 Python 的时候，你肯定听过这么一句话：<font color="darkblue">Python 中一切皆对象</font>。没错，在 Python 世界里，一切都是对象。整数是一个对象、字符串是一个对象、字典是一个对象，甚至 int, str, list 以及我们使用 class 关键字自定义的类，它们也是对象。</p>
<p>像 int, str, list 等基本类型，以及自定义的类，由于它们可以表示类型，因此我们称之为<font color="darkblue">类型对象</font>；类型对象实例化得到的对象，我们称之为<font color="darkblue">实例对象</font>。但不管是哪种对象，它们都属于对象。因此 Python 将面向对象理念贯彻的非常彻底，面向对象中的类和对象在 Python 中都是通过对象实现的。</p>
<p>在面向对象理论中，存在着<font color="darkblue">类</font>和<font color="darkblue">对象</font>两个概念，像 int、dict、tuple、以及使用 class 关键字自定义的类型对象实现了面向对象理论中<font color="darkblue">类</font>的概念，而 123、3.14、&quot;string&quot; 等实例对象则实现了面向对象理论中<font color="darkblue">对象</font>的概念。但在 Python 里面，面向对象中的类和对象都是通过对象实现的。</p>
<p>我们举个例子：</p>
<pre><code class="language-Python"># dict 是一个类，因此它属于类型对象
# 类型对象实例化得到的对象属于实例对象
print(dict)
&quot;&quot;&quot;
&lt;class 'dict'&gt;
&quot;&quot;&quot;
print(dict(a=1, b=2))
&quot;&quot;&quot;
{'a': 1, 'b': 2}
&quot;&quot;&quot;
</code></pre>
<p>因此可以用一张图来描述面向对象在 Python 中的体现。</p>
<p><img src="./images/5.png" alt="" /></p>
<p>而如果想查看一个对象的类型，可以使用 type，或者通过对象的 __class__ 属性。</p>
<pre><code class="language-python">data = [1, 2, 3]
# 查看类型
print(type(data))
&quot;&quot;&quot;
&lt;class 'list'&gt;
&quot;&quot;&quot;
print(data.__class__)
&quot;&quot;&quot;
&lt;class 'list'&gt;
&quot;&quot;&quot;
</code></pre>
<p>如果想判断一个对象是不是指定类型的实例对象，可以使用 isinstance。</p>
<pre><code class="language-Python">data = [1, 2, 3]
# 判断是不是指定类型的实例对象
print(isinstance(data, list))
&quot;&quot;&quot;
True
&quot;&quot;&quot;
</code></pre>
<p>但是问题来了，按照面向对象的理论来说，对象是由类实例化得到的，这在 Python 中也是适用的。既然是对象，那么就必定有一个类来实例化它，换句话说对象一定要有类型。至于一个对象的类型是什么，就看这个对象是被谁实例化的，被谁实例化，那么类型就是谁，比如列表的类型是 list，字典的类型是 dict 等等。</p>
<p>而 Python 中一切皆对象，所以像 int, str, tuple 这些内置的类对象也是具有相应的类型的，那么它们的类型又是谁呢？使用 type 查看一下就知道了。</p>
<pre><code class="language-Python">print(type(int))  # &lt;class 'type'&gt;
print(type(str))  # &lt;class 'type'&gt;
print(type(dict))  # &lt;class 'type'&gt;
print(type(type))  # &lt;class 'type'&gt;
</code></pre>
<p>我们看到类型对象的类型，无一例外都是 type。而 type 我们也称其为<font color="red">元类</font>，表示类型对象的类型。至于 type 本身，它的类型还是 type，所以它连自己都没放过，把自己都变成自己的对象了。</p>
<p>因此在 Python 中，你能看到的任何对象都是有类型的，可以使用 type 查看，也可以获取该对象的 __class__ 属性查看。所以：实例对象、类型对象、元类，Python 中任何一个对象都逃不过这三种身份。</p>
<p>到这里可能有人会发现一个有意思的点，我们说 int 是一个类对象，这显然是没有问题的。因为站在整数（比如 123）的角度上，int 是一个不折不扣的类对象；但如果站在 type 的角度上呢？显然我们又可以将 int 理解为实例对象，因此 class 具有二象性。</p>
<p>至于 type 也是同理，虽然它是元类，但本质上也是一个类对象。</p>
<blockquote>
<p>注：不仅 type 是元类，那些继承了 type 的类也可以叫做元类。</p>
</blockquote>
<p>然后 Python 中还有一个关键的类型（对象），叫做 object，它是所有类型对象的基类。不管是什么类，内置的类也好，我们自定义的类也罢，它们都继承自 object。因此 object 是所有类型对象的基类、或者说父类。</p>
<p>那如果我们想获取一个类都继承了哪些基类，该怎么做呢？方式有三种：</p>
<pre><code class="language-python">class A: pass

class B: pass

class C(A): pass

class D(B, C): pass

# 首先 D 继承自 B 和 C, C 又继承 A
# 我们现在要来查看 D 继承的父类

# 方法一: 使用 __base__
print(D.__base__)  
&quot;&quot;&quot;
&lt;class '__main__.B'&gt;
&quot;&quot;&quot;

# 方法二: 使用 __bases__
print(D.__bases__)  
&quot;&quot;&quot;
(&lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;)
&quot;&quot;&quot;

# 方法三: 使用 __mro__
print(D.__mro__)
&quot;&quot;&quot;
(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, 
 &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, 
 &lt;class 'object'&gt;)
&quot;&quot;&quot;
</code></pre>
<ul>
<li>__base__：如果继承了多个类，那么只显示继承的第一个类，没有显式继承则返回 <font color="blue">&lt;class 'object'&gt;</font></li>
<li>__bases__：返回一个元组，会显示所有直接继承的父类，没有显式继承则返回 <font color="blue">(&lt;class 'object'&gt;,)</font></li>
<li>__mro__: mro（Method Resolution Order）表示方法查找顺序，会从自身出发，找到最顶层的父类。因此返回自身、继承的基类、以及基类继承的基类，一直找到 object</li>
</ul>
<p>而如果想查看某个类型是不是另一个类型的子类，可以通过 issubclass。</p>
<pre><code class="language-python">print(issubclass(str, object))
&quot;&quot;&quot;
True
&quot;&quot;&quot;
</code></pre>
<p>因此，我们可以得出以下两个结论：</p>
<ul>
<li>type 站在类型金字塔的最顶端，任何一个对象按照类型追根溯源，最终得到的都是 type；</li>
<li>object 站在继承金字塔的最顶端，任何一个类型对象按照继承关系追根溯源，最终得到的都是 object；</li>
</ul>
<p>但要注意的是，我们说 type 的类型还是 type，但 object 的基类则不再是 object，而是 None。</p>
<pre><code class="language-python">print(type.__class__)  # &lt;class 'type'&gt;

# 注：以下打印结果容易让人产生误解
# 它表达的含义是 object 的基类为空
# 而不是说 object 继承 None
print(object.__base__)  # None
</code></pre>
<p>但为什么 object 的基类是 None，而不是它自身呢？其实答案很简单，Python 在查找属性或方法的时候，自身如果没有的话，会按照 __mro__ 指定的顺序去基类中查找。所以继承链一定会有一个终点，否则就会像没有出口的递归一样出现死循环了。</p>
<p>我们用一张图将对象之间的关系总结一下：</p>
<p><img src="./images/6.png" alt="" /></p>
<ul>
<li>实例对象的类型是类型对象，类型对象的类型是元类；</li>
<li>所有类型对象的基类都收敛于 object；</li>
<li>所有对象的类型都收敛于 type；</li>
</ul>
<p>因此 Python 算是将<font color="blue"><strong>一切皆对象</strong></font>的理念贯彻到了极致，也正因为如此，Python 才具有如此优秀的动态特性。</p>
<p>但是还没结束，我们再重新审视一下上面那张图，会发现里面有两个箭头看起来非常的奇怪。object 的类型是 type，type 又继承了 object。</p>
<pre><code class="language-python">print(type.__base__)  # &lt;class 'object'&gt;
print(object.__class__)  # &lt;class 'type'&gt;
</code></pre>
<p>因为 type 是所有类的元类，而 object 是所有类的基类，这就说明 type 要继承自 object，而 object 的类型是 type。很多人都会对这一点感到奇怪，这难道不是一个先有鸡还是先有蛋的问题吗？答案不是的，这两个对象是共存的，它们之间的定义是互相依赖的。而具体是怎么一回事，我们后续分析。</p>
<h2 id="变量其实是指针"><a class="header" href="#变量其实是指针">变量其实是指针</a></h2>
<p>Python 的变量只是一个名字，如果站在 C 语言的角度来看，那么就是一个指针。所以 Python 的变量保存的其实是对象的内存地址，或者说指针，而<font color="blue">指针指向的内存</font>存储的才是对象。</p>
<p>所以在 Python 中，我们都说变量指向了某个对象。在其它静态语言中，变量相当于是为某块内存起的别名，获取变量等于获取这块内存所存储的值。而 Python 中变量代表的内存所存储的不是对象，而是对象的指针（或者说引用）。</p>
<p>我们举例说明，看一段 C 代码。</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;

void main()
{
    int a = 666;
    printf(&quot;address of a = %p\n&quot;, &amp;a);

    a = 667;
    printf(&quot;address of a = %p\n&quot;, &amp;a);
}
</code></pre>
<p>编译执行一下：</p>
<p><img src="./images/7.png" alt="" /></p>
<p>赋值前后地址都是 0x7fff9eda521c，没有变化，再来看一段 Python 代码。</p>
<pre><code class="language-python">a = 666
print(hex(id(a)))  # 0x7febf803a3d0

a = 667
print(hex(id(a)))  # 0x7fec180677b0
</code></pre>
<p>我们看到 Python 里面输出的地址发生了变化，下面分析一下原因。</p>
<p>首先在 C 中，创建一个变量的时候必须规定好类型，比如 <font color="blue">int a = 666</font>，那么变量 a 就是 int 类型，以后在所处的作用域中就不可以变了。如果这时候再设置 <font color="blue">a = 777</font>，那么等于是把内存中存储的 666 换成 777，a 的地址和类型是不会变化的。</p>
<p>而在 Python 中，<font color="blue">a = 666</font> 等于是先开辟一块内存，存储的值为 666，然后让变量 a 指向这片内存，或者说让变量 a 保存这块内存的地址。然后 <font color="blue">a = 777</font> 的时候，再开辟一块内存，然后让 a 指向存储 777 的内存，由于是两块不同的内存，所以它们的地址是不一样的。</p>
<p><img src="./images/8.png" alt="" /></p>
<p>所以 Python 的变量只是一个和对象关联的名字，它代表的是对象的指针。换句话说 Python 的变量就是个便利贴，可以贴在任何对象上，一旦贴上去了，就代表这个对象被引用了。</p>
<h2 id="值传递引用传递"><a class="header" href="#值传递引用传递">值传递？引用传递？</a></h2>
<p>再来看看变量之间的传递，在 Python 中是如何体现的。</p>
<pre><code class="language-python">a = 666
print(hex(id(a)))  # 0x1f4e8ca7fb0

b = a
print(hex(id(b)))  # 0x1f4e8ca7fb0
</code></pre>
<p>我们看到打印的地址是一样的，再用一张图解释一下。</p>
<p><img src="images/9.png" alt="" /></p>
<p><font color="blue">a = 666</font> 的时候，先开辟一份内存，再让 a 存储对应内存的地址；然后 <font color="blue">b = a</font> 的时候，会把 a 拷贝一份给 b，所以 b 和 a 存储了相同的地址，它们都指向了同一个对象。</p>
<p>因此说 Python 是值传递、或者引用传递都是不准确的，准确的说 Python 是<font color="red">变量的值传递，对象的引用传递</font>。因为 Python 的变量可以认为是 C 的一个指针，在 <font color="blue">b = a</font> 的时候，等于把 a 指向的对象的地址（a 本身）拷贝一份给 b，所以对于变量来说是值传递；然后 a 和 b 又都是指向对象的指针，因此对于对象来说是引用传递。</p>
<p><strong>在这个过程中，对象没有重复创建，它只是多了一个引用。</strong></p>
<p>另外还有最关键的一点，Python 的变量是一个指针，当传递变量的时候，传递的是指针；但是在操作变量的时候，会操作变量指向的内存。所以 <font color="blue">id(a)</font> 获取的不是 a 的地址，而是 a 指向的内存的地址（在底层其实就是 a 本身）；同理 b = a，是将 a 本身，或者说将 a 存储的、指向某个具体的对象的地址传递给了 b。</p>
<p>另外在 C 的层面，显然 a 和 b 属于指针变量，那么 a 和 b 有没有地址呢？显然是有的，只不过在 Python 中是获取不到的，解释器只允许获取对象的地址。</p>
<p>我们再举个函数的例子：</p>
<pre><code class="language-python">def some_func(num):
    print(&quot;address of local num&quot;, hex(id(num)))
    num = 667
    print(&quot;address of local num&quot;, hex(id(num)))

num = 666
print(&quot;address of global num&quot;, hex(id(num)))
some_func(num)
&quot;&quot;&quot;
address of global num 0x2356cd698d0
address of local num 0x2356cd698d0
address of local num 0x2356c457f90
&quot;&quot;&quot;
</code></pre>
<p>函数的参数也是一个变量，所以 some_func(num) 其实就是把全局变量 num 存储的对象的地址拷贝一份给局部变量 num，所以两个 num 指向了同一个对象，打印的地址相同。然后函数内部又执行了 num = 667，相当于让局部变量指向新的对象，或者说保存新对象的地址，因此打印的结果发生变化。</p>
<h2 id="变量有类型吗"><a class="header" href="#变量有类型吗">变量有类型吗？</a></h2>
<p>当提到类型时，这个类型指的是变量的类型还是对象的类型呢？不用想，肯定是对象的类型。因为 Python 的变量是个指针，操作指针会自动操作它指向的内存，所以使用 type(a) 查看的其实是变量 a 指向的对象的类型。</p>
<p>那么问题来了，我们在创建变量的时候，并没有显式地指定类型啊，那么解释器是如何判断一个变量指向什么类型的数据呢？答案是：解释器是通过靠猜的方式，通过赋的值（或者说变量引用的值）来推断类型。</p>
<p>因此在 Python 中，如果你想创建一个变量，那么必须在创建变量的时候同时赋值，否则解释器就不知道这个变量指向的数据是什么类型。所以 Python 是先创建相应的值，这个值在 C 中对应一个结构体，结构体里面有一个字段专门用来记录该值对应的类型，<font color="red">因此在 Python 中，类型是和对象绑定的，而不是和变量</font>。当创建完值之后，再让这个变量指向它，所以 Python 中是先有值后有变量。</p>
<p>但在 C 里面显然不是这样的，因为 C 的变量代表的内存所存储的就是具体的值，所以在 C 里面可以直接声明一个变量的同时不赋值。因为 C 要求声明变量时必须指定类型，所以变量声明之后，其类型和内存大小就已经固定了。</p>
<p>而 Python 的变量存的是个地址，它只是指向了某个对象，所以由于其便利贴的特性，可以贴在任意对象上面。但是不管贴在哪个对象，都必须先有对象才可以，不然变量贴谁去。</p>
<blockquote>
<p>另外，尽管 Python 在创建变量的时候不需要指定类型，但 Python 是强类型语言，而且是动态强类型。</p>
</blockquote>
<h2 id="小结-1"><a class="header" href="#小结-1">小结</a></h2>
<p>以上我们就聊了聊 Python 的变量和对象，核心就在于：变量保存的不是对象本身，而是对象的内存地址，站在 C 的角度上看变量就是一个指针。</p>
<p>尽管 Python 一切皆对象，但你拿到的都是对象的指针，变量是一个指针，函数是一个指针，元组、列表、字典里面存储的还是指针。我们可以想象一下列表，它底层是基于数组实现的，由于 C 数组要求里面每个元素的类型和大小都相同，因此从这个角度上讲，列表内部存储的只能是指针。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子"><a class="header" href="#楔子">楔子</a></h2>
<p>在程序开发中，我们每时每刻都在创建对象，那到底什么是对象呢？</p>
<p>其实一个对象就是一片被分配的内存空间，空间可以是连续的，也可以是不连续的。然后空间里面存储了指定的数据，并提供了操作数据的一些功能方法。而按照是否可变和内存大小是否固定，我们可以将对象进行如下分类。</p>
<ul>
<li>可变对象和不可变对象；</li>
<li>定长对象和变长对象；</li>
</ul>
<p>下面来详细解释一下。</p>
<h2 id="可变对象和不可变对象"><a class="header" href="#可变对象和不可变对象">可变对象和不可变对象</a></h2>
<p><font color="blue">不可变对象</font>一旦创建，其内存中存储的值就不可以再修改了。如果想修改，只能创建一个新的对象，然后让变量指向新的对象，所以前后的地址会发生改变。而<font color="blue">可变对象</font>在创建之后，其存储的值可以动态修改。</p>
<p>像整数就是一个不可变对象。</p>
<pre><code class="language-python">&gt;&gt;&gt; a = 666
&gt;&gt;&gt; id(a)
140176818069136
&gt;&gt;&gt; a += 1
&gt;&gt;&gt; id(a)
140176818068368
</code></pre>
<p>我们看到执行 a += 1 操作之后，前后地址发生了变化，所以整数不支持本地修改，因此是一个不可变对象；</p>
<p><img src="./images/10.png" alt="" /></p>
<p>原来 a = 666，而我们说操作一个变量等于操作这个变量指向的内存，所以 a += 1 会将 a 指向的整数对象 666 和 1 进行加法运算，得到 667。因此会开辟新的空间来存储 667，然后让 a 指向这片新的空间。至于原来的 666 所占的空间怎么办，解释器会看它的引用计数，如果不为 0 代表还有变量引用（指向）它，如果为 0 则证明没有变量引用了，所以会被回收。</p>
<p>关于引用计数，我们后面会详细说，目前只需要知道，如果对象被变量引用了，那么该对象的引用计数就会加 1。有几个变量引用，那么它的引用计数就是几。</p>
<p>除了整数之外，浮点数、字符串、布尔值等等，都是不可变对象，它们的值不能本地修改。</p>
<p><font color="darkblue"><strong>然后是可变对象，像列表、字典、集合等都是可变对象，它们支持动态修改。</strong></font></p>
<blockquote>
<p>这里先多提一句，Python 对象本质上就是 C 的 malloc 函数为结构体实例在堆区申请的一块内存。Python 的任何对象在 C 中都会对应一个结构体，这个结构体除了存放具体的值之外，还存放了一些额外信息，具体细节在后续剖析内置对象的时候会细说。</p>
</blockquote>
<p>在上一篇文章中我们说到，列表、元组、集合这些容器的内部存储的不是具体的对象，而是对象的指针。比如：<font color="blue">lst = [1, 2, 3]</font>，你以为列表存储的是三个整数对象吗？其实不是的，它存储的是三个整数对象的指针，当我们获取 lst[0] 的时候，拿到的是一个指针，但是操作（比如 print）的时候会自动操作指针指向的内存。</p>
<p>因为 Python 底层是用 C 实现的，所以列表的实现必然要借助 C 的数组。可 C 数组里面的元素的类型是一致的，但列表却可以存放任意的元素，因此从这个角度上讲，列表里面的元素就不可能是对象，因为不同的对象在底层对应的结构体是不同的，所以元素只能是指针。</p>
<p>可能有人又好奇了，不同对象的指针也是不同的啊，是的，但 C 指针是可以转化的。Python 底层将所有对象的指针，都转成了 PyObject 类型的指针，这样不就是同一种类型的指针了吗？关于这个 PyObject，它是我们后面要剖析的重中之重，贯穿了整个系列。不过目前只需要知道列表（还有其它容器）存储的元素、以及 Python 的变量，它们都是一个泛型指针 PyObject *。</p>
<pre><code class="language-Python">&gt;&gt;&gt; lst = [1, 2, 3]
&gt;&gt;&gt; id(lst)
140176818170432
&gt;&gt;&gt; lst.append(4)
&gt;&gt;&gt; lst.append(5)
&gt;&gt;&gt; lst
[1, 2, 3, 4, 5]
&gt;&gt;&gt; id(lst)
140176818170432
</code></pre>
<p>我们看到列表在添加元素的时候，前后地址并没有改变。列表在 C 中是通过 PyListObject 结构体实现的，我们在介绍列表的时候会细说。这个 PyListObject 内部除了一些基本信息之外，还维护了一个 PyObject 的二级指针，指向了 PyObject * 类型的数组的首元素。</p>
<p><img src="./images/11.png" alt="" /></p>
<p>显然图中的指针数组用来存储具体的对象的指针，每一个指针都指向了相应的对象（这里是整数对象）。</p>
<p>然后我们还可以看到一个现象，那就是列表在底层是分开存储的，因为 PyListObject 结构体实例并没有存储相应的指针数组，而是存储了一个二级指针。显然添加、删除、修改元素等操作，都是通过这个二级指针来间接操作指针数组。</p>
<p>因为一个对象一旦被创建（任何语言都是如此），那么它在内存中的大小就不可以变了。所以这就意味着那些可以容纳可变长度数据的可变对象，要在内部维护一个指针，指针指向一片内存区域，该区域存放具体的数据。如果空间不够了，那就申请一片更大的内存区域，然后将元素依次拷贝过去，再让指针指向新的内存区域。而列表的底层也是这么做的，其内部并没有直接存储具体的指针数组，而是存储了指向指针数组首元素的二级指针。</p>
<p><strong>那么问题来了，为什么要这么做？</strong></p>
<p>其实很好理解，遵循这样的规则可以使通过指针维护对象的工作变得非常简单。一旦允许对象的大小可在运行期改变，那么我们就要考虑如下场景。</p>
<p>在内存中有对象 A，并且其后面紧跟着对象 B。如果在运行的某个时候，A 的大小增大了，这就意味着必须将 A 整个移动到内存中的其他位置，否则 A 增大的部分会覆盖掉原本属于 B 的数据。但要将 A 移动到内存的其他位置，那么所有指向 A 的指针就必须立即得到更新。可想而知这样的工作是多么的繁琐，因此通过在可变对象的内部维护一个指针就变得简单多了。</p>
<h2 id="定长对象和变长对象"><a class="header" href="#定长对象和变长对象">定长对象和变长对象</a></h2>
<p>所谓<font color="blue">定长</font>和<font color="blue">变长</font>，取决于对象所占的内存大小是否固定，举个例子。</p>
<pre><code class="language-Python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.getsizeof(&quot;&quot;)
49
&gt;&gt;&gt; sys.getsizeof(&quot;hello&quot;)
54
&gt;&gt;&gt; sys.getsizeof(&quot;hello world&quot;)
60

&gt;&gt;&gt; sys.getsizeof(1.0)
24
&gt;&gt;&gt; sys.getsizeof(3.14)
24
&gt;&gt;&gt; sys.getsizeof((2 &lt;&lt; 30) + 3.14)
24
&gt;&gt;&gt; 
</code></pre>
<p>我们看到字符串的长度不同，所占的内存也不同，像这种内存大小不固定的对象，我们称之为<font color="blue">变长对象</font>；而浮点数所占的内存都是一样的，像这种内存大小固定的对象，我们称之为<font color="blue">定长对象</font>。</p>
<blockquote>
<p>至于 Python 如何计算对象所占的内存，我们在剖析具体对象的时候会说，因为这涉及到底层对应的结构体。</p>
</blockquote>
<p>所以变长对象的特点是：同一个类型的实例对象，如果值不同，那么占用的内存大小不同。像字符串、列表、元组、字典等，它们毫无疑问都是变长对象。值得一提的是，整数也是变长对象，因为 Python 整数的值在底层是通过数组维护的，后续介绍整数实现的时候再聊。</p>
<p>而定长对象的特点是：同一个类型的实例对象，不管值是多少，占用的内存大小始终是固定的，比如浮点数。因为 Python 的浮点数的值在 C 中是通过一个 double 来维护的。而 C 里面值的类型一旦确定，那么内存大小就不变了，所以 Python 浮点数的内存大小也是不变的。</p>
<p>但既然类型固定，内存大小固定，那么范围肯定是有限的。所以当浮点数不断增大，会牺牲精度来进行存储。</p>
<p><img src="./images/12.png" alt="" /></p>
<p>如果实在过大，则抛出 OverFlowError。</p>
<p><img src="./images/13.png" alt="" /></p>
<p>当然除了浮点数之外，布尔值、复数等也属于定长对象，它们占用的内存大小是固定的。</p>
<h2 id="小结-2"><a class="header" href="#小结-2">小结</a></h2>
<p>以上我们就分析了对象的种类，对象可以被分为可变对象和不可变对象，以及变长对象和定长对象。</p>
<ul>
<li>不可变对象：对象不支持本地修改；</li>
<li>可变对象：对象支持本地修改；</li>
<li>变长对象：对象维护的值不同，占用的内存大小也不同；</li>
<li>定长对象：占用的内存大小始终固定；</li>
</ul>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-1"><a class="header" href="#楔子-1">楔子</a></h2>
<p>在前面的文章中我们说到，面向对象理论中的类和对象这两个概念在 Python 内部都是通过对象实现的。类是一种对象，称为<font color="red">类型对象</font>，类实例化得到的也是对象，称为<font color="red">实例对象</font>。但是对象在 Python 的底层是如何实现的呢？Python 解释器是基于 C 语言编写的 ，但 C 并不是一个面向对象的语言，那么它是如何实现 Python 的面向对象的呢？</p>
<p>首先对于人的思维来说，对象是一个比较形象的概念，但对于计算机来说，对象却是一个抽象的概念。它并不能理解这是一个整数，那是一个字符串，计算机所知道的一切都是字节。通常的说法是：<font color="blue">对象是数据以及基于这些数据所能进行的操作的集合</font>。在计算机中，一个对象实际上就是一片被分配的内存空间，这些内存可能是连续的，也可能是离散的。</p>
<p>而 Python 的任何对象在 C 中都对应一个结构体实例，在 Python 中创建一个对象，等价于在 C 中创建一个结构体实例。所以 Python 的对象，其本质就是 C 的 malloc 函数为结构体实例在堆区申请的一块内存。</p>
<p>下面我们就来分析一下对象在 C 中是如何实现的。</p>
<h2 id="对象的地基pyobject"><a class="header" href="#对象的地基pyobject">对象的地基：PyObject</a></h2>
<p>Python 一切皆对象，而所有的对象都拥有一些共同的信息（也叫头部信息），这些信息位于 PyObject 中，它是 Python 对象机制的核心，下面来看看它的定义。</p>
<pre><code class="language-C">// Include/object.h

typedef struct _object {
    _PyObject_HEAD_EXTRA
    Py_ssize_t ob_refcnt;
    struct _typeobject *ob_type;
} PyObject;
</code></pre>
<p>首先解释一下结构体里面的 _PyObject_HEAD_EXTRA，这是一个宏，定义如下。</p>
<pre><code class="language-C">// Include/object.h

// 如果定义了宏 Py_TRACE_REFS
#ifdef Py_TRACE_REFS
// 那么 _PyObject_HEAD_EXTRA 会展开成如下两个字段
// 显然程序中创建的对象会组成一个双向链表
#define _PyObject_HEAD_EXTRA            \
    struct _object *_ob_next;           \
    struct _object *_ob_prev;
// 用于将 _ob_next 和 _ob_prev 初始化为空
#define _PyObject_EXTRA_INIT 0, 0,
// 否则说明没有定义宏 Py_TRACE_REFS
// 那么 _PyObject_HEAD_EXTRA 和 _PyObject_EXTRA_INIT 不会有任何作用
#else
#define _PyObject_HEAD_EXTRA
#define _PyObject_EXTRA_INIT
#endif
</code></pre>
<p>所以如果定义了宏 Py_TRACE_REFS，那么展开之后 PyObject 就是下面这样。</p>
<pre><code class="language-C">typedef struct _object {
    PyObject *_ob_next;
    PyObject *_ob_prev;
    Py_ssize_t ob_refcnt;
    struct _typeobject *ob_type;
} PyObject;
</code></pre>
<p>但 Py_TRACE_REFS 一般只在编译调试的时候会开启，我们从官网下载的都是 Release 版本，不包含这个宏，因此这里我们也不考虑它。所以 PyObject 最终就等价于下面这个样子：</p>
<pre><code class="language-C">typedef struct _object {
    Py_ssize_t ob_refcnt;
    struct _typeobject *ob_type;
} PyObject;
</code></pre>
<p>所以 PyObject 里面包含了两个字段，分别是 ob_refcnt 和 ob_type。</p>
<p>ob_refcnt 表示对象的引用计数，当对象被引用时，ob_refcnt 会自增 1；引用解除时，ob_refcnt 会自减 1。而当对象的引用计数为 0 时，则会被回收。</p>
<p>那么在哪些情况下，引用计数会加 1 呢？哪些情况下，引用计数会减 1 呢？</p>
<p><font color="green"><strong>引用计数加 1 的情况：</strong></font></p>
<ul>
<li>对象被创建：比如 name = &quot;古明地觉&quot;，此时对象就是 &quot;古明地觉&quot; 这个字符串，创建成功时它的引用计数为 1；</li>
<li>变量传递使得对象被新的变量引用：比如 name2 = name；</li>
<li>引用该对象的某个变量作为参数传递到一个函数或者类中：比如 func(name)；</li>
<li>引用该对象的某个变量作为元组、列表、集合等容器的元素：比如 lst = [name]；</li>
</ul>
<p><font color="green"><strong>引用计数减 1 的情况：</strong></font></p>
<ul>
<li>引用该对象的变量被显式地销毁：del name；</li>
<li>引用该对象的变量指向了别的对象：name = &quot;&quot;；</li>
<li>引用该对象的变量离开了它的作用域，比如函数的局部变量在函数执行完毕时会被删除；</li>
<li>引用该对象的变量所在的容器被销毁，或者变量从容器里面被删除；</li>
</ul>
<p>因为变量只是一个和对象绑定的符号，更接地气一点的说法就是，变量是个便利贴，贴在指定的对象上面。所以 <font color="red">del 变量</font> 并不是删除变量指向的对象，而是删除变量本身，可以理解为将对象身上的便利贴给撕掉了，其结果就是对象的引用计数减一。至于对象是否被删除（回收）则是解释器判断其引用计数是否为 0 决定的，为 0 就删，不为 0 就不删，就这么简单。</p>
<p>然后看一下字段 ob_refcnt 的类型，该类型为 Py_ssize_t，它是 ssize_t 的别名，在 64 位机器上等价于 int64。因此一个对象的引用计数不能超过 int64 所能表示的最大范围。但很明显，如果不费九牛二虎之力去写恶意代码，是不可能超过这个范围的。</p>
<p>说完了 ob_refcnt，再来看看 PyObject 的另一个字段 ob_type，相信你能猜到它的含义。对象是有类型的，类型对象描述实例对象的行为，而 ob_type 存储的便是对应的类型对象的指针，所以类型对象在底层是一个  <font color="blue">struct _typeobject</font> 结构体实例。另外 <font color="blue">struct _typeobject</font> 还有一个类型别名叫 <font color="blue">PyTypeObject</font>，关于类型对象，我们后续再聊。</p>
<p>以上就是 PyObject，它的定义非常简单，就一个引用计数和一个类型对象的指针。这两个字段的大小都是 8 字节，所以一个 PyObject 结构体实例的大小是 16 字节。由于 PyObject 是所有对象都具有的，换句话说就是所有对象对应的结构体都内嵌了 PyObject，因此你在 Python 里面看到的任何一个对象都有引用计数和类型这两个属性。</p>
<pre><code class="language-Python">&gt;&gt;&gt; num = 666  
&gt;&gt;&gt; sys.getrefcount(num)
2
&gt;&gt;&gt; num.__class__
&lt;class 'int'&gt;

&gt;&gt;&gt; sys.getrefcount(sys)
56
&gt;&gt;&gt; sys.__class__
&lt;class 'module'&gt;

&gt;&gt;&gt; sys.getrefcount(sys.path)
2
&gt;&gt;&gt; sys.path.__class__
&lt;class 'list'&gt;

&gt;&gt;&gt; def foo():  pass
... 
&gt;&gt;&gt; sys.getrefcount(foo)
2
&gt;&gt;&gt; foo.__class__
&lt;class 'function'&gt;
</code></pre>
<p>引用计数可以通过 sys.getrefcount 函数查看，类型可以通过 type(obj) 或者 obj.__class__ 查看。</p>
<h2 id="可变对象的地基pyvarobject"><a class="header" href="#可变对象的地基pyvarobject">可变对象的地基：PyVarObject</a></h2>
<p>PyObject 是所有对象的核心，它包含了所有对象都共有的信息，但是还有那么一个属性虽然不是每个对象都有，但至少有一大半的对象会有，能猜到是什么吗？</p>
<p>之前说过，对象根据所占的内存是否固定，可以分为定长对象和变长对象，而变长对象显然有一个长度的概念，比如字符串、列表、元组等等。即便是相同类型的实例对象，但是长度不同，所占的内存也是不同的。比如字符串内部有多少个字符，元组、列表内部有多少个元素，显然这里的<font color="red">多少</font>也是 Python 中很多对象的共有特征。虽然不像引用计数和类型那样是每个对象都必有的，但也是绝大部分对象所具有的。</p>
<p>所以针对变长对象，Python 底层也提供了一个结构体，因为 Python 里面很多都是变长对象。</p>
<pre><code class="language-C">// Include/object.h

typedef struct {
    PyObject ob_base;
    Py_ssize_t ob_size;
} PyVarObject;
</code></pre>
<p>我们看到 PyVarObject 实际上是 PyObject 的一个扩展，它在 PyObject 的基础上添加了一个 ob_size 字段，用于记录内部的元素个数。比如列表，列表的 ob_size 维护的就是列表的元素个数，插入一个元素，ob_size 会加 1，删除一个元素，ob_size 会减 1。</p>
<p>因此使用 len 函数获取列表的元素个数是一个时间复杂度为 O(1) 的操作，因为 ob_size 始终和内部的元素个数保持一致，所以会直接返回 ob_size。</p>
<p>所有的变长对象都拥有 PyVarObject，而所有的对象都拥有 PyObject，这就使得在 Python 中，对<font color="blue">对象</font>的引用变得非常统一。我们只需要一个 <font color="red">PyObject *</font> 就可以引用任意一个对象，而不需要管这个对象实际是一个什么样的对象。</p>
<p>所以 Python 变量、以及容器内部的元素，本质上都是一个 PyObject *。而在操作变量的时候，也要先根据 ob_type 字段判断指向的对象的类型，然后再寻找该对象具有的方法，这也是 Python 效率慢的原因之一。</p>
<p>由于 PyObject 和 PyVarObject 要经常使用，所以底层提供了两个宏，方便定义。</p>
<pre><code class="language-C">// Include/object.h

#define PyObject_HEAD    PyObject ob_base;
#define PyObject_VAR_HEAD    PyVarObject ob_base;
</code></pre>
<p>比如定长对象浮点数，在底层对应的结构体为 PyFloatObject，它只需在 PyObject 的基础上再加一个 double 即可。</p>
<pre><code class="language-c">typedef struct {
    // 等价于 PyObject ob_base;
    PyObject_HEAD
    double ob_fval;
} PyFloatObject;
</code></pre>
<p>再比如变长对象列表，在底层对应的结构体是 PyListObject，所以它需要在 PyVarObject 的基础上再加一个指向指针数组首元素的二级指针和一个容量。</p>
<pre><code class="language-C">typedef struct {
    // 等价于 PyVarObject ob_base;
    PyObject_VAR_HEAD
    PyObject **ob_item;
    Py_ssize_t allocated;
} PyListObject;
</code></pre>
<p>这上面的每一个字段都代表什么，我们之前提到过，当然这些内置的数据结构后续还会单独剖析。</p>
<p>对于 PyListObject，里面的 ob_item 就是指向指针数组首元素的二级指针，而 allocated 表示已经分配的容量，一旦添加元素的时候发现 ob_size 自增 1 之后会大于 allocated，那么解释器就知道数组已经满了（容量不够了）。于是会申请一个长度更大的指针数组，然后将旧数组内部的元素按照顺序逐个拷贝到新数组里面，并让 ob_item 指向新数组的首元素，这个过程就是列表的扩容，后续在剖析列表的时候还会细说。</p>
<p>所以我们看到列表在添加元素的时候，地址是不会改变的，即使容量不够了也没关系，直接让 ob_item 指向新的数组就好了，至于 PyListObject 对象（列表）本身的地址是不会变化的。</p>
<h2 id="小结-3"><a class="header" href="#小结-3">小结</a></h2>
<p>PyObject 是 Python 对象的核心，因为 Python 对象在 C 的层面就是一个结构体，并且所有的结构体都嵌套了 PyObject 结构体。而 PyObject 内部有引用计数和类型这两个字段，因此我们可以肯定的说 Python 的任何一个对象都有引用计数和类型这两个属性。</p>
<p>另外大部分对象都有长度的概念，所以又引入了 PyVarObject，它在 PyObject 的基础上添加了一个 ob_size 字段，用于描述对象的长度。比如字符串内部的 ob_size 维护的是字符串的字符个数，元组、列表、集合等等，其内部的 ob_size 维护的是存储的元素个数，所以使用 len 函数获取对象长度是一个 O(1) 的操作。 </p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-2"><a class="header" href="#楔子-2">楔子</a></h2>
<p>通过 PyObject 和 PyVarObject，我们看到了所有对象的公共信息以及变长对象的公共信息。任何一个对象，不管它是什么类型，内部必有引用计数（ob_refcnt）和类型指针（ob_type）。任何一个变长对象，不管它是什么类型，内部除了引用计数和类型指针之外，还有一个表示元素个数的 ob_size。</p>
<p>显然目前没有什么问题，一切都是符合预期的，但是当我们顺着时间轴回溯的话，就会发现端倪。比如：</p>
<ul>
<li>当在内存中创建对象、分配空间的时候，解释器要给对象分配多大的空间？显然不能随便分配，那么对象的内存信息在什么地方？</li>
<li>对象是可以执行相关操作的，解释器怎么知道某个对象支持哪些操作呢？再比如一个整数可以和一个整数相乘，一个列表也可以和一个整数相乘，即使是相同的操作，但不同类型的对象执行也会有不同的效果，那么此时解释器又是如何进行区分的？</li>
</ul>
<p>想都不用想，这些信息肯定都在对象的类型对象中。因为占用的空间大小实际上是对象的一个元信息，这样的元信息和其所属类型是密切相关的，因此它一定会出现在与之对应的类型对象当中。至于支持的操作就更不用说了，我们平时自定义类的时候，功能函数都写在什么地方，显然都是写在类里面，因此一个对象支持的操作也定义在类型对象当中。</p>
<p>而将<font color="blue">对象</font>和<font color="blue">它的类型对象</font>关联起来的，毫无疑问正是该对象内部的 PyObject 的 ob_type 字段，也就是类型指针。我们通过对象的 ob_type 字段即可获取类型对象的指针，然后通过指针获取存储在类型对象中的某些元信息。</p>
<p>下面我们来看看类型对象在底层是怎么定义的。</p>
<h2 id="解密-pytypeobject"><a class="header" href="#解密-pytypeobject">解密 PyTypeObject</a></h2>
<p>PyObject 的 ob_type 字段的类型是 PyTypeObject *，所以类型对象由 PyTypeObject 结构体负责实现，看一看它长什么样子。</p>
<pre><code class="language-C">// Include/cpython/object.h

typedef struct _typeobject {
    PyObject_VAR_HEAD
    const char *tp_name;
    Py_ssize_t tp_basicsize, tp_itemsize;

    destructor tp_dealloc;
    Py_ssize_t tp_vectorcall_offset;
    getattrfunc tp_getattr;
    setattrfunc tp_setattr;
    PyAsyncMethods *tp_as_async;
    reprfunc tp_repr;

    PyNumberMethods *tp_as_number;
    PySequenceMethods *tp_as_sequence;
    PyMappingMethods *tp_as_mapping;

    hashfunc tp_hash;
    ternaryfunc tp_call;
    reprfunc tp_str;
    getattrofunc tp_getattro;
    setattrofunc tp_setattro;

    PyBufferProcs *tp_as_buffer;

    unsigned long tp_flags;
    const char *tp_doc;
    traverseproc tp_traverse;
    inquiry tp_clear;
    richcmpfunc tp_richcompare;

    Py_ssize_t tp_weaklistoffset;

    getiterfunc tp_iter;
    iternextfunc tp_iternext;

    struct PyMethodDef *tp_methods;
    struct PyMemberDef *tp_members;
    struct PyGetSetDef *tp_getset;
    
    struct _typeobject *tp_base;
    PyObject *tp_dict;
    descrgetfunc tp_descr_get;
    descrsetfunc tp_descr_set;
    Py_ssize_t tp_dictoffset;
    initproc tp_init;
    allocfunc tp_alloc;
    newfunc tp_new;
    freefunc tp_free;
    inquiry tp_is_gc;
    PyObject *tp_bases;
    PyObject *tp_mro;
    PyObject *tp_cache;
    PyObject *tp_subclasses;
    PyObject *tp_weaklist;
    destructor tp_del;

    unsigned int tp_version_tag;

    destructor tp_finalize;
    vectorcallfunc tp_vectorcall;

    Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);

#ifdef COUNT_ALLOCS
    Py_ssize_t tp_allocs;
    Py_ssize_t tp_frees;
    Py_ssize_t tp_maxalloc;
    struct _typeobject *tp_prev;
    struct _typeobject *tp_next;
#endif
} PyTypeObject;
</code></pre>
<p>类型对象在底层对应的是 struct _typeobject，或者说 PyTypeObject，它保存了实例对象的元信息。</p>
<p>所以不难发现，无论是 int、str、dict 等内置类型，还是使用 class 关键字自定义的类型，它们在 C 的层面都是由 PyTypeObject 这个结构体实例化得到的，只不过内部字段的值不同，PyTypeObject 结构体在实例化之后得到的类型对象也不同。</p>
<p>然后我们来看看 PyTypeObject 里面的字段都代表啥含义，字段还是比较多的，我们逐一介绍。</p>
<p><font color="darkblue"><strong>PyObject_VAR_HEAD</strong></font></p>
<p>宏，会被替换为 PyVarObject，所以类型对象是一个变长对象。因此类型对象也有引用计数和类型，这与我们前面分析的是一致的。</p>
<p><font color="darkblue"><strong>tp_name</strong></font></p>
<p>对应 Python 中类型对象的 __name__ 属性，即类型对象的名称。</p>
<pre><code class="language-python"># 类型对象在底层对应的是 PyTypeObject 结构体实例
# 它的 tp_name 字段表示类型对象的名称
print(int.__name__)  # int
# 动态创建一个类
A = type(&quot;我是 A&quot;, (object,), {})
print(A.__name__)  # 我是 A
</code></pre>
<p>所以任何一个类型对象都有 __name__ 属性，也就是都有名称。</p>
<p><font color="darkblue"><strong>tp_basicsize，tp_itemsize</strong></font></p>
<ul>
<li>tp_basicsize：表示创建实例对象所需的基本内存大小；</li>
<li>tp_itemsize：如果对象是变长对象，并且元素保存在对应的结构体内部，比如元组，那么 tp_itemsize 表示内部每个元素的内存大小。如果是定长对象，或者虽然是变长对象，但结构体本身不保存数据，而是只保存了一个指针，那么 tp_itemsize 为 0；</li>
</ul>
<p><font color="darkblue"><strong>tp_dealloc</strong></font></p>
<p>析构函数，对应 Python 中类型对象的 __del__，会在实例对象被销毁时执行。</p>
<p><font color="darkblue"><strong>tp_vectorcall_offset</strong></font></p>
<p>如果想调用一个对象，那么它的类型对象要定义 __call__ 函数。</p>
<pre><code class="language-Python">class A:

    def __call__(self, *args, **kwargs):
        return &quot;被调用了&quot;

a = A()
# 如果调用 a，那么 type(a) 要定义 __call__ 函数
print(a())
&quot;&quot;&quot;
被调用了
&quot;&quot;&quot;
# 底层会转成如下逻辑
print(A.__call__(a))
&quot;&quot;&quot;
被调用了
&quot;&quot;&quot;


# 函数也是一个实例对象，它能被调用
# 说明 type(函数) 也一定实现了 __call__
def some_func(name, age):
    return f&quot;name: {name}, age: {age}&quot;
# 函数的类型是 function
print(type(some_func))
&quot;&quot;&quot;
&lt;class 'function'&gt;
&quot;&quot;&quot;
# 调用函数
print(some_func(&quot;古明地觉&quot;, 17))
&quot;&quot;&quot;
name: 古明地觉, age: 17
&quot;&quot;&quot;
# 也可以这么做
print(type(some_func).__call__(some_func, &quot;古明地觉&quot;, 17))
&quot;&quot;&quot;
name: 古明地觉, age: 17
&quot;&quot;&quot;
</code></pre>
<p>以上就是对象最通用的调用逻辑，但通用也意味着平庸，这种调用方式的性能是不高的。自定义类的实例对象还好，因为需要支持调用的场景不多，而函数则不同，尽管它也是实例对象，但它生下来就是要被调用的。如果函数调用也走通用逻辑的话，那么效率不高，因此 Python 从 3.8 开始引入了 vectorcall 协议，即矢量调用协议，用于优化和加速函数调用。相比常规调用，矢量调用具备如下优势：</p>
<ul>
<li>避免创建临时元组来传递参数</li>
<li>减少参数打包/解包的开销</li>
<li>支持关键字参数的快速处理</li>
</ul>
<p>总之当一个对象被调用时，如果它支持 vectorcall 协议，那么会通过 tp_vectorcall_offset 找到实现矢量调用的函数指针。</p>
<p>注意：vectorcall 函数指针定义在实例对象中，而 tp_vectorcall_offset 字段维护了 vectorcall 函数指针在实例对象中的偏移量，该偏移量用于定位到一个特定的函数指针，这个函数指针符合 vectorcall 协议。</p>
<p>如果类型对象的 tp_vectorcall_offset 为 0，表示其实例对象不支持矢量调用，因此会退化为常规调用，即通过类型对象的 __call__ 进行调用。</p>
<p><font color="darkblue"><strong>tp_getattr，tp_setattr</strong></font></p>
<p>对应 Python 中类型对象的 __getattr__ 和 __setattr__，用于操作实例对象的属性。但这两个字段已经不推荐使用了，因为它要求在操作属性时，属性名必须为 C 字符串，以及不支持通过描述符协议处理属性。</p>
<p>所以这两个字段主要用于兼容旧版本，现在应该使用 tp_getattro 和 tp_setattro。</p>
<p><font color="darkblue"><strong>tp_as_number、tp_as_sequence、tp_as_mapping、tp_as_async</strong></font></p>
<p>tp_as_number：实例对象为数值时，所支持的操作。这是一个结构体指针，指向的结构体中的每一个字段都是一个函数指针，指向的函数就是对象可以执行的操作，比如四则运算、左移、右移、取模等等。</p>
<p>tp_as_sequence：实例对象为序列时，所支持的操作，也是一个结构体指针。</p>
<p>tp_as_mapping：实例对象为映射时，所支持的操作，也是一个结构体指针。</p>
<p>tp_as_async：实例对象为协程时，所支持的操作，也是一个结构体指针。</p>
<p><font color="darkblue"><strong>tp_repr、tp_str</strong></font></p>
<p>对应 Python 中类型对象的 __repr__ 和 __str__，用于控制实例对象的打印输出。</p>
<p><font color="darkblue"><strong>tp_hash</strong></font></p>
<p>对应 Python 中类型对象的 __hash__，用于定义实例对象的哈希值。</p>
<p><font color="darkblue"><strong>tp_call</strong></font></p>
<p>对应 Python 中类型对象的 __call__，用于控制实例对象的调用行为。当然这属于常规调用，而对象不仅可以支持常规调用，还可以支持上面提到的矢量调用（通过减少参数传递的开销，提升调用性能）。</p>
<p>但要注意的是，不管使用哪种调用协议，对象调用的行为必须都是相同的。因此一个对象如果支持矢量调用，那么它也必须支持常规调用，换句话说对象如果实现了 vectorcall，那么它的类型对象也必须实现 tp_call。</p>
<blockquote>
<p>如果你在实现 vectorcall 之后发现它比 tp_call 还慢，那么你就不应该实现 vectorcall，因为实现 vectorcall 是有条件的，当条件不满足时性能反而会变差。</p>
</blockquote>
<p><font color="darkblue"><strong>tp_getattro，tp_setattro</strong></font></p>
<p>对应 Python 中类型对象的 __getattr__ 和 __setattr__。</p>
<p><font color="darkblue"><strong>tp_as_buffer</strong></font></p>
<p>指向 PyBufferProcs 类型的结构体，用于共享内存。通过暴露出一个缓冲区，可以和其它对象共享同一份数据，因此当类型对象实现了 tp_as_buffer，我们也说其实例对象实现了缓冲区协议，举个例子。</p>
<pre><code class="language-python">import numpy as np

buf = bytearray(b&quot;abc&quot;)
# 和 buf 共享内存
arr = np.frombuffer(buf, dtype=&quot;uint8&quot;)
print(arr)  # [97 98 99]
# 修改 buf
buf[0] = 255
# 会发现 arr 也改变了，因为它和 buf 共用一块内存
print(arr)  # [255  98  99]
</code></pre>
<p>所以 tp_as_buffer 主要用于那些自身包含大量数据，且需要允许其它对象直接访问的类型。通过实现缓冲区协议，其它对象可以直接共享数据，而无需事先拷贝，这在处理大型数据或进行高性能计算时非常有用。</p>
<p>关于缓冲区协议，后续还会详细介绍。</p>
<p><font color="darkblue"><strong>tp_flags</strong></font></p>
<p>对应 Python 中类型对象的 __flags__，负责提供类型对象本身的附加信息，通过和指定的一系列标志位进行按位与运算，即可判断该类型是否具有某个特征。</p>
<p>那么标志位都有哪些呢？我们介绍几个常见的。</p>
<pre><code class="language-C">// Include/object.h

// 类型对象的内存是否是动态分配的
// 像内置的类型对象属于静态类，它们不是动态分配的
#define Py_TPFLAGS_HEAPTYPE (1UL &lt;&lt; 9)
// 类型对象是否允许被继承
#define Py_TPFLAGS_BASETYPE (1UL &lt;&lt; 10)
// 类型对象的实例对象是否参与垃圾回收
#define Py_TPFLAGS_HAVE_GC (1UL &lt;&lt; 14)
// 类型对象是否是抽象基类
#define Py_TPFLAGS_IS_ABSTRACT (1UL &lt;&lt; 20)
</code></pre>
<p>我们通过 Python 来演示一下。</p>
<pre><code class="language-python"># 是否是自定义的动态类
Py_TPFLAGS_HEAPTYPE = 1 &lt;&lt; 9
class A:
    pass
# 如果与运算的结果为真，则表示是动态类，否则不是
print(A.__flags__ &amp; Py_TPFLAGS_HEAPTYPE)
&quot;&quot;&quot;
512
&quot;&quot;&quot;
print(int.__flags__ &amp; Py_TPFLAGS_HEAPTYPE)
&quot;&quot;&quot;
0
&quot;&quot;&quot;


# 类型对象是否允许被继承
Py_TPFLAGS_BASETYPE = 1 &lt;&lt; 10
# object 显然允许被继承，因此与运算的结果为真
print(object.__flags__ &amp; Py_TPFLAGS_BASETYPE)
&quot;&quot;&quot;
1024
&quot;&quot;&quot;
# 但 memoryview 就不允许被继承
try:
    class B(memoryview):
        pass
except TypeError as e:
    print(e)
    &quot;&quot;&quot;
    type 'memoryview' is not an acceptable base type
    &quot;&quot;&quot;
print(memoryview.__flags__ &amp; Py_TPFLAGS_BASETYPE)
&quot;&quot;&quot;
0
&quot;&quot;&quot;


# 类型对象的实例对象是否参与垃圾回收
Py_TPFLAGS_HAVE_GC = 1 &lt;&lt; 14
# int 的实例对象（整数）不会产生循环引用，所以不会参与垃圾回收
print(int.__flags__ &amp; Py_TPFLAGS_HAVE_GC)
&quot;&quot;&quot;
0
&quot;&quot;&quot;
# 但列表是会参与垃圾回收的
print(list.__flags__ &amp; Py_TPFLAGS_HAVE_GC)
&quot;&quot;&quot;
16384
&quot;&quot;&quot;


# 类型对象是否是抽象基类
Py_TPFLAGS_IS_ABSTRACT = 1 &lt;&lt; 20
from abc import ABCMeta, abstractmethod
# 显然 C 不是抽象基类，而 D 是
class C:
    pass
class D(metaclass=ABCMeta):
    @abstractmethod
    def foo(self):
        pass
print(C.__flags__ &amp; Py_TPFLAGS_IS_ABSTRACT)
&quot;&quot;&quot;
0
&quot;&quot;&quot;
print(D.__flags__ &amp; Py_TPFLAGS_IS_ABSTRACT)
&quot;&quot;&quot;
1048576
&quot;&quot;&quot;
</code></pre>
<p>所以这就是 tp_flags 的作用，它负责描述一个类型对象都具有哪些额外特征。</p>
<p><font color="darkblue"><strong>tp_doc</strong></font></p>
<p>对应 Python 中类型对象的 __doc__。</p>
<pre><code class="language-Python">class People:
    &quot;&quot;&quot;以前我没得选&quot;&quot;&quot;

print(People.__doc__)
&quot;&quot;&quot;
以前我没得选
&quot;&quot;&quot;
</code></pre>
<p>这个比较简单。</p>
<p><font color="darkblue"><strong>tp_traverse，tp_clear</strong></font></p>
<p>这两个字段是一对，负责参与垃圾回收机制。</p>
<ul>
<li>tp_traverse：用于标记阶段，通过遍历实例对象所引用的其它对象，确定对象之间的引用关系，帮助垃圾回收器识别出所有活跃的对象和出现循环引用的对象。</li>
<li>tp_clear：用于清除阶段，负责减少出现循环引用的对象的引用计数。</li>
</ul>
<p><font color="darkblue"><strong>tp_richcompare</strong></font></p>
<p>负责实现对象的比较逻辑，包含 &gt;、&gt;=、&lt;、&lt;=、!=、==。</p>
<p><font color="darkblue"><strong>tp_weaklistoffset</strong></font></p>
<p>实例对象的弱引用列表在实例对象中的偏移量，如果 tp_weaklistoffset 为 0，则表示实例对象不支持弱引用。</p>
<p><font color="darkblue"><strong>tp_iter、tp_iternext</strong></font></p>
<p>对应 Python 中类型对象的 __iter__ 和 __next__。</p>
<p><font color="darkblue"><strong>tp_methods</strong></font></p>
<p>负责保存类型对象里的成员函数，我们以 list 为例。</p>
<p><img src="./images/14.png" alt="" /></p>
<p><font color="darkblue"><strong>tp_members</strong></font></p>
<p>负责指定可以绑定在实例对象上的属性，我们使用 class 关键字定义动态类的时候，会在 __init__ 函数中给实例对象绑定属性，而对于底层 C 来说，需要通过 tp_members 字段。 </p>
<p>以 slice 为例，它负责创建一个切片。</p>
<pre><code class="language-python">lst = list(range(10))
print(lst[1: 7: 2])  # [1, 3, 5]
# 等价于
print(lst[slice(1, 7, 2)])  # [1, 3, 5]
</code></pre>
<p>slice 是一个底层实现好的静态类，接收 start、end、step 三个参数，所以它底层的 tp_members 就是这么定义的。</p>
<p><img src="./images/15.png" alt="" /></p>
<p>对于静态类而言，可以给 self 绑定哪些属性、以及类型是什么，都已经事先在 tp_members 里面写死了，后续不可以新增或删除属性。</p>
<pre><code class="language-python">s = slice(1, 7, 2)
# 静态类的实例对象不可以新增或删除属性
try:
    s.xx = &quot;xx&quot;
except AttributeError as e:
    print(e)
    &quot;&quot;&quot;
    'slice' object has no attribute 'xx'
    &quot;&quot;&quot;

# 至于能否修改，则看定义属性时是否要求属性是 READONLY
# 对于 slice 来说，它的三个属性都是 READONLY，所以不能修改
try:
    s.start = 2
except AttributeError as e:
    print(e)
    &quot;&quot;&quot;
    readonly attribute
    &quot;&quot;&quot;
</code></pre>
<p>但使用 class 自定义的动态类而言，新增、删除、修改属性都是可以的，至于里面的更多细节，后续在介绍类的时候会详细剖析。</p>
<p><font color="darkblue"><strong>tp_getset</strong></font></p>
<p>指向一个 PyGetSetDef 结构体数组，里面的每个结构体都定义了一个属性的名称、获取该属性的函数、设置该属性的函数、属性的文档字符串。</p>
<p><img src="./images/16.png" alt="" /></p>
<ul>
<li>name：属性的名称，Python 代码可以通过该名称来访问属性。</li>
<li>get：属性的 getter 函数，如果设置了这个函数，Python 代码读取属性时会调用它。</li>
<li>set：属性的 setter 函数，如果设置了这个函数，Python 代码修改属性时会调用它。</li>
<li>doc：属性的文档字符串，为属性提供描述信息。</li>
<li>closure：一个 void * 指针，用于传递额外的信息给 getter 和 setter，不常用。</li>
</ul>
<p>所以我们发现 tp_getset 的作用不就类似于 @property 装饰器吗？tp_getset 数组里面的每个结构体负责实现一个 property 属性。</p>
<p><font color="darkblue"><strong>tp_base</strong></font></p>
<p>对应 Python 中类型对象的 __base__，返回继承的第一个父类。</p>
<p><font color="darkblue"><strong>tp_dict</strong></font></p>
<p>对应 Python 中类型对象的 __dict__，即属性字典。</p>
<p><font color="darkblue"><strong>tp_descr_get、tp_descr_set</strong></font></p>
<p>对应 Python 中类型对象的 __get__ 和 __set__，用于实现描述符。</p>
<p><font color="darkblue"><strong>tp_dictoffset</strong></font></p>
<p>注意它和 tp_dict 的区别，tp_dict 表示类型对象的属性字典，而 tp_dictoffset 表示实例对象的属性字典在实例对象中的偏移量。</p>
<p><font color="darkblue"><strong>tp_init</strong></font></p>
<p>对应 Python 中类型对象的 __init__，用于实例对象属性的初始化。</p>
<p><font color="darkblue"><strong>tp_alloc</strong></font></p>
<p>负责为实例对象申请内存，申请多大呢？取决于 tb_basicsize 和 tp_itemsize。</p>
<p><font color="darkblue"><strong>tp_new</strong></font></p>
<p>对应 Python 中类型对象的 __new__，即构造函数，在 tp_new 内部会调用 tp_alloc 为实例对象申请内存。</p>
<p><font color="darkblue"><strong>tp_free</strong></font></p>
<p>内存释放函数，负责释放实例对象所占的内存，注意它和 tp_dealloc 的区别与联系。tp_dealloc 表示析构函数，当对象的引用计数降到零的时候执行，内部会负责如下工作。</p>
<ul>
<li>减少引用的其它对象的引用计数；</li>
<li>释放对象拥有的资源，比如文件句柄或网络连接；</li>
<li>调用内存释放函数来释放对象本身占用的内存，这一步由 tp_free 来完成。</li>
</ul>
<p>所以要注意这几个字段之间的区别，我们再总结一下。</p>
<p><img src="./images/17.png" alt="" /></p>
<p><font color="darkblue"><strong>tp_is_gc</strong></font></p>
<p>指示该类型对象的实例对象是否参与垃圾回收。</p>
<pre><code class="language-C">// Objects/typeobject.c
unsigned long
PyType_GetFlags(PyTypeObject *type)
{
    return type-&gt;tp_flags;
}

// Include/object.h
#define PyType_HasFeature(t,f)  ((PyType_GetFlags(t) &amp; (f)) != 0)

// Include/objimpl.h
// 显然只需判断 tp_flags &amp; Py_TPFLAGS_HAVE_GC 是否不等于 0 即可
#define PyType_IS_GC(t) PyType_HasFeature((t), Py_TPFLAGS_HAVE_GC)
</code></pre>
<p>如果参与垃圾回收，那么 <font color="blue">tp_flags &amp; Py_TPFLAGS_HAVE_GC</font> 的结果不等于 0。</p>
<p><font color="darkblue"><strong>tp_bases</strong></font></p>
<p>对应 Python 中类型对象的 __bases__，返回一个元组，里面包含直接继承的所有父类。</p>
<p><font color="darkblue"><strong>tp_mro</strong></font></p>
<p>对应 Python 中类型对象的 __mro__，返回一个元组，里面包含自身以及直接继承和间接继承的所有父类，直到 object。</p>
<p>注意：返回的元组中的类是有顺序关系的，它基于 C3 线性算法生成，定义了方法解析的顺序。当 Python 需要查找方法或属性时，将按照此顺序进行搜索。</p>
<p><font color="darkblue"><strong>tp_cache</strong></font></p>
<p>该字段已废弃，这里不做介绍。</p>
<p><font color="darkblue"><strong>tp_subclasses</strong></font></p>
<p>等价于 Python 中类型对象的 __subclasses__，会返回继承该类的所有子类。</p>
<pre><code class="language-python">class A:
    pass

class B(A):
    pass

class C(B):
    pass

print(A.__subclasses__())
&quot;&quot;&quot;
[&lt;class '__main__.B'&gt;]
&quot;&quot;&quot;
</code></pre>
<p>但是只返回直接继承的子类，间接继承的不返回，比如这里只返回了 B，而 C 没有返回。</p>
<p><font color="darkblue"><strong>tp_weaklist</strong></font></p>
<p>类型对象的弱引用列表，注意它和前面提到的 tp_weaklistoffset 的区别。tp_weaklist 表示类型对象的弱引用列表，tp_weaklistoffset 表示实例对象的弱引用列表在实例对象中的偏移量。</p>
<p><font color="darkblue"><strong>tp_del</strong></font></p>
<p>和 tp_dealloc 作用相同，但 tp_del 主要是兼容以前的旧版本，现在直接使用 tp_dealloc 即可。</p>
<p><font color="darkblue"><strong>tp_version_tag</strong></font></p>
<p>用于标记类型对象的版本，每当类型的定义发生变化时（例如添加、删除或修改成员函数），版本标签就会更新。解释器会使用这个版本标签来确定方法缓存是否有效，从而避免每次调用方法时都重新解析和查找。</p>
<p><font color="darkblue"><strong>tp_finalize</strong></font></p>
<p>负责在对象被销毁之前执行相应的清理操作，确保资源得到妥善处理，它的调用时机在对象的引用计数达到零之后、tp_dealloc（析构函数）被调用之前。</p>
<p>该字段不常用，一般只出现在生成器和协程当中。然后 tp_dealloc、tp_del、tp_finalize 三个字段的类型是一致的，都是 destructor 类型，那么它们三者有什么区别呢？</p>
<ul>
<li>tp_dealloc：在所有的类型对象中都需要指定，因为它是管理实例对象生命周期的关键，它负责减少引用的其它对象的引用计数，以及调用 tp_free 释放当前对象占用的内存，当然也可以执行必要的清理操作。 </li>
<li>tp_finalize：负责在对象的生命周期结束前执行相关清理操作，一般只用于生成器和协程当中，此时会和 tp_dealloc 搭配使用。</li>
<li>tp_del：除非是兼容遗留代码，否则应避免使用 tp_del，而是依赖于更现代的垃圾回收和清理机制，即使用 tp_dealloc。</li>
</ul>
<p><font color="darkblue"><strong>tp_vectorcall</strong></font></p>
<p>前面说了，实例对象在调用时，可以走类型对象的 tp_call，但这样效率不高。为此 Python 引入了矢量调用，实现矢量调用的函数指针定义在实例对象内部，偏移量则由类型对象的 tp_vectorcall_offset 字段维护。</p>
<p>如果实例对象支持矢量调用，那么会通过类型对象的 tp_vectorcall_offset 定位到对应的 vectorcall 函数指针，进行调用。否则执行类型对象的 tp_call。</p>
<p>那么问题来了，既然实例对象可以支持矢量调用，那么类型对象当然也可以支持。而类型对象的矢量调用函数，便由 tp_vectorcall 字段指定。</p>
<p>所以 tp_vectorcall 和 tp_vectorcall_offset 之间的关系，就类似于 tp_dict 和 tp_dictoffset 之间的关系。</p>
<ul>
<li>tp_dict 表示类型对象自身的属性字典，tp_dictoffset 表示实例对象的属性字典相对于实例对象首地址的偏移量。</li>
<li>tp_vectorcall 表示类型对象自身的矢量调用函数，tp_vectorcall_offset 表示实例对象的矢量调用函数相对于实例对象首地址的偏移量。</li>
<li>tp_weaklist 表示类型对象自身的弱引用列表，tp_weaklistoffset 表示实例对象的弱引用列表相对于实例对象首地址的偏移量。</li>
</ul>
<blockquote>
<p>offset 机制允许实例对象拥有更加弹性的内存布局。</p>
</blockquote>
<p>另外如果类型对象的 tp_vectorcall 字段为空，则表示类型对象不支持矢量调用，那么它在调用时会走元类的 tp_call。所以我们说 class 具有二象性，而这种平行的设计使得 Python 能够统一处理类型对象和实例对象的属性访问和调用行为。</p>
<p>以上就是 PyTypeObject 的各个字段的含义。</p>
<h2 id="一些常见的类型对象"><a class="header" href="#一些常见的类型对象">一些常见的类型对象</a></h2>
<p>下面来介绍一些常见的类型在底层的定义。</p>
<p><img src="./images/18.png" alt="" /></p>
<p>Python 底层的 C API 和对象的命名都遵循统一的标准，比如类型对象均以 <font color="blue">Py***_Type</font> 的形式命名，当然啦，它们都是 PyTypeObject 结构体实例。所以我们发现，Python 里的类在底层是以全局变量的形式静态定义好的。</p>
<p><img src="./images/19.png" alt="" /></p>
<p>所以实例对象可以有很多个，但对应的类型对象则是唯一的，在底层直接以全局变量的形式静态定义好了。比如列表的类型是 list，列表可以有很多个，但 list 类型对象则全局唯一。</p>
<pre><code class="language-python">data1 = [1, 2, 3]
data2 = [4, 5, 6]
print(
    data1.__class__ is data2.__class__ is list
)  # True
</code></pre>
<p>如果站在 C 的角度来理解的话：</p>
<p><img src="./images/20.png" alt="" /></p>
<p>data1 和 data2 变量均指向了列表，列表在底层对应 PyListObject 结构体实例，里面字段的含义之前说过。但需要注意的是，指针数组里面保存的是对象的指针，而不是对象。不过为了方便，图中就用对象代替了。</p>
<p>然后列表的类型是 list，在底层对应 PyList_Type，它是 PyTypeObject 结构体实例，保存了列表的元信息（比如内存分配信息、支持的相关操作等）。</p>
<p>而将这两者关联起来的便是 ob_type，它位于 PyObject 中，是所有对象都具有的。因为变量只是一个 PyObject * 指针，那么解释器要如何得知变量指向的对象的类型呢？答案便是通过 ob_type 字段。</p>
<h2 id="小结-4"><a class="header" href="#小结-4">小结</a></h2>
<p>不同类型的实例对象，在底层由不同的结构体实现，比如整数对应 PyLongObject 实例、浮点数对应 PyFloatObject 实例、列表对应 PyListObject 实例等等。</p>
<p>但所有的类型对象，在底层由同一个结构体实现，它们都是 PyTypeObject 实例。而 PyTypeObject 结构体在实例化时，内部字段接收的值不同，那么生成的类型对象也不同，可以是 PyLong_Type、PyFloat_Type、PyList_Type 等等。并且每个类型对象都是唯一的，比如在程序中可以创建很多个<font color="blue">列表（PyListObject 实例）</font>，但类型对象 <font color="blue">&lt;class 'list'&gt;（PyList_Type）</font>只会存在一个。</p>
<p>因为类型对象都是静态定义在源码中的，并以全局变量的形式存在。而将实例对象和类型对象关联起来的，则是实例对象的 ob_type 字段，在 Python 里面可以通过调用 type 或者获取 __class__ 属性查看。</p>
<p>关于类型对象的更多内容，后续会继续介绍。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-3"><a class="header" href="#楔子-3">楔子</a></h2>
<p>type 和 object 两者的关系估计会让很多人感到困惑，我们说 type 站在<font color="blue">类型金字塔</font>的顶端，任何对象按照类型追根溯源，最终得到的都是 type。而 object 站在<font color="blue">继承金字塔</font>的顶端，任何类型对象按照继承关系追根溯源，最终得到的都是 object。</p>
<p>因此我们可以得出以下结论：</p>
<ul>
<li>type 的父类是 object</li>
<li>object 的类型是 type</li>
</ul>
<p>验证一下：</p>
<pre><code class="language-python">print(type.__base__)  # &lt;class 'object'&gt;
print(object.__class__)  # &lt;class 'type'&gt;
</code></pre>
<p>打印结果说明结论正确，但这就奇怪了，type 的父类是 object，而 object 的类型又是 type，那么问题来了，是先有 type 还是先有 object 呢？带着这些疑问，开始下面的内容。</p>
<h2 id="类是由谁创建的"><a class="header" href="#类是由谁创建的">类是由谁创建的</a></h2>
<p>首先必须要澄清一个事实，类对象的类型是 type，这句话是没有问题的。但如果说类对象都是由 type 创建的，就有些争议了。因为 type 能够创建的是自定义的类，而内置的类在底层是预先定义好的。</p>
<pre><code class="language-python"># int、tuple、dict 等内置类型
# 在底层是预先定义好的，以全局变量的形式存在
# 我们直接就可以拿来用
print(int)  # &lt;class 'int'&gt;
print(tuple)  # &lt;class 'tuple'&gt;

# 但对于自定义的类，显然就需要在运行时动态创建了
# 而创建这一过程，就交给 type 来做
class Girl:
    pass
</code></pre>
<p>然后 type 也只能对自定义类进行属性上的增删改，内置的类则不行。</p>
<pre><code class="language-Python">class Girl:
    pass

# 给类对象增加一个成员函数
type.__setattr__(
    Girl,
    &quot;info&quot;,
    lambda self: &quot;name: 古明地觉, age: 17&quot;
)
# 实例化之后就可以调用了
print(Girl().info())  # name: 古明地觉, age: 17

# 但内置的类对象，type 是无法修改的
try:
    type.__setattr__(int, &quot;a&quot;, &quot;b&quot;)
except TypeError as e:
    print(e)
&quot;&quot;&quot;
can't set attributes of built-in/extension type 'int'
&quot;&quot;&quot;
</code></pre>
<p>上一篇文章中我们说了，Python 所有的类型对象（包括 type）都是由 PyTypeObject 结构体实例化得到的，只不过结构体字段的值不同，得到的类也不同。并且内置的类型对象在底层是预定义好的，它们在解释器看来是同级别的，不存在谁创建谁。</p>
<p>而每一个对象都有引用计数和类型，然后解释器将这些类对象的类型都设置成了 type，我们举例说明。不过在此之前，需要先说一个宏。</p>
<pre><code class="language-C">// Include/object.h

// _PyObject_EXTRA_INIT 可以忽略掉
// 我们看到这个宏是用来初始化引用计数和类型的
#define PyObject_HEAD_INIT(type)        \
    { _PyObject_EXTRA_INIT              \
    1, type },

// 负责初始化引用计数、类型和 ob_size
#define PyVarObject_HEAD_INIT(type, size)       \
    { PyObject_HEAD_INIT(type) size },
</code></pre>
<p>下面我们来看几个类型对象。 </p>
<p><img src="./images/21.png" alt="" /></p>
<p>我们看到所有类型对象的类型都被设置成了 &amp;PyType_Type，也就是 Python 里的 type。所以结论很清晰了，虽然内置的类型对象可以看做是 type 的实例对象，但它却不是由 type 实例化得到的，而是在底层预定义好，并以全局变量的形式静态出现。</p>
<p>所以内置的类型对象之间不存在谁创建谁，它们都是预定义好的，只是在定义的时候，将自身的类型设置成了 type 而已，包括 type 本身（类型还是 type）。这样一来，每一个对象都会有一个类型，从而将面向对象理念贯彻的更加彻底。</p>
<pre><code class="language-Python">print(int.__class__)
print(tuple.__class__)
print(set.__class__)
print(type.__class__)
&quot;&quot;&quot;
&lt;class 'type'&gt;
&lt;class 'type'&gt;
&lt;class 'type'&gt;
&lt;class 'type'&gt;
&quot;&quot;&quot;

print(
    type.__class__.__class__.__class__ is type
)  # True

print(
    type(type(type(type(type(type))))) is type
)  # True
</code></pre>
<p>好，说完了这些之后我们来正式考察 type 和 object 的底层实现。</p>
<h2 id="类型对象的类型pytype_type"><a class="header" href="#类型对象的类型pytype_type">类型对象的类型：PyType_Type</a></h2>
<p>type 是所有类型对象的类型，我们称之为元类型或者元类，即 metaclass，当然它同时也是一个类型对象。下面看一下它的底层实现。</p>
<pre><code class="language-C">// Objects/typeobject.c

PyTypeObject PyType_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;type&quot;,                                     /* tp_name */
    sizeof(PyHeapTypeObject),                   /* tp_basicsize */
    sizeof(PyMemberDef),                        /* tp_itemsize */
    (destructor)type_dealloc,                   /* tp_dealloc */
    0,                                          /* tp_vectorcall_offset */
    0,                                          /* tp_getattr */
    0,                                          /* tp_setattr */
    0,                                          /* tp_as_async */
    (reprfunc)type_repr,                        /* tp_repr */
    0,                                          /* tp_as_number */
    0,                                          /* tp_as_sequence */
    0,                                          /* tp_as_mapping */
    0,                                          /* tp_hash */
    (ternaryfunc)type_call,                     /* tp_call */
    // ...
};
</code></pre>
<p>所有的类型对象加上元类都是由 PyTypeObject 这个结构体实例化得到的，所以它们内部的字段都是一样的。只不过传入的值不同，实例化之后得到的结果也不同，可以是 PyLong_Type、可以是 PyFloat_Type，也可以是这里的 PyType_Type。</p>
<p>再看一下里面的宏 PyVarObject_HEAD_INIT，它用来初始化引用计数、类型和 ob_size，其中类型被初始化成了 &amp;PyType_Type。换句话说，PyType_Type 里面的 ob_type 字段指向的还是 PyType_Type，而对应 Python 的话，就是 type 的类型还是 type。</p>
<pre><code class="language-Python">&gt;&gt;&gt; type.__class__
&lt;class 'type'&gt;
&gt;&gt;&gt; type.__class__.__class__.__class__.__class__.__class__ is type
True
&gt;&gt;&gt; type(type(type(type(type(type))))) is type
True
</code></pre>
<p>显然不管套娃多少次，最终的结果都是 True，这也是符合预期的。</p>
<h2 id="类型对象的基类pybaseobject_type"><a class="header" href="#类型对象的基类pybaseobject_type">类型对象的基类：PyBaseObject_Type</a></h2>
<p>Python 中有两个类型对象比较特殊，一个是站在类型金字塔顶端的 type，另一个是站在继承金字塔顶端的 object。看完了 type，再来看看 object。</p>
<p>由于 object 的类型是 type，那么在初始化 PyBaseObject_Type 的时候，它的 ob_type 一定也被设置成了 &amp;PyType_Type。</p>
<p>我们看一下 PyBaseObject_Type 的具体实现，它同样定义在 Objects/typeobject.c 中。</p>
<p><img src="./images/22.png" alt="" /></p>
<p>类型对象在创建的时候，ob_type 字段都会被初始化成 &amp;PyType_Type，而 object 也不例外，所以它的类型为 type，这个非常简单。但 type 的基类是 object，又是怎么一回事呢？</p>
<p>之前介绍类型对象的时候，我们说类型对象内部的 tp_base 指向继承的基类，那么对于 PyType_Type 来讲，它内部的 tp_base 肯定是 &amp;PyBaseObject_Type，即 object。</p>
<p><img src="./images/23.png" alt="" /></p>
<p>但令我们吃鲸的是，它的 tp_base 居然是个 0，也就是说基类为空。</p>
<blockquote>
<p>在 C 中，将指针变量赋值为 0 和赋值为 NULL 是等价的，因为 NULL 就是值为 0 的指针常量。</p>
</blockquote>
<p>不是说 type 的基类是 object 吗？为啥 tp_base 是 0 呢。事实上如果你去看其它类型的话，会发现它们内部的 tp_base 也是 0。为 0 的原因就在于我们目前看到的类型对象还不够完善，因为 Python 的动态性，显然不可能在定义的时候就将所有字段属性都设置好、然后解释器一启动就得到我们平时使用的类型对象。</p>
<p>因此目前看到的类型对象还不是最终形态，有一部分字段属性是在解释器启动之后再动态完善的，而这个完善的过程被称为<font color="blue">类型对象的初始化</font>，它由函数 PyType_Ready 负责。</p>
<pre><code class="language-C">// Objects/typeobject.c

int
PyType_Ready(PyTypeObject *type)
{
    // ...
  
    // 注意这里的 type 是一个 C 函数的参数，不是 Python 里的 &lt;class 'type'&gt;
    // 获取类型对象的基类（指针）
    base = type-&gt;tp_base;
    // 如果类型对象的 tp_base 为空，并且本身也不是 &amp;PyBaseObject_Type
    // 那么就将它的 tp_base 设置为 &amp;PyBaseObject_Type
    if (base == NULL &amp;&amp; type != &amp;PyBaseObject_Type) {
        base = type-&gt;tp_base = &amp;PyBaseObject_Type;
        Py_INCREF(base);
    }

    // ...
}
</code></pre>
<p>当解释器发现类对象还没有初始化时，会将其作为参数传递给 PyType_Ready，进行初始化。</p>
<p>初始化过程会做很多的工作，用于完善类型对象，而其中一项工作就是设置基类。如果发现类型对象的基类为空，那么就将基类设置为 object，因为在 Python3 里面新式类都要继承 object。当然啦，这个类不能是 object 本身，object 的基类是 None，因为继承链向上要有一个终点。</p>
<p>当 PyType_Ready 完成初始化之后，就得到我们平常使用的类型对象了，最终 PyType_Type 和 PyBaseObject_Type 的关系如下。</p>
<p><img src="./images/24.png" alt="" /></p>
<p>因此到目前为止，type 和 object 之间的恩怨纠葛算是真相大白了，总结一下：</p>
<p>1）和自定义类不同，内置的类不是由 type 实例化得到的，它们都是在底层预先定义好的，不存在谁创建谁。只是内置的类在定义的时候，它们的类型都被设置成了 type。这样不管是内置的类，还是自定义类，在调用时都可以执行 type 的 __call__ 函数，从而让它们的行为是一致的。</p>
<p>2）虽然内置的类在底层预定义好了，但还有一些瑕疵，因为有一部分逻辑无法以源码的形式体现，只能在解释器启动的时候再动态完善。而这个完善的过程，便包含了基类的填充，会将基类设置成 object。</p>
<p>所以 type 和 object 是同时出现的，它们的存在需要依赖彼此。首先这两者会以<font color="blue">不完全体</font>的形式定义在源码中，并且在定义的时候将 object 的类型设置成 type；然后当解释器启动的时候，再经过动态完善，进化成完全体，而进化的过程中会将 type 的基类设置成 object。</p>
<p>因此 object 的类型是 type，type 继承 object 就是这么来的。</p>
<h2 id="小结-5"><a class="header" href="#小结-5">小结</a></h2>
<p>至此，我们算是从解释器的角度完全理清了 Python 中对象之间的关系，用之前的一张图总结一下。</p>
<p><img src="./images/25.png" alt="" /></p>
<p>当然，目前还远远没有结束，后续还会针对内置的对象进行专门的剖析，如浮点数、整数、字符串、字节串、元组、列表、字典、集合等等，都会一点一点剖析。我们会从 Python 的角度介绍对象该怎么用，然后再看它的底层实现，最后再用 Python 代码进行验证，加深理解。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-4"><a class="header" href="#楔子-4">楔子</a></h2>
<p>本篇文章来聊一聊对象的创建，一个对象是如何从无到有产生的呢？</p>
<pre><code class="language-python">&gt;&gt;&gt; n = 123
&gt;&gt;&gt; n
123
</code></pre>
<p>比如在终端中执行 n = 123，一个整数对象就创建好了，但它的背后都发生了什么呢？带着这些疑问，开始今天的内容。</p>
<h2 id="python-为什么这么慢"><a class="header" href="#python-为什么这么慢">Python 为什么这么慢</a></h2>
<p>前面我们介绍了 Python 对象在底层的数据结构，知道了 Python 底层是通过 PyObject 实现了对象的多态。所以我们先来分析一下 Python 为什么慢？</p>
<p>在 Python 中创建一个对象，会分配内存并进行初始化，然后用一个 PyObject * 指针来维护这个对象，当然所有对象都是如此。因为指针是可以相互转化的，所以变量在保存一个对象的指针时，会将指针转成 PyObject * 之后再交给变量保存。</p>
<p>因此在 Python 中，变量的传递（包括函数的参数传递）实际上传递的都是泛型指针 PyObject *。这个指针具体指向什么类型的对象我们并不知道，只能通过其内部的 ob_type 字段进行动态判断，而正是因为这个 ob_type，Python 实现了多态机制。</p>
<p>比如 a.pop()，我们不知道 a 指向的对象是什么类型，它可能是列表、也可能是字典，或者是我们实现了 pop 方法的自定义类的实例对象。至于它到底是什么类型，只能通过 ob_type 动态判断。</p>
<p>如果 a 的 ob_type 为 &amp;PyList_Type，那么 a 指向的对象就是列表，于是会调用 list 类型中定义的 pop 操作。如果 a 的 ob_type 为 &amp;PyDict_Type，那么 a 指向的对象就是字典，于是会调用 dict 类型中定义的 pop 操作。所以变量 a 在不同的情况下，会表现出不同的行为，这正是 Python 多态的核心所在。</p>
<p>再比如列表，它内部的元素也都是 PyObject *，因为类型要保持一致，所以对象的指针不能直接存（因为类型不同），而是需要统一转成泛型指针 PyObject * 之后才可以存储。当我们通过索引获取到该指针进行操作的时候，也会先通过 ob_type 判断它的类型，看它是否支持指定的操作。所以操作容器内的某个元素，和操作一个变量并无本质上的区别，它们都是 PyObject *。</p>
<p><font color="blue"><strong>从这里我们也能看出 Python 为什么慢了，因为有一部分时间浪费在类型和属性的查找上面。</strong></font></p>
<p>以变量 a + b 为例，这个 a 和 b 指向的对象可以是整数、浮点数、字符串、列表、元组、以及实现了 __add__ 方法的类的实例对象。因为 Python 的变量都是 PyObject *，所以它可以指向任意的对象，这就意味着 Python 无法做基于类型的优化。</p>
<p>底层在执行 a + b 时，首先要通过 ob_type 判断变量指向的对象是什么类型，这在 C 的层面需要一次属性查找。然后 Python 将每一个算术操作都抽象成了一个魔法方法，所以实例相加时要在类型对象中找到该方法对应的函数指针，这又是一次属性查找。找到了之后将 a、b 作为参数传递进去，这会产生一次函数调用，将对象维护的值拿出来进行运算，然后根据相加的结果创建一个新的对象，再将新的对象的指针转成 PyObject * 之后返回。</p>
<p>所以一个简单的加法运算，Python 内部居然做了这么多的工作，要是再放到循环里面，那么上面的步骤要重复 N 次。而对于 C 来讲，由于已经规定好了类型，所以 a + b 在编译之后就是一条简单的机器指令，因此两者在效率上差别很大。</p>
<p>当然我们不是来吐槽 Python 效率的问题，因为任何语言都有擅长的一面和不擅长的一面，这里只是通过回顾前面的知识来解释为什么 Python 效率低。因此当别人问你 Python 为什么效率低的时候，希望你能从这个角度来回答它，主要就两点：</p>
<ul>
<li>Python 无法基于类型做优化；</li>
<li>Python 对象基本都存储在堆上；</li>
</ul>
<p>建议不要一上来就谈 GIL，那是在多线程情况下才需要考虑的问题。而且我相信大部分觉得 Python 慢的人，都不是因为 Python 无法利用多核才觉得慢的。</p>
<h2 id="python-的-c-api"><a class="header" href="#python-的-c-api">Python 的 C API</a></h2>
<p>然后来说一说 Python 的 C API，这个非常关键。首先 Python 解释器听起来很高大上，但按照<font color="blue">陈儒老师</font>的说法，它不过就是用 C 语言写出的一个开源软件，从形式上和其它软件并没有本质上的不同。</p>
<p>比如你在 Windows 系统中打开 Python 的安装目录，会发现里面有一个二进制文件 python.exe 和一个动态库文件 python38.dll。二进制文件负责执行，动态库文件则包含了相应的依赖，当然编译的时候也可以把动态库里的内容统一打包到二进制文件中，不过大部分软件在开发时都会选择前者。</p>
<p>既然解释器是用 C 写的，那么在执行时肯定会将 Python 代码翻译成 C 代码，这是毫无疑问的。比如创建一个列表，底层就会创建一个 PyListObject 实例，比如调用某个内置函数，底层会调用对应的 C 函数。</p>
<p>所以如果你想搞懂 Python 代码的执行逻辑或者编写 Python 扩展，那么就必须要清楚解释器提供的 API 函数。而按照通用性来划分的话，这些 API 可以分为两种。</p>
<ul>
<li>泛型 API；</li>
<li>特定类型 API；</li>
</ul>
<p><font color="darkblue"><strong>泛型 API</strong></font></p>
<p>顾名思义，泛型 API 和参数类型无关，属于抽象对象层。这类 API 的第一个参数是 PyObject *，可以处理任意类型的对象，API 内部会根据对象的类型进行区别处理。</p>
<p>而且泛型 API 的名称也是有规律的，格式为 <font color="blue">PyObject_###</font>，我们举例说明。</p>
<p><img src="./images/26.png" alt="" /></p>
<p>所以泛型 API 一般以 PyObject_ 开头，第一个参数是 PyObject *，表示可以处理任意类型的对象。</p>
<p><font color="darkblue"><strong>特定类型 API</strong></font></p>
<p>顾名思义，<font color="red">特定类型 API</font> 和对象的类型是相关的，属于具体对象层，只能作用在指定类型的对象上面。因此不难发现，每种类型的对象，都有属于自己的一组<font color="red">特定类型 API</font>。</p>
<pre><code class="language-C">// 通过 C 的 double 创建 PyFloatObject
PyObject* PyFloat_FromDouble(double v);

// 通过 C 的 long 创建 PyLongObject
PyObject* PyLong_FromLong(long v);
// 通过 C 的 char * 创建 PyLongObject
PyObject* PyLong_FromString(const char *str, char **pend, int base)
</code></pre>
<p>以上就是解释器提供的两种 C API，了解完之后我们再来看看对象是如何创建的。</p>
<h2 id="对象是如何创建的"><a class="header" href="#对象是如何创建的">对象是如何创建的</a></h2>
<p>创建对象可以使用泛型 API，也可以使用特定类型 API，比如创建一个浮点数。</p>
<p><font color="darkblue"><strong>使用泛型 API 创建</strong></font></p>
<pre><code class="language-c">PyObject* pi = PyObject_New(PyObject, &amp;PyFloat_Type);
</code></pre>
<p>通过泛型 API 可以创建任意类型的对象，因为该类 API 和类型无关。那么问题来了，解释器怎么知道要给对象分配多大的内存呢？</p>
<p>在介绍类型对象的时候我们提到，对象的内存大小、支持哪些操作等等，都属于元信息，而元信息会存在对应的类型对象中。其中 tp_basicsize 和 tp_itemsize 负责指定实例对象所需的内存空间。</p>
<pre><code class="language-c">// Include/objimpl.h

// 创建定长对象
#define PyObject_New(type, typeobj) \
                ( (type *) _PyObject_New(typeobj) )
// 创建变长对象
#define PyObject_NewVar(type, typeobj, n) \
                ( (type *) _PyObject_NewVar((typeobj), (n)) )
/* 所以 PyObject* pi = PyObject_New(PyObject, &amp;PyFloat_Type) 等价于如下
 * PyObject* pi = (PyObject *)_PyObject_New(&amp;PyFloat_Type)
 */
</code></pre>
<p>所以实际申请内存的动作由 _PyObject_New 和 _PyObject_NewVar 负责，看看它的逻辑。</p>
<pre><code class="language-C">// Objects/object.c
PyObject *
_PyObject_New(PyTypeObject *tp)
{
    PyObject *op;
    // 通过 PyObject_Malloc 为对象申请内存，大小为 _PyObject_SIZE(tp)
    op = (PyObject *) PyObject_MALLOC(_PyObject_SIZE(tp));
    if (op == NULL)
        return PyErr_NoMemory();
    // 设置对象的类型和引用计数
    return PyObject_INIT(op, tp);
}

PyVarObject *
_PyObject_NewVar(PyTypeObject *tp, Py_ssize_t nitems)
{
    PyVarObject *op;
    const size_t size = _PyObject_VAR_SIZE(tp, nitems);
    // 通过 PyObject_Malloc 为对象申请内存，大小为 _PyObject_VAR_SIZE(tp, nitems)
    op = (PyVarObject *) PyObject_MALLOC(size);
    if (op == NULL)
        return (PyVarObject *)PyErr_NoMemory();
    // 设置对象的类型、引用计数和 ob_size
    return PyObject_INIT_VAR(op, tp, nitems);
}

// Include/objimpl.h
#define _PyObject_SIZE(typeobj) ( (typeobj)-&gt;tp_basicsize )

#define _PyObject_VAR_SIZE(typeobj, nitems)     \
    _Py_SIZE_ROUND_UP((typeobj)-&gt;tp_basicsize + \
        (nitems)*(typeobj)-&gt;tp_itemsize,        \
        SIZEOF_VOID_P)
/* 类型对象的 tp_basicsize 字段表示它的实例对象的基础大小，即底层结构体的大小
 * 对于像浮点数这种不可变的定长对象来说，显然大小就等于 PyFloat_Type 的 tp_basicsize
 *
 * 如果对象内部可以容纳指定数量的元素，比如元组，那么 tp_itemsize 便是每个元素的大小
 * 对于元组来说，它的大小等于 tp_basicsize + 元素个数 * tp_itemsize，并且按照 8 字节对齐
 */
</code></pre>
<p>以上便是泛型 API 创建对象的流程，但泛型 API 属于通用逻辑，而内置类型的实例对象一般会采用<font color="red">特定类型 API</font> 创建。</p>
<p><font color="darkblue"><strong>使用特定类型 API 创建</strong></font></p>
<pre><code class="language-C">// 创建浮点数，值为 2.71
PyObject* e = PyFloat_FromDouble(2.71);
// 创建一个可以容纳 5 个元素的元组
PyObject* tpl = PyTuple_New(5);
// 创建一个可以容纳 5 个元素的列表
// 当然这是初始容量，列表还可以扩容
PyObject* lst = PyList_New(5); 
</code></pre>
<p>和泛型 API 不同，使用<font color="red">特定类型 API</font> 只能创建指定类型的对象，因为这种 API 是和类型绑定的。比如我们可以用 PyDict_New 创建一个字典，但不可能创建一个集合出来。</p>
<p>如果使用特定类型 API，那么可以直接分配内存。因为内置类型的实例对象，它们的定义在底层都是写死的，解释器对它们了如指掌，因此可以直接分配内存并初始化。</p>
<p>比如通过 e = 2.71 创建一个浮点数，解释器看到 2.71 就知道要创建 PyFloatObject 结构体实例，那么申请多大内存呢？显然是 sizeof(PyFloatObject)，直接计算一下结构体实例的大小即可。</p>
<pre><code class="language-C">// Include/floatobject.h
typedef struct {
    // ob_refcnt 占 8 字节，ob_type 也占 8 字节
    PyObject_HEAD
    // 占 8 字节
    double ob_fval;
} PyFloatObject;
</code></pre>
<p>由于 PyFloatObject 只是在 PyObject 的基础上引入了一个 double 字段，用于维护浮点数的值，所以一个 PyFloatObject 实例的大小为 24 字节。既然内存大小知道，那么直接分配就可以了，分配之后再将 ob_refcnt 初始化为 1、将 ob_type 设置为 &amp;PyFloat_Type、将 ob_fval 设置为 2.71 即可。</p>
<p>同理可变对象也是一样，因为字段都是固定的，容纳的元素个数也可以根据赋的值得到，所以内部的所有字段占用了多少内存可以算出来，因此也是可以直接分配内存的。</p>
<p>还是那句话，解释器对内置的数据结构了如指掌，因为这些结构在底层都是定义好的，源码直接写死了。所以解释器根本不需要借助类型对象去创建实例对象，它只需要在实例对象创建完毕之后，再将 ob_type 设置为指定的类型即可（让实例对象和类型对象建立联系）。</p>
<p>所以采用<font color="red">特定类型 API</font> 创建实例的速度会更快，但这只适用于内置的数据结构，而我们自定义类的实例对象显然没有这个待遇。假设通过 <font color="blue">class Person:</font> 定义了一个类，那么在实例化的时候，显然不可能通过 PyPerson_New 去创建，因为底层压根就没有这个 API。这种情况下创建 Person 的实例对象就需要 Person 这个类型对象了，因此自定义类的实例对象如何分配内存、如何进行初始化，需要借助对应的类型对象。</p>
<p><strong>总的来说，Python 内部创建一个对象有两种方式：</strong></p>
<ul>
<li>通过特定类型 API，适用于内置数据结构，即内置类型的实例对象。</li>
<li>通过调用类型对象去创建（底层会调用泛型 API），多用于自定义类型。</li>
</ul>
<h2 id="-和-list应该使用哪种方式"><a class="header" href="#-和-list应该使用哪种方式">[] 和 list()，应该使用哪种方式</a></h2>
<p>lst = [] 和 lst = list() 都会创建一个空列表，但这两种方式有什么区别呢？</p>
<p>我们说创建实例对象可以通过解释器提供的特定类型 API，用于内置类型；也可以通过实例化类型对象去创建，既可用于自定义类型，也可用于内置类型。</p>
<pre><code class="language-Python"># 通过特定类型 API 创建
&gt;&gt;&gt; lst = [] 
&gt;&gt;&gt; lst
[]
# 通过调用类型对象创建
&gt;&gt;&gt; lst = list()  
&gt;&gt;&gt; lst
[]
</code></pre>
<p>还是那句话，解释器对内置数据结构了如指掌，并且做足了优化。</p>
<ul>
<li>看到 123，就知道创建 PyLongObject 实例；</li>
<li>看到 2.71，就知道创建 PyFloatObject 实例；</li>
<li>看到 ( )，就知道创建 PyTupleObject 实例；</li>
<li>看到 [ ]，就知道创建 PyListObject 实例；</li>
<li>······</li>
</ul>
<p>这些都会使用<font color="red">特定类型 API</font> 去创建，直接为结构体申请内存，然后设置引用计数和类型，所以使用 [ ] 创建列表是最快的。但如果使用 list() 创建列表，那么就产生了一个调用，要进行参数解析、类型检测、创建栈帧、销毁栈帧等等，所以开销会大一些。</p>
<pre><code class="language-Python">import time

start = time.perf_counter()
for _ in range(10000000):
    lst = []
end = time.perf_counter()
print(end - start) 
&quot;&quot;&quot;
0.2144167000001289
&quot;&quot;&quot;

start = time.perf_counter()
for _ in range(10000000):
    lst = list()
end = time.perf_counter()
print(end - start) 
&quot;&quot;&quot;
0.4079916000000594
&quot;&quot;&quot;
</code></pre>
<p>通过 [ ] 的方式创建一千万次空列表需要 0.21 秒，但通过 list() 的方式创建一千万次空列表需要 0.40 秒，主要就在于 list() 是一个调用，而 [ ] 会直接被解析成 PyListObject，因此 [ ] 的速度会更快一些。</p>
<p>所以对于内置类型的实例对象而言，使用<font color="red">特定类型 API</font> 创建要更快一些。而且事实上通过类型对象去创建的话，会先调用 tp_new，然后在 tp_new 内部还是调用了<font color="red">特定类型 API</font>。</p>
<p>比如：</p>
<ul>
<li>创建列表：可以是 list()、也可以是 [ ]；</li>
<li>创建元组：可以是 tuple()、也可以是 ( )；</li>
<li>创建字典：可以是 dict()、也可以是 { }；</li>
</ul>
<p>前者是通过<font color="blue">类型对象</font>创建的，后者是通过<font color="red">特定类型 API</font> 创建的。对于内置类型的实例对象而言，我们推荐使用<font color="red">特定类型 API</font> 创建，会直接解析为对应的 C 一级数据结构，因为这些结构在底层都是已经实现好了的，可以直接用。而无需通过诸如 list() 这种调用<font color="blue">类型对象</font>的方式来创建，因为它们内部最终还是使用了<font color="red">特定类型 API</font>，相当于多绕了一圈。</p>
<p>不过以上都是针对内置类型，而自定义的类型就没有这个待遇了，它的实例对象只能通过调用它自己创建。比如 Person 这个类，解释器不可能事先定义一个 PyPersonObject 然后将 API 提供给我们，所以我们只能通过调用 Person 来创建它的实例对象。</p>
<p>另外内置类型被称为<font color="green">静态类</font>，它和它的实例对象在底层已经定义好了，无法动态修改。我们自定义的类型被称为动态类，它是在解释器运行的过程中动态构建的，所以我们可以对其进行动态修改。</p>
<p>事实上 Python 的动态性、GIL 等特性，都是解释器在将字节码翻译成 C 代码时动态赋予的，而内置类型在编译之后已经是指向 C 一级的数据结构，因此也就丧失了相应的动态性。不过与之对应的就是效率上的提升，因为<font color="green">运行效率</font>和<font color="green">动态性</font>本身就是鱼与熊掌的关系。</p>
<h2 id="小结-6"><a class="header" href="#小结-6">小结</a></h2>
<p>以上我们就简单分析了 Python 对象的创建过程，当然这只是一个开头，其背后还隐藏了大量的细节，我们后续会慢慢说。</p>
<p>下一篇文章来聊一聊，对象是如何被调用的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-5"><a class="header" href="#楔子-5">楔子</a></h2>
<p>在上一篇文章中，我们分析了对象是如何创建的，主要有两种方式，一种是通过<font color="red">特定类型 API</font>，另一种是通过<font color="blue">调用类型对象</font>。</p>
<p>对于内置类型的实例对象而言，这两种方式都是支持的，比如列表，我们既可以通过 [ ] 创建，也可以通过 list() 创建，前者是列表的特定类型 API，后者是调用类型对象。但对于自定义类的实例对象而言，我们只能通过调用类型对象的方式来创建。</p>
<p>而一个对象如果可以被调用，那么这个对象就是 callable，否则就不是 callable。那么问题来了，如果一个对象是 callable，那么它都具有哪些特征呢？</p>
<ul>
<li>从 Python 的角度看，如果对象是 callable，那么它的类型对象一定实现了 __call__ 函数；</li>
<li>从解释器的角度看，如果对象是 callable，那么它的类型对象的 tp_call 字段一定不为空。</li>
</ul>
<h2 id="从-python-的角度看对象的调用"><a class="header" href="#从-python-的角度看对象的调用">从 Python 的角度看对象的调用</a></h2>
<p>调用 int 可以创建一个整数，调用 str 可以创建一个字符串，调用 tuple 可以创建一个元组，调用自定义的类也可以创建出相应的实例对象，这就说明类型对象是可调用的，也就是 callable。既然类型对象可调用，那么类型对象的类型对象（type）内部一定实现了 __call__ 函数。</p>
<pre><code class="language-python"># int 可以调用，那么它的类型对象、也就是元类（type）一定实现了 __call__ 函数
print(hasattr(type, &quot;__call__&quot;))  # True

# 而调用一个对象，等价于调用其类型对象的 __call__ 函数
# 所以 int(2.71) 实际上就等价于如下
print(type.__call__(int, 2.71))  # 2
</code></pre>
<p>我们说 int、str、float 这些都是类型对象（简单来说就是类），而 123、&quot;你好&quot;、2.71 是其对应的实例对象，这些都没问题。但如果相对 type 而言，int、str、float 是不是又成了实例对象呢？因为它们的类型都是 type。</p>
<p>所以 class 具有二象性：</p>
<ul>
<li>如果站在实例对象（如：123、&quot;你好&quot;、2.71）的角度上，它是类型对象；</li>
<li>如果站在 type 的角度上，它是实例对象；</li>
</ul>
<p>同理，由于 type 的类型还是 type，那么 type 既是 type 的类型对象，type 也是 type 的实例对象。虽然这里描述的有一些绕，但应该不难理解，而为了避免后续的描述出现歧义，这里我们做一个申明：</p>
<ul>
<li>整数、浮点数、字符串、列表等等，我们称之为<font color="blue">实例对象</font></li>
<li>int、float、str、dict，以及自定义的类，我们称之为<font color="blue">类型对象</font></li>
<li>type 虽然也是类型对象，但我们称它为<font color="blue">元类</font></li>
</ul>
<p>由于 type 的内部定义了 __call__ 函数，那么说明类型对象都是可调用的，因为调用类型对象就是调用元类 type 的 __call__ 函数。而实例对象能否调用就不一定了，这取决于它的类型对象是否定义了 __call__ 函数，因为调用一个对象，本质上是调用其类型对象内部的 __call__ 函数。</p>
<pre><code class="language-python">class A:
    pass

a = A()
# 因为自定义的类 A 里面没有 __call__
# 所以 a 是不可以被调用的
try:
    a()
except Exception as e:
    # 告诉我们 A 的实例对象无法被调用
    print(e)  # 'A' object is not callable

# 如果我们给 A 设置了一个 __call__
type.__setattr__(A, &quot;__call__&quot;, lambda self: &quot;这是__call__&quot;)
# 发现可以调用了
print(a())  # 这是__call__
</code></pre>
<p>这就是动态语言的特性，即便在类创建完毕之后，依旧可以通过 type 进行动态设置，而这在静态语言中是不支持的。所以 type 是所有类的元类，它控制了自定义类的生成过程，因此 type 这个古老而又强大的类可以让我们玩出很多新花样。</p>
<p><img src="./images/27.png" alt="" /></p>
<p>但对于内置的类，type 是不可以对其动态增加、删除或者修改属性的，因为内置的类在底层是静态定义好的。从源码中我们看到，这些内置的类、包括元类，它们都是 PyTypeObject 对象，在底层已经被声明为全局变量了，或者说它们已经作为静态类存在了。所以 type 虽然是所有类型对象的类型，但只有面对自定义的动态类，type 才具有对属性进行增删改的能力。</p>
<p>而且在上一篇文章中我们也解释过，Python 的动态性是解释器将字节码翻译成 C 代码的时候赋予的，因此给类对象动态设置属性只适用于动态类，也就是在 py 文件中使用 class 关键字定义的类。而对于静态类，它们在编译之后已经是指向 C 一级的数据结构了，不需要再被解释器解释了，因此解释器自然也就无法在它们身上动手脚，毕竟彪悍的人生不需要解释。</p>
<pre><code class="language-python">try:
    type.__setattr__(dict, &quot;ping&quot;, &quot;pong&quot;)
except Exception as e:
    print(e) 
    &quot;&quot;&quot;
    can't set attributes of built-in/extension type 'dict'
    &quot;&quot;&quot;

try:
    type.__setattr__(list, &quot;ping&quot;, &quot;pong&quot;)
except Exception as e:
    print(e) 
    &quot;&quot;&quot;
    can't set attributes of built-in/extension type 'list'
    &quot;&quot;&quot;
</code></pre>
<p>同理其实例对象亦是如此，静态类的实例对象也不可以动态设置属性：</p>
<pre><code class="language-Python">lst = list()
try:
    lst.name = &quot;古明地觉&quot;
except Exception as e:
    print(e)  # 'list' object has no attribute 'name'
</code></pre>
<p>在介绍 PyTypeObject 结构体的时候我们说过，静态类的实例对象可以绑定哪些属性，已经写死在 tp_members 字段里面了。</p>
<h2 id="从解释器的角度看对象的调用"><a class="header" href="#从解释器的角度看对象的调用">从解释器的角度看对象的调用</a></h2>
<p>如果一个对象可以被调用，那么它的类型对象中一定要有 tp_call，更准确的说是 tp_call 字段的值是一个具体的函数指针，而不是 0。由于 PyList_Type 是可以调用的，这就说明 PyType_Type 内部的 tp_call 是一个函数指针，这在 Python 的层面我们已经验证过了，下面再来通过源码看一下。</p>
<p><img src="./images/28.png" alt="" /></p>
<p>在创建 PyType_Type 的时候，PyTypeObject 内部的 tp_call 字段被设置成了 type_call。所以当我们调用 PyList_Type 的时候，会执行 type_call 函数。</p>
<p>因此 list() 在 C 的层面上等价于：</p>
<pre><code class="language-C">(&amp;PyList_Type)-&gt;ob_type-&gt;tp_call(&amp;PyList_Type, args, kwargs);
// 即：
(&amp;PyType_Type)-&gt;tp_call(&amp;PyList_Type, args, kwargs);
// 而在创建 PyType_Type 的时候，给 tp_call 字段传递的是 type_call
// 因此最终等价于
type_call(&amp;PyList_Type, args, kwargs)
</code></pre>
<p>如果用 Python 来演示这一过程的话：</p>
<pre><code class="language-python"># 以 list(&quot;abcd&quot;) 为例，它等价于
lst1 = list.__class__.__call__(list, &quot;abcd&quot;)
# 等价于
lst2 = type.__call__(list, &quot;abcd&quot;)
print(lst1)  # ['a', 'b', 'c', 'd']
print(lst2)  # ['a', 'b', 'c', 'd']
</code></pre>
<p>这就是 list() 的秘密，相信其它类型在实例化的时候是怎么做的，你已经知道了，做法是相同的。</p>
<pre><code class="language-Python"># dct = dict([(&quot;name&quot;, &quot;古明地觉&quot;), (&quot;age&quot;, 17)])
dct = dict.__class__.__call__(
    dict, [(&quot;name&quot;, &quot;古明地觉&quot;), (&quot;age&quot;, 17)]
)
print(dct)  # {'name': '古明地觉', 'age': 17}

# buf = bytes(&quot;hello world&quot;, encoding=&quot;utf-8&quot;)
buf = bytes.__class__.__call__(
    bytes, &quot;hello world&quot;, encoding=&quot;utf-8&quot;
)
print(buf)  # b'hello world'
</code></pre>
<p>当然，目前还没有结束，我们还需要看一下 type_call 的源码实现。</p>
<h2 id="type_call-源码解析"><a class="header" href="#type_call-源码解析">type_call 源码解析</a></h2>
<p>调用类型对象，本质上会调用 type.__call__，在底层对应 type_call 函数，因为 PyType_Type 的 tp_call 字段被设置成了 type_call。当然调用 type 也是如此，因为 type 的类型还是 type。</p>
<p>那么这个 type_call 都做了哪些事情呢？</p>
<pre><code class="language-C">// Objects/typeobject.c

static PyObject *
type_call(PyTypeObject *type, PyObject *args, PyObject *kwds)
{
	// 参数 type 表示类型对象或者元类，假设调用的是 list，那么它就是 &amp;PyList_Type
    // 参数 args 和 kwds 表示位置参数和关键字参数，args 是元组，kwds 是字典

    // 指向创建的实例对象，当然也可能是类型对象，取决于参数 type
    // 如果参数 type 表示元类，那么 obj 会指向类型对象，并且是自定义的动态类
    // 如果参数 type 表示类型对象，那么 obj 会指向实例对象
    PyObject *obj;
    
    // 执行类型对象（也可能是元类）的 tp_new，也就是 __new__
    // 如果不存在，那么会报错，而在 Python 中见到的报错信息就是这里指定的
    if (type-&gt;tp_new == NULL) {
        PyErr_Format(PyExc_TypeError,
                     &quot;cannot create '%.100s' instances&quot;,
                     type-&gt;tp_name);
        return NULL;
    }
    obj = type-&gt;tp_new(type, args, kwds);
    // 检测调用是否正常，如果调用正常，那么 obj 一定指向一个合法的 PyObject
    // 而如果 obj 为 NULL，则表示执行出错，此时解释器会抛出异常
    obj = _Py_CheckFunctionResult((PyObject*)type, obj, NULL);
    if (obj == NULL)
        return NULL;

    // 这里要做一个额外判断：
    // 如果参数 type 是 &amp;PyType_Type，也就是 Python 中的元类
    // 那么它可以接收一个位置参数（查看对象类型），也可以接收三个位置参数（创建自定义类）
    // 所以当 type 是 &amp;PyType_Type，位置参数的个数为 1，并且没有传递关键字参数时
    // 那么表示查看对象的类型，此时直接返回 obj 即可
    if (type == &amp;PyType_Type &amp;&amp;
        PyTuple_Check(args) &amp;&amp; PyTuple_GET_SIZE(args) == 1 &amp;&amp;
        (kwds == NULL ||
         (PyDict_Check(kwds) &amp;&amp; PyDict_GET_SIZE(kwds) == 0)))
        return obj;

    // 到这里说明不是查看对象类型，而是创建类或者实例
    // 如果参数 type 是元类，那么表示创建类，此时 args 的长度必须为 3
    // 如果参数 type 是类型对象，那么表示创建实例对象
    // 所以为了描述方便，我们就假设参数 type 是类型对象，但我们知道它也可以是元类

    // 总之到这里 __new__ 已经执行完了，那么之后该干啥了？显然是执行 __init__，但需要先做一个检测
    // 如果 __new__ 返回的实例对象的类型不是当前类型，那么直接返回，不再执行 __init__
    // 比如自定义 class A，那么在 __new__ 里面应该返回 A 的实例对象，但我们故意返回个 123
    // 由于返回值的类型不是当前类型，那么不再执行初始化函数 __init__
    if (!PyType_IsSubtype(Py_TYPE(obj), type))
        return obj;

    // 走到这里说明类型一致，那么执行 __init__，将 obj、args、kwds 一起传过去
    type = Py_TYPE(obj);
    if (type-&gt;tp_init != NULL) {
        int res = type-&gt;tp_init(obj, args, kwds);
        if (res &lt; 0) {
            assert(PyErr_Occurred());
            Py_DECREF(obj);
            obj = NULL;
        }
        else {
            assert(!PyErr_Occurred());
        }
    }
    // 返回创建的对象 obj，当然准确来说是对象的泛型指针
    // 因为 Python 虽然一切皆对象，但我们拿到的都是对象的泛型指针
    // 只是有时为了描述方便，我们会说成是对象，这一点我们心里清楚就好
    return obj;
}
</code></pre>
<p>所以整个过程就三步：</p>
<ul>
<li>如果传递的是元类，并且只有一个参数，那么直接返回对象的类型；</li>
<li>否则先调用 tp_new 为实例对象申请内存；</li>
<li>再调用 tp_init（如果有）进行初始化，设置对象属性；</li>
</ul>
<p>所以这对应了 Python 中的 __new__ 和 __init__，其中 __new__ 负责为实例对象开辟一份内存，然后返回指向对象的指针，并且该指针会自动传递给 __init__ 中的 self。</p>
<pre><code class="language-python">class Girl:

    def __new__(cls, name, age):
        print(&quot;__new__ 方法执行啦&quot;)
        # 调用 object.__new__(cls) 创建 Girl 的实例对象
        # 然后该对象的指针会自动传递给 __init__ 中的 self
        return object.__new__(cls)

    def __init__(self, name, age):
        print(&quot;__init__ 方法执行啦&quot;)
        self.name = name
        self.age = age


g = Girl(&quot;古明地觉&quot;, 16)
print(g.name, g.age)
&quot;&quot;&quot;
__new__ 方法执行啦
__init__ 方法执行啦
古明地觉 16
&quot;&quot;&quot;
</code></pre>
<p>__new__ 里面的参数要和 __init__ 里面的参数保持一致，因为会先执行 __new__ ，然后解释器再将 __new__  的返回值和传递的参数组合起来一起传给 __init__。因此从这个角度上讲，设置属性完全可以在 __new__  里面完成。</p>
<pre><code class="language-python">class Girl:

    def __new__(cls, name, age):
        self = object.__new__(cls)
        self.name = name
        self.age = age
        return self


g = Girl(&quot;古明地觉&quot;, 16)
print(g.name, g.age)
&quot;&quot;&quot;
古明地觉 16
&quot;&quot;&quot;
</code></pre>
<p>这样也是没问题的，不过 __new__ 一般只负责创建实例，设置属性应该交给 __init__ 来做，毕竟一个是构造函数、一个是初始化函数，各司其职。另外由于 __new__ 里面不负责初始化，那么它的参数除了 cls 之外，一般都会写成 *args 和 **kwargs。</p>
<p>然后再回过头来看一下 type_call 中的这两行代码：</p>
<p><img src="./images/29.png" alt="" /></p>
<p>tp_new 应该返回该类型对象的实例对象，而且一般情况下我们是不重写 __new__ 的，会默认执行 object 的 __new__。但如果我们重写了，那么必须要手动返回 object.__new__(cls)。可如果我们不返回，或者返回其它的话，会怎么样呢？</p>
<pre><code class="language-Python">class Girl:

    def __new__(cls, *args, **kwargs):
        print(&quot;__new__ 方法执行啦&quot;)
        instance = object.__new__(cls)
        # 打印看看 instance 到底是个啥
        print(&quot;instance:&quot;, instance)
        print(&quot;type(instance):&quot;, type(instance))

        # 正确做法是将 instance 返回
        # 但是我们不返回，而是返回一个整数 123
        return 123

    def __init__(self, name, age):
        print(&quot;__init__ 方法执行啦&quot;)


g = Girl()
&quot;&quot;&quot;
__new__ 方法执行啦
instance: &lt;__main__.Girl object at 0x0000019A2B7270A0&gt;
type(instance): &lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>这里面有很多可以说的点，首先就是 __init__ 里面需要两个参数，但是我们没有传，却还不报错。原因就在于这个 __init__ 压根就没有执行，因为 __new__ 返回的不是 Girl 的实例对象。</p>
<p>通过打印 instance，我们知道了 <font color="blue">object.__new__(cls)</font> 返回的就是 cls 的实例对象，而这里的 cls 就是 Girl 这个类本身。所以我们必须要返回 instance，才会自动执行相应的 __init__。</p>
<p>我们在外部来打印一下创建的实例对象吧，看看结果：</p>
<pre><code class="language-python">class Girl:

    def __new__(cls, *args, **kwargs):
        return 123

    def __init__(self, name, age):
        print(&quot;__init__ 方法执行啦&quot;)


g = Girl()
print(g)
&quot;&quot;&quot;
123
&quot;&quot;&quot;
</code></pre>
<p>我们看到打印的结果是 123，所以再次总结一下 <font color="blue">tp_new</font> 和 <font color="blue">tp_init</font> 之间的区别，当然也对应 <font color="blue">__new__</font> 和 <font color="blue">__init__</font> 的区别：</p>
<ul>
<li>tp_new：为实例对象申请内存，底层会调用 tp_alloc，至于对象的大小则记录在 tp_basicsize 字段中，而在 Python 里面则是调用 object.__new__(cls)，然后一定要将实例对象返回；</li>
<li>tp_init：tp_new 的返回值会自动传递给 self，然后为 self 绑定相应的属性，也就是进行实例对象的初始化；</li>
</ul>
<p>但如果 tp_new 返回的对象的类型不对，比如 type_call 的第一个参数接收的是 &amp;PyList_Type，但 tp_new 返回的却是 PyTupleObject *，那么此时就不会执行 tp_init。对应上面的 Python 代码就是，Girl 的 __new__ 应该返回 Girl 的实例对象（指针）才对，但却返回了整数，因此类型不一致，不会执行 __init__。</p>
<p>所以都说类在实例化的时候会先调用 __new__，再调用 __init__，相信你应该知道原因了，因为在源码中先调用 tp_new，再调用 tp_init。所以源码层面表现出来的，和我们在 Python 层面看到的是一样的。</p>
<h2 id="小结-7"><a class="header" href="#小结-7">小结</a></h2>
<p>到此，我们就从 Python 和解释器两个层面剖析了对象是如何调用的，更准确的说，我们是从解释器的角度对 Python 层面的知识进行了验证，通过 tp_new 和 tp_init 的关系，来了解 __new__ 和 __init__ 的关系。</p>
<p>当然对象调用还不止目前说的这么简单，更多的细节隐藏在了幕后。后续我们会循序渐进，一点点地揭开它的面纱，并且在这个过程中还会不断地学习到新的东西。比如说，实例对象在调用方法的时候会自动将实例本身作为参数传递给 self，那么它为什么会传递呢？解释器在背后又做了什么工作呢？这些在之后的文章中都会详细说明。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>之前我们提到了泛型 API，这类 API 的特点是可以处理任意类型的对象，举个例子。</p>
<pre><code class="language-C">// 返回对象的长度
PyObject_Size
// 返回对象的某个属性的值
PyObject_GetAttr
// 返回对象的哈希值
PyObject_Hash
// 将对象转成字符串后返回
PyObject_Str
</code></pre>
<p>对应到 Python 代码中，就是下面这个样子。</p>
<pre><code class="language-python"># PyObject_Size
print(len(&quot;古明地觉&quot;))
print(len([1, 2, 3]))
&quot;&quot;&quot;
4
3
&quot;&quot;&quot;

# PyObject_GetAttr
print(getattr(&quot;古明地觉&quot;, &quot;lower&quot;))
print(getattr([1, 2, 3], &quot;append&quot;))
print(getattr({}, &quot;update&quot;))
&quot;&quot;&quot;
&lt;built-in method lower of str object at 0x7f081aa7e920&gt;
&lt;built-in method append of list object at 0x7f081adc1100&gt;
&lt;built-in method update of dict object at 0x7f081aa8fd80&gt;
&quot;&quot;&quot;

# PyObject_Hash
print(hash(&quot;古明地觉&quot;))
print(hash(2.71))
print(hash(123))
&quot;&quot;&quot;
8152506393378233203
1637148536541722626
123
&quot;&quot;&quot;

# PyObject_Str
print(str(&quot;古明地觉&quot;))
print(str(object()))
&quot;&quot;&quot;
古明地觉
&lt;object object at 0x7fdfa0209d10&gt;
&quot;&quot;&quot;
</code></pre>
<p>这些 API 能处理任意类型的对象，这究竟是怎么办到的？要想搞清楚这一点，还是要从 PyObject 入手。</p>
<p>我们知道对象在 C 看来就是一个结构体实例，并且结构体嵌套了 PyObject。</p>
<pre><code class="language-python"># 创建一个浮点数，让变量 var 指向它
var = 2.71
# 创建一个列表，让变量 var 指向它
var = [1, 2, 3]
</code></pre>
<p>浮点数对应的结构体是 PyFloatObject，列表对应的结构体是 PyListObject，变量 var 是指向对象的指针。那么问题来了，凭啥一个变量可以指向不同类型的对象呢？或者说变量和容器里面为什么可以保存不同对象的指针呢？</p>
<p>原因在前面的文章中解释的很详细了，因为对象的指针会统一转成 PyObject * 之后再交给变量保存，以创建列表为例。</p>
<p><img src="./images/30.png" alt="" /></p>
<p>当然创建浮点数也是同理，因此变量和容器里的元素本质上就是一个泛型指针 PyObject *。而对象的指针在交给变量保存的时候，也都会先转成 PyObject *，因为不管什么对象，它底层的结构体都嵌套了 PyObject。正是因为这个设计，变量才能指向任意的对象。</p>
<p><img src="./images/31.png" alt="" /></p>
<p>所以 Python 变量相当于一个便利贴，可以贴在任意对象上。</p>
<p>不过问题来了，由于对象的指针会统一转成 PyObject * 之后再交给变量保存，那么变量怎么知道自己指向的是哪种类型的对象呢？相信你肯定知道答案：通过 ob_type 字段。</p>
<p><img src="./images/32.png" alt="" /></p>
<p>对象对应的结构体可以有很多个字段，比如 PyListObject，但变量能看到的只有前两个字段。至于之后的字段是什么，则取决于对象的类型。</p>
<p>所以变量会先通过 ob_type 字段获取对象的类型，如果 ob_type 字段的值为 &amp;PyList_Type，那么变量指向的就是 PyListObject。如果 ob_type 字段的值为 &amp;PyFloat_Type，那么变量指向的就是 PyFloatObject，其它类型同理。当得到了对象的类型，那么再转成相应的指针即可，假设 ob_type 是 &amp;PyList_Type，那么变量会再转成 PyListObject *，这样就可以操作列表的其它字段了。</p>
<p>所以我们再总结一下：</p>
<p><img src="./images/33.png" alt="" /></p>
<p>变量和容器里的元素只能保存相同的指针类型，而不同类型的对象，其底层的结构体是不同的。但这些结构体无一例外都嵌套了 PyObject，因此它们的指针会统一转成 PyObject * 之后再交给变量保存。</p>
<p>然后变量在操作对象时，会先通过 ob_type 判断对象的类型，假如是 &amp;PyList_Type，那么会再转成 PyListObject *，其它类型同理。我们以获取列表元素为例：</p>
<p><img src="./images/34.png" alt="" /></p>
<p>相信你已经知道为什么泛型 API 可以处理任意类型的对象了，我们再以 PyObject_GetAttr 为例，它内部会调用类型对象的 tp_getattro。</p>
<pre><code class="language-C">// Objects/object.c

// 等价于 getattr(v, name)
PyObject *
PyObject_GetAttr(PyObject *v, PyObject *name)
{   
    // 获取对象 v 的类型对象
    PyTypeObject *tp = Py_TYPE(v);
    // 属性名称必须是字符串
    if (!PyUnicode_Check(name)) {
        PyErr_Format(PyExc_TypeError,
                     &quot;attribute name must be string, not '%.200s'&quot;,
                     name-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
    // 如果类型对象实现了 tp_getattro，那么进行调用
    // 等价于 Python 中的 type(v).__getattr__(v, name)
    if (tp-&gt;tp_getattro != NULL)
        return (*tp-&gt;tp_getattro)(v, name);
    // 否则会退化为 tp_getattr，它要求属性名称必须是 C 字符串
    // 不过 tp_getattr 已经废弃，应该使用 tp_getattro
    if (tp-&gt;tp_getattr != NULL) {
        const char *name_str = PyUnicode_AsUTF8(name);
        if (name_str == NULL)
            return NULL;
        return (*tp-&gt;tp_getattr)(v, (char *)name_str);
    }
    // 否则说明对象 v 没有该属性
    PyErr_Format(PyExc_AttributeError,
                 &quot;'%.50s' object has no attribute '%U'&quot;,
                 tp-&gt;tp_name, name);
    return NULL;
}
</code></pre>
<p>函数先通过 ob_type 找到对象的类型，然后通过类型对象的 tp_getattro 调用对应的属性查找函数。所以对象的类型不同，PyObject_GetAttr 调用的属性查找函数也不同，而这就是泛型 API 能处理任意对象的秘密。</p>
<p>我们再以 Python 代码为例：</p>
<pre><code class="language-Python">class A:

    def __getattr__(self, item):
        return f&quot;class：A，item：{item}&quot;

class B:

    def __getattr__(self, item):
        return f&quot;class：B，item：{item}&quot;

a = A()
b = B()
print(getattr(a, &quot;some_attr&quot;))
print(getattr(b, &quot;some_attr&quot;))
&quot;&quot;&quot;
class：A，item：some_attr
class：B，item：some_attr
&quot;&quot;&quot;
# 以上等价于
print(type(a).__getattr__(a, &quot;some_attr&quot;))
print(type(b).__getattr__(b, &quot;some_attr&quot;))
&quot;&quot;&quot;
class：A，item：some_attr
class：B，item：some_attr
&quot;&quot;&quot;
</code></pre>
<p>在 Python 里的表现和源码是一致的，我们再举个 iter 的例子：</p>
<pre><code class="language-Python">data = [1, 2, 3]
print(iter(data))
print(type(data).__iter__(data))
&quot;&quot;&quot;
&lt;list_iterator object at 0x7fb8200f29a0&gt;
&lt;list_iterator object at 0x7fb8200f29a0&gt;
&quot;&quot;&quot;
</code></pre>
<p>如果一个对象支持创建迭代器，那么它的类型对象一定实现了 __iter__，通过 type(data) 可以获取到类型对象，然后再将 data 作为参数调用 __iter__ 即可。</p>
<p>所以通过 ob_type 字段，这些泛型 API 实现了类似多态的效果，一个函数，多种实现。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>我们知道所有类型对象在底层都由结构体 PyTypeObject 实例化得到，但内部字段接收的值不同，得到的类型对象就不同。类型对象不同，那么实例对象的表现就不同，这也正是一种对象区别于另一种对象的关键所在。</p>
<p>比如 PyLong_Type 的 tp_iter 是空，那么整数就不是可迭代对象，而 PyList_Type 的 tp_iter 不是空，那么列表就是可迭代对象。再比如 PyLong_Type 和 PyFloat_Type，虽然内部都实现了 tp_hash，但它们是不同的类型，所以整数和浮点数的哈希值计算方式也不一样。</p>
<p>因此类型对象决定了实例对象的行为，比如能否调用、能否计算哈希值、能否迭代等等，这些都由类型对象决定。</p>
<p>PyTypeObject 里面定义了很多函数指针，比如 tp_call、tp_hash 等等，它们可能指向某个具体的函数，也可能为空。这些函数指针可以看做是类型对象所定义的<font color="blue">操作</font>，这些操作决定了其实例对象在运行时的<font color="blue">行为</font>。</p>
<pre><code class="language-python">class A:
    
    # tp_new
    def __new__(cls, *args, **kwargs):
        pass
    
    # tp_init
    def __init__(self):
        pass
    
    # tp_call
    def __call__(self):
        pass
    
    # tp_getattro
    def __getattr__(self, attr):
        pass
    
    # tp_setattro
    def __setattr__(self, key, value):
        pass
    
    ...
    ...
</code></pre>
<p>像 tp_call、tp_hash、tp_new 等字段会直接对应 Python 里的魔法函数，它们以双下划线开头、以双下划线结尾。但除了魔法函数之外，每种类型还可以有很多自定义的成员函数。</p>
<pre><code class="language-python"># 自定义 foo 和 bar
class A:

    def foo(self):
        pass

    def bar(self):
        pass

# 当然内置类型也是如此
# 像 str 定义了 join、split、upper 等
print(str.join)
print(str.split)
print(str.upper)
# 像 list 定义了 append、extend，insert 等
print(list.append)
print(list.extend)
print(list.insert)
</code></pre>
<p>这些自定义的函数会一起保存在类型对象的 tp_methods 里面，负责让实例对象更具有表现力。另外需要补充的是，类型对象里面定义的是函数，也叫成员函数，但实例对象在获取之后会自动包装成方法。所以当提到魔法函数和魔法方法时，其实表达的是同一个意思，只不过一个是站在类的角度，一个是站在实例的角度。</p>
<p>所以实例对象能调用的方法都定义在类型对象里面，并且通过实例调用本质上就是一个语法糖，但用起来更加优雅。假设有一个类 A，实例对象为 a，那么 <font color="blue">a.some()</font> 底层会转成 <font color="blue">A.some(a)</font>，至于这背后的细节后续再聊。</p>
<p>但除了以上这些，PyTypeObject 还提供了三个字段。</p>
<p><img src="./images/35.png" alt="" /></p>
<p>每个字段分别指向一个结构体实例，结构体实例中有大量的字段，这些字段都是函数指针，指向了具体的函数。所以它们也被称为<font color="blue">方法簇</font>，分别应用于如下操作。</p>
<ul>
<li>tp_as_number：负责数值型操作，比如整数、浮点数的加减乘除；</li>
<li>tp_as_sequence：负责序列型操作，比如字符串、列表、元组等通过索引取值的行为；</li>
<li>tp_as_mapping：负责映射型操作，比如字典通过 key 映射出 value；</li>
</ul>
<p>我们以 tp_as_number 为例，它指向 PyNumberMethods 类型的结构体实例，那么这个结构体长什么样子呢？</p>
<pre><code class="language-C">// Include/cpython/object.h

typedef struct {
    // __add__，对应 + 操作符，如 a + b
    binaryfunc nb_add;
    // __sub__，对应 - 操作符，如 a - b
    binaryfunc nb_subtract;
    // __mul__，对应 * 操作符，如 a * b
    binaryfunc nb_multiply;
    // __mod__，对应 % 操作符，如 a % b
    binaryfunc nb_remainder;
    // __divmod__，对应 divmode 函数，如 divmod(a, b)
    binaryfunc nb_divmod;
    // __power__，对应 ** 操作符，如 a ** b
    ternaryfunc nb_power;
    // __neg__，对应 - 操作符，如 -a
    unaryfunc nb_negative;
    // __pos__，对应 + 操作符，如 +a
    unaryfunc nb_positive;
    // __abs__，对应 abs 函数，如 abs(a)
    unaryfunc nb_absolute;
    // __bool__，如 bool(a)
    inquiry nb_bool;
    // __invert__，对应 ~ 操作符，如 ~a
    unaryfunc nb_invert;
    // __lshift__，对应 &lt;&lt; 操作符，如 a &lt;&lt; b
    binaryfunc nb_lshift;
    // __rshift__，对应 &gt;&gt; 操作符，如 a &gt;&gt; b
    binaryfunc nb_rshift;
    // __and__，对应 &amp; 操作符，如 a &amp; b
    binaryfunc nb_and;
    // __xor__，对应 ^ 操作符，如 a ^ b
    binaryfunc nb_xor;
    // __or__，对应 | 操作符，如 a | b
    binaryfunc nb_or;
    // __int__，如 int(a)
    unaryfunc nb_int;
    // ...
} PyNumberMethods;
</code></pre>
<p>你看到了什么？是不是想到了 Python 里面的魔法方法，所以它们也被称为方法簇。</p>
<p>在 PyNumberMethods 这个方法簇里面定义了作为一个数值对象应该支持的操作，同理，在 PySequenceMethods 和 PyMappingMethods 中分别定义了作为一个序列对象和映射对象应该支持的操作，这两种对象的典型例子就是 list 和 dict。</p>
<p>所以，只要<font color="blue">类型对象</font>提供<font color="red">相关操作</font>，<font color="blue">实例对象</font>便具备<font color="red">对应的行为</font>，因为实例对象所调用的方法都是由类型对象提供的。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def say(self):
        pass

    def cry(self):
        pass


g = Girl(&quot;古明地觉&quot;, 16)
print(g.__dict__)  # {'name': '古明地觉', 'age': 16}
print(&quot;say&quot; in Girl.__dict__)  # True
print(&quot;cry&quot; in Girl.__dict__)  # True
</code></pre>
<p>实例对象的属性字典，只包含了一些在 __init__ 里面设置的属性而已，而实例能够调用的 say、cry 都是定义在类型对象中的。</p>
<p>因此一定要记住：<font color="blue">类型对象定义的操作，决定了实例对象的行为</font>。</p>
<pre><code class="language-python">class Int(int):

    def __getitem__(self, item):
        return item


a = Int(1)
b = Int(2)

print(a + b)  # 3
print(a[&quot;你好&quot;])  # 你好
</code></pre>
<p>继承了 int 的自定义类 Int 在实例化之后自然是一个数值对象，但 a[&quot;&quot;] 却是一个类似于字典才具有的行为，那为什么可以实现呢？原因就是我们重写了 <font color="blue">__getitem__</font> 这个魔法函数，它在底层对应 <font color="blue">PyMappingMethods</font> 中的 <font color="blue">mp_subscript</font> 操作，因此最终 Int 实例对象表现的像一个字典一样。</p>
<p>归根结底就在于这几个方法簇都只是 PyTypeObject 的一个字段罢了，默认使用 PyTypeObject 结构体创建的 PyLong_Type 所生成的实例对象（整数）是不具备列表和字典的属性特征的。但我们通过继承 PyLong_Type，同时指定 __getitem__，使得构建出来的类型对象所生成的实例对象，同时具备多种属性特征，就是因为解释器支持这种做法。</p>
<p>自定义的类在底层也是 PyTypeObject 结构体实例，而在继承 int 的时候，将其内部定义的 PyNumberMethods 方法簇也继承了下来，而我们又单独实现了 PyMappingMethods 中的 mp_subscript。所以<font color="blue">自定义类 Int</font> 的实例对象具备了整数的全部行为，以及字典的部分行为（因为我们只实现了 __getitem__）。</p>
<p>下面再通过 PyLong_Type 实际考察一下：</p>
<p><img src="./images/36.png" alt="" /></p>
<p>整数对象支持数值操作，所以在创建 PyLong_Type 时，实现了 tp_as_number。但整数显然不支持序列和映射操作，因此字段 tp_as_sequence 和 tp_as_mapping 就是 0，相当于空。</p>
<p>而 tp_as_number 字段被赋值为 long_as_number，看一下它长什么样。</p>
<p><img src="./images/37.png" alt="" /></p>
<p>里面的 long_add、long_sub、long_mul 等等显然都是已经定义好的函数指针，在创建 PyNumberMethods 结构体实例 long_as_number 的时候，这些函数指针分别赋值给了字段 nb_add、nb_substract、nb_multiply 等等。然后创建完 long_as_number 之后，再将其指针交给 PyLong_Type 的 tp_as_number 字段。</p>
<p>因此整数在操作的时候，比如相加，会先通过 <font color="blue">变量-&gt;ob_type-&gt;tp_as_number-&gt;nb_add</font> 获取该操作对应的函数指针，其中 int 类型对象的 tp_as_number 字段的值是 &amp;long_as_number，因此获取其字段 nb_add 的时候，拿到的就是 long_add 函数指针，然后调用。</p>
<p>同理 float 类型里的 tp_as_number 字段则被赋值成了 &amp;float_as_number，获取 nb_add 字段的时候，拿到的就是 float_add 函数指针。不同类型的对象的行为不同，它们都有属于自己的一组方法簇。</p>
<p>最后再画一张图总结一下，假设有两个变量，分别是 e = 2.71 和 num = 666。</p>
<p><img src="./images/38.png" alt="" /></p>
<p>所以对象的行为是由其类型对象定义的操作所决定的，比如一个对象可以计算长度，那么它的类型对象要实现 __len__；一个对象可以转成整数，那么它的类型对象要实现 __int__ 或 __index__。</p>
<pre><code class="language-python">class A:

    def __len__(self):
        return 123

    def __int__(self):
        return 456

a = A()
print(len(a))  # 123
print(int(a))  # 456
# len(a) 在底层会执行 A.__len__(a)
# int(a) 在底层会执行 A.__int__(a)
print(A.__len__(a))  # 123
print(A.__int__(a))  # 456
</code></pre>
<p>总之核心就是一句话：类型对象定义了哪些操作，决定了实例对象具有哪些行为。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-6"><a class="header" href="#楔子-6">楔子</a></h2>
<p>如果对编程语言进行分类的话，一般可以分为静态语言和动态语言，也可以分为编译型语言和解释型语言。但个人觉得还有一种划分标准，就是<font color="blue">是否自带垃圾回收</font>。关于有没有垃圾回收，陈儒老师在《Python 2.5源码剖析》中，总结得非常好。</p>
<p>对于像 C 和 C++ 这类语言，程序员被赋予了极大的自由，可以任意地申请内存。但权力的另一面对应着责任，程序员最后不使用的时候，必须负责将申请的内存释放掉，并把无效指针设置为空。可以说，这一点是万恶之源，大量内存泄漏、悬空指针、越界访问的 bug 由此产生。</p>
<p>而现代的开发语言（比如 C#、Java）都带有垃圾回收机制，将开发人员从维护内存分配和清理的繁重工作中解放出来，开发者不用再担心内存泄漏的问题，但同时也被剥夺了和内存亲密接触的机会，并牺牲了一定的程序运行效率。不过好处就是提高了开发效率，并降低了 bug 发生的概率。</p>
<p>由于现在的垃圾回收机制已经非常成熟了，把对性能的影响降到了最低，因此大部分场景选择的都是带垃圾回收的语言。</p>
<p>而 Python 里面同样具有垃圾回收，只不过它是为引用计数机制服务的。所以解释器通过引用计数和垃圾回收，代替程序员进行繁重的内存管理工作，关于垃圾回收我们后面会详细说，先来看一下引用计数。</p>
<h2 id="引用计数"><a class="header" href="#引用计数">引用计数</a></h2>
<p>Python 一切皆对象，所有对象都有一个 ob_refcnt 字段，该字段维护着对象的引用计数，从而也决定对象的存在与消亡。下面来探讨一下引用计数，当然引用计数在介绍 PyObject 的时候说的很详细了，这里再回顾一下。</p>
<p>但需要说明的是，<font color="blue">比起类型对象，我们更关注实例对象的行为</font>。引用计数也是如此，只有实例对象，我们探讨引用计数才是有意义的。因为内置的类型对象超越了引用计数规则，永远都不会被析构，或者销毁，因为它们在底层是被静态定义好的。同理，自定义的类虽然可以被回收，但是探讨它的引用计数也是没有价值的。我们举个栗子：</p>
<pre><code class="language-Python">class A:
    pass

del A
</code></pre>
<p>首先 del 关键字只能作用于变量，不可以作用于对象。比如 e = 2.71，可以 <font color="blue">del e</font>，但是不可以 <font color="blue">del 2.71</font>，这是不符合语法规则的。因为 del 的作用是删除变量，并将其指向的对象的引用计数减 1，所以我们只能 <font color="blue">del 变量</font>，不可以 <font color="blue">del 对象</font>。</p>
<p>至于 def、class 语句执行完之后拿到的也是变量，前面说了，Python 虽然一切皆对象，但我们拿到的都是对象的泛型指针。比如上面代码中的 <font color="red">class A</font>，它会先创建一个类对象，然后再让变量 A 指向这个类对象。所以我们拿到的 A 也是一个变量，只要是变量，就可以被 del。但是 <font color="red">del 变量</font>只是删除了该变量，换言之就是让该变量无法再被使用，至于变量指向的对象是否会被回收，就看是否还有其它的变量也指向它。</p>
<p><font color="darkblue"><strong>总结：对象是否会被回收，完全由解释器判断它的引用计数是否为 0 所决定。</strong></font></p>
<h2 id="引用计数的相关操作"><a class="header" href="#引用计数的相关操作">引用计数的相关操作</a></h2>
<p>操作引用计数无非就是将其加一或减一，至于什么时候加一、什么时候减一，在介绍 PyObject 的时候已经说的很详细了。这里我们通过源码，看看引用计数具体是怎么操作的。</p>
<p>在底层，解释器会通过 Py_INCREF 和 Py_DECREF 两个宏来增加和减少对象的引用计数，而当对象的引用计数为 0 时，会调用对应的析构函数来销毁该对象，这个析构函数由对象的类型对象内部的 tp_dealloc 字段决定。</p>
<p>下面我们来看看底层实现，不过在介绍 Py_INCREF 和 Py_DECREF 之前，先来看几个其它的宏，这些宏非常常见，有必要单独说一下。</p>
<pre><code class="language-C">// Include/object.h

// 将对象的指针转成 PyObject *
#define _PyObject_CAST(op) ((PyObject*)(op))
// 将对象的指针转成 PyVarObject *
#define _PyVarObject_CAST(op) ((PyVarObject*)(op))

// 返回对象的引用计数，即对象的 ob_refcnt 字段
#define Py_REFCNT(ob)           (_PyObject_CAST(ob)-&gt;ob_refcnt)
// 返回对象的类型，即对象的 ob_type 字段
#define Py_TYPE(ob)             (_PyObject_CAST(ob)-&gt;ob_type)
// 返回对象的长度，即对象的 ob_size 字段
#define Py_SIZE(ob)             (_PyVarObject_CAST(ob)-&gt;ob_size)
</code></pre>
<p>然后再来看看 Py_INCREF 和 Py_DECREF，它们负责对引用计数执行加一和减一操作。</p>
<pre><code class="language-C">// Include/object.h

// 将对象的 ob_refcnt 加 1
#define Py_INCREF(op) _Py_INCREF(_PyObject_CAST(op))
static inline void _Py_INCREF(PyObject *op)
{
    _Py_INC_REFTOTAL;
    op-&gt;ob_refcnt++;
}

// 将对象的 ob_refcnt 减 1
#define Py_DECREF(op) _Py_DECREF(__FILE__, __LINE__, _PyObject_CAST(op))
tatic inline void _Py_DECREF(const char *filename, int lineno,
                              PyObject *op)
{
    (void)filename; /* may be unused, shut up -Wunused-parameter */
    (void)lineno; /* may be unused, shut up -Wunused-parameter */
    _Py_DEC_REFTOTAL;
    // 将引用计数减 1 之后进行判断，如果结果不等于 0，则什么也不做
    if (--op-&gt;ob_refcnt != 0) {
        // 正常情况下，Py_REF_DEBUG 宏不会被定义，因为引用计数不可能小于 0
#ifdef Py_REF_DEBUG
        if (op-&gt;ob_refcnt &lt; 0) {
            _Py_NegativeRefcount(filename, lineno, op);
        }
#endif
    }
    // 否则说明引用计数为 0，意味着对象已经不被任何变量引用了，那么应该被销毁
    else {
        // 调用 _Py_Dealloc 将对象销毁，这个 _Py_Dealloc 函数内部的逻辑很简单
        // 虽然里面存在宏判断，但如果只看编译后的最终结果，那么代码就只有下面两行
        /* destructor dealloc = Py_TYPE(op)-&gt;tp_dealloc;
         * (*dealloc)(op);
         */
        // 会获取类型对象的 tp_dealloc，然后调用，销毁实例对象
        _Py_Dealloc(op);
    }
}
</code></pre>
<p>以上就是 Py_INCREF 和 Py_DECREF 两个宏的具体实现，但是它们不能接收空指针，如果希望能接收空指针，那么可以使用另外两个宏。</p>
<pre><code class="language-c">// Include/object.h

#define Py_XINCREF(op) _Py_XINCREF(_PyObject_CAST(op))
static inline void _Py_XINCREF(PyObject *op)
{
    if (op != NULL) {
        Py_INCREF(op);
    }
}

#define Py_XDECREF(op) _Py_XDECREF(_PyObject_CAST(op))
static inline void _Py_XDECREF(PyObject *op)
{
    if (op != NULL) {
        Py_DECREF(op);
    }
}
</code></pre>
<p>所以 Py_XINCREF 和 Py_XDECREF 会额外对指针做一次判断，如果为空则什么也不做，不为空再调用 Py_INCREF 和 Py_DECREF。而当一个对象的引用计数为 0 时，与该对象对应的析构函数就会被调用。</p>
<p>但要特别注意的是，我们上面说调用析构函数之后会回收对象，或者说销毁对象，意思是将这个对象从内存中抹去，但并不意味着要释放空间，也就是对象没了，但对象占用的内存却还在。</p>
<p>如果对象没了，占用的内存也要释放的话，那么频繁申请、释放内存空间会使 Python 的执行效率大打折扣，更何况 Python 已经背负了人们对其执行效率的不满这么多年。</p>
<p>所以 Python 底层大量采用了缓存池的技术，使用这种技术可以避免频繁地申请和释放内存空间。因此在析构的时候，只是将对象占用的空间放到缓存池中，并没有真的释放。</p>
<p>这一点，在后面剖析内置实例对象的实现中，将会看得一清二楚，因为大部分内置的实例对象都会有自己的缓存池。</p>
<h2 id="小结-8"><a class="header" href="#小结-8">小结</a></h2>
<p>到此我们就把这些基础概念说完了，后续你会发现目前花费的这些笔墨都是值得的，总之先对 Python 有一个宏观的认识，然后再学习具体的数据结构就简单多了。</p>
<p>所以从下一篇文章开始就要详细剖析内置对象的底层实现了，比如浮点数、复数、整数、布尔值、None、bytes 对象、bytearray 对象、字符串、元组、列表、字典、集合等等，所有的内置对象都会详细地剖析一遍，看看它是如何实现的。</p>
<p>有了目前为止的这些基础，我们后面就会轻松很多。先把对象、变量等概念梳理清楚，然后再来搞这些数据结构的底层实现。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-7"><a class="header" href="#楔子-7">楔子</a></h2>
<p>从现在开始，我们就来分析 Python 的内置对象，看看它们在底层是如何实现的。但说实话，我们在前面几篇文章中介绍对象的时候，已经说了不少了，不过从现在开始要进行更深入的分析。</p>
<p>除了对象本身，还要看对象支持的操作在底层是如何实现的。我们首先以浮点数为例，因为它是最简单的，没错，浮点数比整数要简单，至于为什么，等我们分析整数的时候就知道了。</p>
<h2 id="浮点数的底层结构"><a class="header" href="#浮点数的底层结构">浮点数的底层结构</a></h2>
<p>要想搞懂浮点数的实现原理，就要知道它在底层是怎么定义的，当然在这之前我们已经见过它很多遍了。</p>
<pre><code class="language-c">// Include/floatobject.h
typedef struct {
    PyObject_HEAD
    double ob_fval;
} PyFloatObject;
</code></pre>
<p>它包含了一个公共头部 PyObject 和一个 double 类型的 ob_fval 字段，毫无疑问这个 ob_fval 字段负责存储浮点数的具体数值。</p>
<p>我们以 e = 2.71 为例，底层结构如下。</p>
<p><img src="./images/39.png" alt="" /></p>
<p>还是很简单的，每个对象在底层都是由结构体表示的，这些结构体中有的字段负责维护对象的元信息，有的字段负责维护具体的值。比如这里的 2.71，总要有一个字段来存储 2.71 这个值，而这个字段就是 ob_fval。所以浮点数的结构非常简单，直接使用一个 C 的 double 来维护。</p>
<p>假设我们要将两个浮点数相加，相信你已经知道解释器会如何做了。通过 PyFloat_AsDouble 将两个浮点数的 ob_fval 抽出来，然后相加，最后再根据相加的结果创建一个新的 PyFloatObject 即可。</p>
<h2 id="浮点数是怎么创建的"><a class="header" href="#浮点数是怎么创建的">浮点数是怎么创建的</a></h2>
<p>下面来看看浮点数是如何创建的，在前面的文章中，我们说内置对象可以使用对应的特定类型 API 创建，也可以通过调用类型对象创建。</p>
<p>调用类型对象 float 创建实例对象，解释器会执行元类 type 的 tp_call，它指向了 type_call 函数。然后 type_call 内部会先调用类型对象（这里是 float）的 tp_new 为其实例对象申请一份空间，申请完毕之后对象就创建好了。然后再调用 tp_init，并将实例对象作为参数传递进去，进行初始化，也就是设置属性。</p>
<p>但是对于 float 来说，它内部的 tp_init 字段为 0，也就是空。</p>
<p><img src="./images/40.png" alt="" /></p>
<p>这就说明 float 没有 __init__，因为浮点数太过简单，只需要一个 tp_new 即可。我们举个例子：</p>
<pre><code class="language-Python">class Girl1:
    def __init__(self, name, age):
        self.name = name
        self.age = age

# __new__ 负责开辟空间、生成实例对象
# __init__ 负责给实例对象绑定属性

# 但其实 __init__ 所做的工作可以直接在 __new__ 当中完成
# 换言之有 __new__ 就足够了，其实可以没有__init__
# 我们将上面的例子改写一下

class Girl2:
    def __new__(cls, name, age):
        instance = object.__new__(cls)
        instance.name = name
        instance.age = age
        return instance

g1 = Girl1(&quot;古明地觉&quot;, 16)
g2 = Girl2(&quot;古明地觉&quot;, 16)
print(g1.__dict__ == g2.__dict__)  # True
</code></pre>
<p>我们看到效果是等价的，因为 __init__ 负责给 self 绑定属性，而这个 self 是 __new__ 返回的。那么很明显，我们也可以在  __new__ 当中绑定属性，而不需要  __init__。</p>
<p>但是按照规范，属性绑定应该放在 __init__ 中执行。只是对于浮点数而言，由于其结构非常简单，所以底层就没有给 float 实现 __init___，所有操作都是在 __new__ 当中完成的。</p>
<pre><code class="language-Python">print(float.__init__ is object.__init__)  # True
print(tuple.__init__ is object.__init__)  # True
print(list.__init__ is object.__init__)  # False
</code></pre>
<p>所以 float 没有 __init__，即便获取拿到的也是 object 的 __init__，因为 object 是 float 的基类。同理 tuple 也没有，但 list 是有的。</p>
<p>那么下面就来看一下 PyFloat_Type 的 tp_new，看它是如何创建浮点数的。通过 PyFloat_Type 的定义我们可以看到，在创建的时候给 tp_new 字段设置的是 float_new，那么一切秘密就隐藏在 float_new 里面。</p>
<pre><code class="language-c">// Objects/clinic/floatobject.c.h
static PyObject *
float_new(PyTypeObject *type, PyObject *args, PyObject *kwargs)
{
    PyObject *return_value = NULL;
    PyObject *x = _PyLong_Zero;
    // float 不接收关键字参数，如果传递了，那么报错
    if ((type == &amp;PyFloat_Type) &amp;&amp;
        !_PyArg_NoKeywords(&quot;float&quot;, kwargs)) {
        goto exit;
    }
    // float 只接收 0 到 1 个位置参数，如果不满足，那么报错
    if (!_PyArg_CheckPositional(&quot;float&quot;, PyTuple_GET_SIZE(args), 0, 1)) {
        goto exit;
    }
    // 如果参数个数为 0，说明调用 float 时没传参数，那么直接跳转到 skip_optional 标签
    // 由于变量 x 的值初始为 _PyLong_Zero，所以在 Python 中，float() 和 float(0) 是等价的
    if (PyTuple_GET_SIZE(args) &lt; 1) {
        goto skip_optional;
    }
    // 否则说明传递了一个参数，那么获取该参数
    x = PyTuple_GET_ITEM(args, 0);
skip_optional:
    // 调用 float_new_impl，拿到返回值
    // 所以核心实现位于 float_new_impl 函数中
    return_value = float_new_impl(type, x);

exit:
    return return_value;
}


// Objects/floatobject.c
static PyObject *
float_new_impl(PyTypeObject *type, PyObject *x)
{   
    // 如果 type 不是 &amp;PyFloat_Type，那么必须是它的子类，否则调用 float_subtype_new 会报错
    // 但该条件很少触发，因为创建的是浮点数，所以 type 自然是 &amp;PyFloat_Type
    if (type != &amp;PyFloat_Type)
        return float_subtype_new(type, x); 
    // 然后检测 x 的类型，如果它是一个字符串，那么就根据字符串创建浮点数，比如 float(&quot;3.14&quot;)
    if (PyUnicode_CheckExact(x))
        return PyFloat_FromString(x);
    // 不是字符串，则调用 PyNumber_Float
    return PyNumber_Float(x);
}
</code></pre>
<p>再来看看 PyNumber_Float。</p>
<pre><code class="language-C">// Objects/abstract.c
PyObject *
PyNumber_Float(PyObject *o)
{
    PyNumberMethods *m;
    
    // 如果传递的是 NULL，直接返回错误
    if (o == NULL) {
        return null_error();
    }
    
    // 如果传递的本身就是个浮点数，那么增加引用计数，直接返回
    if (PyFloat_CheckExact(o)) {
        Py_INCREF(o);
        return o;
    }
    // 走到这里说明对象不是浮点数，那么它必须要能转成浮点数
    // 也就是类型对象的内部要有 __float__ 这个魔法函数，即 nb_float
    // 获取方法簇
    m = o-&gt;ob_type-&gt;tp_as_number;
    // 如果方法簇不为空，并且也实现了 nb_float
    if (m &amp;&amp; m-&gt;nb_float) {
        // 那么获取 nb_float 指向的函数并调用，将对像转成浮点数
        PyObject *res = m-&gt;nb_float(o);
        double val;
        // 如果 res 不为 NULL，并且是浮点数，那么返回
        // PyFloat_CheckExact 负责检测一个对象的类型是否是 &lt;class 'float'&gt;
        // 其逻辑等价于 type(res) is float
        if (!res || PyFloat_CheckExact(res)) {
            return res;
        }
        // 走到这里说明 __float__ 返回的对象不是浮点数，即对象的类型不是 float
        // 如果不是 float，那么 float 的子类目前也是可以的（会抛警告）
        // PyFloat_Check 负责检测对象的类型是否是 float 或者其子类
        // 其逻辑等价于 isinstance(res, float)
        if (!PyFloat_Check(res)) {
            // 如果返回的对象的类型不是 float 或者其子类，那么报错
            PyErr_Format(PyExc_TypeError,
                         &quot;%.50s.__float__ returned non-float (type %.50s)&quot;,
                         o-&gt;ob_type-&gt;tp_name, res-&gt;ob_type-&gt;tp_name);
            Py_DECREF(res);
            return NULL;
        }
        // 到这里说明返回的对象的类型是 float 的子类，此时也是合法的，但会抛出警告
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                &quot;%.50s.__float__ returned non-float (type %.50s).  &quot;
                &quot;The ability to return an instance of a strict subclass of float &quot;
                &quot;is deprecated, and may be removed in a future version of Python.&quot;,
                o-&gt;ob_type-&gt;tp_name, res-&gt;ob_type-&gt;tp_name)) {
            Py_DECREF(res);
            return NULL;
        }
        // res 虽然是 float 子类的实例对象，但依旧具备浮点数的特征，因此将内部的数值抽出来
        val = PyFloat_AS_DOUBLE(res);
        // 减少 res 指向对象的引用计数
        Py_DECREF(res);
        // 创建 PyFloatObject 实例，并返回它的泛型指针
        // 因此即使 __float__ 返回的是 float 子类的实例对象，也会默认转成 float 对象（浮点数）返回
        return PyFloat_FromDouble(val);
    }
    // 如果 float 接收的参数没有实现 nb_float（__float__），那么会去找 nb_index（__index__）
    if (m &amp;&amp; m-&gt;nb_index) {
        // 内部会调用对象的 nb_index
        PyObject *res = PyNumber_Index(o);
        if (!res) {
            return NULL;
        }
        // __index__ 返回的必须是整数
        // 所以调用的是 PyLong_AsDouble，表示基于 Python 整数创建 C 浮点数
        double val = PyLong_AsDouble(res);
        Py_DECREF(res);
        if (val == -1.0 &amp;&amp; PyErr_Occurred()) {
            return NULL;
        }
        // 通过 C 浮点数创建 Python 浮点数
        return PyFloat_FromDouble(val);
    }
    // 到这里说明对象没有实现 __float__ 和 __index__
    // 那么检测传递的对象的类型是不是 float 的子类
    // 如果是，证明它的结构和浮点数是一致的
    // 直接根据 ob_fval 构建 PyFloatObject
    if (PyFloat_Check(o)) {
        return PyFloat_FromDouble(PyFloat_AS_DOUBLE(o));
    }
    // 如果以上条件都不满足，说明它有可能是字节串、字节数组、字符串（但类型是 str 的子类）等等
    // 那么直接交给 PyFloat_FromString
    return PyFloat_FromString(o);
}
</code></pre>
<p>所以一个 float 调用居然要走这么多逻辑，总之解释器为我们考虑了很多。我们用 Python 来演绎一下：</p>
<pre><code class="language-Python"># 2.71 是一个字符串，所以在 float_new_impl 里面直接调用 PyFloat_FromString
print(float(&quot;2.71&quot;))  # 2.71


class E:

    def __float__(self):
        return 2.71

# 传递的参数是一个 E 类型，所以会进入 PyNumber_Float 函数
# 由于对象实现了 nb_float，所以会直接调用
print(float(E()))  # 2.71


class N:

    def __index__(self):
        return 3

# N 不是字符串类型，显然也会进入 PyNumber_Float 函数
# 由于对象实现了 nb_index，所以会直接调用
print(float(N()))  # 3.0


class PI:

    class Float(float):
        pass

    def __float__(self):
        return self.Float(3.14)

# 显然会调用内部的 __float__，但 __float__ 返回的不是 float 实例，而是 float 子类的实例
# 虽然这种做法是允许的，但会抛出警告，警告的内容就是源码中描述的那样
# DeprecationWarning: PI.__float__ returned non-float (type Float).
print(float(PI()))  # 3.14


# 参数不是字符串，也没有实现 __float__ 和 __index__，那么直接执行 PyFloat_FromString
print(float(b&quot;1.414&quot;))  # 1.414
</code></pre>
<p>以上是通过类型对象创建，但在底层实际上也是调用了对象的<font color="red">特定类型 APl</font>。</p>
<pre><code class="language-C">PyObject *
PyFloat_FromDouble(double);

PyObject *
PyFloat_FromString(PyObject *);
</code></pre>
<ul>
<li>PyFloat_FromDouble：基于 C 浮点数创建 Python 浮点数；</li>
<li>PyFloat_FromString：基于字符串创建 Python 浮点数；</li>
</ul>
<p>如果以 e = 2.71 这种方式创建，那么解释器在编译的时候就知道这是一个浮点数，因此会一步到胃，直接调用 PyFloat_FromDouble，然后在该函数内部会根据 C 的浮点数 2.71 创建对应的 PyFloatObject。而通过类型对象调用的话则会有一些额外的开销，因为这种方式最终也会调用相关的特定类型 API，但是在调用之前会干一些别的事情，比如类型检测等等。</p>
<p><img src="./images/41.png" alt="" /></p>
<p>所以 e = 2.71 比 float(2.71)、float(&quot;2.71&quot;) 都要高效。</p>
<p>因此对于内置对象来说，可以调用它的类型对象去创建，这是最通用的逻辑。但这种做法会先兜个圈子，然后再去使用对象的<font color="red">特定类型 API</font>，肯定没有直接使用<font color="red">特定类型 API </font>的效率高，也就是说 e = 2.71 这种方式是最快的，底层会直接调用 PyFloat_FromDouble。</p>
<p>对于其它对象也是同理，当然大部分情况下我们也都是使用<font color="red">特定类型 API</font> 来创建的。以列表为例，比起 list()，我们更习惯使用［］。</p>
<p>还没结束，浮点数的实际创建过程我们还没有见到，因为最终还是调用特定类型 API 创建的。那么接下来就以 PyFloat_FromDouble 函数为例，看看浮点数在底层的创建过程。</p>
<pre><code class="language-C">// Objects/floatobject.c

// 缓存池（链表）的最大长度，也就是缓存池最多能容纳多少个元素
#define PyFloat_MAXFREELIST    100
// 缓存池已经容纳了多少个元素，最多不能超过 PyFloat_MAXFREELIST
static int numfree = 0;
// 指向缓存池（链表）的头结点，因为缓存池是一个由 PyFloatObject 实例组成的链表
static PyFloatObject *free_list = NULL;
// 介绍引用计数时说过，引用计数如果为 0，那么对象会被销毁
// 但是对象所占的内存则不一定释放，而是会缓存起来，浮点数也是如此
// 销毁浮点数时，会将其放入缓存池中，创建浮点数时，也会优先从缓存池里面获取
// 而缓存池是使用链表实现的，每一个节点都是一个 PyFloatObject 实例，然后 free_list 指向链表的头节点

PyObject *
PyFloat_FromDouble(double fval)
{   
    // 如果 op 不为 NULL，说明缓存池中有可用对象
    PyFloatObject *op = free_list;
    if (op != NULL) {
        // 而一旦获取了，那么要维护 free_list，让它指向下一个节点
        // 但问题来了，为啥获取下一个节点要通过 Py_TYPE，它不是负责返回 ob_type 吗？
        // 相信你已经猜到原因了，因为 ob_type 充当了链表中的 next 指针
        // 关于这里的细节，后续介绍缓存池的时候会详细说
        free_list = (PyFloatObject *) Py_TYPE(op);
        // 然后还要将缓存池（链表）的节点个数减 1
        numfree--;
    } else {
        // 否则说明缓存池里面没有空闲的可用对象，那么要重新申请内存
        // PyObject_MALLOC 是基于 malloc 的一个封装，但对内存碎片做了优化
        op = (PyFloatObject*) PyObject_MALLOC(sizeof(PyFloatObject));
        if (!op)
            return PyErr_NoMemory();
    }
    // 走到这里说明内存分配好了，PyFloatObject 也创建了
    // 但是不是还少了点啥呢？没错，显然内部的字段还没有初始化
    // 还是那句话，内置类型的实例对象该分配多少空间，解释器了如指掌
    // 因为通过 PyFloatObject 内部的字段一算就出来了
    // 所以虽然对象创建了，但是 ob_refcnt、ob_type、以及 ob_fval 三个字段还没有初始化
    // 因此还要将其 ob_refcnt 设置为 1，因为新创建的对象的引用计数是 1
    // 以及将 ob_type 设置为指向 PyFloat_Type 的指针，因为它的类型是 float
    // 而 PyObject_INIT 专们用来设置 ob_refcnt 以及 ob_type，它的源码解释在下面
    (void)PyObject_INIT(op, &amp;PyFloat_Type);
    // 将内部的 ob_fval 字段设置为参数 fval，此时三个字段都已经初始化完毕
    op-&gt;ob_fval = fval;
    // 变量是泛型指针 PyObject *，所以还要转成 PyObject * 之后才能返回
    return (PyObject *) op;
}


// 补充：PyObject_INIT 的定义如下
// Include/objimpl.h
#define PyObject_INIT(op, typeobj) \
    _PyObject_INIT(_PyObject_CAST(op), (typeobj))

static inline PyObject*
_PyObject_INIT(PyObject *op, PyTypeObject *typeobj)
{
    assert(op != NULL);
    // 设置实例对象的 ob_type
    Py_TYPE(op) = typeobj;
    // 如果 typeobj 是自定义的动态类，那么还要将类型对象的引用计数加 1
    // 因为实例对象创建了，意味着类型对象会多一个引用
    // 当然这只是针对于动态类，如果 typeobj 是内置的静态类型，那么不做处理
    // 因为内置类型超越了引用计数规则，永远不会被析构
    if (PyType_GetFlags(typeobj) &amp; Py_TPFLAGS_HEAPTYPE) {
        Py_INCREF(typeobj);
    }
    // 将实例对象的引用计数初始化为 1
    _Py_NewReference(op);
    return op;
}


// Objects/floatobject.c
void
_Py_NewReference(PyObject *op)
{
    if (_Py_tracemalloc_config.tracing) {
        _PyTraceMalloc_NewReference(op);
    }
    _Py_INC_REFTOTAL;
    // 初始化为 1
    op-&gt;ob_refcnt = 1;
    _Py_AddToAllObjects(op, 1);
    _Py_INC_TPALLOCS(op);
}
</code></pre>
<p><strong>所以整体流程如下：</strong></p>
<ul>
<li>为实例对象分配内存空间，空间分配完了对象也就创建了，不过会优先使用缓存池；</li>
<li>初始化实例对象内部的引用计数和类型指针；</li>
<li>初始化 ob_fval 字段为参数 fval；</li>
</ul>
<p>另外这里又体现了之前说的一个现象，对于自定义的类而言，想要创建实例对象必须要借助于类型对象。但使用特定类型 API 创建浮点数，却压根不需要类型对象 float，而是直接就创建了。创建完之后再让其 ob_type 字段指向 float，将类型和实例关联起来即可。</p>
<p>而之所以能这么做的根本原因就在于，内置类型的实例对象在底层都是静态定义好的，字段已经写死了，所以创建的时候不需要类型对象。解释器知道创建这样的对象需要分配多少内存，所以会直接创建，创建完之后再对内部字段进行初始化，比如设置引用计数和类型。</p>
<p>但对于我们自定义的类而言，想要创建实例对象就必须要借助于类型对象了。</p>
<h2 id="浮点数是怎么销毁的"><a class="header" href="#浮点数是怎么销毁的">浮点数是怎么销毁的</a></h2>
<p>当删除一个变量时，解释器会通过函数 Py_DECREF 来减少该变量指向的对象的引用计数，并判断引用计数减一之后是否为 0，如果为 0 则调用其类型对象的 tp_dealloc 回收该对象。</p>
<pre><code class="language-C">// Include/object.h
#define Py_INCREF(op) _Py_INCREF(_PyObject_CAST(op))

static inline void _Py_DECREF(const char *filename, int lineno,
                              PyObject *op)
{
    // ...
    if (--op-&gt;ob_refcnt != 0) {
        // ...
    }
    else {
        _Py_Dealloc(op);
    }
}

// Objects/object.c
void
_Py_Dealloc(PyObject *op)
{
    destructor dealloc = Py_TYPE(op)-&gt;tp_dealloc;
    // 函数里面有个宏判断，编译展开之后就是下面这一行
    (*dealloc)(op);
}
</code></pre>
<p>所以当浮点数被销毁时，会调用 PyFloat_Type 的 tp_dealloc，这是显然的。而 PyFloat_Type 的 tp_dealloc 被初始化为 float_dealloc。</p>
<p><img src="./images/42.png" alt="" /></p>
<p>在 float_dealloc 函数内部我们会清晰地看到一个浮点数被销毁的全部过程，关于它的源代码，我们会在介绍缓存池的时候细说。总之到这里我们已经知道了浮点数被销毁的整个流程，下面来画张图描述一下。</p>
<p><img src="./images/43.png" alt="" /></p>
<p>以上就是浮点数对象被销毁的流程图，整个过程很简单。</p>
<p>在将对象的引用计数减 1 之后会判断是否为 0，如果为 0，则调用 _Py_Dealloc 销毁对象。而在 _Py_Dealloc 内部会获取对象的类型对象，然后拿到类型对象的 tp_dealloc 字段指向的函数。对于浮点数来说，这个函数就是 float_dealloc。</p>
<p>然后执行 <font color="blue">float_dealloc(obj)</font> 将对象销毁，但占用的空间会被缓存起来（取决于是否有缓存池以及缓存池的容量）。</p>
<p>所以整个流程理解起来没有任何难度，里面唯一没有说的就是 float_dealloc，即浮点数的具体销毁过程，这个等介绍缓存池的时候再一起说。</p>
<h2 id="小结-9"><a class="header" href="#小结-9">小结</a></h2>
<p>以上就是浮点数在底层的创建和销毁过程，下一篇文章来聊一聊浮点数的缓存池。当一些占用内存较小的对象在被销毁时，不会释放所占的内存，而是缓存起来。等下一次再使用的时候，直接从缓存池中获取，从而避免了频繁申请内存。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-8"><a class="header" href="#楔子-8">楔子</a></h2>
<p>浮点数这种对象经常容易被创建和销毁，因为它很简单，使用频率高。如果每次创建都借助操作系统分配内存、每次销毁都借助操作系统回收内存的话，那效率会低到什么程度，可想而知。</p>
<p>因此 Python 解释器在操作系统之上封装了一个内存池，在内存管理的时候会详细介绍，目前可以认为内存池就是解释器预先向操作系统申请的一部分内存，专门用于小对象的快速创建和销毁，从而避免了频繁和操作系统打交道，这便是 Python 的内存池机制。</p>
<p>但浮点数的使用频率很高，并且使用时还会创建和销毁大量的临时对象，举个例子:</p>
<pre><code class="language-Python">a = 95.5
b = 117.3
c = 108.9

avg = (a + b + c) / 3
</code></pre>
<p>计算平均值的时候，会先计算 a + b，创建一个临时对象。接着让临时对象和 c 相加再创建一个临时对象，然后除以 3得到结果。最后销毁临时对象，并将结果交给变量 avg。</p>
<p>尽管我们平常很少注意到这些，但运算背后所产生的对象的创建和销毁的次数，比我们想象的要多。特别是在循环的时候，会伴随大量的对象创建和销毁操作，
如果每次创建和销毁对象都要伴随着内存操作，这个时候即便有内存池机制，效率也是不高的，因为使用内存池虽然可以不经过操作系统，但它也会增加解释器系统的开销。</p>
<p>因此解释器在浮点数对象被销毁后，并不急着回收对象所占用的内存，换句话说其实对象还在，只是将该对象放入一个空闲的链表中。之前我们说对象可以理解为一片内存空间，对象如果被销毁，那么理论上内存空间要归还给操作系统，或者回到内存池中。但 Python 考虑到效率，并没有真正地释放内存，而是将对象放入到链表中，占用的内存还在。</p>
<p>后续如果需要创建新的浮点数对象时，那么从链表中直接取出之前放入的对象（我们认为被回收的对象），然后根据新的浮点数对象重新初始化对应的字段即可，这样就避免了内存分配造成的开销。而这个链表就是我们说的<font color="blue">缓存池</font>，当然不光浮点数对象有缓存池，Python 的很多其它对象也有对应的缓存池，比如列表。</p>
<h2 id="缓存池的实现细节"><a class="header" href="#缓存池的实现细节">缓存池的实现细节</a></h2>
<p>下面看一下浮点数的缓存池的具体细节。</p>
<pre><code class="language-C">// Objects/floatobject.c

// 缓存池（链表）的最大长度
// 因此池子里面最多容纳 100 个 PyFloatobject
#define PyFloat_MAXFREELIST    100

// 缓存池已经容纳了多少个 PyFloatobject
static int numfree = 0;
// 指向缓存池（链表）的头节点
static PyFloatObject *free_list = NULL;
</code></pre>
<p>我们观察一下 free_list，发现它是一个 PyFloatObect *，这就说明缓存池（链表）中的每一个节点都是 PyFloatObject 实例。但以我们刷 Leetcode 的经验，链表里的每个节点应该有一个 next 字段指向下一个节点，可 PyFloatObject 里面似乎并没有这样的字段啊。</p>
<p>相信你已经猜到原因了，因为解释器是使用 ob_type 字段来指向下一个对象。本来 ob_type 指向的应该是 PyFloat_Type，但在缓存池中指向的是下一个 PyFloatObject。</p>
<p><img src="./images/44.png" alt="" /></p>
<p>以上就是浮点数的缓存池，说白了就是一个链表，free_list 指向链表的头节点，节点之间通过 ob_type 字段充当 next 指针。</p>
<h2 id="再探浮点数的创建与销毁"><a class="header" href="#再探浮点数的创建与销毁">再探浮点数的创建与销毁</a></h2>
<p>我们以 PyFloat_FromDouble 这个 API 为例，再回顾一下浮点数的创建,</p>
<pre><code class="language-C">// Objects/floatobject.c

PyObject *
PyFloat_FromDouble(double fval)
{   
    // 获取缓存池的头结点指针
    PyFloatObject *op = free_list;
    // 如果 op 不为 NULL，说明它指向了 PyFloatObject
    // 换句话说就是，缓存池里面有可用节点
    if (op != NULL) {
        // 维护 free_list，让它指向链表的下一个节点
        free_list = (PyFloatObject *) Py_TYPE(op);
        // 缓存池的节点个数减 1
        numfree--;
    } else {
        op = (PyFloatObject*) PyObject_MALLOC(sizeof(PyFloatObject));
        if (!op)
            return PyErr_NoMemory();
    }
    (void)PyObject_INIT(op, &amp;PyFloat_Type);
    op-&gt;ob_fval = fval;
    return (PyObject *) op;
}
</code></pre>
<p>在链表中，ob_type 被用于指向下一个节点，换言之 ob_type 保存的是下一个 <font color="blue">PyFloatObject 的地址</font>。不过话虽如此，可 ob_type 的类型仍是 PyTypeObject *。因此在存储的时候，PyFloatObject * 一定是先转成了 PyTypeObject *，之后再交给 ob_type 保存。因为对于指针来说，是可以任意转化的，我们一会儿看 float_dealloc 的时候就知道了。</p>
<p>那么同理，这里的 Py_TYPE(op) 在获取下一个节点的指针之后，还要再转成 PyFloatObject *，然后才能交给 free_list 保存。如果没有下一个对象了，那么 free_list 就是 NULL，在下一次分配的时候，上面的 <font color="blue">if (op!=NULL)</font> 就会不成立，从而走下面的 else，使用 PyObject_MALLOC 重新分配内存。</p>
<p>既然对象创建时可以从缓存池获取，那么销毁的时候，肯定要放入到缓存池中。而销毁对象时，会调用类型对象的 tp_dealloc（析构函数），对于浮点数而言就是 float_dealloc，我们看一下源代码。</p>
<pre><code class="language-C">static void
float_dealloc(PyFloatObject *op)
{   
    // 如果要放入浮点数的缓存池，那么它必须是浮点数
    if (PyFloat_CheckExact(op)) {
        // 如果缓存池中的节点个数已经达到了 PyFloat_MAXFREELIST，那么直接释放掉
        if (numfree &gt;= PyFloat_MAXFREELIST)  {
            PyObject_FREE(op);
            return;
        }
        // 否则放入到缓存池中
        // 缓存池的节点个数加 1
        numfree++;
        // 因为对象要成为链表的新头结点，那么它的 ob_type（充当 next）要指向当前头结点
        // 所以将 ob_type 的值设置为 state-&gt;free_list 即可
        // 但 ob_type 字段的类型为 PyTypeObject *，而 free_list 是 PyFloatobject *
        // 因此赋值之后，要将类型转换一下
        Py_TYPE(op) = (struct _typeobject *)free_list;
        // 然后将 op 赋值为 state-&gt;free_list，也就是让 free_list 指向新的头结点
        free_list = op;
    }
    // 如果销毁的对象不是浮点数，而是 float 子类的实例，那么直接释放内存
    else
        Py_TYPE(op)-&gt;tp_free((PyObject *)op);
}

</code></pre>
<p>以上便是浮点数缓存池的具体实现，说白了缓存池的作用只有一个，就是在对象被销毁的时候不释放所占的内存，下次创建新的对象时能够直接拿来用。因为内存没有被释放，因此创建起来就会快很多。</p>
<h2 id="侵入-pyfloatobject"><a class="header" href="#侵入-pyfloatobject">侵入 PyFloatObject</a></h2>
<p>下面我们修改解释器源代码，当创建和销毁浮点数的时候，打印一些日志信息。</p>
<p><img src="./images/45.png" alt="" /></p>
<p>日志信息以字典的形式打印，里面有三个 key，含义如下：</p>
<ul>
<li>action：如果值为 &quot;from_freelist&quot;，表示从缓存池获取对象；如果值为 &quot;to_freelist&quot; 表示对象放入缓存池。</li>
<li>numfree：从缓存池获取对象、或将对象放入缓存池之后的元素个数。</li>
<li>address of object：创建或销毁的对象的地址。</li>
</ul>
<p>当创建 f1 的时候，指向的浮点数会从缓存池中获取，日志信息中的对象地址显然和 Python 里打印的地址是一样的。然后 <font color="blue">del f1</font>，会将对象放入缓存池中。最后新建一个变量 f2，显然它指向的浮点数会复用 f1 指向的浮点数的内存。</p>
<p>再举个例子：</p>
<p><img src="./images/46.png" alt="" /></p>
<p>我们重新创建变量 f1、f2，并打印对象地址，然后删除 f1、f2 变量，之后再重新创建 f1、f2 变量并打印对象地址，结果发现地址在删除前后正好是相反的。至于原因，如果思考一下将对象放入缓存池、以及从缓存池获取对象时所采取的策略，那么很容易就明白了。</p>
<p>因为 <font color="blue">del f1,f2</font> 的时候会先删除 f1，再删除 f2。删除 f1 的时候，会将 f1 指向的对象作为链表中的头结点，然后删除 f2 的时候，会将 f2 指向的对象作为链表中新的头结点，所以之前 f1 指向的对象就变成了链表中的第二个节点。</p>
<blockquote>
<p>浮点数缓存池在添加节点的时候，采用的是头插法。</p>
</blockquote>
<p>而获取的时候，也会从链表的头部开始获取，所以当重新创建变量 f1 的时候，其指向的对象使用的是之前变量 f2 指向的对象所占的内存，而一旦获取，那么 free_list 指针会指向下一个节点。然后创建变量 f2 的时候，其指向的对象使用的就是之前变量 f1 指向的对象所占的内存。</p>
<p>因此前后打印的地址是相反的，所以我们算是通过实践从另一个角度印证了之前分析的结论。</p>
<h2 id="通过-ctypes-模拟底层数据结构"><a class="header" href="#通过-ctypes-模拟底层数据结构">通过 ctypes 模拟底层数据结构</a></h2>
<p>有时我们想观察底层数据结构的表现行为时，不一定非要修改解释器，因为那样太麻烦，还要重新编译。Python 在上层提供了一种方式，可以让我们通过 Python 的类轻松地模拟 C 的结构体。</p>
<pre><code class="language-python">from ctypes import *


class PyObject(Structure):
    &quot;&quot;&quot;
    继承 ctypes.structure，便可以得到c的结构体
    然后通过 fields 指定结构体字段
    &quot;&quot;&quot;
    # _fields_ 是一个列表，内部的元组对应结构体的字段
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
    ]
    # ob_refcnt 是 Py_ssize_t 类型，等价于 c_ssize_t
    # 至于 ob_type，我们就指定 void *，因为暂时不用这个字段


class PyFloatObject(PyObject):
    &quot;&quot;&quot;
    继承 Pyobject，相当于结构体的嵌套
    &quot;&quot;&quot;
    _fields_ = [
        (&quot;ob_fval&quot;, c_double)
    ]


e = 2.71
# 创建 PyFloatObject 实例，返回它的指针
# from_address 表示根据对象的地址创建
f = PyFloatObject.from_address(id(e))
# 此时 e 和 f 都指向了 2.71 这个浮点数

# 注意接下来会发生神奇的一幕
print(e)  # 2.71
print(hex(id(e)))  # 0x1f94d2382f0

# f 等价于底层的 PyFloatObject *，修改 ob_fval 字段
f.ob_fval = 3.14
print(e)  # 3.14
print(hex(id(e)))  # 0x1f94d2382f0
</code></pre>
<p>我们看到 id(e) 在前后并没有发生改变，证明 e 指向的始终是同一个对象，但是它的值却变了。咦，不是说浮点数是不可变对象吗？<font color="blue">如果想变的话只能创建一个新的浮点数</font>，这样一来前后打印的地址应该会变才对啊。</p>
<p>首先说明结论是没错的，可这是从 Python 的角度而言。如果是从解释器的角度来看的话，没有什么可变不可变，只要我们想让它可变，那么它就是可变的。</p>
<p>另外为了更好地观察底层数据结构的表现，我们后面会经常使用这种方式，而且会介绍更多的骚操作，但是切记这种动态修改解释器的做法不可用于生产环境。</p>
<h2 id="小结-10"><a class="header" href="#小结-10">小结</a></h2>
<p>以上就是浮点数的缓存池机制，简单来说是一种<font color="blue">空间换时间</font>的做法。</p>
<p>为了避免频繁地和内核打交道，CPython 引入了内存池机制，事先会向操作系统申请一部分内存，然后根据大小划分成不同的单元，按需分配。这样就无需频繁和操作系统的内核打交道了，因为系统调用是代价昂贵的操作。</p>
<p>但有了内存池还不够，我们知道 Python 对象是分配在堆上的，而在堆上分配内存效率要比栈差很多。所以又引入了缓存池，对象在被销毁后不释放所占内存，而是通过一个链表串起来，留着下次备用。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-9"><a class="header" href="#楔子-9">楔子</a></h2>
<p>本篇文章来聊一聊浮点数支持的操作，之前说过实例对象的相关操作都定义在类型对象里面，所以我们需要查看 PyFloat_Type。</p>
<pre><code class="language-C">// Objects/floatobject.c
PyTypeObject PyFloat_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;float&quot;,
    sizeof(PyFloatObject),
    // 浮点数的 __repr__ 方法
    (reprfunc)float_repr,                       /* tp_repr */
    // 浮点数作为数值对象拥有的算数操作
    &amp;float_as_number,                           /* tp_as_number */
    // ...
    // 浮点数的哈希操作
    (hashfunc)float_hash,                       /* tp_hash */
    // ...
    // 浮点数支持的比较操作
    float_richcompare,                          /* tp_richcompare */
    // ...
};

</code></pre>
<p>还是之前说的，Python 底层的函数命名以及 API 都是很有规律的，举个例子：</p>
<ul>
<li>tp_repr 字段表示实例对象的字符串格式化，在 PyFloat_Type 里面它被赋值为 float_repr。</li>
<li>tp_hash 字段表示实例对象的哈希操作，在 PyFloat_Type 里面它被赋值为 float_hash。</li>
<li>tp_richcompare 字段表示实例对象的比较操作，所有的比较运算均由该字段负责实现，在 PyFloat_Type 里面它被赋值为 float_richcompare。</li>
</ul>
<p>下面我们来通过源码看一下底层实现。</p>
<h2 id="浮点数的字符串打印"><a class="header" href="#浮点数的字符串打印">浮点数的字符串打印</a></h2>
<p>由于 PyFloat_Type 没有实现 tp_str（字段的值为 0 ），所以打印一个浮点数会执行 tp_repr，它对应的具体实现为 float_repr 函数。</p>
<pre><code class="language-C">// Objects/floatobject.c

static PyObject *
float_repr(PyFloatObject *v)
{
    PyObject *result;  // 返回值
    char *buf;
    // 将 Python 浮点数转成 C 的浮点数，然后再转成字符串
    buf = PyOS_double_to_string(PyFloat_AS_DOUBLE(v),
                                'r', 0,
                                Py_DTSF_ADD_DOT_0,
                                NULL);
    if (!buf)
        return PyErr_NoMemory();
    // 基于 C 字符串创建 Python 字符串
    result = _PyUnicode_FromASCII(buf, strlen(buf));
    // 释放 buf，然后返回
    PyMem_Free(buf);
    return result;
}
</code></pre>
<p>比较简单，当然具体的转换逻辑由 PyOS_double_to_string 函数负责，内部最终会调用 C 的库函数，感兴趣可以看一下。</p>
<h2 id="浮点数的哈希值"><a class="header" href="#浮点数的哈希值">浮点数的哈希值</a></h2>
<p>获取浮点数的哈希值会执行 tp_hash，它对应的具体实现为 float_hash。</p>
<pre><code class="language-C">// Objects/floatobject.c
static Py_hash_t
float_hash(PyFloatObject *v)
{
    return _Py_HashDouble(v-&gt;ob_fval);
}
</code></pre>
<p>具体的哈希计算逻辑由 _Py_HashDouble 负责，通过 <code>v-&gt;ob_fval</code> 拿到 C 浮点数，然后传进去计算哈希值。</p>
<p><img src="./images/47.png" alt="" /></p>
<p>感兴趣可以看一下具体的哈希值计算逻辑，该函数位于 Python/pyhash.c 中。</p>
<h2 id="浮点数的比较操作"><a class="header" href="#浮点数的比较操作">浮点数的比较操作</a></h2>
<p>浮点数之间的比较操作由 tp_richcompare 字段负责实现，该字段的值为 float_richcompare。</p>
<pre><code class="language-C">// Include/object.h
#define Py_LT 0  // 小于
#define Py_LE 1  // 小于等于
#define Py_EQ 2  // 等于
#define Py_NE 3  // 不等于
#define Py_GT 4  // 大于
#define Py_GE 5  // 大于等于

// Objects/floatobject.c
static PyObject*
float_richcompare(PyObject *v, PyObject *w, int op)
{   
   // 假设在 Python 里面执行了 3.14 == 2.71
   // 那么这里的 v 和 w 就会指向 3.14 和 2.71，而 op 就是 Py_EQ
    double i, j;
    int r = 0;

    assert(PyFloat_Check(v));
    // 通过 ((PyFloatObject *) v)-&gt;ob_fval 拿到具体的 C 浮点数
    i = PyFloat_AS_DOUBLE(v);

    // 变量只是泛型指针 PyObject *，它究竟指向什么类型的对象是需要判断的
    // 对于 v == w 来讲，如果能执行该函数，我们只能确保 v 一定指向浮点数，但 w 则不一定
    // 所以需要判断，如果 w 的类型是 float 或者 float 的子类，那么转成 C double 并赋值给 j
    if (PyFloat_Check(w))
        // 绝大部分情况都会触发此分支
        j = PyFloat_AS_DOUBLE(w);

    else if (!Py_IS_FINITE(i)) {
        // ...
    }

    else if (PyLong_Check(w)) {
        // ...
    } 

    else        /* w isn't float or int */
        goto Unimplemented;

 Compare:
    PyFPE_START_PROTECT(&quot;richcompare&quot;, return NULL)
    // 拿到 i 和 j 之后，判断 op 是哪一种操作符，然后执行相应的比较逻辑      
    switch (op) {
    case Py_EQ:
        r = i == j;
        break;
    case Py_NE:
        r = i != j;
        break;
    case Py_LE:
        r = i &lt;= j;
        break;
    case Py_GE:
        r = i &gt;= j;
        break;
    case Py_LT:
        r = i &lt; j;
        break;
    case Py_GT:
        r = i &gt; j;
        break;
    }
    PyFPE_END_PROTECT(r)
    return PyBool_FromLong(r);

 Unimplemented:
    Py_RETURN_NOTIMPLEMENTED;
}
</code></pre>
<p>该函数的代码量还是有一些大的，但逻辑很好理解，主要是会对 w 做一些类型上的检测。因为 w 不一定是浮点数，比如 <font color="blue">3.14 != []</font> 同样会触发该函数，但函数里的 w 指向的就不是浮点数，而是列表。</p>
<p>不过大部分情况下，两个对象比较的时候，如果符号左侧是浮点数，那么右侧基本也是浮点数。所以基本上都会走开始的 if 分支，然后进入比较逻辑。但如果符号右侧不是浮点数，那么会执行剩下的分支，逻辑会更复杂一些。</p>
<h2 id="浮点数的算数操作"><a class="header" href="#浮点数的算数操作">浮点数的算数操作</a></h2>
<p>最后是重头戏，来看看浮点数是如何运算的。由于加减乘除等算术操作很常见，所以解释器将其抽象成 PyNumberMethods 方法簇。对于数值型对象来说，它的类型对象会实现此方法簇，并由 tp_as_number 字段指向。</p>
<pre><code class="language-C">// Include/cpython/object.h
typedef struct {
    binaryfunc nb_add;
    binaryfunc nb_subtract;
    binaryfunc nb_multiply;
    binaryfunc nb_remainder;
    binaryfunc nb_divmod;
    ternaryfunc nb_power;
    unaryfunc nb_negative;
    unaryfunc nb_positive;
    unaryfunc nb_absolute;
    inquiry nb_bool;
    unaryfunc nb_invert;
    binaryfunc nb_lshift;
    binaryfunc nb_rshift;
    binaryfunc nb_and;
    binaryfunc nb_xor;
    binaryfunc nb_or;
    // ...
} PyNumberMethods;
</code></pre>
<p>PyNumberMethods 这个结构体在前面已经介绍过，每个字段都是一个函数指针，对应一个算术操作。而根据参数个数的不同，这些函数可以分为多种。</p>
<p><img src="./images/48.png" alt="" /></p>
<ul>
<li>unaryfunc： 一元函数，只接收一个参数，返回 PyObject *；</li>
<li>binaryfunc： 二元函数，接收两个参数，返回 PyObject *；</li>
<li>ternaryfunc： 三元函数，接收三个参数，返回 PyObject *；</li>
<li>inquiry：一元函数，接收一个参数，但返回的是 int。</li>
</ul>
<p>它们本质上就是解释器基于参数的类型和个数而起的别名，除了以上这些，还有很多其它的别名，具体可以查看 Include/object.h。</p>
<p>由于浮点数是数值型对象，所以 PyFloat_Type 实现了该方法簇，值为 float_as_number，来看一下，它位于 Objects/floatobject.c 中。</p>
<p><img src="./images/49.png" alt="" /></p>
<p>像 float_add 负责浮点数的加法运算，float_sub 负责浮点数的减法运算，都比较简单。但我们看到有的函数指针被赋值成了 0，如果为 0 则表示不支持相应操作，比如浮点数不支持位运算。</p>
<blockquote>
<p>在 C 语言中，给指针类型的字段赋值为 0 和赋值为 NULL 是等价的。</p>
</blockquote>
<p>好，下面我们以加法运算为例，看一下具体实现。</p>
<pre><code class="language-C">// Objects/floatobject.c
static PyObject *
float_add(PyObject *v, PyObject *w)
{
    // 显然两个 Python 浮点数相加，一定是先转成 C 的浮点数，然后再相加
    // 加完之后再根据结果创建新的 Python 浮点数
    double a,b;  // 声明两个 double 变量
    // CONVERT_TO_DOUBLE 是一个宏，从名字上也能看出来它的作用
    // 将 PyFloatObject 里面的 ob_fval 抽出来，赋值给 double 变量
    CONVERT_TO_DOUBLE(v, a);
    CONVERT_TO_DOUBLE(w, b);
    PyFPE_START_PROTECT(&quot;add&quot;, return 0)
    // 将 a 和 b 相加，然后再重新赋值给 a      
    a = a + b;
    PyFPE_END_PROTECT(a)
    // 根据相加后的结果创建新的 PyFloatObject 对象
    // 并将其指针转成 PyObject * 之后返回
    return PyFloat_FromDouble(a);
}
</code></pre>
<p>以上就是浮点数的加法运算，核心如下：</p>
<ul>
<li>定义两个 double 变量 a 和 b。</li>
<li>将相加的两个 Python 浮点数维护的值（ob_fval）抽出来，交给 a 和 b。</li>
<li>让 a 和 b 相加，将相加的结果传入 PyFloat_FromDouble 函数中创建新的 PyFloatObject，然后返回其 PyObject *。</li>
</ul>
<blockquote>
<p>另外 float_add 里面还有两个宏我们没有说，分别是：PyFPE_START_PROTECT 和 PyFPE_END_PROTECT，它们是做什么的呢？首先浮点数计算一般都遵循 IEEE-754 标准，如果计算时出现了错误，那么需要将 IEEE-754 异常转换成 Python 异常，而这两个宏就是用来干这件事情的。</p>
<p>所以我们不需要管它，这两个宏定义在 Include/pyfpe.h 中，并且已经在 Python3.9 的时候被移除了。</p>
</blockquote>
<p>以上便是浮点数的加法运算，所谓的浮点数在底层就是一个 PyFloatObject 结构体实例。而结构体实例无法直接相加，所以必须先将结构体中维护的值抽出来，对于浮点数而言就是 ob_fval，然后转成 C 的 double 再进行相加。最后根据相加的结果创建新的结构体实例，于是新的 Python 对象便诞生了。</p>
<p>假设 <font color="blue">a, b = 1.1, 2.2</font>，那么 c = a + b 的流程如下所示：</p>
<p><img src="./images/50.png" alt="" /></p>
<p>但如果是 C 的两个浮点数相加，那么编译之后就是一条简单的机器指令，然而 Python 则需要额外做很多其它工作。并且后续在介绍整数的时候，你会发现 Python 的整数相加更麻烦，但对于 C 而言同样是一条简单的机器码就可以搞定。</p>
<blockquote>
<p>所以为什么 Python 会比 C 慢很多倍，从一个简单的加法上面就可以看出来。</p>
</blockquote>
<p>以上是浮点数的加法操作，至于减法、乘法、除法等操作也是类似的。</p>
<pre><code class="language-C">// Objects/floatobject.c
static PyObject *
float_add(PyObject *v, PyObject *w)
{
    double a,b;
    CONVERT_TO_DOUBLE(v, a);
    CONVERT_TO_DOUBLE(w, b);
    PyFPE_START_PROTECT(&quot;add&quot;, return 0)
    a = a + b;
    PyFPE_END_PROTECT(a)
    return PyFloat_FromDouble(a);
}

static PyObject *
float_sub(PyObject *v, PyObject *w)
{
    double a,b;
    CONVERT_TO_DOUBLE(v, a);
    CONVERT_TO_DOUBLE(w, b);
    PyFPE_START_PROTECT(&quot;subtract&quot;, return 0)
    a = a - b;
    PyFPE_END_PROTECT(a)
    return PyFloat_FromDouble(a);
}

static PyObject *
float_mul(PyObject *v, PyObject *w)
{
    double a,b;
    CONVERT_TO_DOUBLE(v, a);
    CONVERT_TO_DOUBLE(w, b);
    PyFPE_START_PROTECT(&quot;multiply&quot;, return 0)
    a = a * b;
    PyFPE_END_PROTECT(a)
    return PyFloat_FromDouble(a);
}

static PyObject *
float_div(PyObject *v, PyObject *w)
{
    double a,b;
    CONVERT_TO_DOUBLE(v, a);
    CONVERT_TO_DOUBLE(w, b);
    if (b == 0.0) {
        PyErr_SetString(PyExc_ZeroDivisionError,
                        &quot;float division by zero&quot;);
        return NULL;
    }
    PyFPE_START_PROTECT(&quot;divide&quot;, return 0)
    a = a / b;
    PyFPE_END_PROTECT(a)
    return PyFloat_FromDouble(a);
}
</code></pre>
<p>代码逻辑是类似的，整个过程就是将 Python 浮点数里面的值抽出来，得到 C 浮点数，然后进行运算，再基于运算的结果创建 Python 浮点数，并返回它的泛型指针。</p>
<h2 id="小结-11"><a class="header" href="#小结-11">小结</a></h2>
<p>到此浮点数就介绍完了，之所以先介绍浮点数，是因为浮点数最简单。至于整数，其实并没有那么简单，因为它的值在底层是通过数组存储的。而浮点数的值则是用一个 double 类型的字段来维护，会更简单一些，所以我们就先拿浮点数<font color="blue">开刀</font>了。</p>
<p>首先我们介绍了浮点数的创建和销毁，创建有两种方式，分别是使用对象的<font color="blue">特定类型API</font> 和调用类型对象。前者速度更快，但只适用于内置数据结构，而后者更加通用。</p>
<p>销毁的时候则调用类型对象内部的 tp_dealloc 字段指向的 float_dealloc 函数。当然为了保证效率，避免内存的频繁创建和回收，解释器为浮点数引入了缓存池机制，我们也分析了背后的原理。</p>
<p>最后浮点数还支持数值运算，PyFloat_Type 的 tp_as_number 字段指向了 PyNumberMethods 结构体实例 float_as_number，里面有大量的函数指针，每个指针指向了具体的函数，专门用于浮点数的运算。至于运算的具体逻辑，我们也以加法为例详细介绍了 float_add 函数的实现。核心就是将 Python 对象内部的值抽出来，转成 C 的类型，然后运算，最后再根据运算的结果创建 Python 对象，并返回泛型指针。</p>
<p>关于浮点数，如果你还想知道它的更多内容，可以进入源码中，大肆探索一番。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-10"><a class="header" href="#楔子-10">楔子</a></h2>
<p>本篇文章来聊一聊复数，尽管在日常开发中基本用不到复数，但对它有一个深刻的认识，知道它是做什么的，个人觉得还是很有必要的。另外，本系列力求精致、详细，因此每一个细节都要到位。</p>
<p>那么下面就来解释一下什么是复数。</p>
<h2 id="什么是复数"><a class="header" href="#什么是复数">什么是复数</a></h2>
<p>复数是一种用来扩展实数的数，它由实数和虚数两部分组成，用来解决实数范围内无法解决的问题，基本形式如下。</p>
<p><img src="./images/51.png" alt="" /></p>
<p>形如 a + bi 的数，我们称之为复数，其中 a 和 b 是浮点数（实数），i 是虚数，满足 i 的平方等于 -1。</p>
<p>所以复数不仅包含实数，还包含虚数，形式为 a + bi，然后 a 被称为复数的实部，b 被称为复数的虚部。如果两个复数的实部相同，虚部相反，那么它们互为共轭复数，比如 1 + 3i 和 1-3i。</p>
<p>如果对复数的实部和虚部进行平方和再开根号，便可得到复数的模，比如 3 + 4i 的模便是 5。</p>
<p>复数的引入可以帮助我们更好地理解和解决许多数学以及物理问题，特别是在涉及振动、波动和电路分析等领域，比如：</p>
<ul>
<li>电工程：分析交流电路和信号处理；</li>
<li>控制系统：用于系统稳定性分析；</li>
<li>量子力学：描述波函数和量子态；</li>
<li>流体力学：用于描述流动问题；</li>
</ul>
<p>当然复数也有自己的运算规则。</p>
<p><font color="darkblue"><strong>加法：两个复数相加等于对应的实部和虚部分别相加</strong></font></p>
<p><img src="./images/52.png" alt="" /></p>
<p><font color="darkblue"><strong>减法：两个复数相减等于对应的实部和虚部分别相减</strong></font></p>
<p><img src="./images/53.png" alt="" /></p>
<p><font color="darkblue"><strong>乘法：两个复数的乘法使用分配率</strong></font></p>
<p><img src="./images/54.png" alt="" /></p>
<p><font color="darkblue"><strong>除法：两个复数的乘法涉及到共轭复数</strong></font></p>
<p><img src="./images/55.png" alt="" /></p>
<p>以上就是复数的基本概念，下面来看看 Python 的复数是怎么实现的。</p>
<h2 id="复数的底层结构"><a class="header" href="#复数的底层结构">复数的底层结构</a></h2>
<p>复数的实现比想象中要简单很多，说白了就是维护两个浮点数而已。</p>
<pre><code class="language-C">// Include/complexobject.h
typedef struct {
    double real;
    double imag;
} Py_complex;

typedef struct {
    PyObject_HEAD
    Py_complex cval;
} PyComplexObject;
</code></pre>
<p>我们看到复数的结构和浮点数是非常相似的，只不过浮点数只用一个 double 来维护具体的值。而复数因为存在实部和虚部，因此需要两个 double，其中 real 维护复数的实部，imag 维护复数的虚部。</p>
<pre><code class="language-python"># 在别的语言中，虚数都是用 i 来表示
# 而 Python 觉得 i 是一个很常用的变量，所以使用 j 来表示虚数
cpx = 3 + 4j
# 其中 3 为实部，4 为虚部
print(cpx)  # (3+4j)
# 如果虚部为 1，那么要写成 1j，不能只写 j，否则解释器会认为 j 是一个变量
print(3 + 1j)  # (3+1j)
# 复数的实部可以为 0
print(2j)  # 2j
# 当然虚部也可以为 0，如果虚部为 0，那么要写成 0j，不能不写
# 因为 3 和 3+0j 不是等价的，前者是整数，后者是复数
print(0j)  # 0j
print(3 + 0j)  # (3+0j)
</code></pre>
<p>整个过程非常简单，当解释器看到 3 + 4j 的时候，就知道要创建复数了，因为解释器对内置的数据结构了如指掌，所以在底层会创建一个 PyComplexObject 结构体实例。</p>
<p><img src="./images/56.png" alt="" /></p>
<p>没有什么难度，和浮点数是类似的。</p>
<h2 id="复数的行为"><a class="header" href="#复数的行为">复数的行为</a></h2>
<p>类型对象定义的操作，决定了实例对象的行为，所以我们需要查看复数的类型都定义了哪些操作。复数的类型在 Python 里面对应 <font color="blue">&lt;class 'complex'&gt;</font>，那么根据解释器的命名规则，它在底层应该由 PyComplex_Type 负责实现。</p>
<pre><code class="language-C">// Objects/complexobject.c
PyTypeObject PyComplex_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;complex&quot;,
    sizeof(PyComplexObject),
    // ...
    &amp;complex_as_number,                         /* tp_as_number */
    0,                                          /* tp_as_sequence */
    0,                                          /* tp_as_mapping */
    // ...
    complex_richcompare,                        /* tp_richcompare */
    // ...
    complex_methods,                            /* tp_methods */
    complex_members,                            /* tp_members */
    // ...
};
</code></pre>
<p>complex 的类型也是 type，它的实例对象的大小就是 PyComplexObject 结构体的大小。然后我们看下它的 tp_members，该字段表示实例对象有哪些属性，它被赋值为 complex_members。</p>
<p><img src="./images/57.png" alt="" /></p>
<p>它有两个属性，分别是 real 和 imag，类型为 double，并且是只读的。那么在 Python 里面创建复数之后，便可以获取 real 和 imag 属性。</p>
<pre><code class="language-Python">cpx = 3 + 4j
# 注意：虽然写的是 3 + 4j，但实部和虚部都是浮点数
print(cpx.real)  # 3.0
print(cpx.imag)  # 4.0
</code></pre>
<p>然后 complex 类型还实现了 tp_richcompare，用于复数之间的比较，但对于复数来说，比较操作只支持等于和不等于。</p>
<pre><code class="language-C">// Objects/complexobject.c
static PyObject *
complex_richcompare(PyObject *v, PyObject *w, int op)
{
    PyObject *res;  // 比较结果
    Py_complex i;   // 复数的实部和虚部组成的结构体
    int equal;      // 两个复数是否相等
    
    // 如果 op 不是 ==、也不是 !=，那么报错
    // 因为复数只支持这两种比较操作
    if (op != Py_EQ &amp;&amp; op != Py_NE) {
        goto Unimplemented;
    }

    assert(PyComplex_Check(v));
    // 获取复数 v 的 cval 字段，并赋值给 i
    // 即 i = ((PyComplexObject *) v)-&gt;cval
    TO_COMPLEX(v, i);

    if (PyLong_Check(w)) {
        // ...
    }
    else if (PyFloat_Check(w)) {
        // ...
    }
    else if (PyComplex_Check(w)) {
        Py_complex j;
        // j = ((PyComplexObject *) w)-&gt;cval
        TO_COMPLEX(w, j);
        // 如果实部和虚部都相等，那么两个复数相等
        equal = (i.real == j.real &amp;&amp; i.imag == j.imag);
    }
    else {
        goto Unimplemented;
    }
    // equal 为 1，表示两个复数相等，为 0 表示两个复数不相等
    // 如果 op 为 Py_EQ，那么相等返回 True，不等返回 False
    // 如果 op 为 Py_NE，那么相等返回 False，不等返回 True
    if (equal == (op == Py_EQ))
         res = Py_True;
    else
         res = Py_False;

    Py_INCREF(res);
    return res;

Unimplemented:
    Py_RETURN_NOTIMPLEMENTED;
}
</code></pre>
<p>以上就是复效的比较，核心就是比较对应的实部和虚部是否均相等。</p>
<p>由于复数也属于数值型对象，所以它也实现了 tp_as_number 方法簇。</p>
<p><img src="./images/58.png" alt="" /></p>
<p>我们以复数的加法和减法为例，看一下源码细节。</p>
<pre><code class="language-C">// Objects/complexobject.c

// 负责将两个 Py_complex 结构体实例相加
Py_complex
_Py_c_sum(Py_complex a, Py_complex b)
{
    // 复数的值由 Py_complex 结构体维护，它里面有 real 和 imag 两个字段
    Py_complex r;
    // 两个 Py_complex 实例相加的时候，等于内部的 real 和 imag 字段分别相加
    r.real = a.real + b.real;
    r.imag = a.imag + b.imag;
    return r;
}

// 负责将两个 Py_complex 结构体实例相减
Py_complex
_Py_c_diff(Py_complex a, Py_complex b)
{
    Py_complex r;
    r.real = a.real - b.real;
    r.imag = a.imag - b.imag;
    return r;
}

// 基于 Py_complex 创建 PyComplexObject
PyObject *
PyComplex_FromCComplex(Py_complex cval)
{
    PyComplexObject *op;
    // 为 PyComplexObject 结构体实例申请内存
    // 我们看到内存大小可以直接计算出来，因为内置数据结构在底层是写死的
    // 解释器对它们了如指掌，直接通过 sizeof 算一下即可，不需要借助类型对象
    op = (PyComplexObject *) PyObject_MALLOC(sizeof(PyComplexObject));
    // 如果 op 为 NULL，表示内存不够，申请失败
    if (op == NULL)
        return PyErr_NoMemory();
    // 初始化引用计数，并将 op-&gt;ob_type 初始化为 &amp;PyComplex_Type
    // 也就是让实例对象和类型对象建立联系
    (void)PyObject_INIT(op, &amp;PyComplex_Type);
    // 最后初始化 cval 字段，它是 Py_complex 结构体实例，负责维护复数具体的值
    op-&gt;cval = cval;
    // 转成泛型指针 PyObject * 之后返回
    return (PyObject *) op;
}

// 复数的加法
static PyObject *
complex_add(PyObject *v, PyObject *w)
{
    Py_complex result;
    // 将两个复数的 cval 抽出来，赋值给 a 和 b
    Py_complex a, b;
    TO_COMPLEX(v, a);
    TO_COMPLEX(w, b);
    PyFPE_START_PROTECT(&quot;complex_add&quot;, return 0)
    // 调用 _Py_c_sum 进行相加，得到新的 Py_complex
    result = _Py_c_sum(a, b);
    PyFPE_END_PROTECT(result)
    // 基于 Py_complex 创建 PyComplexObject
    return PyComplex_FromCComplex(result);
}

// 复数的减法
static PyObject *
complex_sub(PyObject *v, PyObject *w)
{
    Py_complex result;
    // 将两个复数的 cval 抽出来，赋值给 a 和 b
    Py_complex a, b;
    TO_COMPLEX(v, a);
    TO_COMPLEX(w, b);
    PyFPE_START_PROTECT(&quot;complex_sub&quot;, return 0)
    // 调用 _Py_c_diff 进行相减，得到新的 Py_complex
    result = _Py_c_diff(a, b);
    PyFPE_END_PROTECT(result)
    // 基于 Py_complex 创建 PyComplexObject      
    return PyComplex_FromCComplex(result);
}
</code></pre>
<p>以上就是复数的加法和减法，比较简单，至于其它操作，感兴趣可以自己阅读一下源码。</p>
<h2 id="小结-12"><a class="header" href="#小结-12">小结</a></h2>
<p>本次我们就介绍了复数的底层结构以及它的一些相关操作，总的来说和浮点数是比较像的。不过还是像上面说的那样，对于我们日常开发来说，复数用的并不多，甚至可以说是几乎不用，但通过它来加深对源码的理解以及感受 Python 对象的设计哲学，还是非常有意义的。</p>
<p>下一篇文章来说一说整数，我们知道 Python 整数不会溢出，那么它是怎么设计的呢？背后有什么黑科技呢？我们下一篇文章再聊。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-11"><a class="header" href="#楔子-11">楔子</a></h2>
<p>本篇文章来分析一下 Python 整数的实现原理，我们知道 Python 整数是不会溢出的，换句话说它可以计算无穷大的数。只要你的内存足够，它就能计算，但对于 C 来说显然是不行的，C 能保存的整数范围是有限的。</p>
<p>但问题是，Python 的底层是 C 实现的，那么它是怎么做到整数不溢出的呢？想要知道答案，那么看一下整数在底层是怎么定义的就行了。</p>
<h2 id="整数的底层结构"><a class="header" href="#整数的底层结构">整数的底层结构</a></h2>
<p>Python 整数在底层由 PyLongObject 结构体负责承载，看一下它的定义。</p>
<pre><code class="language-C">// Include/longobject.h
typedef struct _longobject PyLongObject;

// Include/longintrepr.h
struct _longobject {
    PyObject_VAR_HEAD
    digit ob_digit[1];
};
</code></pre>
<p>里面每个字段的含义如下：</p>
<ul>
<li>ob_refcnt：对象的引用计数；</li>
<li>ob_type：对象的类型；</li>
<li>ob_size：数组 ob_digit 的长度；</li>
<li>ob_digit：digit 类型的数组；</li>
</ul>
<p>别的先不说，就冲里面的 ob_size 我们就可以思考一番。首先 Python 的整数有大小、但应该没有长度的概念吧，那为什么会有一个 ob_size 呢？从结构体字段来看，这个 ob_size 表示<font color="blue">数组 ob_digit</font> 的长度，而这个 ob_digit 显然是用来维护具体的值。</p>
<p>相信你已经猜到 Python 整数不会溢出的秘密了，因为它内部通过数组来存储整数，所以能存储无限大的数。因此答案出来了，虽然整数没有我们生活中的那种<font color="blue">长度</font>的概念，但它是个<font color="blue">变长对象</font>，因为不同的整数占用的内存可能是不一样的。尽管它没有字符串、列表那种长度的概念，或者说无法对整数使用 len 函数，但它是个变长对象。</p>
<p>接下来的重点就是这个 ob_digit 数组，我们要从它的身上挖掘信息，看看整数是怎么放在里面的，不过首先我们要搞清楚这个 digit 是什么类型。</p>
<pre><code class="language-C">// Include/longintrepr.h
#if PYLONG_BITS_IN_DIGIT == 30
    typedef uint32_t digit;
#elif PYLONG_BITS_IN_DIGIT == 15
    typedef unsigned short digit;
#else
    #error &quot;PYLONG_BITS_IN_DIGIT should be 15 or 30&quot;
</code></pre>
<p>PYLONG_BITS_IN_DIGIT 是一个宏，这个宏是做什么的我们先不管，总之如果机器是 64 位的，那么它会被定义为 30，机器是 32 位的，则会被定义为 15。而现在的机器基本都是 64 位的，所以 PYLONG_BITS_IN_DIGIT 等于 30，因此 digit 等价于 uint32_t，即 unsigned int。</p>
<p>因此 ob_digit 是一个无符号 32 位整型数组，至于长度，虽然声明为 1，但其实没有限制，你可以当成任意长度的数组来用，这是 C 语言的一个常见特性。和 Go 不同，C 数组的长度不属于类型信息。至于数组具体多长，取决于存储的整数有多大，显然整数越大，这个数组就越长，占用的空间也就越大。</p>
<h2 id="探究整数的秘密"><a class="header" href="#探究整数的秘密">探究整数的秘密</a></h2>
<p>了解了 ob_digit 数组之后，来分析一下它是怎么存储整数的？</p>
<p>首先抛出一个问题，如果你是 Python 的设计者，要保证整数不会溢出，你会怎么办？我们不妨再把问题简化一下，假设有一个 8 位无符号整数类型，我们知道它能表示的最大数字是 255，但这时候如果要表示 256，该怎么办呢？</p>
<p>可能有人会想，那用两个数来存储不就好了，一个存储 255，一个存储 1，然后将这两个数放在数组里面。这个答案虽然有些接近，但其实还有偏差：就是我们并不能简单地按照大小拆分，比如 256 拆分成 255 和 1，要是 265 就拆分成 255 和 10，不能这样拆分，而是要通过二进制的方式，也就是用新的整数来模拟更高的位。</p>
<p>如果感到困惑的话没有关系，我们以 Python 整数的底层存储为例，来详细解释一下这个过程。解释器实现整数也是通过我们上面说的这种方式，但考虑的会更加全面一些。</p>
<p><font color="#ac39ff"><strong>整数 0</strong></font></p>
<p>注意：当表示的整数为 0 时，ob_digit 数组为空，不存储任何值。而 ob_size 为 0，表示这个整数的值为 0，这是一种特殊情况。</p>
<p><img src="./images/59.png" alt="" /></p>
<p><font color="#ac39ff"><strong>整数 1</strong></font></p>
<p><img src="./images/60.png" alt="" /></p>
<p><font color="#ac39ff"><strong>整数 -1</strong></font></p>
<p><img src="./images/61.png" alt="" /></p>
<p>我们看到 ob_digit 数组没有变化，但是 ob_size 变成了 -1。没错，整数的正负是通过 ob_size 决定的，ob_digit 存储的其实是绝对值。无论整数 n 是多少，-n 和 n 对应的 ob_digit 是完全一致的，但是 ob_size 则互为相反数。所以 ob_size 除了表示数组的长度之外，还可以表示对应整数的正负。</p>
<p>因此我们之前说整数越大，底层的 ob_digit 数组就越长。更准确地说是绝对值越大，底层数组就越长。所以 Python 在比较两个整数的大小时，会先比较 ob_size，如果 ob_size 不一样则可以直接比较出大小。显然 ob_size 越大，对应的整数越大，不管 ob_size 是正是负，都符合这个结论。</p>
<p><font color="#ac39ff"><strong>整数 2 ** 30 - 1</strong></font></p>
<p><img src="./images/62.png" alt="" /></p>
<p>如果想表示 <font color="blue">2 ** 30 - 1</font>，那么也可以使用一个 digit 表示。话虽如此，但为什么突然说这个数字呢？答案是：虽然 digit 是 4 字节、32 位，但解释器只用 30 个位。</p>
<p>之所以这么做是和加法进位有关系，如果 32 个位全部用来存储其绝对值，那么相加产生进位的时候，可能会溢出。比如 <font color="blue">2 ** 32 - 1</font>，此时 32 个位全部占满了，即便它只加上 1，也会溢出。那么为了解决这个问题，就需要先强制转换为 64 位整数再进行运算，从而会影响效率。但如果只用 30 个位的话，那么加法是不会溢出的。</p>
<p>因为 30 个位最大就是 <font color="blue">2 ** 30 - 1</font>，即便两个这样的数相加，结果也是 <font color="blue">2 ** 31 - 2</font>。而 32 个位最大能表示 <font color="blue">2 ** 32 - 1</font>，所以肯定不会溢出的。如果一开始 30 个位就存不下，那么数组中会有两个 digit。</p>
<p>所以虽然将 32 位全部用完，可以只用一个 digit 表示更大的整数，但会面临相加之后一个 digit 存不下的情况，于是只用 30 个位。如果数值大到 30 个位存不下的话，那么就会多使用一个 digit。</p>
<p>这里可能有人发现了，如果使用 31 个位的话，那么相加产生的最大值就是 <font color="blue">2 ** 32 - 2</font>，依旧可以使用一个 32 位整型存储啊，那 Python 为啥要牺牲两个位呢？答案是为了乘法运算。</p>
<blockquote>
<p>为了方便计算乘法，需要多保留 1 位用于计算溢出。这样当两个整数相乘的时候，可以直接按 digit 计算，并且由于兼顾了&quot;溢出位&quot;，可以把结果直接保存在一个寄存器中，以获得最佳性能。</p>
</blockquote>
<p>具体细节就不探究了，只需要知道整数在底层是使用 unsigned int 类型的数组来维护具体的值即可，并且虽然该类型的整数有 32 个位，但解释器只用 30 个位。</p>
<p>然后还记得我们在看 digit 类型的时候，说过一个宏吗？PYLONG_BITS_IN_DIGIT，在 64 位机器上等于 30，在 32 位机器上等于 15。相信这个宏表示的是啥你已经清楚了，它代表的就是使用的 digit 的位数。</p>
<p><font color="#ac39ff"><strong>整数 2 ** 30</strong></font></p>
<p>问题来了，我们说 digit 只用 30 个位，所以 <font color="blue">2 ** 30 - 1</font> 是一个 digit 能存储的最大值。而现在是 <font color="blue">2 ** 30</font>，所以数组中就要有两个 digit 了。</p>
<p><img src="./images/63.png" alt="" /></p>
<p>我们看到此时就用两个 digit 来存储了，然后数组里面的元素是 0 和 1，而且充当高位的放在后面，因为是使用新的 digit 来模拟更高的位。由于一个 digit 只用 30 位，那么数组中第一个 digit 的最低位就是 1，第二个 digit 的最低位就是 31，第三个 digit 的最低位就是 61，以此类推。</p>
<p>所以如果 ob_digit 为 <font color="blue">[a, b, c]</font>，那么对应的整数就等于：</p>
<p><img src="./images/64.png" alt="" /></p>
<p>如果 ob_digit 不止 3 个，那么就按照 30 个位往上加，比如 ob_digit 还有第四个元素 d，那么就再加上 <font color="blue">d * 2 ** 90</font> 即可。</p>
<p>以上就是 Python 整数的存储奥秘，说白了就是串联多个小整数来表达大整数。并且这些小整数之间的串联方式并不是简单的相加，而是将各自的位组合起来，共同形成一个具有更高位的大整数，比如将两个 32 位整数串联起来，表示 64 位整数。</p>
<h2 id="整数占的内存大小是怎么计算的"><a class="header" href="#整数占的内存大小是怎么计算的">整数占的内存大小是怎么计算的</a></h2>
<p>下面我们再分析一下，一个整数要占用多大的内存。</p>
<p>相信所有人都知道可以使用 sys.getsizeof 计算内存大小，但是这大小到底是怎么来的，估计会一头雾水。因为 Python 中对象的大小，是根据底层的结构体计算出来的。</p>
<p>由于 ob_refcnt、ob_type、ob_size 这三个是整数所必备的，它们都是 8 字节，加起来 24 字节，所以任何一个整数所占内存都至少 24 字节。至于具体占多少，则取决于 ob_digit 里面的元素有多少个。</p>
<p>因此整数所占内存等于 <font color="blue">24 + 4 * ob_size的绝对值</font>。</p>
<pre><code class="language-Python">import sys

# 如果是 0 的话，ob_digit 数组为空，所以大小就是 24 字节
print(sys.getsizeof(0))  # 24

# 如果是 1 的话，ob_digit 数组有一个元素，所以大小是 24 + 4 = 28 字节
print(sys.getsizeof(1))  # 28
# 同理
print(sys.getsizeof(2 ** 30 - 1))  # 28

# 一个 digit 只用 30 位，所以最大能表示 2 ** 30 - 1
# 如果是 2 ** 30，那么就需要两个元素，所以大小是 24 + 4 * 2 = 32 字节
print(sys.getsizeof(2 ** 30))  # 32
print(sys.getsizeof(2 ** 60 - 1))  # 32

# 如果是两个 digit，那么能表示的最大整数就是 2 ** 60 - 1
# 因此 2 ** 60 需要三个 digit，所以大小是 24 + 4 * 3 = 36 字节
print(sys.getsizeof(1 &lt;&lt; 60))  # 36
print(sys.getsizeof((1 &lt;&lt; 90) - 1))  # 36

print(sys.getsizeof(1 &lt;&lt; 90))  # 40
</code></pre>
<p>所以整数的大小就是这么计算的，当然不光整数，其它的对象也是如此，计算的都是底层结构体的大小。</p>
<p>另外我们也可以反推一下，如果有一个整数 88888888888，那么它对应的底层数组 ob_digit 有几个元素呢？每个元素的值又是多少呢？下面来分析一波。</p>
<pre><code class="language-Python">import numpy as np

# 假设占了 n 个位
# 由于 n 个位能表达的最大整数是 2 ** n - 1
a = 88888888888
# 所以只需获取以 2 为底、a + 1 的对数，即可算出 n 的大小
print(np.log2(a + 1))  # 36.371284042320475
</code></pre>
<p>计算结果表明，如果想要存下这个整数，那么至少需要 37 个位。而 1 个 digit 用 30 个位，很明显需要两个 digit。</p>
<pre><code class="language-Python"># 如果 ob_digit 有两个元素
# 那么对应的整数就等于 ob_digit[0] + ob_digit[1] * 2 ** 30
a = 88888888888
print(a // 2 ** 30)  # 82
print(a - 82 * 2 ** 30)  # 842059320
</code></pre>
<p>所以整数 88888888888 在底层对应的 ob_digit 数组为 [842059320, 82]，下面修改解释器，来验证这一结论。</p>
<p><img src="./images/65.png" alt="" /></p>
<p>我们看到结果和我们分析的是一样的，但这种办法有点麻烦，我们可以通过之前说的 ctypes 来构造底层的结构体，在 Python 的层面模拟 C 的行为。</p>
<pre><code class="language-Python">from ctypes import *

class PyLongObject(Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
        (&quot;ob_size&quot;, c_ssize_t),
        (&quot;ob_digit&quot;, c_uint32 * 2)
    ]

a = 88888888888
# 基于对象的地址构造 PyLongObject 对象
long_obj = PyLongObject.from_address(id(a))
# 打印结果和我们预期的一样
print(long_obj.ob_digit[0])  # 842059320
print(long_obj.ob_digit[1])  # 82

# 如果将 ob_digit[1] 改成 28，那么 a 会变成多少呢？
# 很简单，算一下就知道了
long_obj.ob_digit[1] = 28
print(842059320 + 28 * 2 ** 30)  # 30906830392
# 那么 a 会不会也打印这个结果呢？毫无疑问，肯定会的
print(a)  # 30906830392

# 并且前后 a 保存的地址没有发生改变，因为我们修改的是底层数组
# 因此所谓的可变和不可变，都只是根据 Python 的表现抽象出来的
# 或者说，对象是否可变，取决于解释器有没有将修改对象的接口暴露出来
# 要是解释器没有提供修改对象的接口，那么对象就是不可变的
# 但如果站在解释器的层面上看，则没啥可变或不可变，一切都由我们决定
</code></pre>
<p>通过打印 ob_digit 存储的值，我们验证了得出的结论，原来 Python 是通过数组来存储整数，并且数组的类型虽然是无符号 32 位整数，但是只用 30 个位。</p>
<h2 id="小结-13"><a class="header" href="#小结-13">小结</a></h2>
<p>以上我们就探究了 Python 整数的秘密，它是怎么实现的。不过还没有结束，后续还要继续分析小整数对象池，以及整数的行为。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>之前分析过浮点数的创建，而整数的创建与之是类似的，都是基于字面量形式的 C 数据创建 Python 数据。</p>
<ul>
<li>创建浮点数可以使用 PyFloat_FromDouble、PyFloat_FromString 等；</li>
<li>创建整数可以使用 PyLong_FromLong、PyLong_FromDouble、PyLong_FromString 等；</li>
</ul>
<p>创建整数的这些函数直接去 Objects/longobject.c 里面查看即可，这里就不多说了，我们重点来看一下小整数对象池。</p>
<p>我们知道整数属于不可变对象，运算之后会创建新的对象。</p>
<pre><code class="language-Python">&gt;&gt;&gt; a = 666
&gt;&gt;&gt; id(a)
140078521506224
&gt;&gt;&gt; a += 1
&gt;&gt;&gt; id(a)
140078521506096
&gt;&gt;&gt;
</code></pre>
<p>显然这种做法一定存在性能缺陷，因为程序运行时会有大量的对象创建和销毁。根据浮点数的经验，我们猜测 Python 应该也对整数使用了缓存池吧。答案是差不多，只不过不是缓存池，而是小整数对象池。</p>
<p><strong>一些使用频率高的整数在创建之后，会被保存在一个静态数组里面，我们称之为小整数对象池。</strong></p>
<p>看一下小整数对象池的实现。</p>
<pre><code class="language-C">// Objects/longobject.c

#define NSMALLPOSINTS           257
#define NSMALLNEGINTS           5

static PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];
</code></pre>
<p>数组 small_ints 便是小整数对象池，它是一个类型为 PyLongObject、长度为 262 的数组，里面缓存了 -5 到 256 之间的整数。当然这只是解释器的默认行为，因为 -5 到 256 之间的整数使用频率最高，但你也可以根据自身情况修改源码，让它缓存更多的整数，以提升效率，当然这也会额外占用一些内存。</p>
<p>小整数对象池是预先创建好的，里面的整数全局唯一，我们来验证一下。</p>
<pre><code class="language-python">&gt;&gt;&gt; n1 = 256
&gt;&gt;&gt; n2 = 256
&gt;&gt;&gt; id(n1), id(n2)
(140078528922016, 140078528922016)
&gt;&gt;&gt; 
&gt;&gt;&gt; n1 = 257
&gt;&gt;&gt; n2 = 257
&gt;&gt;&gt; id(n1), id(n2)
(140078521507472, 140078521506704)
&gt;&gt;&gt;
</code></pre>
<p>256 位于小整数对象池内，所以全局唯一，需要使用的话直接去取即可，因此它们的地址是一样的。但 257 不在小整数对象池内，所以它们的地址不一样。</p>
<p>另外上面的代码是交互式执行的，但如果有小伙伴不是通过交互式，那么打印地址的时候会得到出乎意料的结果。</p>
<pre><code class="language-Python">a = 257
b = 257
print(id(a) == id(b))  # True
</code></pre>
<p>可能有人会好奇，为什么地址又是一样的了，257 明明不在小整数对象池中啊。虽然涉及到了后面的内容，但提前解释一下也是可以的。主要区别就在于一个是交互式执行的，另一个是通过 <font color="blue">python3 xxx.py</font> 的方式执行的。</p>
<p>首先 Python 的编译单元是函数，每个函数都有自己的作用域，在这个作用域中出现的所有常量都是唯一的，并且都位于常量池中，由 co_consts 指向。虽然上面的对象不在函数中，而是在全局作用域中，但全局也可以看成是一个函数，它也是一个独立的编译单元。同一个编译单元中，相同的常量只会出现一次。</p>
<p>当执行 a = 257 的时候，会创建 257 这个整数，并放入常量池中。所以 b = 257 的时候就不会再创建了，因为常量池中已经有了，所以会直接从常量池中获取，因此它们的地址是一样的，因为是同一个 PyLongObject。</p>
<p>而对于交互式环境来说，因为输入一行代码就会立即执行一行，所以任何一行可独立执行的代码都是一个独立的编译单元。注意：是可独立执行的代码，比如变量赋值、函数、方法调用等等。但如果是 if、for、while、def 等需要多行表示的逻辑，比如 <font color="blue">if 2 &gt; 1:</font>，显然就不是一行可独立执行的代码，它还依赖你输入的下面的内容。</p>
<pre><code class="language-python"># 此时按下回车，我们看到不再是 &gt;&gt;&gt;，而是 ...
# 这代表还没有结束，还需要你输入下面的内容
&gt;&gt;&gt; if 2 &gt; 1:
...     print(&quot;2 &gt; 1&quot;)
... # 此时这个 if 语句整体才是一个独立的编译单元
2 &gt; 1
&gt;&gt;&gt; 
</code></pre>
<p>但是像 a = 1、foo()、lst.appned(123) 这些显然是一行可独立执行的代码，因此在交互式中它们是独立的编译单元。</p>
<pre><code class="language-python"># 此时这行代码已经执行了，它是一个独立的编译单元
&gt;&gt;&gt; a = 257
# 这行代码也是独立的编译单元，所以它里面的常量池为空，因此要重新创建 257
&gt;&gt;&gt; b = 257
# 由于它们是不同常量池内的整数，所以 id 是不一样的
&gt;&gt;&gt; id(a), id(b)
(140078521506768, 140078521506096)
</code></pre>
<p>再来看个例子。</p>
<pre><code class="language-python">&gt;&gt;&gt; a = 666; b = 666
&gt;&gt;&gt; id(a), id(b)
(140078521506512, 140078521506512)
&gt;&gt;&gt;
&gt;&gt;&gt; a, b = 777, 777
&gt;&gt;&gt; id(a), id(b)
(140078521506224, 140078521506224)
</code></pre>
<p>666 和 777 明显不在常量池中，为啥 a 和 b 指向对象的地址是一样的呢？相信你能猜到原因，因为上面两种方式无论哪一种，都是在同一行，因此整体会作为一个编译单元。既然是同一个编译单元，那么常量池里面的每个常量只会创建一次，所以地址是一样的。</p>
<p>注意：常量池里面的常量一定在编译期间就可以确定，比如整数、浮点数、字符串等等，解释器在编译期间会静态收集起来，保存在常量池中。但如果编译期间无法确定，就不会静态收集了，举个例子。</p>
<pre><code class="language-python">&gt;&gt;&gt; a, b = int(&quot;257&quot;), int(&quot;257&quot;)
&gt;&gt;&gt; id(a), id(b)
(140078521506768, 140078521506512)
&gt;&gt;&gt; 
&gt;&gt;&gt; a, b = int(&quot;123&quot;), int(&quot;123&quot;)
&gt;&gt;&gt; id(a), id(b)
(140078528917760, 140078528917760)
&gt;&gt;&gt; 
&gt;&gt;&gt; a, b = 258, 258
&gt;&gt;&gt; id(a), id(b)
(140078521507632, 140078521507632)
</code></pre>
<p>int(&quot;257&quot;) 需要在运行时执行，因此会创建两个 257，然后赋值给 a 和 b，所以地址不一样。</p>
<p>int(&quot;123&quot;) 虽然也在运行时执行，但解释器创建完之后发现 123 位于小整数对象池中，于是会直接从池子里面取，所以打印的地址一样。注意：int(&quot;123&quot;) 肯定是会执行的，只是执行之后发现结果存在于小整数对象池中，会再将创建的对象销毁。</p>
<p>258 属于编译期间可以静态收集的常量，会被保存在常量池中，而常量池里的常量只会出现一次，所以打印的地址一样。</p>
<blockquote>
<p>⭐️：常量不仅仅是 123、&quot;hello&quot; 这种，像 <font color="blue">2 ** 10</font>、<font color="blue">&quot;AAA&quot; + &quot;BBB&quot;</font> 这种也属于常量，它们在编译之后会被替换为 <font color="blue">1024</font>、<font color="blue">&quot;AAABBB&quot;</font>，这个过程被称为<font color="blue">常量折叠</font>。</p>
</blockquote>
<p>以上就是小整数对象池相关的内容，比较简单，因为小整数对象池就是一个数组，里面缓存了 -5 到 256 之间的 Python 整数，而这些整数可以直接拿来用。</p>
<p>下一篇文章我们来分析整数的运算，这也是最关键的地方。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-12"><a class="header" href="#楔子-12">楔子</a></h2>
<p>通过考察整数的底层实现，我们明白了它能够保证不溢出的缘由。整数的值在底层是由 C 数组来维护的，通过组合多个 digit（uint32_t）来实现大整数的存储。这么做的好处就是 Python 整数没有大小限制了，因此不会溢出，而不会溢出是因为数组没有长度限制，所以只要你的内存足够，就可以存任意大的数。</p>
<p>Python 表示：存不下？会溢出？这都不是事儿，直接继续往数组里面塞 digit 就 ok 了。另外数组存的是绝对值，符号是通过 ob_size 体现的。</p>
<p>不过说实话，用数组实现大整数的做法非常普遍，并没有什么神秘的，就是将多个整数组合起来，模拟具有更高位的大整数。但这种实现方式的难点在于大整数的数学运算，它们才是重点，实现的时候比较考验编程技巧以及思维逻辑。</p>
<p>因此 Python 的整数比浮点数要复杂的多，浮点数在底层直接用 C 的 double 来维护具体的值，因此运算的话，比如相加，直接转成 C 的 double 做加法即可。但整数就不行了，在底层不能简单地将数组相加。</p>
<p>下面来看看具体实现。</p>
<h2 id="整数的大小比较"><a class="header" href="#整数的大小比较">整数的大小比较</a></h2>
<p>先来看看整数的大小比较，由于整数具体的值是通过数组维护的，显然数组越长，整数的绝对值就越大，这是毫无疑问的。至于整数的正负，则由 ob_size 来体现。</p>
<p>因此可以得出一个结论：当两个整数在比大小时，可以先比较各自的 ob_size，如果 ob_size 不一样，可以直接比较出大小，并且 ob_size 越大，对应的整数越大。但如果两个整数的 ob_size  一样，那么就从数组 ob_digit 的尾部元素开始，不断向前进行比较。只要两个整数的 ob_digit 中有一个对应元素不相同，那么就可以比较出大小。</p>
<p>之所以从数组的尾部开始，是因为数组元素的索引越大，那么充当的位数就越高，而在比较的时候显然要从高位开始比。</p>
<pre><code class="language-Python"># ob_digit = [892311, 32, 3]
a = 3458764548181171607
# ob_digit = [2296, 31, 3]
b = 3458764547106539768
</code></pre>
<p>我们以 a 和 b 为例，显然 a 大于 b，那么在底层，它们是如何比较的呢？</p>
<p><img src="./images/66.png" alt="" /></p>
<p>如果 ob_size 不相等，那么可以直接比较出大小。但这里两个整数的 ob_size 是相等的，所以需要比较 ob_digit，并且是从后往前比。具体做法就是让索引从 <font color="blue">ob_digit 长度减 1</font> 开始，依次往前遍历。</p>
<ul>
<li>因为 <code>a-&gt;ob_digit[2]</code> 等于 <code>b-&gt;ob_digit[2]</code>，此时无法比较出大小，因此索引减一，比较上一个元素。</li>
<li>因为 <code>a-&gt;ob_digit[1]</code> 大于 <code>b-&gt;ob_digit[1]</code>，所以成功比较出大小，可以得出 |a| 大于 |b|。</li>
</ul>
<p>当然啦，由于数组反映的是绝对值的大小，所以还需要判断符号。</p>
<ul>
<li>如果是正数，那么和绝对值相同。</li>
<li>但如果是负数，那么绝对值越大，对应的整数反而越小，因此比较之后的结果还要再乘上 -1。</li>
</ul>
<pre><code class="language-Python">from ctypes import *

class PyLongObject(Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
        (&quot;ob_size&quot;, c_ssize_t),
        (&quot;ob_digit&quot;, c_uint32 * 3)
    ]

a = 3458764548181171607
b = 3458764547106539768
long_obj1 = PyLongObject.from_address(id(a))
long_obj2 = PyLongObject.from_address(id(b))
print(list(long_obj1.ob_digit))  # [892311, 32, 3]
print(list(long_obj2.ob_digit))  # [2296, 31, 3]
</code></pre>
<p>以上就是整数的大小比较逻辑，下面再看一下具体的源码实现。</p>
<p><img src="./images/67.png" alt="" /></p>
<p>int 类型对象的 tp_richcompare 字段的值为 long_richcompare，所以具体的比较逻辑便由该函数负责实现。</p>
<pre><code class="language-C">// Objects/longobject.c

static PyObject *
long_richcompare(PyObject *self, PyObject *other, int op)
{   
    // 比较结果
    int result;
    // 类型检测，确保 self 和 other 的类型都是整数
    CHECK_BINOP(self, other);
    // self 和 other 都是泛型指针 PyObject *
    // 如果 self == other，说明指针保存的地址相同，它们指向的是同一个对象
    // 因此可以直接判定两者相等
    if (self == other)
        result = 0;
    else
        // 否则调用 long_compare，将对象维护的 ob_digit 抽出来，挨个比较
        // 如果 self &gt; other，那么 result 为 1
        // 如果 self == other，那么 result 为 0
        // 如果 self &lt; other，那么 result 为 -1
        result = long_compare((PyLongObject*)self, (PyLongObject*)other);
    // 一会儿解释
    Py_RETURN_RICHCOMPARE(result, 0, op);
}
</code></pre>
<p>在 Python 中不同的算术操作符会对应不同的魔法方法，而在 C 中均由 long_richcompare 函数实现。</p>
<p><img src="./images/68.png" alt="" /></p>
<p>而在 long_richcompare 里面，不管操作符是什么，result 都是固定的。</p>
<ul>
<li>如果 self &gt; other，那么 result 为 1；</li>
<li>如果 self == other，那么 result 为 0；</li>
<li>如果 self &lt; other，那么 result 为 -1；</li>
</ul>
<p>不管我们传入的操作符 op 是什么，都不影响上面的结论，因为 result 只是表达了 self 和 other 之间的关系。然后再看一下结尾的 Py_RETURN_RICHCOMPARE 这个宏，它的定义如下。</p>
<pre><code class="language-C">// Include/object.h
#define Py_RETURN_RICHCOMPARE(val1, val2, op)                               \
    do {                                                                    \
        switch (op) {                                                       \
        case Py_EQ: if ((val1) == (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;  \
        case Py_NE: if ((val1) != (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;  \
        case Py_LT: if ((val1) &lt; (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;   \
        case Py_GT: if ((val1) &gt; (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;   \
        case Py_LE: if ((val1) &lt;= (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;  \
        case Py_GE: if ((val1) &gt;= (val2)) Py_RETURN_TRUE; Py_RETURN_FALSE;  \
        default:                                                            \
            Py_UNREACHABLE();                                               \
        }                                                                   \
    } while (0)
</code></pre>
<p>这个宏做的事情很简单，就是基于操作符比较 val1 和 val2，如果 if 条件成立，返回 Python 的 True，否则返回 Python 的 False。而在 long_richcompare 里面，最后调用这个宏的时候，给 val1、val2 传的是 result 和 0。注意：这一步稍微有点绕，我们举个例子就简单了。</p>
<p>假设 self = 5，other = 6，我们要判断 <font color="blue">self &gt; other</font> 是 True 还是 False。</p>
<p>首先 self 小于 other，因此在 long_richcompare 里面比较之后，result 会等于 -1。那么调用宏的时候，传的三个参数就是 -1、0、Py_GT。然后执行对应分支，发现 val1 &gt; val2 不成立，于是返回 False，因此 self &gt; other 的结果也是 False。</p>
<p>所以 long_richcompare 里面的 result 只是通过 1、0、-1 描述了 self 和 other 之间的关系（C 语言的特点之一），而判断 self &gt; other 最终等价于判断 result &gt; 0，同理其它操作符也是如此。</p>
<p>再举个例子，假设要判断 self &lt;= other，那么最终等价于判断 result &lt;= 0。</p>
<ul>
<li>如果 self &gt; other，那么 result 就是 1，而 1 &lt;= 0 不成立，所以 self &lt;= other 就是 False。</li>
<li>如果 self == other，那么 result 就是 0，而 0 &lt;= 0 成立，所以 self &lt;= other 就是 True。</li>
<li>如果 self &lt; other，那么 result 就是 -1，而 -1 &lt;= 0 成立，所以 self &lt;= other 就是 True。</li>
</ul>
<p>因此最后这一步还是很巧妙的，但也稍微有一点绕。估计有人会好奇，为啥不能像浮点数那样直接比较呢？其实原因很好想，因为浮点数在底层使用 double 类型的字段来维护具体的值，比较逻辑非常简单。但整数不同，由于整数的值是通过数组维护的，比较起来非常复杂，如果还按照上面那种做法，那么每个分支里面会存在大量重复代码。</p>
<p>所以整数在比较的时候，先不管指定的操作符是什么，而是先判断两个数的大小关系。如果两个数是大于关系，那么给 result 赋值为 1；等于关系，赋值为 0；小于关系，赋值为 1。</p>
<p>最后将两个整数的比较操作，转成 result 和 0 的比较操作，这个实现思路非常巧妙，你在工作中也可以用起来。</p>
<p>但是还没结束，我们还有最关键的一步没有看。</p>
<p><img src="./images/69.png" alt="" /></p>
<p>显然这最关键的一步就在 long_compare 身上，它负责具体的比较逻辑。</p>
<pre><code class="language-C">// Objects/longobject.c

static int
long_compare(PyLongObject *a, PyLongObject *b)
{
    Py_ssize_t sign;
    // 如果两个整数的 ob_size 不一样，那么直接可以比较出大小
    if (Py_SIZE(a) != Py_SIZE(b)) {
        sign = Py_SIZE(a) - Py_SIZE(b);
    }
    else {
        // 否则说明 ob_size 一样，那么获取 ob_size 的绝对值，即数组 ob_digit 的长度
        Py_ssize_t i = Py_ABS(Py_SIZE(a));
        // 从后往前依次比较数组元素的大小
        while (--i &gt;= 0 &amp;&amp; a-&gt;ob_digit[i] == b-&gt;ob_digit[i])
            ;
        // 如果两个数组的元素全部一样，那么 i 最终会等于 -1
        if (i &lt; 0)
            sign = 0;
        // 否则说明两个数组中索引为 i 的元素存在不同
        else {
            // 那么比较大小
            sign = (sdigit)a-&gt;ob_digit[i] - (sdigit)b-&gt;ob_digit[i];
            // 如果 ob_size &lt; 0，说明是负数，那么比较结果还要再乘上 -1
            if (Py_SIZE(a) &lt; 0)
                sign = -sign;
        }
    }
    // 如果 a &lt; b，那么 sign &lt; 0，直接返回 -1
    // 如果 a == b，那么 sign == 0，直接返回 0
    // 如果 a &gt; b，那么 sign &gt; 0，直接返回 1
    return sign &lt; 0 ? -1 : sign &gt; 0 ? 1 : 0;
}
</code></pre>
<p>以上就是 Python 整数的比较逻辑，所以一个简单的整数比较，Python 底层居然做了这么多工作。</p>
<h2 id="小结-14"><a class="header" href="#小结-14">小结</a></h2>
<p>以上就是整数的比较逻辑，所以用数组实现大整数的思路没什么特别的，但难点就在于运算。而为了方便大家理解和消化，本篇文章暂时只介绍比较操作，下一篇文章来介绍整数的运算。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-13"><a class="header" href="#楔子-13">楔子</a></h2>
<p>本篇文章来探讨一下整数的加减法是怎么做的，因为整数在底层采用数组进行存储，所以它的加减法就不像浮点数那么简单。</p>
<p>在介绍浮点数的时候说过，对于数值型对象，它的类型一定实现了 tp_as_number 字段，该字段指向了 PyNumberMethods 结构体实例。结构体里面的每个字段都是一个函数指针，对应数值型对象的一个操作。</p>
<p><img src="./images/70.png" alt="" /></p>
<p>比如 nb_add 负责加法操作，nb_substract 负责减法操作等等，本篇文章就来探讨一下。首先整数支持的操作非常多，这里我们只探讨加减法。</p>
<h2 id="整数加减法的运算原理"><a class="header" href="#整数加减法的运算原理">整数加减法的运算原理</a></h2>
<p>整数的加法和减法分别由 long_add 和 long_sub 实现，但运算的核心却不在这两个函数上，它们内部会调用另外两个函数。因为数组保存了整数的绝对值，所以 Python 将整数的运算转成了绝对值运算，而底层有两个函数专门用来做这件事情，分别是 x_add 和 x_sub。</p>
<ul>
<li>x_add(a, b)：计算 a 和 b 的绝对值之和；</li>
<li>x_sub(a, b)：计算 a 和 b 的绝对值之差；</li>
</ul>
<p>所以整数相加就可以这么做，假设两个整数 a 和 b 相加：</p>
<ul>
<li>如果 a 和 b 均为正数，那么通过 x_add 计算 a 和 b 的绝对值之和即可；</li>
<li>如果 a 和 b 均为负数，那么通过 x_add 计算两者的绝对值之和，然后再取相反数；</li>
<li>如果 a 为负数，b 为正数，那么通过 x_sub 计算 b 和 a 的绝对值之差即可；</li>
<li>如果 a 为正数，b 为负数，那么通过 x_sub 计算 a 和 b 的绝对值之差即可；</li>
</ul>
<p>而整数相减也是同理，还是整数 a 和 b，两者相减：</p>
<ul>
<li>如果 a 为正数，b 为负数，那么通过 x_add 计算两者的绝对值之和即可；</li>
<li>如果 a 为负数，b 为正数，那么通过 x_add 计算两者的绝对值之和，然后再取相反数；</li>
<li>如果 a 和 b 均为正数，那么通过 x_sub 计算 a 和 b 的绝对值之差即可；</li>
<li>如果 a 和 b 均为负数，那么通过 x_sub 计算 b 和 a 的绝对值之差即可；</li>
</ul>
<blockquote>
<p>相加时，符号相同会调用 x_add、符号不同会调用 x_sub。相减时，符号相同会调用 x_sub、符号不同会调用 x_add。</p>
</blockquote>
<p>所以这就是 Python 的设计，因为绝对值的加减法不用考虑符号的影响，实现更为简单，所以 Python 将整数运算转化成整数的绝对值运算。那么下面我们的重心就在 x_add 和 x_sub 上面了，看看它们是如何对大整数绝对值进行运算的。到这里你可能会有疑问，大整数运算这么复杂，效率会差吧。显然这是啃腚的，整数数值越大，整数对象的底层数组就越长，运算开销也就越大。</p>
<p><strong>但 Python 底层有一个机制叫做快分支，因为通用逻辑能处理所有情况，那么它的效率必然不高。而快分支则是对那些可以简单运算的情况提前进行处理，比如在对 a 和 b 计算加减法的时候，底层会先判断数组的长度是否均小于等于 1，如果是则说明数组中最多只有一个元素。这样的话，就可以直接转成 C 的整数进行运算了，这样性能损耗就可以忽略不计。</strong></p>
<blockquote>
<p>关于快分支，需要再单独解释一下。我们举个生活中的例子：好比你去见女朋友，正常情况下，你需要买花，并且精心打扮。但如果女朋友不在生理期，那么这一切都不需要做，只需买杯奶茶就好了。所以先判断女朋友是否在生理期，如果不在，那么只需买杯奶茶就能牵手便属于快分支。快分支具有命中率高等特点，绝大部分都是这个情况，而一旦命中快分支，那么程序便可快速处理。</p>
</blockquote>
<p>回到上面的例子，只要整数不超过 2 ** 30 - 1，都可以走快分支，显然这可以满足绝大部分场景，因为这个数字已经很大了。至于 x_add 和 x_sub 则属于通用逻辑，而通用也意味着平庸，但如果快分支没有命中，那么就只能走通用逻辑了。</p>
<p>而我们的重点就是要研究 x_add 和 x_sub 的实现，感受大整数运算的魅力。不过在介绍之前，不妨想象一下我们平时将两个整数相加的时候是怎么做的。</p>
<p><img src="./images/71.png" alt="" /></p>
<p>从最低位开始进行相加，逢十进一，ob_digit 也是同理。我们可以把数组中的每一个元素看成是一个整体，只不过它不再是逢十进一，而是逢 <font color="blue">2 ** 30</font> 进一。</p>
<pre><code class="language-python"># 数组的每个元素最大能表示 2 ** 30 - 1
# 把元素整体想象成我们生活中加法的个位、十位、百位...
# 然后对应的位相加，逢 2 ** 30 进一
a = [1024, 22]
b = [342, 18]
c = [1024 + 342, 22 + 18]  # [1366, 40]

print(
    a[0] + a[1] * 2 ** 30
    +
    b[0] + b[1] * 2 ** 30
    ==
    c[0] + c[1] * 2 ** 30
)  # True
</code></pre>
<p>所以仍旧是对应的位进行相加，和我们生活中的加法并无本质上的区别。只不过生活中的加法，每一位能表示 <font color="blue">0~9</font>，逢十进一。而 Python 底层的加法，因为整数使用数组存储，那么每一个位能表示 <font color="blue">0 ~ 2 ** 30 - 1</font>，逢 <font color="blue">2 ** 30</font> 进一。</p>
<p><img src="./images/72.png" alt="" /></p>
<p>把 1024、342 想象成个位，把 22、18 想象成十位，并且此时不再是逢十进一，而是逢 2 ** 30 进一。</p>
<pre><code class="language-python">a = [2 ** 30 - 1, 16]
b = [2 ** 30 - 1, 21]
# a[0] + b[0] 超过了 2 ** 30，要进个 1
# 而逢十进一之后，该位要减去十
# 那么逢 2 ** 30 进一之后，显然要减去 2 ** 30
c = [
    a[0] + b[0] - 2 ** 30,
    a[1] + b[1] + 1
]

print(
    a[0] + a[1] * 2 ** 30
    +
    b[0] + b[1] * 2 ** 30
    ==
    c[0] + c[1] * 2 ** 30
)  # True
</code></pre>
<p>然后是绝对值减法，和绝对值加法一样，也可以类比生活中的减法，从低位到高位分别相减。如果某一位相减的时候发现不够了，那么要向高位借一位。比如 <font color="blue">27 减去 9</font>，由于 7 比 9 小，因此向 <font color="blue">2</font> 借一位变成 <font color="blue">17</font>，减去 9，得 8。但 2 被借了一位，所以剩下 1，因此结果为 <font color="blue">18</font>。</p>
<pre><code class="language-python">a = [5, 3]
b = [6, 1]
result = []

# 如果计算 a - b，整个过程是怎样的呢？
# 首先是 a[0] - b[0]，由于 a[0] &lt; b[0]
# 所以要借一位，而一个位是 2 ** 30
result.append(a[0] + 2 ** 30 - b[0])
# 然后是 a[1] - b[1]
# 由于 a[1] 被借走了一个位，因此要减 1
result.append(a[1] - 1 - b[1])
print(result)  # [1073741823, 1]

# 验证一下
print(
    (a[0] + a[1] * 2 ** 30)
    -
    (b[0] + b[1] * 2 ** 30)
)  # 2147483647
print(
    result[0] + result[1] * 2 ** 30
)  # 2147483647
</code></pre>
<p>结果没有问题，以上我们就从原理上介绍了大整数的加减法，下面再看一下源码实现。</p>
<h2 id="整数加减法源码实现"><a class="header" href="#整数加减法源码实现">整数加减法源码实现</a></h2>
<p>当整数相加时会执行 long_add 函数，看一下它的具体实现。</p>
<pre><code class="language-c">// Objects/longobject.c
static PyObject *
long_add(PyLongObject *a, PyLongObject *b)
{
    PyLongObject *z;  // 指向运算后的整数
    CHECK_BINOP(a, b);  // 确保 a 和 b 都指向整数
    
    // 如果两个整数的 ob_digit 数组最多只有一个元素
    // 那么取出来判断正负之后，直接进行运算即可
    // 由于 2 ** 30 - 1 已经很大了，所以绝大部分场景，都会执行此分支
    if (Py_ABS(Py_SIZE(a)) &lt;= 1 &amp;&amp; Py_ABS(Py_SIZE(b)) &lt;= 1) {
        // MEDIUM_VALUE 是一个宏，接收一个 abs(ob_size) &lt;= 1 的 PyLongObject *
        // 如果 ob_size 等于 0, 那么返回 0
        // 如果 ob_size 等于 1, 那么返回 ob_digit[0]
        // 如果 ob_size 等于 -1, 那么返回 -ob_digit[0]        
        // 所以计算出 MEDIUM_VALUE(a) + MEDIUM_VALUE(b) 之后
        // 将结果转成 PyLongObject，然后返回其泛型指针即可
        // 因此当数组中元素个数不超过 1 的时候，显然是可以直接相加的
        return PyLong_FromLong(MEDIUM_VALUE(a) + MEDIUM_VALUE(b));
    }
    // 否则走通用分支
    if (Py_SIZE(a) &lt; 0) {
        // 如果 a 是负数、b 是负数，那么先计算 |a| + |b|
        if (Py_SIZE(b) &lt; 0) {
            z = x_add(a, b);
            if (z != NULL) {
                // 然后对 z 取相反数
                assert(Py_REFCNT(z) == 1);
                Py_SIZE(z) = -(Py_SIZE(z));
            }
        }
        // 如果 a 是负数、b 是正数，那么计算 |b| - |a|      
        else
            z = x_sub(b, a);
    }
    else {
        // 如果 a 是正数、b 是负数，那么计算 |a| - |b|
        if (Py_SIZE(b) &lt; 0)
            z = x_sub(a, b);
        // 如果 a 是正数、b 是正数，那么计算 |a| + |b|      
        else
            z = x_add(a, b);
    }
    return (PyObject *)z;
}
</code></pre>
<p>因此 long_add 函数并不长，但是调用了 x_add 和 x_sub，显然核心逻辑是在这两个函数里面。至于 long_add 函数，它的逻辑如下：</p>
<ul>
<li>判断两个整数底层对应的数组的长度是否均小于等于 1，如果是的话那么通过宏 MEDIUM_VALUE 直接将其转成 C 的一个 digit，当然符号也会考虑在内。然后直接相加、返回即可。显然这里走的是快分支，或者说快速通道。</li>
<li>但如果其中一方的数组长度（ob_size）大于 1，那么判断两者的符号。如果都为负数，那么通过 x_add 计算两者的绝对值之和，然后取相反数。</li>
<li>如果 a 为负数，b 为正数，那么通过 x_sub 计算 b 和 a 的绝对值之差即可；</li>
<li>如果 a 为正数，b 为负数，那么通过 x_sub 计算 a 和 b 的绝对值之差即可；</li>
<li>如果都为正数，那么通过 x_add 计算 a 和 b 的绝对值之和即可；</li>
</ul>
<p>所以 Python 整数设计的非常巧妙，ob_digit 虽然用来维护具体数值，但它并没有考虑正负，整数的正负是通过 ob_size 来表示的。通过将运算变成绝对值运算，实现起来会方便很多。</p>
<p>说完了 long_add，再来看看 long_sub，这两者是类似的。</p>
<pre><code class="language-C">// Objects/longobject.c
static PyObject *
long_sub(PyLongObject *a, PyLongObject *b)
{
    PyLongObject *z;  // 指向运算后的整数
    CHECK_BINOP(a, b);  // 确保 a 和 b 都指向整数
    
    // 如果两个整数的 ob_digit 数组最多只有一个元素
    // 那么取出来判断正负之后，直接进行运算即可
    if (Py_ABS(Py_SIZE(a)) &lt;= 1 &amp;&amp; Py_ABS(Py_SIZE(b)) &lt;= 1) {
        return PyLong_FromLong(MEDIUM_VALUE(a) - MEDIUM_VALUE(b));
    }
    // 否则走通用分支    
    if (Py_SIZE(a) &lt; 0) {
        // 如果 a 是负数、b 是负数，那么先计算 |a| - |b|
        if (Py_SIZE(b) &lt; 0)
            z = x_sub(a, b);
        // 如果 a 是负数、b 是正数，那么先计算 |a| + |b|
        else
            z = x_add(a, b);
        // 然后对 z 取相反数
        if (z != NULL) {
            assert(Py_SIZE(z) == 0 || Py_REFCNT(z) == 1);
            Py_SIZE(z) = -(Py_SIZE(z));
        }
    }
    else {
        // 如果 a 是正数、b 是负数，那么计算 |a| + |b|
        if (Py_SIZE(b) &lt; 0)
            z = x_add(a, b);
        // 如果 a 是正数、b 是正数，那么计算 |a| - |b|
        else
            z = x_sub(a, b);
    }
    return (PyObject *)z;
}
</code></pre>
<p>所以 long_add 和 long_sub 的代码是类似的，它们将整数的运算转成了整数的绝对值运算，所以关键要理解什么时候用 x_add，什么时候用 x_sub。</p>
<p><font color="#ac39ff"><strong>a + b</strong></font></p>
<ul>
<li>如果 a 是正数，b 是正数，调用 <font color="blue">x_add(a, b)</font>，计算 <font color="blue">|a| + |b|</font>；</li>
<li>如果 a 是负数、b 是负数，调用 <font color="blue">x_add(a, b)</font>，计算 <font color="blue">|a| + |b|</font>，然后再取反；</li>
<li>如果 a 是正数、b 是负数，调用 <font color="blue">x_sub(a, b)</font>，计算 <font color="blue">|a| - |b|</font>；</li>
<li>如果 a 是负数、b 是正数，调用 <font color="blue">x_sub(b, a)</font>，计算 <font color="blue">|b| - |a|</font>；</li>
</ul>
<p>所以相加时，符号相同会调用 x_add、符号不同会调用 x_sub。</p>
<p><font color="#ac39ff"><strong>a - b</strong></font></p>
<ul>
<li>如果 a 是正数、b 是负数，调用 <font color="blue">x_add(a, b)</font>，计算 <font color="blue">|a| + |b|</font>；</li>
<li>如果 a 是负数、b 是正数，调用 <font color="blue">x_add(a, b)</font>，计算 <font color="blue">|a| + |b|</font>，然后再取反；</li>
<li>如果 a 是正数，b 是正数，调用 <font color="blue">x_sub(a, b)</font>，计算 <font color="blue">|a| - |b|</font>；</li>
<li>如果 a 是负数，b 是负数，调用 <font color="blue">x_sub(b, a)</font>，计算 <font color="blue">|b| - |a|</font>。当然在源码中调用的是 <font color="blue">x_sub(a, b)</font>，计算 <font color="blue">|a| - |b|</font>，然后再取相反数；</li>
</ul>
<p>所以相减时，符号相同会调用 x_sub、符号不同会调用 x_add。</p>
<p>接下来我们的重点就是绝对值加法和绝对值减法的具体实现细节。</p>
<h2 id="绝对值加法x_add"><a class="header" href="#绝对值加法x_add">绝对值加法：x_add</a></h2>
<p>函数 x_add 负责绝对值加法，但是介绍之前，需要先了解几个宏，它们在 x_add 中会有体现。</p>
<pre><code class="language-C">// Include/longintrepr.h
#define PyLong_SHIFT    30
#define PyLong_BASE     ((digit)1 &lt;&lt; PyLong_SHIFT)
#define PyLong_MASK     ((digit)(PyLong_BASE - 1))
</code></pre>
<p>显然 PyLong_BASE 等于 2 ** 30，PyLong_MASK 等于 2 ** 30 - 1（说明 32 个位，前两个位是 0，后三十个位都是 1）。</p>
<p>然后我们可以看 x_add 的具体实现了。</p>
<pre><code class="language-C">// Objects/longobject.c

static PyLongObject *
x_add(PyLongObject *a, PyLongObject *b)
{
    // 参数 a 和 b 指向了两个要相加的整数对象
    // 获取整数在底层的 ob_size
    Py_ssize_t size_a = Py_ABS(Py_SIZE(a)), size_b = Py_ABS(Py_SIZE(b));
    // 指向两个整数的相加结果
    PyLongObject *z;
    // 循环变量
    Py_ssize_t i;
    // 每个部分的运算结果
    digit carry = 0;
    
    // 如果 size_a 小于 size_b，说明 |a| &lt; |b|
    // 那么将两个整数交换位置，确保操作符左边的数大于右边的数
    // 这么做也符合人类习惯，可以想象一下小学时候的加法计算
    // 如果一个位数多，一个位数少，也会习惯将位数多的放在左边
    if (size_a &lt; size_b) {
        { PyLongObject *temp = a; a = b; b = temp; }
        { Py_ssize_t size_temp = size_a;
            size_a = size_b;
            size_b = size_temp; }
    }
    // 申请一个 ob_digit 的长度为 size_a + 1 的 PyLongObject
    // 但为什么是 size_a + 1 呢? 由于上面的 if 语句，使得 size_a 一定不小于 size_b
    // 那么 a 和 b 相加之后的 z 的 ob_size 一定不小于 size_a
    // 但是也可能比 size_a 多 1，比如: a = 2 ** 60 - 1, b = 1
    // 那么相加之后结果为 2 ** 60，于是 ob_size 就变成了 3
    // 因此在创建 z 的时候，ob_digit 的容量会等于 size_a + 1
    z = _PyLong_New(size_a+1);
    
    // 正常情况下, z 是一个 PyLongObject *，但如果 z == NULL, 表示分配失败（程序崩溃）
    // 但说实话, 除非你内存不够了, 否则这种情况不会发生
    if (z == NULL)
        return NULL;
    
    // 重点来了，因为 size_a &gt; size_b，所以会以 size_b 为准，两者从低位向高位依次对应相加
    // 当 b 到头了，再单独算 a 的剩余部分
    // 因此以 i &lt; size_b 作为条件
    for (i = 0; i &lt; size_b; ++i) {
        // 将 a-&gt;ob_digit[i] + b-&gt;ob_digit[i] + carry（初始为 0）作为 carry
        // 如果 carry 没有超过 2 ** 30 - 1，那么它就是 z -&gt; ob_digit[i] 的值
        carry += a-&gt;ob_digit[i] + b-&gt;ob_digit[i];
        // 但 carry 是可能溢出的，当溢出时，应该要减去 2 ** 30，所以还要判断是否产生了进位
        // 但解释器没有使用常规的判断，而是选择了效率更高的位运算（carry &amp; PyLong_MASK）
        // 由于 PyLong_MASK 等于 (1 &lt;&lt; 30) - 1，所以它的前两个位是 0，后面三十个位全是 1
        // 因此当 carry 不超过 2 ** 30 - 1 时，carry &amp; PyLong_MASK 就等于 carry
        // 当 carry 超过 2 ** 30 - 1 时，carry &amp; PyLong_MASK 就等于 carry - 2 ** 30
        z-&gt;ob_digit[i] = carry &amp; PyLong_MASK;
        // 然后当 carry 产生进位时，显然不可以丢，它们要作用在数组中下一个元素相加的结果上
        // 所以这里将 carry 右移 30 位，得到进位，然后重新赋值给 carry，并作用在下一轮循环中
        // 如果没有产生进位，那么 carry 为 0，如果产生了进位，那么 carry 为 1
        carry &gt;&gt;= PyLong_SHIFT;
    }
    
    // 如果 b 到头了, 那么继续从当前的 i 开始遍历，直到 i == size_a, 逻辑还是和上面一样
    for (; i &lt; size_a; ++i) {
        // 此时只需要加上 a-&gt;ob_digit[i] 和 carry 即可，因为 b 到头了
        carry += a-&gt;ob_digit[i];
        // 这里也要按位与 PyLong_MASK, 因为也可能存在进位的情况
        // 拿生活中的 99999 + 1 为例，此时 a = 99999, b = 1，显然第一次循环 b 就到头了
        // 但后面单独循环 a 的时候, 依旧会产生进位，所以这里也是同理
        z-&gt;ob_digit[i] = carry &amp; PyLong_MASK;
        // carry 右移 30 位得到进位，然后重新赋值给 carry
        carry &gt;&gt;= PyLong_SHIFT;
    }
    // 两个循环结束之后, 其实还差一步，还拿 99999 + 1 举例子
    // 按照顺序相加得到的是 00000，因为最后还进了一个 1，这里的 carry 也是同理
    // 因此 z 的 ob_size 要比 size_a 多 1，目的就在于此
    // 所以要将 z-&gt;ob_digit 的最后一个元素设置成 carry
    z-&gt;ob_digit[i] = carry;
    // 但如果最后的 carry 没有进位的话，显然其结果就是 0
    // 所以最后没有直接返回 z，而是返回了 long_normalize(z)
    // 这个 long_normalize 函数的作用是从后往前依次检查 ob_digit 的元素
    // 如果为 0，那么就将其 ob_size 减去 1, 直到出现一个不为 0 的元素
    // 比如 ob_digit 为 [0, 3, 1, 0, 0, 0]，长度为 6，但规范化之后的 ob_size 显然是 3
    // 不过对于当前来说，显然最多只会检查一次，因为它的 ob_size 只比 size_a 多 1
    // 所以判断数组最后一个元素是否为 0 也可以，如果为 0 则说明没有产生进位
    return long_normalize(z);
}
</code></pre>
<p>整数在底层实现的很巧妙，不理解的话可以多看几遍，然后我们在 Python 的层面上再反推一下绝对值加法，进一步感受底层的运算过程。</p>
<pre><code class="language-Python"># 假设有 a 和 b 两个整数
# 当然这里是使用列表直接模拟底层数组 ob_digit
a = [1073741744, 999, 765, 123341]
b = [841, 1073741633, 2332]
# 然后创建 z，表示 a 和 b 的相加结果
z = []

# 为了更直观，我们一步步手动相加
# 首先是 a[0] + b[0]，得到 carry
carry = a[0] + b[0]
# 但 carry 可能大于 2 ** 30 - 1，所以要进行判断
# 如果大于，那么要减去 2 ** 30，否则保持不变
# 而这一步可以使用位运算来实现，将 carry 和 (2 ** 30 - 1) 按位与即可
print(carry &amp; (2 ** 30 - 1))  # 761
# 结果是 761，说明 carry 比 2 ** 30 - 1 大
# 然后 z 的第一个元素就是 761
z.append(761)

# 接着计算 a[1] + b[1] 得到新的 carry
# 但是之前的 carry 大于 2 ** 30 - 1，所以还要再加上 carry &gt;&gt; 30，即进位
# 当然，如果没有产生进位，那么 carry &gt;&gt; 30 就是 0
carry = (carry &gt;&gt; 30) + a[1] + b[1]
# 然后 carry &amp; (2 ** 30 - 1) 得到 809，说明 carry 依旧大于 2 ** 30 - 1
print(carry &amp; (2 ** 30 - 1))  # 809
# 所以 z 的第二个元素就是 809
z.append(809)

# 计算 a[2] + b[2] 的时候也是同理
carry = (carry &gt;&gt; 30) + a[2] + b[2]
# 但显然此时的 carry 已经不大于 2 ** 30 - 1 了
print(carry &amp; (2 ** 30 - 1))  # 3098
# 说明 z 的第三个元素是 3098
z.append(3098)

# 此时 b 到头了，所以直接将 a[3] 作为 carry
# 当然还要判断上一步的 carry 是否大于 2 ** 30 - 1
# 所以还是右移 30 位，当不大于 2 ** 30 - 1 时，carry &gt;&gt; 30 就是 0
carry = (carry &gt;&gt; 30) + a[3]
print(carry &amp; (2 ** 30 - 1))  # 123341
z.append(123341)

# 此时 a 也遍历完毕，但是不要忘记再对 carry 进行判断
# 如果大于 2 ** 30 - 1，那么会产生进位，所以 z 还要再 append 一个 1
# 当然这里 carry 没有超过 2 ** 30 - 1

# 此时 z 为 [761, 809, 3098, 123341]
print(z)  # [761, 809, 3098, 123341]

# a = [1073741744, 999, 765, 123341]
# b = [841, 1073741633, 2332]
# z = [761, 809, 3098, 123341]
# 因此 ob_digit 为 [1073741744, 999, 765, 123341]
# 和 ob_digit 为 [841, 1073741633, 2332] 的两个 PyLongObject 相加
# 得到的新的 PyLongObject 的 ob_digit 为 [761, 809, 3098, 123341]
print(
    a[0] + a[1] * 2 ** 30 + a[2] * 2 ** 60 + a[3] * 2 ** 90
    +
    b[0] + b[1] * 2 ** 30 + b[2] * 2 ** 60
    ==
    z[0] + z[1] * 2 ** 30 + z[2] * 2 ** 60 + z[3] * 2 ** 90
)  # True
</code></pre>
<p>以上就是绝对值加法，我们从源码的角度和 Python 代码的角度分别解释了一遍。看完了绝对值加法，再来看看绝对值减法。</p>
<h2 id="绝对值减法x_sub"><a class="header" href="#绝对值减法x_sub">绝对值减法：x_sub</a></h2>
<p>和绝对值加法一样，绝对值减法也可以类比生活中的减法，从低位到高位分别相减。如果某一位相减的时候发现不够了，那么要向高位借一位。比如 27 减去 9，7 比 9 小，因此向 2 借一位变成 17，减去 9，得 8。但 2 被借了一位，所以剩下 1，因此结果为 17。</p>
<pre><code class="language-C">// Objects/longobject.c

static PyLongObject *
x_sub(PyLongObject *a, PyLongObject *b)
{   
    // 依旧是获取两者的 ob_size 的绝对值
    Py_ssize_t size_a = Py_ABS(Py_SIZE(a)), size_b = Py_ABS(Py_SIZE(b));
    // z 指向相加之后的 PyLongObject
    PyLongObject *z;
    // 循环变量
    Py_ssize_t i;
    // 如果 size_a 小于 size_b，那么 sign 就是 -1，否则就是 1
    int sign = 1;
    // 之前 carry 保存相加的结果，这里的 borrow 保存相减的结果
    // 名字很形象，相加要进位叫 carry，相减要借位叫 borrow
    digit borrow = 0;

    // 接下来依旧要判断两个整数的大小，确保相减的时候，绝对值大的一方在左边
    // 相加的时候，大的一方在左边还是在右边，其实没太大影响
    // 而相减的时候如果大的一方在左边，显然会省事很多
    // 所以如果 size_a 比 size_b 小，说明 a 的绝对值比 b 小
    if (size_a &lt; size_b) {
        // 那么令 sign = -1，因为 a 和 b 交换了位置，所以后续相减之后还要再乘上 sign
        // 因为计算的是绝对值之差，符号是在绝对值之差计算完毕之后通过 sign 判断的
        sign = -1;
        // 交换 a 和 b 的位置
        { PyLongObject *temp = a; a = b; b = temp; }
        { Py_ssize_t size_temp = size_a;
            size_a = size_b;
            size_b = size_temp; }
    }
    // 如果 size_a == size_b，那么需要依次比较 ob_digit 里的元素，才能判断出大小
    else if (size_a == size_b) {
        // 所以从 ob_digit 的尾部开始遍历
        i = size_a;
        while (--i &gt;= 0 &amp;&amp; a-&gt;ob_digit[i] == b-&gt;ob_digit[i])
            ;
        // 如果所有元素都相等，那么 i 会等于 -1，相减的结果为 0，此时直接返回 0 即可
        // 所以这一步也是为了能够快速返回结果，而额外做的一层判断
        if (i &lt; 0)
            return (PyLongObject *)PyLong_FromLong(0);
        // 但如果某个对应的元素不相等，那么只需判断这两者谁大谁小即可
        // 假设 a 的 ob_digit 是 [2, 3, 4, 5]，b 的 ob_digit 是 [1, 2, 4, 5]
        // 那么上面的 while 循环结束之后，i 会等于 1，显然只需要判断索引为 1 时，对应的值谁大谁小即可
        if (a-&gt;ob_digit[i] &lt; b-&gt;ob_digit[i]) {
            // 如果 a-&gt;ob_digit[i] &lt; b-&gt;ob_digit[i]，同样说明 a 小于 b
            // 那么将 sign 设置为 -1，并交换 a 和 b 的位置
            sign = -1;
            { PyLongObject *temp = a; a = b; b = temp; }
        }
        // 因为高位在减法的时候会被抵消掉，所以将 size_a 和 size_b 设置成 i + 1 即可
        // 假设两个整数的 ob_digit 分别是 [2, 3, 4, 5] 和 [1, 2, 4, 5]
        // 因为后两个元素是一样的，所以后续只需要对索引为 [0: i+1] 的部分做差即可
        size_a = size_b = i+1;
    }
    // a 和 b 相减之后，结果一定不超过 a，因此 ob_digit 的长度一定小于等于 size_a
    z = _PyLong_New(size_a);
    if (z == NULL)
        return NULL;
    // 然后下面的逻辑和 x_add 是类似的
    for (i = 0; i &lt; size_b; ++i) {
        // 让 a 的 ob_digit[i] 减去 b 的 ob_digit[i] 
        // 当然，由于上一个元素在相减的时候，可能会向当前元素借位，因此还要再减去 borrow
        // 如果没借位，那么 borrow 是 0，如果借位了，那么 borrow 是 1
        // 然后如果当前元素相减的结果也小于 0，那么继续向下一个元素借位
        // 但我们似乎没有看到借位的逻辑，这是因为 digit 是无符号 32 位整型，负数会发生环绕
        // 假设这里相减得到的是 -100，那么结果就是 2 ** 32 - 100
        // 所以存储的负数会变成 &quot;2 ** 32 + 该负数&quot;，相当于自动向数组的下一个元素借了一位
        // 但 digit 只用 30 个位，所以借一位之后应该加上 2 ** 30，而目前加的是 2 ** 32
        borrow = a-&gt;ob_digit[i] - b-&gt;ob_digit[i] - borrow;
        // 所以还要和 PyLong_MASK 按位与，只保留后 30 个位的值
        // 当然如果没有产生借位，borrow &amp; PyLong_MASK 的结果还是 borrow
        z-&gt;ob_digit[i] = borrow &amp; PyLong_MASK;
        // 如果借位了，下一轮循环的时候，肯定要多减个 1，但问题是怎么判断有没有借位呢？
        // 很简单，如果没有借位，borrow 一定小于 2 ** 30，第 31 个位一定是 0
        // 如果借位了，那么 borrow 一定大于 2 ** 30，第 31 个位一定是 1
        // 所以让 borrow 右移 30 个位
        borrow &gt;&gt;= PyLong_SHIFT;
        // 然后和 1 按位与，如果产生了借位，borrow 就是 1，否则就是 0
        // 等到下一轮循环的时候，再减去 borrow
        borrow &amp;= 1;
        /*
        所以 Python 底层的整数只用 30 个位真的非常巧妙，尤其是在减法的时候
        由于 digit 是 32 位，借位时会加上 2 ** 32
        但底层只用 30 个位，所以再和 PyLong_MASK 按位与，只保留后 30 个位

        而当前元素如果借位了，那么数组下一个元素要减去 1，但怎么判断它有没有借位呢？
        首先两个不超过 2 ** 30 - 1 的数，相减的结果如果为正（没产生借位）
        那么一定也不会超过 2 ** 30 - 1，换句话说其结果对应的第 31 位一定是 0
        但如果两个整数相减的结果为负，那么会自动加上 2 ** 32，因此第 31 位一定是 1
        
        所以再让 borrow 右移 30 位，并和 1 按位与
        如果结果为 1，证明相减为负数，确实向下一个元素借了 1，因此下一次循环时会多减一个 1
        如果结果为 0，那么说明没有借位，下一次循环时相当于多减了一个 0
        */
    }
  
    // 如果 size_a 和 size_b 不相等，那么还需要继续处理 a 的 ob_digit 剩余的元素
    for (; i &lt; size_a; ++i) {
        // 这里的逻辑和之前分析 x_add 是类似的
        borrow = a-&gt;ob_digit[i] - borrow;
        z-&gt;ob_digit[i] = borrow &amp; PyLong_MASK;
        borrow &gt;&gt;= PyLong_SHIFT;
        borrow &amp;= 1;
    }  // 只不过由于不会产生进位，因此不需要再对 borrow 做额外判断
       // 而 x_add 中最后还要判断 carry 有没有进位
    assert(borrow == 0);
    // 如果 sign &lt; 0，那么证明是负数，因此还要改变 z 的符号
    if (sign &lt; 0) {
        Py_SIZE(z) = -Py_SIZE(z);
    }
    // 最后同样要将 z 规范化，将高位的 0 忽略掉
    // 比如 100000 - 99999，结果是 000001，显然只需要保留最低位的 1 即可
    // 另外如果相减的结果是小整数，那么直接从池子里获取，否则返回新创建的
    return long_normalize(z);
}
</code></pre>
<p>同样的，关于绝对值减法，我们也用 Python 代码演示一遍，感受底层的运算过程。</p>
<pre><code class="language-Python">a = [5, 3]
b = [6, 1]
result = []

# 如果计算 a - b，整个过程是怎样的呢？
# 首先是 a[0] - b[0]，由于 a[0] &lt; b[0]，所以要借一位，而一个位是 2 ** 30
result.append(a[0] + 2 ** 30 - b[0])
# 注：源码中加的是 2 ** 32，所以之后还要和 PyLong_MASK 按位与
# 因此 a[0] + 2 ** 30 - b[0] 等价于 (a[0] + 2 ** 32 - b[0]) &amp; (2 ** 30 - 1)

# 然后是 a[1] - b[1]，由于 a[1] 被借走了一个位，因此要减 1
result.append(a[1] - 1 - b[1])
print(result)  # [1073741823, 1]

# 验证一下
print(
    (a[0] + a[1] * 2 ** 30)
    -
    (b[0] + b[1] * 2 ** 30)
)  # 2147483647
print(
    result[0] + result[1] * 2 ** 30
)  # 2147483647
</code></pre>
<p>以上就是绝对值减法，设计的非常巧妙，可以多看几遍，并用列表模拟 ob_digit 数组，然后实际测试一下。</p>
<h2 id="小结-15"><a class="header" href="#小结-15">小结</a></h2>
<p>关于整数的内容，我们就介绍完了。回顾一下，首先我们剖析了整数的底层实现，了解了它不会溢出的奥秘，然后又介绍了小整数对象池。但也正如之前所说，使用数组实现大整数并不是什么特别新颖的思路，它的难点在于数学运算，这是非常考验编程技巧的地方。</p>
<p>而我们这里只是分析了加减法，至于乘除则更加复杂，这里就不再分析了。关于乘法，解释器采用的是效率更高的 karatsuba 算法，比较有意思，有兴趣可以自己查看一下。</p>
<p>综上所述不难发现 Python 效率低的原因，毕竟一个简单的整数运算都要做这么多工作。当然了，解释器内部也定义了很多快分支，会提前检测能否使用快速通道进行处理，当无法使用快速通道时，再走通用逻辑。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-14"><a class="header" href="#楔子-14">楔子</a></h2>
<p>本篇文章来聊一聊布尔值是怎么实现的，在 Python 里面 True 和 False 虽然是关键字，但它们其实也是对象。</p>
<p>下面我们就来详细地解释一下。</p>
<h2 id="布尔类型"><a class="header" href="#布尔类型">布尔类型</a></h2>
<p>先来说一下布尔类型本身，我们知道 bool 继承自 int，所以 True 和 False 也具备整数的特征。</p>
<pre><code class="language-Python">print(bool.__base__)  # &lt;class 'int'&gt;
print(isinstance(True, bool))  # True

# True 和 False 可以当成 1 和 0 来用
print(True * 2)  # 2
print(3 // 3 == True)  # True
print(sum([True, 1, 2]))  # 4
print(False + 1)  # 1
</code></pre>
<p>bool 在底层对应 PyBool_Type，因此我们可以肯定地讲，PyBool_Type 的 tp_base 字段的值一定是 &amp;PyLong_Type。</p>
<pre><code class="language-c">// Objects/boolobject.c
PyTypeObject PyBool_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;bool&quot;,
    sizeof(struct _longobject),
    0,
    0,                                          /* tp_dealloc */
    0,                                          /* tp_vectorcall_offset */
    0,                                          /* tp_getattr */
    0,                                          /* tp_setattr */
    0,                                          /* tp_as_async */
    bool_repr,                                  /* tp_repr */
    &amp;bool_as_number,                            /* tp_as_number */
    // ...
    &amp;PyLong_Type,                               /* tp_base */
    // ...
};
</code></pre>
<p>bool 继承 int，所以它也实现了 tp_as_number。</p>
<h2 id="布尔值的底层结构"><a class="header" href="#布尔值的底层结构">布尔值的底层结构</a></h2>
<p>既然 bool 继承 int，那么布尔值和整数的底层结构是一样的。</p>
<pre><code class="language-C">// Objects/boolobject.c

// PyLongObject 是 struct _longobject 的类型别名
struct _longobject _Py_FalseStruct = {
    PyVarObject_HEAD_INIT(&amp;PyBool_Type, 0)
    { 0 }
};

struct _longobject _Py_TrueStruct = {
    PyVarObject_HEAD_INIT(&amp;PyBool_Type, 1)
    { 1 }
};
</code></pre>
<p>我们看到布尔值在底层是静态定义好的 PyLongObject 结构体实例，ob_digit 分别为 [0] 和 [1]，所以 False 和 True 完全可以当成 0 和 1 来用。当然啦，由于变量都是 PyObject *，所以这两个结构体实例一般不直接用，而是用底层提供的两个宏。</p>
<pre><code class="language-C">// Include/boolobject.h

/* Use these macros */
#define Py_False ((PyObject *) &amp;_Py_FalseStruct)
#define Py_True ((PyObject *) &amp;_Py_TrueStruct)
</code></pre>
<p>当返回 Python 的 True 和 False 时，底层会返回 Py_True 和 Py_False，也就是转成 PyObject * 之后再返回。为此解释器还提供了两个宏。</p>
<pre><code class="language-C">// Include/boolobject.h

#define Py_RETURN_TRUE return Py_INCREF(Py_True), Py_True
#define Py_RETURN_FALSE return Py_INCREF(Py_False), Py_False
</code></pre>
<p>当然这些应该比较简单了。</p>
<h2 id="布尔值的创建"><a class="header" href="#布尔值的创建">布尔值的创建</a></h2>
<p>创建布尔值有两种方式，一种是基于 C 整数创建，另一种是将 Python 对象转成布尔值。</p>
<p>基于 C 整数创建，会通过 PyBool_FromLong 函数，显然它是布尔对象的特定类型 API。</p>
<pre><code class="language-C">// Objects/boolobject.c

PyObject *PyBool_FromLong(long ok)
{
    PyObject *result;

    if (ok)
        result = Py_True;
    else
        result = Py_False;
    Py_INCREF(result);
    return result;
}
</code></pre>
<p>这个特定类型 API 一般都是解释器内部使用，或者编写扩展的时候使用。而除了这种方式，我们还可以调用 bool 类型，将对象转成布尔值。</p>
<pre><code class="language-C">// Objects/boolobject.c

// 基于 Python 对象创建，比如 bool(obj)
// 显然会调用 PyBool_Type 的 tp_new，在底层该字段被赋值为 bool_new
tatic PyObject *
bool_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
{   
    // 保存接收的参数，先设置为 False
    PyObject *x = Py_False;
    long ok;
    // bool 类型不接收关键字参数
    if (!_PyArg_NoKeywords(&quot;bool&quot;, kwds))
        return NULL;
    // 最多接收 1 个位置参数，解析出来赋值给 x
    // 如果不传位置参数，那么 x 就是上面设置的 Py_False
    if (!PyArg_UnpackTuple(args, &quot;bool&quot;, 0, 1, &amp;x))
        return NULL;
    // 调用 Pyobject_Islrue 判断 x 是真是假
    // 如果为真返回 1，否则返回 0
    ok = PyObject_IsTrue(x);
    if (ok &lt; 0)
        return NULL;
    // 将整数转成布尔值
    return PyBool_FromLong(ok);
}
</code></pre>
<p>所以核心就在 PyObject_IsTrue 函数里面，看一下它的内部逻辑。</p>
<pre><code class="language-C">// Objects/object.c
int
PyObject_IsTrue(PyObject *v)
{
    Py_ssize_t res;
    // 如果 v 本身是布尔值 True，那么返回 1
    if (v == Py_True)
        return 1;
    // 如果 v 本身是布尔值 False，那么返回 0
    if (v == Py_False)
        return 0;
    // 如果 v 是 None，那么返回 0
    if (v == Py_None)
        return 0;
    // 如果 v 是数值型对象，并且它的类型对象定义了 __bool__，那么调用
    else if (v-&gt;ob_type-&gt;tp_as_number != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_number-&gt;nb_bool != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_number-&gt;nb_bool)(v);
    // 如果 v 是映射型对象，并且它的类型对象定义了 __len__，那么调用
    // 说白了就是基于内部的键值对个数进行判断
    else if (v-&gt;ob_type-&gt;tp_as_mapping != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_mapping-&gt;mp_length != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_mapping-&gt;mp_length)(v);
    // 如果 v 是序列型对象，并且它的类型对象定义了 __len__，那么调用
    // 也就是基于内部的元素个数进行判断
    else if (v-&gt;ob_type-&gt;tp_as_sequence != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_sequence-&gt;sq_length != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_sequence-&gt;sq_length)(v);
    // 否则默认为真，比如我们自定义类的实例
    else
        return 1;
    // 如果 res 大于 0，返回 1，否则返回 0
    return (res &gt; 0) ? 1 : Py_SAFE_DOWNCAST(res, Py_ssize_t, int);
}
</code></pre>
<p>当 PyObject_IsTrue 调用完之后，再基于 PyBool_FromLong 创建布尔值即可，我们用 Python 代码演示一下。</p>
<pre><code class="language-python"># 不传参数，默认返回 False
print(bool())  # False

# 整数实现了 __bool__，所以 bool(1) 会调用 int.__bool__(1)
print(bool(1))  # True

# 字符串实现了 __len__，所以 bool(&quot;abc&quot;) 会调用 str.__len__(&quot;abc&quot;)
print(bool(&quot;abc&quot;))  # True

class A:
    pass

# 自定义类没有实现 __bool__、__len__
# 所以在 PyObject_IsTrue 里面最终会走 else 分支，直接为真
print(bool(A()))  # True

# 但如果定义了 __len__，那么是否为真取决于 __len__ 的返回值
# 并且 __len__ 要定义在类型对象里面，因为 a.__len__() 其实只是语法糖
# 底层真正执行的是 A.__len__(a)，关于这部分细节后续介绍类的时候会细说
type.__setattr__(A, &quot;__len__&quot;, lambda self: 0)
# 因为 __len__ 返回的是 0，所以为假，注意：__len__ 要返回整数
print(bool(A()))  # False

# 如果再实现一个 __bool__ 呢？
type.__setattr__(A, &quot;__bool__&quot;, lambda self: True)
# 我们发现结果又变成了 True，因为 __bool__ 返回的是 True（必须返回布尔值）
# 并且在源码中，__bool__ 查找的优先级高于 __len__
print(bool(A()))  # True
</code></pre>
<p>现在你是不是对布尔值有一个更深的印象了呢？一个简单的布尔值，居然有这么多可说的。</p>
<p>但是还没结束，我们还要补充一个知识点，先看一段代码。</p>
<pre><code class="language-python">name = &quot;satori&quot;

if name:
    pass

if bool(name):
    pass
</code></pre>
<p>这两个 if 判断有啥区别呢？首先 <font color="blue">if bool(name)</font> 我们已经分析过了，它会执行 bool_new 函数，将参数解析出来，接着再调用 PyObject_IsTrue，最后得到布尔值。</p>
<p>而对于 <font color="blue">if name</font> 来说，它会直接调用 PyObject_IsTrue，后续在分析 if 语句的时候会介绍。所以在工作中，我们使用 <font color="blue">if name</font> 即可。</p>
<p>当然啦，获取布尔值除了 <font color="blue">bool(obj)</font> 之外，还可以使用 <font color="blue">not not obj</font>。</p>
<pre><code class="language-Python">name = &quot;satori&quot;

print(bool(name))  # True
print(not not name)  # True
</code></pre>
<p>这两者又有什么区别呢？首先 bool(name) 在 Python 里面是一个调用，会进行参数解析，拿到对象之后调用 PyObject_IsTrue 判断真假，正常执行的话，会返回 1 或 0。然后基于 1 和 0 创建布尔值，为 1 返回 True，为 0 返回 False。</p>
<p>而 <font color="blue">not name</font> 会对应一条 UNARY_NOT 字节码，它内部也会调用 PyObject_IsTrue，如果结果为 1 返回 False，为 0 返回 True，正好是相反的。所以 <font color="blue">not not name</font> 则相当于在 <font color="blue">not name</font> 的基础上再反过来一次，这样就和 bool(name) 的结果是一致的了。</p>
<p>当然在工作中，使用哪种都可以，看自己喜好。但为了代码的可读性，显式获取布尔值的时候还是建议使用 bool(name)，效率上没太大差别。</p>
<h2 id="小结-16"><a class="header" href="#小结-16">小结</a></h2>
<p>以上就是布尔值相关的内容。</p>
<ul>
<li>bool 继承 int，并且布尔值在底层和整数使用同一个结构体，只是 ob_type 不同；</li>
<li>布尔值具备整数的所有特征，可以像整数一样参与各种运算，其中 True 会被解释成 1，False 会被解释成 0；</li>
<li>布尔值有两种，分别是 True 和 False，它们是单例的，判断时应该使用 is，而不是 ==，除非你把 True 和 False 当成整数使用；</li>
<li>在 Python 里面如果要创建布尔值，有三种方式：通过 True 和 False 字面量、调用类型对象 bool、使用 not not；</li>
</ul>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-15"><a class="header" href="#楔子-15">楔子</a></h2>
<p>None 在 Python 里面也是一个对象，用于表示空（值不存在的情况）。比如基于主键从数据库获取记录，如果没有查询到，那么一般会返回 None。另外如果函数没有返回值，那么也会隐式地返回 None，表示返回的是空。</p>
<p>本篇文章就来聊一聊 None 是怎么实现的。</p>
<h2 id="none-的底层结构"><a class="header" href="#none-的底层结构">None 的底层结构</a></h2>
<p>和其它对象不同，由于 None 没有额外的实体数据，所以它在底层就是一个 PyObject 结构体实例。因此也能看出，None 的大小为 16 字节。</p>
<pre><code class="language-C">// Objects/object.c
PyObject _Py_NoneStruct = {
  _PyObject_EXTRA_INIT
  1, &amp;_PyNone_Type
};
</code></pre>
<p>None 在底层只包含引用计数和类型，然后类型为 _PyNone_Type。由于变量都是 PyObject *，所以和布尔值一样，解释器也提供了相应的宏，从而方便使用。</p>
<pre><code class="language-C">// Include/object.h
#define Py_None (&amp;_Py_NoneStruct)
</code></pre>
<p>注意：None 是单例的，如果要判断对象是否为空，应该使用 is 关键字。</p>
<h2 id="none-的类型"><a class="header" href="#none-的类型">None 的类型</a></h2>
<p>说完了 None 本身，再来看看它的类型。</p>
<pre><code class="language-Python">print(type(None))  # &lt;class 'NoneType'&gt;
</code></pre>
<p>None 的类型是 <font color="blue">&lt;class 'NoneType'&gt;</font>，但这个类解释器没有暴露给我们，需要通过 type 去获取。注意：NoneType 无法被继承，当然我们一般也不会去继承它。</p>
<pre><code class="language-python">class MyType(type(None)):
    pass
&quot;&quot;&quot;
TypeError: type 'NoneType' is not an acceptable base type
&quot;&quot;&quot;
</code></pre>
<p>然后看一下 NoneType 的底层结构，它位于 Objects/object.c 中。</p>
<pre><code class="language-C">PyTypeObject _PyNone_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;NoneType&quot;,
    0,
    0,
    none_dealloc,       /*tp_dealloc*/ /*never called*/
    0,                  /*tp_vectorcall_offset*/
    0,                  /*tp_getattr*/
    0,                  /*tp_setattr*/
    0,                  /*tp_as_async*/
    none_repr,          /*tp_repr*/
    &amp;none_as_number,    /*tp_as_number*/
    0,                  /*tp_as_sequence*/
    0,                  /*tp_as_mapping*/
    0,                  /*tp_hash */
    0,                  /*tp_call */
    0,                  /*tp_str */
    0,                  /*tp_getattro */
    0,                  /*tp_setattro */
    0,                  /*tp_as_buffer */
    Py_TPFLAGS_DEFAULT, /*tp_flags */
    0,                  /*tp_doc */
    0,                  /*tp_traverse */
    0,                  /*tp_clear */
    0,                  /*tp_richcompare */
    0,                  /*tp_weaklistoffset */
    0,                  /*tp_iter */
    0,                  /*tp_iternext */
    0,                  /*tp_methods */
    0,                  /*tp_members */
    0,                  /*tp_getset */
    0,                  /*tp_base */
    0,                  /*tp_dict */
    0,                  /*tp_descr_get */
    0,                  /*tp_descr_set */
    0,                  /*tp_dictoffset */
    0,                  /*tp_init */
    0,                  /*tp_alloc */
    none_new,           /*tp_new */
};
</code></pre>
<p>NoneType 的类型也是 type，然后它实现了 tp_as_number。</p>
<pre><code class="language-C">// Objects/object.c
static PyNumberMethods none_as_number = {
    // ...
    (inquiry)none_bool,         /* nb_bool */
    // ...
}      
</code></pre>
<p>但是只实现了里面的 nb_bool，用于生成布尔值。</p>
<pre><code class="language-c">// Objects/object.c
static int
none_bool(PyObject *v)
{
    return 0;
}
</code></pre>
<p>函数返回的是 0，因此调用 PyBool_FromLong 的时候，会返回 Py_False。</p>
<pre><code class="language-python">print(bool(None))  # False
print(not not None)  # False
</code></pre>
<h2 id="小结-17"><a class="header" href="#小结-17">小结</a></h2>
<p>以上我们就简单介绍了 None，当然内容有些过于简单了，因为 None 本身就没多少内容，核心就两点：</p>
<ul>
<li>None 是单例的；</li>
<li>判断的时候使用 is 关键字；</li>
</ul>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-16"><a class="header" href="#楔子-16">楔子</a></h2>
<p>本篇文章来探讨一下切片是如何实现的，因为在操作字符串、元组、列表等数据结构时，我们经常会使用切片截取数据，所以对切片做一个全方位的了解是很有必要的。</p>
<pre><code class="language-Python">data = list(range(10))
print(data[1: 8: 3])  # [1, 4, 7]
</code></pre>
<p>以上就是基于切片截取数据，在工作中我们会大量使用切片。但你知道吗，其实切片也是一个对象，类型为 slice，下面我们来看一下切片的底层结构。</p>
<h2 id="切片的底层结构"><a class="header" href="#切片的底层结构">切片的底层结构</a></h2>
<p>切片的类型是 slice，那么根据解释器的 API 命名规则，我们猜测：</p>
<ul>
<li>切片（slice 对象）在底层对应 PySliceObject 结构体实例；</li>
<li>slice 类型本身在底层对应 PySlice_Type；</li>
</ul>
<p>下面看一下具体实现。</p>
<pre><code class="language-C">// Include/sliceobject.h
typedef struct {
    PyObject_HEAD
    PyObject *start, *stop, *step;
} PySliceObject;
</code></pre>
<p>切片是不可变对象，除了对象的公共头部之外，还有三个字段，分别表示切片的起始位置、终止位置、步长。这也意味着创建切片时，可以给 slice 传递三个参数。</p>
<pre><code class="language-Python"># 创建一个切片
s = slice(1, 8, 3)
print(s)  # slice(1, 8, 3)
</code></pre>
<p>问题来了，切片创建的时候，传递的参数绑定在了哪些属性上呢？前面我们说过，实例对象可以绑定哪些属性，会定义在类型对象的 tp_members 字段中。</p>
<p><img src="./images/73.png" alt="" /></p>
<p>我们看到切片拥有三个属性，名称也是 start、stop、step。</p>
<pre><code class="language-python">s = slice(1, 8, 3)
print(s)  # slice(1, 8, 3)
print(s.start)  # 1
print(s.stop)  # 8
print(s.step)  # 3
</code></pre>
<p>非常简单，你在 Python 里面看到的一切，都能从源码中找到答案。</p>
<h2 id="切片是怎么创建的"><a class="header" href="#切片是怎么创建的">切片是怎么创建的</a></h2>
<p>切片是内置类型的实例对象，对于这样的对象，有两种创建方式，相信你已经知道我要说什么了。我们在最开始专门用了十篇文章，从宏观的角度介绍了 Python 的对象模型，目的就在于此。</p>
<p>创建内置对象的两种方式：</p>
<ul>
<li>通过对象的特定类型 API 创建，只适用于内置对象；</li>
<li>通过调用类型对象创建，所有对象都适用；</li>
</ul>
<p>解释器对内置对象了如指掌，它们对应的结构体在源码中是写死的，直接 sizeof 一下即可知晓要申请多大内存，完全不需要借助类型对象。</p>
<pre><code class="language-python">data = list(range(10))
# 通过特定类型 API 创建
print(data[1: 8: 3])  # [1，4，7]
# 通过调用类型对象创建
print(data[slice(1, 8, 3)])  # [1，4，7]
</code></pre>
<p>解释器看到 data[1: 8: 3] 就知道要创建一个切片，并且是在数据截取的过程中创建的，我们不能单独写一个 <font color="blue">1: 8: 3</font>，这是不符合语法规则的。如果真的想单独创建一个切片，那么需要通过 <font color="blue">slice(1, 8, 3)</font> 的方式。</p>
<p>下面通过源码，看一下底层的创建过程。</p>
<pre><code class="language-C">// Objects/sliceobject.c
static PyObject *
slice_new(PyTypeObject *type, PyObject *args, PyObject *kw)
{
    PyObject *start, *stop, *step;
    start = stop = step = NULL;
    // slice 不接收关键字参数，因此 kw 要指向空字典
    if (!_PyArg_NoKeywords(&quot;slice&quot;, kw))
        return NULL;
    // slice 接收 1 ~ 3 个位置参数，因此 args 指向的元组必须包含 1 ~ 3 个元素
    // 然后解析 args，将内部的元素分别赋值给 start、stop、step
    if (!PyArg_UnpackTuple(args, &quot;slice&quot;, 1, 3, &amp;start, &amp;stop, &amp;step))
        return NULL;

    // 如果 stop == NULL，说明只传递了一个参数，按照顺序这个参数会赋值给 start
    // 但很明显，如果只有一个参数，那么这个参数应该交给 stop 保存
    // 于是让 stop = start，并让 start = NULL，至于这么做的原因可以想象一下 range
    // 如果是 range(0, 9)，那么起始位置和终止位置就是 0 和 9
    // 但如果是 range(9)，那么这个 9 就是终止位置
    if (stop == NULL) {
        stop = start;
        start = NULL;
    }
    // 假设传了一个参数 8，那么这里就是 PySlice_New(NULL, 8, NULL)
    // 假设传了两个参数 1、8，那么这里就是 PySlice_New(1, 8, NULL)
    // 假设传了三个参数 1、8、3，那么这里就是 PySlice_New(1, 8, 3)
    return PySlice_New(start, stop, step);
}

// 切片缓存，注：slice_cache 只能缓存一个切片
static PySliceObject *slice_cache = NULL;

PyObject *
PySlice_New(PyObject *start, PyObject *stop, PyObject *step)
{
    PySliceObject *obj;
    // 如果 slice_cache 不为 NULL，证明缓存了切片，那么赋值给 obj
    // 由于 slice_cache 只能缓存一个切片，那么赋值给 obj 之后，自身要重置为 NULL
    if (slice_cache != NULL) {
        obj = slice_cache;
        slice_cache = NULL;
        _Py_NewReference((PyObject *)obj);
    } else {
        // 否则调用 PyObject_GC_New 为 PySliceObject 实例申请内存
        obj = PyObject_GC_New(PySliceObject, &amp;PySlice_Type);
        if (obj == NULL)
            return NULL;
    }
    // 如果 start、stop、step 是 NULL，那么转成 Python 的 None
    if (step == NULL) step = Py_None;
    Py_INCREF(step);
    if (start == NULL) start = Py_None;
    Py_INCREF(start);
    if (stop == NULL) stop = Py_None;
    Py_INCREF(stop);
    // 设置切片的 start、stop、step 属性
    obj-&gt;step = step;
    obj-&gt;start = start;
    obj-&gt;stop = stop;
    // 接收 GC 跟踪（在之后的篇章中会解释）
    _PyObject_GC_TRACK(obj);
    // 转成泛型指针之后返回
    return (PyObject *) obj;
}
</code></pre>
<p>以上就是切片的创建过程，非常简单，我们用 Python 代码演示一遍。</p>
<pre><code class="language-Python">print(slice(8))  # slice(None, 8, None)
print(slice(1, 8))  # slice(1, 8, None)
print(slice(1, 8, 3))  # slice(1, 8, 3)
</code></pre>
<p>结果和源码是一致的。</p>
<h2 id="切片的缓存"><a class="header" href="#切片的缓存">切片的缓存</a></h2>
<p>从源码中可以看到，切片是有缓存的。</p>
<pre><code class="language-c">static PySliceObject *slice_cache = NULL;
</code></pre>
<p>这个字段用于缓存被回收的切片，并且从切片的创建过程可以看出只会缓存一个，而不是像浮点数那样以链表的形式缓存多个。之所以这么做，是因为在大部分情况下，切片用完之后会立即销毁。</p>
<pre><code class="language-python">data = list(range(10))
# 创建一个切片，截取完数据之后就销毁
print(data[0: 3])  # [0, 1, 2]
# 创建一个切片，截取完数据之后就销毁
print(data[2: 7])  # [2, 3, 4, 5, 6]
</code></pre>
<p>像 <font color="blue">data[start: stop: step]</font> 这种形式，当数据截取完毕之后，创建的切片会立即回收，所以对于解释器来说，它只需要缓存一个切片即可。因此你可以认为同一时刻只会存在一个有效切片，那什么时候会存在多个呢？</p>
<pre><code class="language-Python">data = list(range(10))
s1 = slice(0, 3)
s2 = slice(2, 7)
print(data[s1])  # [0, 1, 2]
print(data[s2])  # [2, 3, 4, 5, 6]
</code></pre>
<p>在这种情况下，会同时存在多个有效切片，比如 s1 和 s2 都指向了有效的切片。但很明显，我们在工作中不会这么做，而是在截取数据时，让解释器通过切片的特定类型 API 自动创建。</p>
<p>下面我们来打印切片的地址，看看切片是否被缓存起来了。</p>
<pre><code class="language-python"># 创建一个切片，缓存如果存在，从缓存获取，否则创建新的切片
&gt;&gt;&gt; s1 = slice(0, 3)
&gt;&gt;&gt; id(s1)
140190801666944

# 创建切片，因为 s1 和 s2 是两个独立的切片，所以它们的地址是不一样的
&gt;&gt;&gt; s2 = slice(2, 7)
&gt;&gt;&gt; id(s2)
140190800965120

# 删除 s1，那么它指向的切片会被放到缓存中
&gt;&gt;&gt; del s1

# 创建新的切片，使用缓存，显然它的地址和之前 s1 指向的切片的地址是一样的
&gt;&gt;&gt; s3 = slice(1, 5)
&gt;&gt;&gt; id(s3)
140190801666944

# 由于缓存为空，那么删除 s2，它指向的切片会被放入缓存
&gt;&gt;&gt; del s2

# 创建新的切片，显然它的地址和之前 s2 指向的切片的地址是一样的
&gt;&gt;&gt; s4 = slice(1, 6)
&gt;&gt;&gt; id(s4)
140190800965120
</code></pre>
<p>打印结果表明，切片是会被缓存的，但我们怎么证明切片只会缓存一个呢？这个直接看源码即可，根据之前的经验，对象被放入缓存这一步一定发生在对象被销毁的时候，所以我们只需要看切片的销毁过程即可。</p>
<p>对象被销毁时，会调用类型对象的 tp_dealloc，也就是析构函数。</p>
<p><img src="./images/74.png" alt="" /></p>
<p>类型对象的 tp_basicsize 保存了实例对象的基础大小，对于切片而言就是 sizeof(PySliceObject)，然后切片又是定长对象，因此 tp_itemsize 是 0。所以切片的大小是固定的，PyObject 占 16 字节，start、end、step 各占 8 字节，总共 40 字节，因此任何一个切片的大小都是固定的 40 字节。</p>
<p>而这个大小即使不借助类型对象也可以计算出来，因为内置对象的定义都是写死的，解释器对它们了如指掌。</p>
<p>为了唤醒大家的记忆，加深理解，以前的内容会时不时回顾一下。我们继续看切片的销毁，对应的析构函数是 slice_dealloc。</p>
<pre><code class="language-C">// Objects/sliceobject.c
static void
slice_dealloc(PySliceObject *r)
{
    // 取消 GC 跟踪，相关内容后续介绍
    _PyObject_GC_UNTRACK(r);
    // 切片销毁时，减少 start、stop、step 指向对象的引用计数
    Py_DECREF(r-&gt;step);
    Py_DECREF(r-&gt;start);
    Py_DECREF(r-&gt;stop);
    // 关键来了，如果 slice_cache 为 NULL，证明没有缓存
    // 那么让 slice_cache 保存销毁的切片的指针，而切片的内存不释放
    // 这样下一次创建切片时就不需要申请内存了，直接使用缓存即可
    // 因为没有申请内存，只是初始化了 start、stop、step 三个字段，所以效率会更高
    if (slice_cache == NULL)
        slice_cache = r;
    // 否则释放切片所占的内存
    else
        PyObject_GC_Del(r);
}
</code></pre>
<p>从源码中可以看到，如果 slice_cache 不为空，说明已经缓存了一个切片，if 条件不成立，于是会选择释放内存，所以切片只会缓存一个。</p>
<h2 id="切片属性的初始化"><a class="header" href="#切片属性的初始化">切片属性的初始化</a></h2>
<p>切片接收 1 到 3 个元素，但我们可能只传一个，那么剩余的属性是怎么初始化的呢？举个例子：</p>
<pre><code class="language-python">&gt;&gt;&gt; data = list(range(10))
&gt;&gt;&gt; data[: 5]
[0, 1, 2, 3, 4]
&gt;&gt;&gt; data[1:]
[1, 2, 3, 4, 5, 6, 7, 8, 9]
&gt;&gt;&gt; data[1:: 2]
[1, 3, 5, 7, 9]
&gt;&gt;&gt; data[:: 2]
[0, 2, 4, 6, 8]
&gt;&gt;&gt; data[:]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
</code></pre>
<p>这些切片都是合法的，当参数不足时，它们的 start、end、step 是怎么设置的呢？</p>
<pre><code class="language-C">// Objects/sliceobject.c

// 该函数接收指向切片的指针，以及三个整型指针
// 会将切片的起始位置、终止位置、步长解析出来，赋值给 *start、*stop、*step
// 所以该函数会在其它函数的内部被调用，先声明 Py_ssize_t start, stop, step
// 然后将切片指针、&amp;start、&amp;stop、&amp;end 传递给 PySlice_Unpack 进行调用
// 当该函数执行完毕时，外部就拿到了切片的起始位置、终止位置以及步长
int
PySlice_Unpack(PyObject *_r,
               Py_ssize_t *start, Py_ssize_t *stop, Py_ssize_t *step)
{
    // 将 PyObject * 转成 PySliceObject *
    PySliceObject *r = (PySliceObject*)_r;
    Py_BUILD_ASSERT(PY_SSIZE_T_MIN + 1 &lt;= -PY_SSIZE_T_MAX);
  
    // 判断步长，如果解析出的步长为空，那么将 *step 赋值为 1
    // 所以当不指定步长时，步长会被设置为 1，因此 data[::] 等价于 data[:: 1]
    if (r-&gt;step == Py_None) {
        *step = 1;
    }
    else {
        // 如果步长不为空，那么它应该是整数，或者是实现了 __index__ 的类的实例对象
        // 但如果步长的类型不合法，那么 _PyEval_SliceIndex 里面会设置异常
        // 合法的话，会将 r-&gt;step 赋值给 *step
        if (!_PyEval_SliceIndex(r-&gt;step, step)) return -1;
        // 步长不能为 0，否则设置 ValueError(&quot;slice step cannot be zero&quot;)
        if (*step == 0) {
            PyErr_SetString(PyExc_ValueError,
                            &quot;slice step cannot be zero&quot;);
            return -1;
        }
        // 如果步长小于 -PY_SSIZE_T_MAX，那么设置为 -PY_SSIZE_T_MAX
        // 显然这一步基本不会发生
        if (*step &lt; -PY_SSIZE_T_MAX)
            *step = -PY_SSIZE_T_MAX;
    }
  
    // 检测起始位置，如果为 None
    // 当步长大于 0 时，将 *start 设置为 0
    // 当步长小于 0 时，将 *start 设置为 int64 最大值，这背后的原理一会儿解释
    if (r-&gt;start == Py_None) {
        *start = *step &lt; 0 ? PY_SSIZE_T_MAX : 0;
    }
    // 说明起始位置不为 None
    else {
        // 如果起始位置的类型不合法，那么设置异常，直接返回，否则赋值给 *start
        if (!_PyEval_SliceIndex(r-&gt;start, start)) return -1;
    }
  
    // 如果终止位置为 None
    // 当步长大于 0 时，将 *stop 设置为 PY_SSIZE_T_MAX，即 int64 最大值
    // 当步长小于 0 时，将 *stop 设置为 PY_SSIZE_T_MIN，即 int64 最小值
    if (r-&gt;stop == Py_None) {
        *stop = *step &lt; 0 ? PY_SSIZE_T_MIN : PY_SSIZE_T_MAX;
    }
    // 说明终止位置不为 None
    else {
        // 如果终止位置不合法，那么设置异常，直接返回，否则赋值给 *stop
        if (!_PyEval_SliceIndex(r-&gt;stop, stop)) return -1;
    }

    return 0;
}
</code></pre>
<p>代码逻辑有一些绕，虽然我们知道它在做什么，但问题是这么做的意义是什么呢？在解释之前，我们先用 Python 代码将该函数所做的事情再描述一遍，这样更容易理解。</p>
<pre><code class="language-Python">PY_SSIZE_T_MAX = 2 ** 63 - 1
PY_SSIZE_T_MIN = -2 ** 63

# 如果切片同时包含起始位置、终止位置、步长，会直接赋值给 start、end、step
# 这种情况最简单，就不赘述了，我们来讨论未被同时指定的情况

# 步长为空，比如 data[1: 8]
start = 1
end = 8
step = 1

# 起始位置为空，步长大于 0，比如 data[: 8]
start = 0
end = 8
step = 1
# 起始位置为空，步长小于 0，比如 data[: 8: -1]
start = PY_SSIZE_T_MAX
end = 8
step = -1

# 终止位置为空，步长大于 0，比如 data[2:]
start = 2
end = PY_SSIZE_T_MAX
step = 1
# 终止位置为空，步长小于 0，比如 data[2:: -1]
start = 2
end = PY_SSIZE_T_MIN
step = -1

# 起始位置、终止位置均为空，步长大于 0，比如 data[::]
start = 0
end = PY_SSIZE_T_MAX
step = 1
# 起始位置、终止位置均为空，步长小于 0，比如 data[:: -1]
start = PY_SSIZE_T_MAX
end = PY_SSIZE_T_MIN
step = -1
</code></pre>
<p>下面来分析一下它为什么要这么做，首先我们要知道，所谓的切片截取数据，本质上就是一层 for 循环。</p>
<pre><code class="language-python">def slice_data(data: list, start: int, end: int, step: int) -&gt; list:
    ret_data = []
    assert step != 0
    if step &gt; 0:
        while start &lt; end and start &lt; len(data):
            ret_data.append(data[start])
            start += step
    else:
        while start &gt; end and start &gt;= 0:
            ret_data.append(data[start])
            start -= step * -1
    return ret_data

data = list(range(0, 10))
print(data[: 5])
print(slice_data(data, 0, 5, 1))
&quot;&quot;&quot;
[0, 1, 2, 3, 4]
[0, 1, 2, 3, 4]
&quot;&quot;&quot;
print(data[8: 3: -1])
print(slice_data(data, 8, 3, -1))
&quot;&quot;&quot;
[8, 7, 6, 5, 4]
[8, 7, 6, 5, 4]
&quot;&quot;&quot;
</code></pre>
<p>所以当步长大于 0 时，从左往右遍历，当步长小于 0 时，从右往左遍历。最后我们再画两张图，看完之后你就彻底理解了。</p>
<p><font color="darkblue"><strong>当步长大于 0 时：</strong></font></p>
<p><img src="./images/75.png" alt="" /></p>
<p>步长大于 0 时，从左往右遍历。</p>
<p>如果 start 未指定，那么设置为 0，表示从头截取，这很好理解，但问题是 end 应该设置为多少。由于 PySlice_Unpack 相当于只是做了一步预处理，它并不包含截取的原始数据的信息，所以 end 如果不指定，直接设置为 int64 最大值。</p>
<p><font color="darkblue"><strong>当步长小于 0 时：</strong></font></p>
<p><img src="./images/76.png" alt="" /></p>
<p>当步长小于 0 时，从右往左遍历。</p>
<p>因为不知道截取的原始数据有多长，所以如果 start 未指定，那么设置为 int64 最大值。但不管是从左往右还是从右往左，end 都是不包含的，所以当 end 为空时，不能指定为 0，否则索引为 0 的元素就取不到了。当然也不能设置为 -1，因为 -1 会被当成是合法的负数索引，后续截取数据时会被解释为最后一个元素的索引，所以它被设置成了 int64 最小值。</p>
<p>我们以使用切片截取列表为例，后续介绍列表的时候还会详细说：</p>
<p><img src="./images/77.png" alt="" /></p>
<p>代码中的 item 指向切片，截取数据之前要先获取它内部的 start、stop、step 属性，于是创建三个 Py_ssize_t 变量，并将指针作为参数，调用 PySlice_Unpack。当调用结束后，就拿到了切片的起始位置、终止位置、步长。</p>
<p>但还没有结束，我们说 PySlice_Unpack 只是对切片里面的值做了一些预处理，比如当 step 为 1 并且 end 没有指定时，那么 end 会被设置为 PY_SSIZE_T_MAX。</p>
<p>所以它下面又调用了函数 PySlice_AdjustIndices，会将截取的原始数据的长度也传进去，然后对 start、end、step 做进一步处理，所有的序列对象在基于切片截取数据时都会有这两步。我们看一下该函数的逻辑。</p>
<pre><code class="language-C">// Objects/sliceobject.c
Py_ssize_t
PySlice_AdjustIndices(Py_ssize_t length,
                      Py_ssize_t *start, Py_ssize_t *stop, Py_ssize_t step)
{
    // 参数 length：截取的原始数据的长度
    // 参数 start、stop：指向起始位置和终止位置的指针
    // 参数 step：步长
  
    assert(step != 0);
    assert(step &gt;= -PY_SSIZE_T_MAX);
    
    // 如果起始位置小于 0
    if (*start &lt; 0) {
        // 那么加上长度，得到正数索引，因为负数索引就是个语法糖
        *start += length;
        // 如果加上长度之后还小于 0，那么判断步长
        /* 如果 step &gt; 0，表示从前往后遍历，因此当 *start &lt; 0 时，
           直接将 *start 设置为 0，最终会从第一个元素开始往后遍历
        
           如果 step &lt; 0，表示从后往前遍历，因此当 *start &lt; 0 时，
           显然遍历不到任何元素，因为索引是大于 0 的，所以直接将 *start 设置为 -1 */        
        if (*start &lt; 0) {
            *start = (step &lt; 0) ? -1 : 0;
        }
    }
    // 如果起始位置大于等于长度，继续判断步长
    else if (*start &gt;= length) {
        /* 如果 step &gt; 0，表示从前往后遍历，因此当 *start &gt;= length 时，
           显然遍历不到任何元素，因为最大索引为 length - 1
           所以直接将 *start 设置为 length
           
           如果 step &lt; 0，表示从后往前遍历，因此当 *start &gt;= length 时，
           直接将 *start 设置为 length - 1，最终会从最后一个元素往前遍历 */       
        *start = (step &lt; 0) ? length - 1 : length;
    }
    
    // 如果终止位置小于 0
    if (*stop &lt; 0) {
        // 那么加上长度，得到正数索引
        *stop += length;
        // 如果加上长度之后还小于 0，那么判断步长
        /* 如果 step &gt; 0，表示从前往后遍历，因此当 *stop &lt; 0 时，
           显然遍历不到任何元素，因此直接将 *stop 设置为 0
           
           如果 step &lt; 0，表示从后往前遍历，因此当 *stop &lt; 0 时，
           直接将 *stop 设置为 -1，最终会从后往前遍历到头 */           
        if (*stop &lt; 0) {
            *stop = (step &lt; 0) ? -1 : 0;
        }
    }
    // 如果终止位置大于等于长度，继续判断步长
    else if (*stop &gt;= length) {
        /* 如果 step &gt; 0，表示从前往后遍历，因此当 *stop &gt;= length 时，
           直接设置为 length，会从 start 往后遍历到头
           
           如果 step &lt; 0，表示从后往前遍历，因此当 *stop &gt;= length 时，
           此时遍历不到任何元素，直接设置为 length - 1 */           
        *stop = (step &lt; 0) ? length - 1 : length;
    }
    
    // 到这里 *start、*stop 就已经转换好了
    // 或者说 PY_SSIZE_T_MIN、PY_SSIZE_T_MAX 已经基于 length 被替换掉了
    // 然后计算 *start 和 *stop 之间的距离，也就是应该要遍历多少个元素
    if (step &lt; 0) {
        if (*stop &lt; *start) {
            return (*start - *stop - 1) / (-step) + 1;
        }
    }
    else {
        if (*start &lt; *stop) {
            return (*stop - *start - 1) / step + 1;
        }
    }
    // 如果不符合条件的话，比如像 data[3: 8: -1]，显然遍历不到任何元素
    // 那么直接返回 0
    return 0;
}
</code></pre>
<p>可以看到，哪有什么岁月静好，我们之所以能够通过各种姿势使用切片，全靠解释器在替我们负重前行，它在背后做了非常多的工作。正如前面提到的，C 是一门很单纯的语言，Python 的花里胡哨的操作回归到 C 里面，就是普通的 if else 以及 while、for。</p>
<h2 id="小结-18"><a class="header" href="#小结-18">小结</a></h2>
<p>以上我们就介绍了切片的底层结构，切片也是一个对象，拥有自己的缓存。并且 Python 针对切片提供的语法也非常丰富：</p>
<ul>
<li>data[:: 1]，从左往右遍历，或者说从前往后遍历；</li>
<li>data[:: -1]，从右往左遍历；</li>
<li>data[:: 2]，只筛选索引为偶数的元素；</li>
<li>起始位置和终止位置可以为负数，会自动转成正数；</li>
</ul>
<p>所以切片用起来很方便，但要明白这背后都是因为解释器做了大量的工作。当然大部分情况下我们使用切片都是无感知的，一般不会刻意地想着要去创建一个切片，只是字符串、列表、元组等数据都支持通过切片截取数据，所以切片还是值得我们深入了解一下的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-17"><a class="header" href="#楔子-17">楔子</a></h2>
<p>本篇文章来聊一聊 bytes 对象，也就是字节串，而说到字节串就不得不提字符串。</p>
<ul>
<li>字符串是由任意数量的字符组成的序列，用于表示文本数据。在大多数编程语言中，字符串被视为一种高层数据类型，能够处理和操作文本信息。</li>
<li>字节串是由任意数量的字节组成的序列，用于表示二进制数据。</li>
</ul>
<p>字符串具有特定的字符编码，比如 UTF-8、ASCII 等等，这些编码定义了字符如何在内存中表示。而字节串没有预定义的编码，它只是原始的二进制序列，在处理非文本数据时非常有用。</p>
<p>计算机在存储数据以及通过网络传输数据时，数据格式都是二进制字节串，所以如果你想传输一段文本，那么必须先将它转成字节串。</p>
<pre><code class="language-python">name = &quot;古明地觉&quot;

print(name.encode(&quot;utf-8&quot;))
&quot;&quot;&quot;
b'\xe5\x8f\xa4\xe6\x98\x8e\xe5\x9c\xb0\xe8\xa7\x89'
&quot;&quot;&quot;
print(name.encode(&quot;utf-16&quot;))
&quot;&quot;&quot;
b'\xff\xfe\xe4S\x0ef0W\xc9\x89'
&quot;&quot;&quot;
print(name.encode(&quot;gbk&quot;))
&quot;&quot;&quot;
b'\xb9\xc5\xc3\xf7\xb5\xd8\xbe\xf5'
&quot;&quot;&quot;
</code></pre>
<p>字节串传输之后还需要转成文本数据，这个过程叫做反序列化。但由于字节串不保存编码信息，它只是一坨字节流，因此反序列化时还需要知道指定的编码，如果编码指定错误，那么反序列化会失败。</p>
<pre><code class="language-python"># name_utf8 和 name_gbk 都只是普通的字节串
name_utf8 = b'\xe5\x8f\xa4\xe6\x98\x8e\xe5\x9c\xb0\xe8\xa7\x89'
name_gbk = b'\xb9\xc5\xc3\xf7\xb5\xd8\xbe\xf5'

# 如果反序列化，必须要知道原始文本使用的编码是什么
print(name_utf8.decode(&quot;utf-8&quot;))
print(name_gbk.decode(&quot;gbk&quot;))
&quot;&quot;&quot;
古明地觉
古明地觉
&quot;&quot;&quot;

# 如果指定了错误的编码，那么反序列化会失败
try:
    name_utf8.decode(&quot;gbk&quot;)
except UnicodeDecodeError as e:
    print(e)
&quot;&quot;&quot;
'gbk' codec can't decode byte 0xa7 in position 10: illegal multibyte sequence
&quot;&quot;&quot;
</code></pre>
<p>另外我们看到字符串只有 4 个字符，但序列化之后的字节串却明显多于 4 个字节。这是因为一个字节最多能表示 256 个字符，对于英文字符来说已经足够了，但对于非英文字符则力不从心，毕竟光普通的中文字符就好几千个。</p>
<p>所以便有了多字节编码，它使用多个字节来表示一个字符，具体使用多少个，则取决于编码。如果是 GBK 编码，那么两个字节表示一个字符，如果是 UTF-8 编码，那么三个字节表示一个字符，当然这里的字符指的是非英文字符。所以在反序列化的时候，需要指定正确的编码，否则解析一定会失败。</p>
<p>以上就是关于 bytes 对象的一些基础概念，下面来看一下它的底层结构。</p>
<h2 id="字节串的底层结构"><a class="header" href="#字节串的底层结构">字节串的底层结构</a></h2>
<p>字节串的类型是 bytes，那么我们有理由相信它在底层由 PyBytesObject 结构体表示。</p>
<pre><code class="language-C">// Include/bytesobject.h
typedef struct {
    PyObject_VAR_HEAD
    Py_hash_t ob_shash;
    char ob_sval[1];
} PyBytesObject;
</code></pre>
<p>我们看一下里面的字段：</p>
<ul>
<li>PyObject_VAR_HEAD：变长对象的公共头部，因为字节串是由若干个字节组成的，具有长度的概念，所以它是变长对象。</li>
<li>ob_shash：保存字节串的哈希值，因为计算哈希值需要遍历所有的字节，如果每获取一次哈希值都要重新计算的话，性能会有影响。所以第一次计算之后会用 ob_shash 字段保存起来，之后就不再计算了。如果 bytes 对象的哈希值尚未计算，那么 ob_shash 为 -1。</li>
<li>ob_sval：char 类型的数组，负责保存具体的字节。这个和整数的 ob_digit 字段的声明方式类似，由于数组长度不属于类型的一部分，因此虽然声明的时候长度是 1，但其实长度不受限制，具体是多少取决于 bytes 对象的字节数量。</li>
</ul>
<p>我们创建几个不同的 bytes 对象，然后通过画图感受一下。</p>
<p><font color="darkblue"><strong>val = b&quot;&quot;</strong></font></p>
<p><img src="./images/78.png" alt="" /></p>
<p>我们看到即便是空的字节序列，底层的 ob_sval 也需要一个 <font color="blue">'\0'</font>，那么这个结构体实例占多大内存呢？首先 ob_sval 之外的四个成员，每个都占 8 字节，而 ob_sval 是一个 char 类型的数组，一个 char 占 1 字节，所以 bytes 对象的内存大小等于 <font color="blue">32 + ob_sval 的长度</font>。</p>
<p>而 ob_sval 里面至少有一个 <font color="blue">'\0'</font>，因此一个空的字节序列需要占 33 字节的内存。</p>
<pre><code class="language-python">&gt;&gt;&gt; sys.getsizeof(b&quot;&quot;)
33
</code></pre>
<p>注意：ob_size 统计的是 ob_sval 中有效字节的个数，不包括 <font color="blue">'\0'</font>，但是计算占用内存的时候，显然是需要考虑在内的，因为它确实占用了一个字节的空间。因此我们说 bytes 对象占的内存等于 <font color="blue">33 + ob_size</font> 也是可以的。</p>
<p><font color="darkblue"><strong>val = b&quot;abc&quot;</strong></font></p>
<p><img src="./images/79.png" alt="" /></p>
<p>显然内存大小等于 32 + 4 = 36 字节。</p>
<p>因此 bytes 对象的底层结构还是很好理解的，因为它是字节序列，所以在底层用一个 char 类型的数组来维护具体的值再合适不过了。</p>
<h2 id="创建-bytes-对象"><a class="header" href="#创建-bytes-对象">创建 bytes 对象</a></h2>
<p>下面来看一下 bytes 对象的创建方式，这里我们暂时先不介绍底层是如何创建的，等到介绍缓存池的时候再说。这里来聊一聊如何在 Python 中创建，虽然该系列是剖析源码，但是光说底层的话可能会有一些无趣，因此这个过程中也会穿插大量的 Python 内容。</p>
<p>先观察 Python 代码执行时的表现，再通过底层的源码进行解析，两者结合起来更容易让人理解。另外该系列也能保证即使你没有相应的 C 语言基础，也一样能收获很多。</p>
<pre><code class="language-Python">b = b&quot;hello&quot;
</code></pre>
<p>以上是最简单的创建方式，它使用我们之前说的特定类型 API，但通过这种方式创建的字节串只能包含 ASCII 字符。下面这种方式是不行的：</p>
<pre><code class="language-python">b = b&quot;古明地觉&quot;
</code></pre>
<p>&quot;古明地觉&quot; 包含非 ASCII 字符，所以采用多字节编码，但编码方式也有多种，比如 UTF-8、GBK 等等，解释器不知道你用的是哪一种。因此采用字面量的方式，只能包含 ASCII 字符，因为对于 ASCII 字符而言，不管使用哪种编码，得到的结果都是一样的。但如果包含非 ASCII 字符，那么必须手动指定编码。</p>
<pre><code class="language-Python">b = bytes(&quot;古明地觉&quot;, encoding=&quot;utf-8&quot;)
print(b)
&quot;&quot;&quot;
b'\xe5\x8f\xa4\xe6\x98\x8e\xe5\x9c\xb0\xe8\xa7\x89'
&quot;&quot;&quot;
</code></pre>
<p>里面的 \x 表示十六进制，我们知道字符 a 的 ASCII 码是 97，对应十六进制是 61。同理字符 b 是 62，字符 c 是 63，那么 b&quot;abc&quot; 就还可以这么创建。</p>
<pre><code class="language-Python">b = b&quot;\x61\x62\x63&quot;
print(b)
&quot;&quot;&quot;
b'abc'
&quot;&quot;&quot;
</code></pre>
<p>以上是根据十六进制的数字创建 bytes 对象，注意：采用这种方式创建必须指定 \x，然后 <font color="blue">b&quot;\x61&quot;</font> 表示的是 1 个字节，并且该字节对应的 ASCII 码的十六进制是 61，也就是字符 a。而 <font color="blue">b&quot;61&quot;</font> 表示的是两个字节。</p>
<pre><code class="language-Python"># \x61、\x62、\x63 均表示 1 字节
print(b&quot;\x61\x62\x63&quot;)
&quot;&quot;&quot;
b'abc'
&quot;&quot;&quot;
# 下面这个创建的 bytes 对象是 6 字节
print(b&quot;616263&quot;)
&quot;&quot;&quot;
b'616263'
&quot;&quot;&quot;
</code></pre>
<p>可如果有一串字符也是十六进制格式，但开头没有 \x，这个时候要怎么转成 bytes 对象呢？很简单，使用 <font color="blue">bytes.fromhex</font> 方法即可。</p>
<pre><code class="language-Python">print(bytes.fromhex(&quot;616263&quot;))
&quot;&quot;&quot;
b'abc'
&quot;&quot;&quot;

# 转成 bytes 对象之后，如果是可打印字符的话
# 那么会显示对应的字符，比如 abc
# 如果是不可打印字符，就原本输出，比如 \xff
print(bytes.fromhex(&quot;616263FF&quot;))
&quot;&quot;&quot;
b'abc\xff'
&quot;&quot;&quot;
</code></pre>
<p>该方法会将里面的字符串当成十六进制来解析，得到 bytes 对象。并且使用这种方式的话，字符的个数一定是偶数，每个字符的范围均是 <font color="blue">0~9、A~F（或者 a~f）</font>。因为十六进制需要两个字符来表示，范围是 <font color="blue">00</font> 到 <font color="blue">FF</font>。即便小于 16，也必须用两个字符表示，比如我们可以写 <font color="blue">05</font>，但绝不能只写个 <font color="blue">5</font>。</p>
<p>总之使用 bytes.fromhex 创建时，字符串的长度一定是一个偶数，从前往后每两个分为一组。使用字面量的方式创建时也是如此，比如我们可以写成 <font color="blue">b&quot;\x01\x02&quot;</font>，但不能写成 <font color="blue">b&quot;\x1\x2&quot;</font>。</p>
<pre><code class="language-python"># 不可以写成 b&quot;\x0&quot;，会报错
print(b&quot;\x00&quot;)  # b'\x00'

# \x 后面至少跟两个字符，但这里跟了 3 个字符
# 所以 \x 会和 61 组合得到 'a'
# 至于后面的那个 1 就单纯的表示字符 '1'
print(b&quot;\x611&quot;)  # b'a1'
</code></pre>
<p>所以 \x 后面可以跟超过两个以上的字符，超过两个以上的部分会被当成普通字符来处理，与十六进制无关。每个 \x 只和它后面的两个字符结合，因此 \x 后面不能少于两个字符。</p>
<p>然后我们通过索引获取的时候，得到的也是一个整数：</p>
<pre><code class="language-python">b = &quot;古&quot;.encode(&quot;utf-8&quot;)
print(b)  # b'\xe5\x8f\xa4'
print([b[0], b[1], b[2]])  # [229, 143, 164]
</code></pre>
<p>所以 bytes 对象的每个字节都是 0 ~ 255 之间的一个整数，那么问题来了，如果我有每个字节对应的整数，那么如何再转成 bytes 对象呢？</p>
<pre><code class="language-Python"># 里面的每个整数都必须位于 0 ~ 255 之间
print(bytes([229, 143, 164]))
print(bytes([229, 143, 164, 97, 98, 99]))
&quot;&quot;&quot;
b'\xe5\x8f\xa4'
b'\xe5\x8f\xa4abc'
&quot;&quot;&quot;

print(bytes([229, 143, 164]).decode(&quot;utf-8&quot;))
print(bytes([229, 143, 164, 97, 98, 99]).decode(&quot;utf-8&quot;))
&quot;&quot;&quot;
古
古abc
&quot;&quot;&quot;
</code></pre>
<p>以上就是 bytes 对象的几种创建方式，我们再总结一下。</p>
<pre><code class="language-python"># 1）通过字面量的方式创建
print(b&quot;hello&quot;)  # b'hello'
# 也可以使用十六进制的 ASCII 码，但要指定 \x 前缀
# \x 会和它后面的两个数字（范围是 0 ~ 9、A ~ F）进行组合，表示一个字符
print(b&quot;\x61\x62\x63&quot;)  # b'abc'
# 除了十六进制之外，还可以使用八进制的 ASCII 码，前缀是 \
# \ 会和它后面的三个数字（范围是 0 ~ 7）进行组合，表示一个字符
# 97、98、99 对应的八进制为 141、142、143
print(b&quot;\141\142\143&quot;)  # b'abc'
# 注：\x 要求后面必须跟两个数字，比如可以写 \x05，但不可以写 \x5
# 而八进制的 \ 则不做要求，后面可以跟 1 ~ 3 个数字
# 比如 9 不属于八进制整数，所以下面这个字节串长度为 4
# 分别是 \014、9、\142、\143，而八进制的 14 对应的十六进制是 c
# 所以打印 b&quot;\x0c9bc&quot;
print(b&quot;\149\142\143&quot;)  # b'\x0c9bc'

# 2）通过调用类型对象 bytes 创建
print(bytes([97, 98, 99]))  # b'abc'
# 也可以传一个字符串，并指定编码
print(bytes(&quot;嘿嘿&quot;, encoding=&quot;utf8&quot;))  # b'\xe5\x98\xbf\xe5\x98\xbf'
# bytes 还可以接收实现了 __bytes__ 方法的实例对象
class A:
    def __bytes__(self):
        return b&quot;A&quot;

print(bytes(A()))  # b'A'

# 3）调用 bytes.fromhex 方法创建
print(bytes.fromhex(&quot;616263&quot;))  # b'abc'
</code></pre>
<p>通过这些方法，我们可以很轻松地将数据转成 bytes 对象。</p>
<h2 id="小结-19"><a class="header" href="#小结-19">小结</a></h2>
<p>本篇文章我们就聊了聊什么是 bytes 对象，以及它的底层结构和几种创建方式。</p>
<p>bytes 对象的含义是字节串，或者字节序列，它由一系列的字节组成。并且随着编码不同、字符范围不同，可能一个字节对应一个字符，也可能两个字节对应一个字符，或者三个字节对应一个字符。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-18"><a class="header" href="#楔子-18">楔子</a></h2>
<p>介绍完 bytes 对象在底层的数据结构之后，我们来研究一下它支持的操作，由于操作定义在类型对象中，显然我们需要查看 bytes 类型。</p>
<h2 id="bytes-类型"><a class="header" href="#bytes-类型">bytes 类型</a></h2>
<p>根据解释器 API 的命名规则，bytes 类型在底层应该对应 PyBytes_Type。</p>
<pre><code class="language-C">// Objects/bytesobject.c
PyTypeObject PyBytes_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;bytes&quot;,
    PyBytesObject_SIZE,
    sizeof(char),
    // ...
    &amp;bytes_as_number,                           /* tp_as_number */
    &amp;bytes_as_sequence,                         /* tp_as_sequence */
    &amp;bytes_as_mapping,                          /* tp_as_mapping */
    // ...
};
</code></pre>
<p>实例对象的大小信息保存在类型对象中，由 tp_basicsize 和 tp_itemsize 负责维护。</p>
<ul>
<li>tp_basicsize：实例对象的基本大小，对于 bytes 对象来说就是 PyBytesObject_SIZE。</li>
<li>tp_itemsize：如果实例对象是变长对象，并且结构体本身还保存了具体的元素，那么该字段则表示每个元素的大小，否则为 0。对于 bytes 对象来说就是 sizeof(char)，即 1 字节。</li>
</ul>
<p>其中 PyBytesObject_SIZE 是一个宏，等于 <font color="blue">offsetof(PyBytesObject, ob_sval) + 1</font>，也就是结构体的起始位置到 ob_sval 字段的偏移量再加 1。显然这个大小是固定不变的基础大小，那么它等于多少呢？</p>
<pre><code class="language-C">typedef struct {
    PyObject_VAR_HEAD
    Py_hash_t ob_shash;
    char ob_sval[1];
} PyBytesObject;
</code></pre>
<p>很明显，大小是 32 + 1 = 33 字节，然后再加上 sizeof(char) * ob_size 就是整个 bytes 对象的大小。由于 sizeof(char) 等于 1，所以 bytes 对象的大小等于 PyBytesObject_SIZE 加上 ob_size，我们后面介绍 bytes 对象的创建时会看到。</p>
<p>然后看一下方法簇，我们发现这三个方法簇 bytes 对象居然都支持。</p>
<pre><code class="language-C">// Objects/bytesobject.c

static PyNumberMethods bytes_as_number = {
    0,              /*nb_add*/
    0,              /*nb_subtract*/
    0,              /*nb_multiply*/
    bytes_mod,      /*nb_remainder*/
};

static PySequenceMethods bytes_as_sequence = {
    // 计算长度，如 len(b&quot;abc&quot;)
    (lenfunc)bytes_length,         /*sq_length*/
    // 将两个 bytes 对象相加
    // 比如 b&quot;abc&quot; + b&quot;def&quot;
    (binaryfunc)bytes_concat,      /*sq_concat*/
    // 将 bytes 对象重复 N 次
    // 比如 &quot;abc&quot; * 3
    (ssizeargfunc)bytes_repeat,    /*sq_repeat*/
    // 基于索引获取 bytes 对象的指定元素
    // 比如 b&quot;abc&quot;[1]
    (ssizeargfunc)bytes_item,      /*sq_item*/
    0,                             /*sq_slice*/
    0,                             /*sq_ass_item*/
    0,                             /*sq_ass_slice*/
    // 判断 bytes 对象是否包含某个元素
    (objobjproc)bytes_contains     /*sq_contains*/
};

static PyMappingMethods bytes_as_mapping = {
    // 获取 bytes 对象的长度
    (lenfunc)bytes_length,
    // 基于切片截取 bytes 对象
    (binaryfunc)bytes_subscript,
    0,
};
</code></pre>
<ul>
<li>对于数值型操作，bytes 对象实现了 nb_remainder，它居然支持求余数，这是怎么回事？好吧，我表现的有些刻意了，其实就是一个字节串的格式化操作。</li>
<li>对于序列型操作，bytes 对象支持五个，从名字上看也知道是做什么的，不过这些我们一会儿都会说。</li>
<li>对于映射型操作，bytes 对象支持两个。虽然 bytes 对象不是字典，但解释器允许它做一些类似于映射的操作，这种设计使得 bytes 对象具有更加丰富和灵活的操作接口。</li>
</ul>
<p>下面我们就来详细介绍这些操作的底层实现，它们都位于 Objects/bytesobject.c 中。</p>
<h2 id="bytes-对象的格式化"><a class="header" href="#bytes-对象的格式化">bytes 对象的格式化</a></h2>
<p>bytes 对象借用取模运算符 % 实现格式化，它对应 <code>bytes_as_number-&gt;nb_remainder</code> 字段，该字段被赋值为 bytes_mod。</p>
<pre><code class="language-C">static PyObject *
bytes_mod(PyObject *self, PyObject *arg)
{
    if (!PyBytes_Check(self)) {
        Py_RETURN_NOTIMPLEMENTED;
    }
    // PyBytes_AS_STRING 会返回 PyBytesObject 的 ob_sval 字段
    // PyBytes_GET_SIZE 会返回 PyBytesObject 的 ob_size 字段，即长度
    // arg 是传递的参数，它是一个元组
    return _PyBytes_FormatEx(PyBytes_AS_STRING(self), PyBytes_GET_SIZE(self),
                             arg, 0);
}
</code></pre>
<p>最终会调用 _PyBytes_FormatEx 进行格式化，我们再以 Python 为例。</p>
<pre><code class="language-Python">info = b&quot;name: %s, age: %d&quot;
print(info % (b&quot;satori&quot;, 17))  # b'name: satori, age: 17'
</code></pre>
<p>bytes 对象的格式化，在工作中其实用的不多。</p>
<h2 id="计算-bytes-对象的长度"><a class="header" href="#计算-bytes-对象的长度">计算 bytes 对象的长度</a></h2>
<p>计算字节串的长度会执行 <code>bytes_as_sequence-&gt;sq_length</code>，该字段被赋值为 bytes_length。</p>
<pre><code class="language-C">static Py_ssize_t
bytes_length(PyBytesObject *a)
{
    return Py_SIZE(a);
}
</code></pre>
<p>Py_SIZE 是一个宏，我们之前说过，它会返回对象的 ob_size。</p>
<pre><code class="language-Python">name = b&quot;satori&quot;
# 直接返回 ob_size
print(len(name))  # 6
</code></pre>
<p>ob_size 维护了 bytes 对象的有效字节个数，计算长度的时候直接返回。</p>
<h2 id="将-bytes-对象重复-n-次"><a class="header" href="#将-bytes-对象重复-n-次">将 bytes 对象重复 N 次</a></h2>
<p>bytes 对象支持乘法操作，可以重复指定次数，举个例子。</p>
<pre><code class="language-python">word = b&quot;abc&quot;
# 重复 3 次
print(word * 3)  # b'abcabcabc'
</code></pre>
<p>我们看到这里使用了乘法运算符，所以很容易联想到 PyNumberMethods 的 nb_mul，但对于 bytes 对象而言却不是这样，它对应的是 PySequenceMethods 的 sq_repeat。所以 Python 的同一个操作符，在底层会对应不同的函数，比如 long_mul 和 float_mul、以及这里的 bytes_repeat，在 Python 的层面都是 <font color="blue">*</font> 这个操作符。</p>
<p>下面我们看一下具体逻辑，它由 bytes_repeat 函数实现。</p>
<pre><code class="language-C">static PyObject *
bytes_repeat(PyBytesObject *a, Py_ssize_t n)
{
    Py_ssize_t i;
    Py_ssize_t j;
    Py_ssize_t size;  // 新创建的 bytes 对象的 ob_size
    PyBytesObject *op;  // 指向新创建的 bytes 对象
    size_t nbytes;  // 应该为 bytes 对象内部的 char 数组（ob_sval）申请多大内存
    
    // 如果 bytes 对象乘上一个小于 0 的数，那么等价于乘以 0
    if (n &lt; 0)
        n = 0;
    // Py_SIZE(a) * n 就是新创建的 bytes 对象的长度
    // 如果这个长度超过了 PY_SSIZE_T_MAX，那么报错，字节串过长
    // 另外注意这里的条件，正常思路是 Py_SIZE(a) * n &gt; PY_SSIZE_T_MAX
    // 但为了避免 Py_SIZE(a) * n 发生溢出，所以改成了除法
    // 这个和我们写二分查找求平均值是一个道理
    if (n &gt; 0 &amp;&amp; Py_SIZE(a) &gt; PY_SSIZE_T_MAX / n) {
        PyErr_SetString(PyExc_OverflowError,
            &quot;repeated bytes are too long&quot;);
        return NULL;
    }
    // 将 Py_SIZE(a) * n 赋值给 size
    size = Py_SIZE(a) * n;
    // 如果 size 和 Py_SIZE(a) 相等，说明 n 为 1，或者 Py_SIZE(a) 为 0
    // 但不管哪一种，都意味着新创建的 bytes 对象和原始的 bytes 对象是相同的
    // 既然这样的话，就没必要创建了，直接给原始的 bytes 对象的引用计数加一，然后返回即可
    if (size == Py_SIZE(a) &amp;&amp; PyBytes_CheckExact(a)) {
        Py_INCREF(a);
        return (PyObject *)a;
    }
    // 需要为内部的 char 数组申请的内存大小，一个元素一个字节
    // 注：严格意义上说，nbytes 应该等于 char 数组的内存大小减 1
    // 因为额外存储 '\0' 所需的一字节被算在了 PyBytesObject_SIZE 里面
    // 所以这个 nbytes 的含义其实和 bytes 对象的长度是等价的
    nbytes = (size_t)size;
    // PyBytesObject_SIZE + nbytes 便是 bytes 对象的内存大小了
    // 但如果两者相加的结果反而小于等于 nbytes，说明产生溢出了（发生了环绕）
    if (nbytes + PyBytesObject_SIZE &lt;= nbytes) {
        // 那么报错，字节串太长了
        PyErr_SetString(PyExc_OverflowError,
            &quot;repeated bytes are too long&quot;);
        return NULL;
    }
    // 为新创建的 bytes 对象申请 PyBytesObject_SIZE + nbytes 大小的内存
    op = (PyBytesObject *)PyObject_MALLOC(PyBytesObject_SIZE + nbytes);
    // 如果 op 为 NULL，说明内存不足
    if (op == NULL)
        return PyErr_NoMemory();
    // 初始化，将 op-&gt;ob_type 设置为 &amp;PyBytes_Type，将 op-&gt;ob_size 设置为 size
    (void)PyObject_INIT_VAR(op, &amp;PyBytes_Type, size);
    // 将 ob_shash 初始化为 -1，等到需要计算的时候，再更新 ob_shash
    // 一旦更新，后续就不用再计算了，会直接返回 ob_shash
    op-&gt;ob_shash = -1;
    // ob_sval 要额外存储一个 '\0'，显然它位于索引为 size 的位置
    // 因此有效字符的数量为 size，但 ob_sval 的大小为 size + 1
    // 那么问题来了，既然这样的话，nbytes 应该等于 size + 1 才对，为啥等于 size 呢
    // 很简单，原因已经说过了，因为 PyBytesObject_SIZE 为 offsetof(PyBytesObject, ob_sval) + 1
    // offsetof(PyBytesObject, ob_sval) 表示从结构体起始位置到 ob_sval 的偏移量
    // 或者你也可以理解为 ob_sval 之前的所有字段的大小
    // 但它又额外加上了 1，所以 '\0' 需要的空间已经被申请了，因此没有问题
    op-&gt;ob_sval[size] = '\0';
    
    // 此时对象的内存就已经申请好了，类型、长度等元数据也设置好了，接下来就是拷贝元素了
    // 首先做一个快分支判断，如果原始的 bytes 对象的长度为 1，证明新的 bytes 对象的所有字节都是一样的
    // 直接将 op-&gt;ob_sval 里面的 n 个元素设置为 a-&gt;ob_sval[0] 即可
    if (Py_SIZE(a) == 1 &amp;&amp; n &gt; 0) {
        memset(op-&gt;ob_sval, a-&gt;ob_sval[0] , n);
        return (PyObject *) op;
    }
    // 否则将 a-&gt;ob_sval 里面除了 '\0' 之外的有效字符拷贝到 op-&gt;ob_sval 里面
    // 每次拷贝 Py_SIZE(a) 个字符，直到拷贝的字符个数达到 size
    i = 0;
    if (i &lt; size) {
        memcpy(op-&gt;ob_sval, a-&gt;ob_sval, Py_SIZE(a));
        i = Py_SIZE(a);
    }
    while (i &lt; size) {
        j = (i &lt;= size-i)  ?  i  :  size-i;
        memcpy(op-&gt;ob_sval+i, op-&gt;ob_sval, j);
        i += j;
    }
    // 将 PyBytesObject * 类型的 op 转成 PyObject *，然后返回，交给变量保存
    return (PyObject *) op;
}
</code></pre>
<p>所以通过观察源码，你会发现 Python 里面的操作并没有什么神奇的，简单思考一下就知道它的底层逻辑。再比如后续介绍的切片截取，即使现在还没看具体源码，但也能猜到底层就是单纯的 for 循环。</p>
<h2 id="基于索引和切片获取元素"><a class="header" href="#基于索引和切片获取元素">基于索引和切片获取元素</a></h2>
<p>bytes 对象也支持通过索引和切片截取指定部分的元素。</p>
<pre><code class="language-Python">buf = b&quot;abcde&quot;
# 基于索引获取元素，拿到的是整数
print(buf[0])  # 97
# 基于切片获取元素，拿到的依旧是字节串
print(buf[0: 1])  # b'a'
</code></pre>
<p>那么底层是怎么做的呢？</p>
<pre><code class="language-C">static PyObject*
bytes_subscript(PyBytesObject* self, PyObject* item)
{
    // 如果是 buf[0] 这种，那么 self 就是 buf，item 就是 0
    // 如果是 buf[0: 3] 这种，那么 self 就是 buf，item 就是 slice(0, 3)
    // 所以要对 item 进行检测，判断它到底是索引还是切片
    if (PyIndex_Check(item)) {
        // 如果 item 是整数或者实现了 tp_as_number-&gt;nb_index
        // 那么表示索引，会转成 Py_ssize_t，如果转换失败，那么会设置异常回溯栈
        Py_ssize_t i = PyNumber_AsSsize_t(item, PyExc_IndexError);
        // 如果 PyErr_Occurred() 为真，那么表示有异常发生
        // 但问题是这里为什么要多一个 i == -1 呢？我们稍后再说
        if (i == -1 &amp;&amp; PyErr_Occurred())
            return NULL;
        // 如果转换之后发现 i 小于 0，表示使用的是负数索引
        // 那么要加上长度，变成正数索引，因此负数索引本质上也是 Python 的一个语法糖
        if (i &lt; 0)
            i += PyBytes_GET_SIZE(self);
        // 到这里发现 i 如果还小于 0，或者本身大于等于长度，那么索引越界
        if (i &lt; 0 || i &gt;= PyBytes_GET_SIZE(self)) {
            PyErr_SetString(PyExc_IndexError,
                            &quot;index out of range&quot;);
            return NULL;
        }
        // 否则说明索引 i 是合法的，那么获取数组 ob_sval 中索引为 i 的元素
        // 但拿到的是 C 的整数，所以还要基于 C 整数创建 Python 整数，然后返回
        return PyLong_FromLong((unsigned char)self-&gt;ob_sval[i]);
    }
    // 如果 item 是切片
    else if (PySlice_Check(item)) {
        // 我们知道切片有三个属性，分别是起始位置、终止位置、步长
        Py_ssize_t start, stop, step, slicelength, i;
        size_t cur;
        char* source_buf;
        char* result_buf;
        PyObject* result;
        // 解析切片，将内部属性赋值给 start、stop、step
        // 关于 PySlice_Unpack 我们在介绍切片的时候说过
        if (PySlice_Unpack(item, &amp;start, &amp;stop, &amp;step) &lt; 0) {
            return NULL;
        }
        // 这个函数在介绍切片的时候也说过
        // 它会调整 start 和 stop 的值，比如将负数转成正数，然后返回应该遍历的元素个数
        slicelength = PySlice_AdjustIndices(PyBytes_GET_SIZE(self), &amp;start,
                                            &amp;stop, step);
        // 如果小于等于 0，说明截取不到任何元素，因此直接返回空字节串
        if (slicelength &lt;= 0) {
            // 基于 C 的字符数组和拷贝的字节数，创建 Python 的字节串
            return PyBytes_FromStringAndSize(&quot;&quot;, 0);
        }
        // 如果 start 为 0，step 为 1，并且截取的元素个数和原始字节串的长度相等
        // 比如 buf[::] 这种，说明截取之后的字节串和原始字节串相同
        // 那么直接给原始字节串增加一个引用计数，然后返回即可
        else if (start == 0 &amp;&amp; step == 1 &amp;&amp;
                 slicelength == PyBytes_GET_SIZE(self) &amp;&amp;
                 PyBytes_CheckExact(self)) {
            Py_INCREF(self);
            return (PyObject *)self;
        }
        // 如果步长为 1，那么从索引为 start 的位置截取 slicelength 个字节即可
        // PyBytes_AS_STRING(self) 会返回字节串的 ob_sval，即 C 字符数组
        // ob_sval + start 会将指针偏移到索引为 start 的位置
        // 然后通过 C 的 memcpy 函数从 start 开始拷贝 slicelength 个字节
        else if (step == 1) {
            return PyBytes_FromStringAndSize(
                PyBytes_AS_STRING(self) + start,
                slicelength);
        }
        // 否则说明步长不为 1，此时只能使用循环了
        else {
            // 拿到原始字节串的 ob_sval
            source_buf = PyBytes_AS_STRING(self);
            // 创建长度为 slicelength 的字节串
            // 注意：此时内部字符数组的容量已经有了，但还没有元素
            result = PyBytes_FromStringAndSize(NULL, slicelength);
            if (result == NULL)
                return NULL;
            // 拿到新创建的字节串的 ob_sval
            result_buf = PyBytes_AS_STRING(result);
            // 从 start 开始遍历，遍历 slicelength 次，指针每次跳 step 个元素
            for (cur = start, i = 0; i &lt; slicelength;
                 cur += step, i++) {
                // 将元素设置进去
                result_buf[i] = source_buf[cur];
            }
            // 返回
            return result;
        }
    }
    // 如果 item 既不是整数也不是切片，那么报错
    else {
        PyErr_Format(PyExc_TypeError,
                     &quot;byte indices must be integers or slices, not %.200s&quot;,
                     Py_TYPE(item)-&gt;tp_name);
        return NULL;
    }
}

</code></pre>
<p>虽然代码有点长，但逻辑一点都不难。还是那句话，对于 C 这样朴素的语言来说，就是 if 判断加循环。</p>
<h2 id="聊一聊异常"><a class="header" href="#聊一聊异常">聊一聊异常</a></h2>
<p>在看 bytes_subscript 源码时，我们提出了一个问题。</p>
<p><img src="./images/80.png" alt="" /></p>
<p>上面代码中为什么要有一个 <font color="blue">i == -1</font> 判断呢？要解释这一点，首先必须要理解 Python 的异常是怎么抛出来的。</p>
<p>所谓的抛异常，本质上就是底层的某个 C 函数的代码逻辑出现了问题，不能继续执行了，于是将异常信息设置到回溯栈中，并给出一个表示错误的返回值。当解释器发现返回值不对时，就知道程序出错了，于是将回溯栈的异常写入到 stderr（标准错误输出）中。</p>
<p><img src="./images/81.png" alt="" /></p>
<p>比如这里，当检测到索引小于 0 或大于等于长度时，就知道索引越界了，不能再执行了。于是会通过 PyErr_SetString 将异常设置到回溯栈中，并返回了 NULL，表示错误的返回值。</p>
<p>因为对于当前函数来说，它的返回值类型是 PyObject *，如果正常执行，那么返回值应该指向一个合法的 PyObject。但当逻辑出现错误时，就意味着函数不能再执行了，于是设置异常并返回 NULL。而解释器在看到返回值为 NULL 时，就知道该函数执行出现错误了，那么会将回溯栈里的异常信息输出到 stderr 中，</p>
<pre><code class="language-Python">data = []
# data[1] 在底层会执行 bytes_subscript(data, 1)
# 但是发现索引 1 大于等于长度，于是会将异常信息写入到 stderr，并返回 NULL
# 解释器发现返回的是 NULL，就知道执行出错了，否则返回值一定会指向一个合法的 PyObject
# 于是解释器会将回溯栈里的异常写入到 stderr，并终止运行（暂时不考虑异常捕获）
print(data[1])
</code></pre>
<p>在 Python 中看到的就是下面这个样子。</p>
<p><img src="./images/82.png" alt="" /></p>
<p>所以这就是抛异常的本质，如果 C 函数执行逻辑有问题，那么会以异常的形式将信息写入到回溯栈，并给出一个表示错误的返回值。外界发现返回值有问题时，就知道执行出错了，最终会由解释器将回溯栈里的异常写入到 stderr 当中。</p>
<p>既然 C 函数执行出现问题会设置异常，那么判断函数执行是否有问题，除了看它的返回值是否正常之外，还可以通过检测异常回溯栈。如果回溯栈里面有异常，调用 PyErr_Occurred 会返回真，否则返回假。</p>
<p>但 PyErr_Occurred 的效率稍微低一些，而直接判断返回值会更快，因为只是一个比较操作。比如这里的 bytes_subscript 函数，只需要检测它的返回值是否等于 NULL 即可判断函数执行是否出现异常。因为返回值类型是 PyObject *，如果正常执行，返回值一定不是 NULL，否则说明程序出问题了。</p>
<p>但 PyNumber_AsSsize_t 函数则不同，该函数的返回值类型是整型。</p>
<p><img src="./images/83.png" alt="" /></p>
<p>索引要么是整数，要么是实现了 __index__ 的类的实例对象，内部调用的 _PyNumber_Index 会统一将 item 转成 Python 整数并返回，如果转换失败则设置异常并返回 NULL。</p>
<p>而 PyNumber_AsSsize_t 函数则负责将 Python 整数转成 C 的 ssize_t 整数，但当它发现返回的 value 没有指向一个合法的 PyObject，而是 NULL，就知道 _PyNumber_Index 执行失败了。那么对于 PyNumber_AsSsize_t 而言，它也不能再执行了，应该返回一个表示错误的返回值。但 PyNumber_AsSsize_t 的返回值类型不是 PyObject *，而是整型，所以它不能返回 NULL。那么返回多少呢？解释器使用 -1 来充当表示错误的哨兵返回值。</p>
<p>但 -1 除了可以表示出现错误，也可能是函数正常执行，而返回值本身就是 -1。所以和指针类型不同，对于指针类型，通过返回值是否为 NULL 即可判断函数是否执行正常，而返回整型则需要借助 PyErr_Occurred。</p>
<p>比如发现 i 不等于 -1，说明 PyNumber_AsSsize_t 执行正常，不用再判断了。如果 i 等于 -1，那么则需要进一步检查异常回溯栈，如果栈不为空，证明确实发生错误了。如果栈为空，证明此时返回的 -1 不是因出现错误而返回的哨兵值，而是函数正常执行、但返回值本身就是 -1。</p>
<p>假设 PyNumber_AsSsize_t 因为索引类型不合法而返回了 -1，那么 bytes_subscript 就知道调用出现了错误，于是也不能再执行了，于是立即返回。由于它的返回值类型是 PyObject *，所以会返回 NULL。而最后当解释器看到 bytes_subscript 返回的是 NULL 时，就知道程序应该报错，于是会将回溯栈里的异常抛出来，并结束进程。</p>
<h2 id="小结-20"><a class="header" href="#小结-20">小结</a></h2>
<p>以上我们就介绍了 bytes 对象（字节串）的一些操作的底层实现，不过还没结束，下一篇文章我们来聊一聊 bytes 对象的加法运算。</p>
<p>当然加法运算本身很简单，之所以单独摘出来是因为背后涉及一个非常重要的概念：缓冲区，它也是 Numpy 得以实现的关键，下一篇文章细聊。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-19"><a class="header" href="#楔子-19">楔子</a></h2>
<p>bytes 对象支持加法运算，将两个 bytes 对象合并为一个，举个例子。</p>
<pre><code class="language-Python">b1 = b&quot;abc&quot;
b2 = b&quot;def&quot;
print(b1 + b2)  # b'abcdef'
</code></pre>
<p>这背后是怎么实现的呢？我们通过源码分析一下，并通过 bytes 对象的相加，介绍一下缓冲区的知识。</p>
<h2 id="bytes-对象的加法运算"><a class="header" href="#bytes-对象的加法运算">bytes 对象的加法运算</a></h2>
<p>提到加法，很容易联想到 PyNumberMethods 的 nb_add，比如：PyLongObject 的 long_add 和 PyFloatObject 的 float_add。</p>
<p>但对于 bytes 对象而言却不是这样，加法操作对应的是 PySequenceMethods 的 sq_concat。所以我们将加法运算改成合并，会更合适一些，只是它在 Python 层面对应的也是 <font color="blue">+</font> 操作符。对于 bytes 对象而言，sq_concat 字段会被赋值为 bytes_concat。</p>
<pre><code class="language-C">static PyObject *
bytes_concat(PyObject *a, PyObject *b)
{
    // 两个 Py_buffer 结构体类型的变量，用于维护缓冲区
    // 关于缓冲区，我们一会儿说
    Py_buffer va, vb;
    // 相加结果
    PyObject *result = NULL;
    // 此时缓冲区啥也没有，默认将缓冲区的长度初始化为 -1
    va.len = -1;
    vb.len = -1;
    // 每个 bytes 对象底层都对应一个缓冲区，可以通过 PyObject_GetBuffer 获取
    // 这里获取两个 bytes 对象的缓冲区，然后交给变量 va 和 vb
    // 获取成功返回 0，获取失败返回非 0
    // 如果下面的条件不成功，就意味着获取失败了，说明至少有一个老铁不是 bytes 类型
    if (PyObject_GetBuffer(a, &amp;va, PyBUF_SIMPLE) != 0 ||
        PyObject_GetBuffer(b, &amp;vb, PyBUF_SIMPLE) != 0) {
        // 然后设置异常，PyExc_TypeError 表示 TypeError（类型错误）
        // 专门用来表示对一个对象执行了它所不支持的操作
        PyErr_Format(PyExc_TypeError, &quot;can't concat %.100s to %.100s&quot;,
                     Py_TYPE(b)-&gt;tp_name, Py_TYPE(a)-&gt;tp_name);
        // 比如 b&quot;123&quot; + 123 就会得到 TypeError: can't concat int to bytes
        // 和这里设置的异常信息是一样的，然后当出现异常之后，直接跳转到 done 标签
        goto done;
    }

    // 这里判断是否有一方长度为 0
    // 如果 a 的长度为 0，那么相加之后的结果就是 b
    if (va.len == 0 &amp;&amp; PyBytes_CheckExact(b)) {
        result = b;
        Py_INCREF(result);
        goto done;
    }
    // 逻辑和上面类似，如果 b 的长度为 0，那么相加之后的结果就是 a
    if (vb.len == 0 &amp;&amp; PyBytes_CheckExact(a)) {
        result = a;
        Py_INCREF(result);
        goto done;
    }
    // 判断两个 bytes 对象合并之后，长度是否超过 PY_SSIZE_T_MAX
    // 所以 bytes 对象是有长度限制的，因为维护长度的 ob_size 有最大范围
    // 但还是之前说的，这个条件基本不可能满足，除非你写恶意代码
    // 补充一句，这个 if 条件看起来会有些别扭，更直观的写法应该像下面这样
    // if (va.len + vb.len &gt; PY_SSIZE_T_MAX)，但 va.len + vb.len 可能会溢出
    if (va.len &gt; PY_SSIZE_T_MAX - vb.len) {
        PyErr_NoMemory();
        goto done;
    }
    // 否则的话，创建指定容量的 PyBytesObject
    result = PyBytes_FromStringAndSize(NULL, va.len + vb.len);
    if (result != NULL) {
        // PyBytes_AS_STRING 会获取 PyBytesObject 的 ob_sval 字段
        // 将缓冲区 va 里面的内容拷贝到 result-&gt;ob_sval 中，拷贝的长度为 va.len
        memcpy(PyBytes_AS_STRING(result), va.buf, va.len);
        // 将缓冲区 vb 里面的内容拷贝到 result-&gt;ob_sval 中，拷贝的长度为 vb.len
        // 但是要从 va.len 的位置开始拷贝，不然会把之前的内容覆盖掉
        memcpy(PyBytes_AS_STRING(result) + va.len, vb.buf, vb.len);
    }

  done:
    // 拷贝完之后，将 va 和 vb 里的内容释放掉，否则可能会导致内存泄漏
    if (va.len != -1)
        PyBuffer_Release(&amp;va);
    if (vb.len != -1)
        PyBuffer_Release(&amp;vb);
    return result;
}
</code></pre>
<p>代码虽然有点长，但是不难理解，重点是里面的 Py_buffer。我们以 <font color="blue">a = b&quot;ab&quot;</font>，<font color="blue">b = b&quot;cde&quot;</font> 为例，看一下 a + b 是怎么做的？</p>
<p><img src="./images/84.png" alt="" /></p>
<p>说白了整个过程就是将 <code>a-&gt;ob_sval</code> 和 <code>b-&gt;ob_sval</code> 拷贝到 <code>result-&gt;ob_sval</code> 中。但问题是为啥不直接拷贝，而是要搞出来一个 Py_buffer 呢？这就要说一说 Python 的缓冲区了。</p>
<h2 id="详解缓冲区"><a class="header" href="#详解缓冲区">详解缓冲区</a></h2>
<p>为了更好地理解缓冲区，我们需要解释一下什么是缓冲区协议。缓冲区协议是一个 C 级协议，它定义了一个具有数据缓冲区和元数据的 C 级结构体，这个结构体就是上面的 Py_buffer。通过 Py_buffer 来描述缓冲区的布局、数据类型和读写权限，并且还定义了支持协议的对象所必须实现的 API。</p>
<p>实现缓冲区协议的对象有 bytes对象、array.array 对象、以及最知名的 numpy.ndarray 对象。</p>
<p>至于缓冲区本身，它就是一个单纯的一维数组，负责存储具体的数据。我们以 numpy 数组为例，不管数组是多少维的，底层的缓冲区永远是一个一维数组。那么问题来了，我们在定义数组时设置的维度信息要如何体现呢？答案是通过 Py_buffer，来看一下它的底层结构。</p>
<pre><code class="language-C">// Include/cpython/object.h

typedef struct bufferinfo {
    // 指针，指向具体的缓冲区，注意：缓冲区就是个一维数组
    void *buf;
    // 指向实现缓冲区协议的对象本身   
    PyObject *obj;
    // 缓冲区的长度
    Py_ssize_t len;
    // 缓冲区中每个元素的大小
    Py_ssize_t itemsize;
    // 缓冲区是否只读，0 表示可读写、1 表示只读
    int readonly;
    // 维度，比如数组的 shape 为 (3, 4, 5)，那么它的 ndim 就是 3
    int ndim;
    // 格式化字符串，用于描述缓冲区的元素类型
    char *format;
    // 等价于 numpy 数组的 shape
    // 因此缓冲区永远是个一维数组，由 buf 字段指向
    // 而其它字段则负责描述这个一维数组应该怎么使用
    Py_ssize_t *shape;
    // 在某个维度下，从一个元素到下一个元素所需要跳跃的字节数
    Py_ssize_t *strides;
    Py_ssize_t *suboffsets;
    void *internal;
} Py_buffer;
</code></pre>
<p>以上就是 Py_buffer，它的 buf 字段指向了具体的缓冲区，对于 bytes 对象而言就是内部的 ob_sval 字段。再比如 numpy 数组的拷贝，默认情况下在拷贝数组时只会将 Py_buffer 拷贝一份，而 Py_buffer 内部的 buf 字段指向的缓冲区则不会拷贝。</p>
<pre><code class="language-python">import numpy as np

# Py_buffer.buf 指向了缓冲区
# Py_buffer.shape 为 (6,)
arr1 = np.array([3, 9, 5, 7, 6, 8])
# 将 Py_buffer 拷贝一份，并且 Py_buffer.shape 变成了 (2, 3)
# 但 Py_buffer.buf 指向的缓冲区没有拷贝
arr2 = arr1.reshape((2, 3))

# 然后在通过索引访问的时候，可以认为 numpy 为其创建了虚拟的索引轴
# 由于 arr1 只有一个维度，那么 numpy 会为其创建一个虚拟的索引轴
&quot;&quot;&quot;
arr1 = [3 9 5 7 6 8]

    index1: 0 1 2 3 4 5
       buf: 3 9 5 7 6 8    
&quot;&quot;&quot;
# arr2 有两个维度，shape 是 (2, 3)
# 那么 numpy 会为其创建两个虚拟的索引轴
&quot;&quot;&quot;
arr2 = [[3, 9, 5]
        [7, 6, 8]]

    index1: 0 0 0 1 1 1
    index2: 0 1 2 0 1 2
       buf: 3 9 5 7 6 8                
&quot;&quot;&quot;
# 缓冲区中索引为 4 的元素被修改
arr2[1, 1] = 666
# 由于 arr1 和 arr2 共享一个缓冲区
# 所以 print(arr1[4]) 也会打印 666
print(arr1[4])  # 666
</code></pre>
<p>以上就是缓冲区的内容，关于缓冲区在后续还会详细介绍，到时候我们也会让自定义的实例对象支持缓冲区。</p>
<p>回到 bytes 对象，它也实现了缓冲区协议，内部的 ob_sval（一个一维数组）就是对应的缓冲区，Py_buffer 里面的 buf 字段同样指向了这个缓冲区，而其它的字段则负责描述该如何使用这个缓冲区，可以理解为元信息。正如 numpy 的数组，虽然多个数组底层共用一个缓冲区，数据也只有一份，但在 numpy 的层面却可以表现出不同的维度，究其原因就是元信息不同。</p>
<p>相信你现在肯定明白 Py_buffer 存在的意义了，就是共享内存。不管什么对象，只要实现了缓冲区协议，那么就可以直接向彼此暴露自身的缓冲区。并且在操作的时候，统一使用 Py_buffer，保证不同类型的对象的操作是一致的。</p>
<pre><code class="language-Python">import numpy as np

# bytes 对象实现了缓冲区协议，后续操作时会创建 Py_buffer 实例
# Py_buffer.buf 指向的缓冲区便是 bytes 对象的 ob_sval
# 对于当前来说就是 {'a', 'b', 'c', 'd', '\0'}
b = b&quot;abcd&quot;

# np.frombuffer 表示基于已有的缓冲区创建数组，因此会共享 bytes 对象的缓冲区
# 但问题是缓冲区只是一个普通的一维数组，numpy 该怎么解析这个缓冲区呢
# 所以我们必须显式地指定 dtype，而 &quot;S1&quot; 表示按照单个字节来进行解析
arr1 = np.frombuffer(b, dtype=&quot;S1&quot;)
print(arr1)  # [b'a' b'b' b'c' b'd']

# &quot;S2&quot; 表示按照两个字节来进行解析
arr2 = np.frombuffer(b, dtype=&quot;S2&quot;)
print(arr2)  # [b'ab' b'cd']

# 那么问题来了，按照三个字节解析是否可行呢？
# 答案是不可行，因为缓冲区的大小不是 3 的整数倍
# 而 &quot;S4&quot; 显然是可以的
arr3 = np.frombuffer(b, dtype=&quot;S4&quot;)
print(arr3)  # [b'abcd']

# 按照 int8 进行解析
arr4 = np.frombuffer(b, dtype=&quot;int8&quot;)
print(arr4)  # [ 97  98  99 100]

# 按照 int16 进行解析
# 显然 97 98 整体会被解析成一个整数，99 100 整体会被解析成一个整数
# 你想到了什么，这不就类似于 Python 整数的底层实现嘛
&quot;&quot;&quot;
97 -&gt; 01100001
98 -&gt; 01100010
那么 97 98 组合起来就是 01100010_01100001

99 -&gt; 01100011
100 -&gt; 01100100
那么 99 100 组合起来就是 01100100_01100011
&quot;&quot;&quot;
print(0b01100010_01100001)  # 25185
print(0b01100100_01100011)  # 25699
print(np.frombuffer(b, dtype=&quot;int16&quot;))  # [25185 25699]

# 按照 int32 来解析，显然这 4 个字节整体表示一个 int32
print(0b01100100_01100011_01100010_01100001)  # 1684234849
print(np.frombuffer(b, dtype=&quot;int32&quot;))  # [1684234849]
</code></pre>
<p>怎么样，是不是有点神奇呢？相信你在使用 numpy 的时候应该会有更加深刻的认识了，这就是缓冲区协议的威力。哪怕是不同的对象，只要都实现了缓冲区协议，那么彼此之间就可以暴露底层的缓冲区，从而实现共享内存。</p>
<p>所以 np.frombuffer 就是直接根据对象的缓冲区来创建数组，然后它底层的 buf 字段也指向这个缓冲区。但它不知道该如何解析这个缓冲区，所以我们需要显式地指定 dtype 来告诉它，相当于告诉它一些元信息。</p>
<p>那么问题来了，我们能不能修改缓冲区呢？</p>
<pre><code class="language-Python">import numpy as np

b = b&quot;abcd&quot;
arr = np.frombuffer(b, dtype=&quot;S1&quot;)

try:
    arr[0] = b&quot;A&quot;
except ValueError as e:
    print(e)  # assignment destination is read-only

# 答案是不可以的，因为原始的 bytes 对象不可修改，所以缓冲区只读
# 但我们真的就没办法了吗？还记得之前介绍的骚操作吗？
from ctypes import *

class PyBytesObject(Structure):

    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
        (&quot;ob_size&quot;, c_ssize_t),
        (&quot;ob_shash&quot;, c_ssize_t),
        (&quot;ob_sval&quot;, 5 * c_byte),
    ]
obj = PyBytesObject.from_address(id(b))
# 修改缓冲区之前，打印 arr
print(arr)  # [b'a' b'b' b'c' b'd']
# 修改缓冲区之后，打印 arr
obj.ob_sval[0] = ord(&quot;A&quot;)
print(arr)  # [b'A' b'b' b'c' b'd']
</code></pre>
<p>我们看到由于共享缓冲区，所以修改 bytes 对象也会影响数组 arr，只是由于 bytes 对象不可变，我们只能出此下策。但其实还有一个办法，就是使用 bytearray 对象。</p>
<pre><code class="language-Python">import numpy as np

# 可以理解为可变的 bytes 对象
b = bytearray(b&quot;abcd&quot;)
arr = np.frombuffer(b, dtype=&quot;S1&quot;)

print(b)  # bytearray(b'abcd')
# 此时缓冲区是可修改的，并且修改任何一个对象都会影响另一个，因为它们共享同一个缓冲区
arr[0] = b&quot;A&quot;
# 再次打印
print(b)  # bytearray(b'Abcd')
</code></pre>
<p>Py_buffer 的实现，也是 numpy 诞生的一个重要原因。</p>
<h2 id="小结-21"><a class="header" href="#小结-21">小结</a></h2>
<p>通过两个 bytes 对象相加，我们了解了什么是缓冲区、缓冲区协议，以及存在的作用，并且通过 numpy 进行了解释。了解缓冲区，可以让你更加深刻地理解 numpy。</p>
<p>下面再来总结一下：</p>
<ul>
<li>如果一个类型对象实现了 tp_as_buffer，那么它的实例对象便支持缓冲区协议；</li>
<li>tp_as_buffer 是一个函数指针，指向的函数负责初始化 Py_buffer；</li>
<li>在共享缓冲区的时候，比如 np.frombuffer(obj)，会直接调用 obj 的类型对象的 tp_as_buffer 字段指向的函数，拿到 Py_buffer 实例的 buf 字段指向的缓冲区。但 numpy 不知道该怎么解析这个缓冲区，所以还需要我们指定 dtype 参数。</li>
<li>缓冲区存在的最大意义就是共享内存，numpy 的数组在拷贝的时候，默认只拷贝 Py_buffer 实例，至于 Py_buffer 的 buf 字段指向的缓冲区默认是不会拷贝的。比如数组有 100 万个元素，这些元素都存储在缓冲区中，被 Py_buffer 的 buf 字段指向，拷贝的时候这 100 万个元素是不会拷贝的。</li>
<li>numpy 数组的维度、shape，是借助于 Py_buffer 中的元信息体现的，维度和 shape 不同，访问缓冲区元素的方式也不同。但存储元素的缓冲区，永远是一个一维数组，由 buf 字段指向。</li>
</ul>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>bytes 对象是不可变对象，那么根据我们对浮点数的了解，可以大胆猜测 bytes 对象也有自己的缓存池。事实上确实如此，为了优化单字节 bytes 对象的创建效率，Python 底层维护了一个缓存池，该缓存池是一个 PyBytesObject * 类型的数组。</p>
<pre><code class="language-C">// Objects/bytesobject.c

// 保存了 256 个单字节 bytes 对象，对应的 ASCII 码为 0 ~ 255
static PyBytesObject *characters[UCHAR_MAX + 1];
// 保存空 bytes 对象
static PyBytesObject *nullstring;
</code></pre>
<p>Python 内部创建单字节 bytes 对象时，会先检查目标对象是否已在缓存池中。PyBytes_FromString 函数是负责创建 bytes 对象的一个常用的 Python/C API，我们看一下它的逻辑。</p>
<pre><code class="language-C">// Objects/bytesobject.c

// 基于 C 字符串创建 bytes 对象
PyObject *
PyBytes_FromString(const char *str)
{
    size_t size;  // bytes 对象的长度
    PyBytesObject *op;  // 指向创建的 bytes 对象

    assert(str != NULL);
    // 计算 C 字符串的长度，它和对应的 bytes 对象的长度是相等的
    size = strlen(str);
    if (size &gt; PY_SSIZE_T_MAX - PyBytesObject_SIZE) {
        PyErr_SetString(PyExc_OverflowError,
            &quot;byte string is too long&quot;);
        return NULL;
    }
    
    // 如果 size 等于 0，并且 nullstring 保存了空 bytes 对象，那么直接返回
    if (size == 0 &amp;&amp; (op = nullstring) != NULL) {
#ifdef COUNT_ALLOCS
        _Py_null_strings++;
#endif
        Py_INCREF(op);
        return (PyObject *)op;
    }
    
    // 如果 size 等于 1，比如 char *str = &quot;a&quot;，证明创建的是单字节对象
    // 而 str 是字符串首元素的地址，所以 *str 会得到 'a'，即 97
    // 假设 *str 是 97，那么 op 就是 bytes_characters[97]
    if (size == 1 &amp;&amp; (op = characters[*str &amp; UCHAR_MAX]) != NULL) {
#ifdef COUNT_ALLOCS
        _Py_one_strings++;
#endif
        Py_INCREF(op);
        return (PyObject *)op;
    }

    // 否则创建新的 PyBytesObject 对象，此时是个空
    op = (PyBytesObject *)PyObject_MALLOC(PyBytesObject_SIZE + size);
    if (op == NULL)
        return PyErr_NoMemory();
    // 初始化内部字段
    (void)PyObject_INIT_VAR(op, &amp;PyBytes_Type, size);
    op-&gt;ob_shash = -1;
    // 将 C 字符串拷贝到 ob_sval 中
    memcpy(op-&gt;ob_sval, str, size+1);
    // 如果 size == 0，说明创建的是空 bytes 对象，那么赋值给 nullstring
    if (size == 0) {
        nullstring = op;
        Py_INCREF(op);
    } else if (size == 1) {
        // 如果 size == 1，说明创建的是单字节 bytes 对象，那么放入到缓存池中
        // 并且在缓存池中的索引，就是该字节对应的 ASCII 码
        characters[*str &amp; UCHAR_MAX] = op;
        Py_INCREF(op);
    }
    // 转成泛型指针之后返回
    return (PyObject *) op;
}
</code></pre>
<p>整体来说并不难，该 API 会将 C 字符串全部拷贝到 ob_sval 中。但如果 C 字符串长度为 10，而我们只希望基于前 n 个字符创建 bytes 对象，这时候可以使用 PyBytes_FromStringAndSize 函数。</p>
<ul>
<li><font color="blue">PyBytes_FromString(&quot;Hello World&quot;)</font> 会返回 b&quot;Hello World&quot;。</li>
<li><font color="blue">PyBytes_FromStringAndSize(&quot;Hello World&quot;, 5)</font> 会返回 b&quot;Hello&quot;，如果传递的第二个参数 size 和 C 字符串长度相同，那么效果和 PyBytes_FromString 是等价的。</li>
</ul>
<p>至于 PyBytes_FromStringAndSize 的逻辑和 PyBytes_FromString 类似，缓存池部分也是一样的，可以自己看一下。</p>
<p>当 Python 程序开始运行时，字节序列缓存池是空的。但随着<font color="blue">单字节 bytes 对象</font>的创建，缓存池中的对象慢慢多了起来。这样一来，单字节序列首次创建后便在缓存池中缓存起来，后续再使用时会直接从缓存池中获取，避免重复创建和销毁。与前面章节介绍的小整数对象池一样，字节序列缓存池也只能容纳为数不多的 256 个单字节序列，但使用频率非常高。</p>
<p><img src="./images/85.png" alt="" /></p>
<p>缓存池技术作为一种以空间换时间的优化手段，只需较小的内存为代价，便可明显提升执行效率。</p>
<pre><code class="language-python">&gt;&gt;&gt; a1 = b&quot;a&quot;
&gt;&gt;&gt; a2 = b&quot;a&quot;
&gt;&gt;&gt; a1 is a2
True
&gt;&gt;&gt;
&gt;&gt;&gt; a1 = b&quot;ab&quot;
&gt;&gt;&gt; a2 = b&quot;ab&quot;
&gt;&gt;&gt; a1 is a2
False
&gt;&gt;&gt;
</code></pre>
<p>显然此时不需要解释了，单字节 bytes 对象会缓存起来，放到缓存池中。至于空字节 bytes 对象，则是由专门的 nullstring 变量保存，它们都是单例的。</p>
<p>到目前为止，关于 bytes 对象的内容就说完了。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-20"><a class="header" href="#楔子-20">楔子</a></h2>
<p>前面我们介绍了 bytes 对象，本篇文章来聊一聊 bytearray 对象，这两者都表示字节串或者字节序列，它们的创建方式和支持的操作也是类似的。</p>
<pre><code class="language-Python"># 基于列表创建，里面的元素为 0 ~ 255 的整数
b1 = bytes([97, 98, 99])
b2 = bytearray([97, 98, 99])
print(b1)
print(b2)
&quot;&quot;&quot;
b'abc'
bytearray(b'abc')
&quot;&quot;&quot;

# 基于字符串创建
b1 = bytes(&quot;hello&quot;, encoding='utf-8')
b2 = bytearray(&quot;hello&quot;, encoding='utf-8')
print(b1)
print(b2)
&quot;&quot;&quot;
b'hello'
bytearray(b'hello')
&quot;&quot;&quot;

b1 = bytes.fromhex(&quot;61626364&quot;)
b2 = bytearray.fromhex(&quot;61626364&quot;)
print(b1)
print(b2)
&quot;&quot;&quot;
b'abcd'
bytearray(b'abcd')
&quot;&quot;&quot;
</code></pre>
<p>但区别在于 bytes 对象是不可变对象，bytearray 对象是可变对象。</p>
<pre><code class="language-Python"># 也可以直接基于 bytes 对象创建 bytearray 对象
# 反过来也是如此
b = bytearray(b&quot;satori&quot;)
print(b)  # bytearray(b'satori')

# 既然是可变对象，那么就意味着可以本地修改内部元素
# 由于字节序列内部的每个元素都是 0 ~ 255 的整数
# 因此这里修改时，也必须赋值整数
b[0] = ord(&quot;S&quot;)
print(b)  # bytearray(b'Satori')

# 当然，如果基于切片修改，那么需要赋值一个 bytes 对象
b[0: 2] = b&quot;SA&quot;
print(b)  # bytearray(b'SAtori')
# 当然也可以赋值一个 bytearray 对象
# 它和 bytes 对象本质一样，无非是 bytes 对象不能本地修改
b[0: 3] = bytearray(b&quot;saT&quot;)
print(b)  # bytearray(b'saTori')

# 在尾部追加字节
b.append(ord(&quot; &quot;))
b.append(ord(&quot;h&quot;))
b.append(ord(&quot;e&quot;))
b.append(ord(&quot;l&quot;))
b.append(ord(&quot;l&quot;))
b.append(ord(&quot;o&quot;))
print(b)  # bytearray(b'saTori hello')
</code></pre>
<p>还是那句话，如果不需要对字节序列做修改的话，那么 bytes 对象和 bytearray 对象是等价的，我们使用 bytes 对象即可。但若是希望字节序列可变，那么只能使用 bytearray 对象。</p>
<p>下面我们来分析一下 bytearray 对象的底层实现。</p>
<h2 id="bytearray-对象的底层实现"><a class="header" href="#bytearray-对象的底层实现">bytearray 对象的底层实现</a></h2>
<p>bytearray 对象在底层由 PyByteArrayObject 结构体表示，定义如下。</p>
<pre><code class="language-C">// Include/bytearrayobject.h

typedef struct {
    PyObject_VAR_HEAD
    Py_ssize_t ob_alloc;
    char *ob_bytes;
    char *ob_start;
    int ob_exports;
} PyByteArrayObject;
</code></pre>
<p>解释一下每个字段的含义：</p>
<ul>
<li>PyObject_VAR_HEAD：变长对象的公共头部，包含引用计数、类型和长度。</li>
<li>ob_alloc：底层缓冲区的长度，即最多能容纳多少个字节。注意它和 ob_size 的区别，ob_size 表示 bytearray 对象的长度，也就是缓冲区当前已经容纳了多少个字节。如果 append 的时候发现 ob_size 达到了 ob_alloc，那么要对缓冲区进行扩容。</li>
<li>ob_bytes：指向缓冲区的指针，缓冲区是一个连续的内存块，用于存储字节序列的所有数据。</li>
<li>ob_start：ob_bytes 指向缓冲区的物理起始位置，而 ob_start 指向缓冲区的逻辑起始位置。说白了 ob_start 可以指向缓冲区的任意位置，允许字节序列使用部分缓冲区，比如通过切片 [1:] 进行截取，那么 ob_start 便指向缓冲区的第二个元素（逻辑起始位置），而无需重新分配内存。</li>
<li>ob_exports：缓冲区被外部对象引用的次数。</li>
</ul>
<p>下面我们来创建几个 bytearray 对象，并通过画图来描述对应的底层结构。</p>
<p><font color="darkblue"><strong>b = bytearray(b&quot;&quot;)</strong></font></p>
<p><img src="./images/86.png" alt="" /></p>
<p>每个结构体字段都是 8 字节，所以一个空 bytearray 对象的大小是 56 字节。</p>
<pre><code class="language-Python">&gt;&gt;&gt; b = bytearray()
&gt;&gt;&gt; b
bytearray(b'')
&gt;&gt;&gt; b.__sizeof__()
56
</code></pre>
<p>结果和我们分析的一样。</p>
<p><font color="darkblue"><strong>b = bytearray(b&quot;abc&quot;)</strong></font></p>
<p><img src="./images/87.png" alt="" /></p>
<p>由于缓冲区长度为 4，因此大小为 56 + 4 = 60 字节。</p>
<pre><code class="language-python">&gt;&gt;&gt; b = bytearray(b&quot;abc&quot;)
&gt;&gt;&gt; b
bytearray(b'abc')
&gt;&gt;&gt; b.__sizeof__()
60
</code></pre>
<p>所以我们可以得出结论，bytearray 对象的大小等于 <font color="blue">56 + 缓冲区的长度</font>，在不发生扩容的情况下，缓冲区的长度等于 <font color="blue">ob_size + 1</font>。</p>
<pre><code class="language-Python">&gt;&gt;&gt; name = &quot;古明地觉&quot;
&gt;&gt;&gt; b = bytearray(name, encoding=&quot;utf-8&quot;)
&gt;&gt;&gt; 
&gt;&gt;&gt; 56 + len(name) * 3 + 1
69
&gt;&gt;&gt; b.__sizeof__()
69
</code></pre>
<p>但如果发生扩容会怎么样呢？</p>
<pre><code class="language-Python">&gt;&gt;&gt; b = bytearray(b&quot;abc&quot;)
&gt;&gt;&gt; b
bytearray(b'abc')
&gt;&gt;&gt; b.__sizeof__()
60
# 添加一个元素
&gt;&gt;&gt; b.append(100)
&gt;&gt;&gt; b
bytearray(b'abcd')
&gt;&gt;&gt; b.__sizeof__()
63
</code></pre>
<p>添加一个元素之后，大小从 60 变成了 63，难道不应该是 61 吗？之所以出现这个现象，就是因为扩容的时候多申请了两个字节，我们画张图来展示一下这个过程。</p>
<p><img src="./images/88.png" alt="" /></p>
<p>以上就是 bytearray 对象的底层结构。</p>
<h2 id="bytearray-对象的创建"><a class="header" href="#bytearray-对象的创建">bytearray 对象的创建</a></h2>
<p>说完了 bytearray 对象的底层结构之后，再来看看它是怎么创建的？</p>
<pre><code class="language-C">// Objects/bytearrayobject.c

PyObject *
PyByteArray_FromStringAndSize(const char *bytes, Py_ssize_t size)
{
    // 基于 C 的字符数组创建 bytearray 对象
    // 参数 size 表示 bytearray 对象的长度
    PyByteArrayObject *new;
    Py_ssize_t alloc;
    // size 必须大于 0
    if (size &lt; 0) {
        PyErr_SetString(PyExc_SystemError,
            &quot;Negative size passed to PyByteArray_FromStringAndSize&quot;);
        return NULL;
    }

    // size 必须小于 PY_SSIZE_T_MAX
    if (size == PY_SSIZE_T_MAX) {
        return PyErr_NoMemory();
    }
    // 为 PybyteArrayObject 申请内存，此处调用的是泛型 API
    new = PyObject_New(PyByteArrayObject, &amp;PyByteArray_Type);
    // 申请失败返回 NULL
    if (new == NULL)
        return NULL;
    // 如果 size == 0，表示 bytearray 对象的长度为 0
    // 那么将 ob_bytes 设置为 NULL，将 alloc 设置为 0
    if (size == 0) {
        new-&gt;ob_bytes = NULL;
        alloc = 0;
    }
    else {
        // 否则将 alloc 设置为 size + 1，因为要多一个 '\0'
        alloc = size + 1;
        // 申请 alloc 个字节的内存，赋值给 ob_bytes
        new-&gt;ob_bytes = PyObject_Malloc(alloc);
        // 为 NULL 表示申请失败，内存不足
        if (new-&gt;ob_bytes == NULL) {
            Py_DECREF(new);
            return PyErr_NoMemory();
        }
        // 将参数 bytes（这里是 C 字符串）拷贝到 ob_bytes 指向的缓冲区
        // 在拷贝的时候，可以指定拷贝的长度，通过 size 参数指定
        // 如果希望整个字符串全部拷贝，那么将 size 指定为 strlen(bytes) 即可
        if (bytes != NULL &amp;&amp; size &gt; 0)
            memcpy(new-&gt;ob_bytes, bytes, size);
        // 将最后一个元素（索引为 size）设置为 '\0'
        new-&gt;ob_bytes[size] = '\0';  /* Trailing null byte */
    }
    // 将 ob_size 字段初始化为 size
    Py_SIZE(new) = size;
    // 将 ob_alloc 字段初始化为 alloc
    new-&gt;ob_alloc = alloc;
    // ob_start 默认等于 ob_bytes
    new-&gt;ob_start = new-&gt;ob_bytes;
    // 缓冲区被引用的次数为 0，因为刚创建
    new-&gt;ob_exports = 0;
    // 转成泛型指针之后返回
    return (PyObject *)new;
}
</code></pre>
<p>之前在创建 bytes 对象的时候介绍过 PyBytes_FromStringAndSize 这个函数，创建 bytearray 对象和它是类似的。但需要注意的是，bytes 对象和 bytearray 对象都实现了缓冲区，但这两者有一个区别。</p>
<ul>
<li>bytes 对象的缓冲区存储在 PyBytesObject 结构体内部；</li>
<li>bytearray 对象则不是这样，PyByteArrayObject 内部存储的是指针，指针指向了缓冲区；</li>
</ul>
<p>我们回顾一下这两个结构体的定义。</p>
<p><img src="./images/89.png" alt="" /></p>
<p>PyBytesObject 里面的 ob_sval 是一个数组，而 PyByteArrayObject 的 ob_bytes 是一个指针。那为什么会出现这种情况呢？原因在这个系列的最开始就说过了，bytes 对象是不可变的，元素会直接存储在对应的结构体内部。</p>
<p>而 bytearray 对象是可变的，那么它内部只能存储指针，指针指向的内存区域负责存储元素。如果发生扩容，只需申请一片更大的内存区域并将元素拷贝过去，然后改变指针（ob_bytes）指向即可。至于 bytearray 对象本身的地址是不会发生任何变化的，它的扩容对引用它的变量来说是无感知的。</p>
<h2 id="小结-22"><a class="header" href="#小结-22">小结</a></h2>
<p>以上就是 bytearray 对象，关于它的具体操作就不赘述了，和 bytes 对象是类似的，可以自己尝试读一读。</p>
<p>总之在工作中，如果你不明确需要字节序列可变，那么使用 bytes 对象即可，否则使用 bytearray 对象。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-21"><a class="header" href="#楔子-21">楔子</a></h2>
<p>接下来我们将分析 Python 的字符串，这应该是使用频率最高的数据结构了，我们会通过多篇文章来详细阐述字符串的实现原理。</p>
<p>首先字符串是一个变长对象，因为不同长度的字符串所占的内存是不一样的。但同时字符串又是一个不可变对象，因为一旦创建就不可以再修改了。</p>
<h2 id="多字节编码"><a class="header" href="#多字节编码">多字节编码</a></h2>
<p>我们知道计算机的存储单位是字节，一个字节可以表示 256 种字符，对于发明计算机的美国人来说足够了。因为英文字母算上大小写只有 52 个，即便再加上一些特殊字符，数量也不会超过 256 个，因此一个字节完全可以表示。</p>
<p>但随着计算机的普及，越来越多的非英文字符出现，导致一个字节已经无法表示了。所以只能曲线救国，对于一个字节无法表示的字符，使用多个字节表示，这便是<font color="blue">多字节编码</font>。而多字节编码也存在相应的问题，就是容易出现乱码。</p>
<p>到这里先不继续往下深入，我们先来理清楚一些概念。</p>
<h2 id="字符集和字符编码"><a class="header" href="#字符集和字符编码">字符集和字符编码</a></h2>
<p>估计有很多小伙伴搞不清这两者的区别，我们先来解释一下所谓的字符集和字符编码是怎么一回事？</p>
<ul>
<li><font color="blue">字符集</font>：系统支持的所有字符组成的集合，像 ASCII、GB2312、Big5、unicode 都属于字符集。只不过不同的字符集所能容纳的字符个数不同，比如 ASCII 字符集不包含中文，unicode 则可以容纳世界上的所有字符；</li>
<li><font color="blue">多字节编码</font>：负责将每个字符转成一个或多个计算机可以接受的具体数字，该数字可以理解为编号，因此字符编码维护了字符和编号之间的对应关系。而编码也分为多种，比如 ASCII、GBK、UTF-8 等等，字符编码不同，那么字符转换之后的编号也不同，当然能转化的字符种类也不同。比如 ASCII 这种字符编码，它就只能转换 ASCII 字符。</li>
</ul>
<p>当然，ASCII 比较特殊，它既是字符集、也是字符编码。并且不管采用什么编码，ASCII 字符对应的编号永远是相同的。</p>
<p>将字符串中的每一个字符转成对应的编号，那么得到的就是<font color="blue">字节序列（bytes 对象）</font>，因为计算机存储和网络通讯的基本单位都是字节，所以字符串必须以字节序列的形式进行存储或传输。</p>
<p>因此字符串和字节序列在某种程度上是很相似的，字符串按照指定的编码进行 encode 即可得到字节序列，<font color="blue">也就是将每个字符都转成对应的编号</font>；字节序列按照相同的编码 decode 即可得到字符串，<font color="blue">也就是根据编号找到对应的字符</font>。</p>
<p>比如我们写了一段文本，然后在存储的时候必须先进行 encode，也就是将每一个字符都转成一个或多个系统可以接受的数字、即对应的编号之后，才可以进行存储。</p>
<pre><code class="language-Python">name = &quot;古明地觉&quot;

print(name.encode(&quot;gbk&quot;))
&quot;&quot;&quot;
b'\xb9\xc5\xc3\xf7\xb5\xd8\xbe\xf5'
&quot;&quot;&quot;
print(name.encode(&quot;utf-8&quot;))
&quot;&quot;&quot;
b'\xe5\x8f\xa4\xe6\x98\x8e\xe5\x9c\xb0\xe8\xa7\x89'
&quot;&quot;&quot;
</code></pre>
<p>采用不同的编码，得到的字节序列是不同的，比如使用 gbk 编码 encode，那么也必须使用 gbk 编码 decode。否则会因为无法解析而报错，因为字符编码不同，字符对应的编号也不同。</p>
<p>再比如每个国家都有自己的字符编码，你在日本的一台计算机上写好的文件拿到中国的计算机上打开，很有可能出现乱码。因为字符编码不同，字符和编号之间的对应关系也不同，采用不同的字符编码进行解析肯定会出问题。</p>
<p>但我们说，对于 ASCII 字符来说，由于不管采用哪一种编码，它们得到的编号都是固定的。所以编码对于 ASCII 字符来说，没有任何影响。</p>
<pre><code class="language-Python">name = &quot;satori&quot;

print(name.encode(&quot;gbk&quot;))
&quot;&quot;&quot;
b'satori'
&quot;&quot;&quot;
print(name.encode(&quot;gbk&quot;).decode(&quot;utf-8&quot;))
&quot;&quot;&quot;
satori
&quot;&quot;&quot;

# 但如果是非 ASCII 字符，就不行了
try:
    &quot;你好&quot;.encode(&quot;gbk&quot;).decode(&quot;utf-8&quot;)
except UnicodeDecodeError as e:
    print(e)
    &quot;&quot;&quot;
    'utf-8' codec can't decode byte 0xc4 in position 0: invalid continuation byte
    &quot;&quot;&quot;
</code></pre>
<p>这里再回忆一下 bytes 对象，创建的时候可以采用字面量的方式，比如 <font color="blue">b&quot;abc&quot;</font>，但是 <font color="blue">b&quot;憨&quot;</font> 却不可以。原因就是<font color="blue">憨</font>这个字符不是 ASCII 字符，那么采用不同的字符编码，其对应的编号是不同的。而解释器又不知道我们使用的是哪一种编码，所以不允许这么做，而是需要通过 <font color="blue">&quot;憨&quot;.encode()</font> 的方式手动指定字符编码。</p>
<p>但对于 ASCII 字符而言，不管采用哪一种字符编码，得到的编号都是一样的， 所以 Python 针对 ASCII 字符则允许这种做法，比如 <font color="blue">b&quot;abc&quot;</font>。并且我们看到，对于汉字来说，在编码之后会对应多个编号，而每个编号占 1 字节，因此不同的字符所占的大小可能不同。</p>
<h2 id="小结-23"><a class="header" href="#小结-23">小结</a></h2>
<p>以上就是字符集和字符编码，字符集就是字符组成的集合，不同字符集所能容纳的字符数量是有限的。字符编码是将字符转成对应的编号，比如将一个字符串中的所有字符都转成对应的编号之后，就得到了字节序列。当然和字符集一样，字符编码能转换的字符种类也是有限的，像汉字我们可以使用 GBK 编码、UTF-8 编码，但是不能使用 ASCII 编码。</p>
<p>以上算是理清楚了一些概念，显然过于简单了，主要是为后面的内容做铺垫。那么下一篇文章，我们就从 Python 的角度来分析字符串的存储方式。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-22"><a class="header" href="#楔子-22">楔子</a></h2>
<p>上一篇文章我们介绍了字符集，它是一系列字符组成的集合，但不同的字符集所能容纳的字符是有限的。于是为了能将全世界的字符统一起来，便诞生了 unicode。</p>
<p>unicode 字符集对世界上出现的所有字符都进行了系统的整理，包括各种 emoji，不管是哪个国家的语言，都可以使用 unicode 字符集。</p>
<pre><code class="language-Python">print(ord(&quot;a&quot;))  # 97
print(ord(&quot;憨&quot;))  # 25000
print(ord(&quot;て&quot;))  # 12390
</code></pre>
<p>不管什么文字，都可以用一个 unicode 来表示，它们在字符集中对应一个唯一的码点。所谓码点，就是字符在字符集中的索引，或者说唯一编号。</p>
<p>但是问题来了，unicode 能表示这么多的字符，占用的内存一定不低吧。的确，根据当时的编码，一个 unicode 字符最高会占用到 4 字节，因此对西方人来说就有点苦不堪言了，明明一个字节就够用了，为啥需要那么多。于是又出现了 utf-8，它是为 unicode 提供的一个新的编码规则，具有可变长的功能。不同种类的字符占用的大小不同，比如英文字符使用一个字节存储，汉字使用 3 个字节存储，emoji 使用 4 个字节存储。</p>
<p>但 Python 在表示 unicode 字符串时，使用的却不是 utf-8 编码，至于原因我们下面来分析一下。</p>
<h2 id="unicode-的三种编码"><a class="header" href="#unicode-的三种编码">unicode 的三种编码</a></h2>
<p>从 Python3 开始，字符串使用的是 unicode。而根据编码的不同，unicode 的每个字符最大可以占用 4 字节，从内存的角度来说，这种编码有时会比较昂贵。为了减少内存消耗并且提高性能，Python 的内部使用了三种编码方式来表示 unicode。</p>
<ul>
<li>Latin-1 编码：每个字符占 1 字节;</li>
<li>UCS2 编码：每个字符占 2 字节；</li>
<li>UCS4 编码：每个字符占 4 字节；</li>
</ul>
<p>在 Python 编程中，所有字符串的行为都是一致的，而且大多数时候我们都没有注意到差异。然而在处理大文本的时候，这种差异就会变得异常显著，甚至有些让人出乎意料。为了看到内部表示的差异，我们看一下字符串所占的内存大小。</p>
<pre><code class="language-Python">&gt;&gt;&gt; sys.getsizeof(&quot;a&quot;)
50
&gt;&gt;&gt; sys.getsizeof(&quot;憨&quot;)
76
&gt;&gt;&gt; sys.getsizeof(&quot;😂&quot;)
80
</code></pre>
<p>我们看到都是一个字符，但它们占用的内存却是不一样的。因为 Python 面对不同的字符会采用不同的编码，进而导致大小不同。但需要注意的是，Python 的每一个字符串都需要额外占用至少 49 个字节，因为要存储一些元数据，比如：公共的头部、哈希、长度、字节长度、编码类型等等。</p>
<pre><code class="language-Python">import sys

# 对于 ASCII 字符，一个占 1 字节，此时是 Latin-1 编码
print(sys.getsizeof(&quot;ab&quot;) - sys.getsizeof(&quot;a&quot;))  # 1

# 对于汉字，日文等等，一个占 2 字节，此时是 UCS2 编码
print(sys.getsizeof(&quot;憨憨&quot;) - sys.getsizeof(&quot;憨&quot;))  # 2
print(sys.getsizeof(&quot;です&quot;) - sys.getsizeof(&quot;で&quot;))  # 2

# 像 Emoji，则是一个占 4 字节 ，此时是 UCS4 编码
print(sys.getsizeof(&quot;😂😂&quot;) - sys.getsizeof(&quot;😂&quot;))  # 4
</code></pre>
<p>而采用不同的编码，底层结构体实例的元数据也会占用不同大小的内存。</p>
<pre><code class="language-Python"># 所以一个空字符串占用 49 个字节
# 此时会采用占用内存最小的 Latin-1 编码
print(sys.getsizeof(&quot;&quot;))  # 49
# 此时使用 UCS2
print(sys.getsizeof(&quot;憨&quot;) - 2)  # 74
# UCS4
print(sys.getsizeof(&quot;🍌&quot;) - 4)  # 76
</code></pre>
<p>如果编码是 Latin-1，那么结构体实例的元数据会占 49 个字节；编码是 UCS2，占 74 个字节；编码是 UCS4，占 76 个字节。然后字符串所占的字节数就等于：<font color="blue">元数据 + 字符个数 * 单个字符所占的字节</font>。</p>
<h2 id="为什么不使用-utf-8-编码"><a class="header" href="#为什么不使用-utf-8-编码">为什么不使用 utf-8 编码</a></h2>
<p>上面提到的三种编码是 Python 在底层所使用的，但我们知道 unicode 还有一个 utf-8 编码，那 Python 为啥不用呢？</p>
<p>先来抛出一个问题，我们知道 Python 支持通过索引查找一个字符串指定位置的字符（注意不是字节），比如 s[2] 查找的就是字符串 s 中的第 3 个字符。</p>
<pre><code class="language-Python">s = &quot;古明地觉&quot;
print(s[2])  # 地
</code></pre>
<p>那么问题来了，通过索引查找字符串的某个字符，时间复杂度为 O(1)，那么 Python 是怎么通过索引瞬间定位到指定字符的呢？显然是通过指针的偏移，用索引乘上每个字符占的字节数，得到偏移量，然后从头部向后偏移指定数量的字节即可，这样就能在定位到指定字符的同时还保证时间复杂度为 O(1)。</p>
<p>但是这需要一个前提：<font color="blue">字符串中每个字符所占的大小必须是相同的</font>，如果字符占的大小不同，比如有的占 1 字节、有的占 3 字节，显然就无法通过指针偏移的方式了。这个时候若还想准确定位的话，只能按顺序对所有字符都逐个扫描，但这样的话时间复杂度肯定不是 O(1)，而是 O(n)。</p>
<p>我们以 Go 为例，Go 字符串默认就是使用的 utf-8 编码。</p>
<pre><code class="language-go">package main

import &quot;fmt&quot;

func main() {
    s := &quot;古明地觉&quot;
    fmt.Println(s[2])  // 164
    fmt.Println(string(s[2]))  // ¤
}
</code></pre>
<p>惊了，我们看到打印的并不是我们希望的结果。因为 Go 底层使用的是 utf-8 编码，不同的字符可能会占用不同的字节。但 Go 通过索引定位的时间复杂度也是 O(1)，所以定位的时候是以字节为单位、而不是字符。在获取的时候也只会获取一个字节，而不是一个字符。</p>
<p>所以 s[2] 在 Go 里面指的是<font color="blue">第 3 个字节</font>，而不是<font color="blue">第 3 个字符</font>，而汉字在 utf-8 编码下占 3 个字节，所以 s[2] 指的就是汉字<font color="blue">古</font>的第三个字节。我们看到打印的时候，该字节的值为 164。</p>
<pre><code class="language-python">s = &quot;古明地觉&quot;
print(s.encode(&quot;utf-8&quot;)[2])  # 164
</code></pre>
<p>这就是采用 utf-8 编码带来的弊端，它无法让我们以 O(1) 的时间复杂度去准确地定位字符，尽管它在存储的时候更省内存。</p>
<h2 id="latin-1ucs2ucs4-该使用哪一种"><a class="header" href="#latin-1ucs2ucs4-该使用哪一种">Latin-1、UCS2、UCS4 该使用哪一种</a></h2>
<p>Python 会使用 3 种编码来表示 unicode，所占字节大小分别是 1、2、4 字节。</p>
<p>因此 Python 在创建字符串的时候会先扫描，尝试使用占字节数最少的 Latin-1 编码存储，但是范围肯定有限。如果发现存储不下的字符，只能改变编码，使用 UCS2，然后继续扫描。但如果又发现 UCS2 也无法存储的字符，因为两个字节最多表示 65535 个不同的字符，那么会再次改变编码，使用 UCS4。UCS4 占四个字节，肯定能存下了。</p>
<p>一旦改变编码，字符串中的所有字符都会使用同样的编码，因为它们不具备可变长功能。比如字符串 <font color="blue">&quot;hello 古明地觉&quot;</font>，肯定都会使用 UCS2，不存在 <font color="blue">&quot;hello &quot;</font> 使用 Latin-1，<font color="blue">&quot;古明地觉&quot;</font> 使用 UCS2，因为一个字符串只能有一个编码。</p>
<p>当通过索引获取的时候，会将索引乘上每个字符占的字节数，这样就能跳到准确位置上，因为字符串的所有字符占的字节都是一样的，然后获取的时候也会获取指定的字节数。比如使用 UCS2 编码，那么定位到某个字符的时候，会取两个字节，这样才能表示一个完整的字符。</p>
<pre><code class="language-Python">import sys

# 此时全部是 ascii 字符，那么 Latin-1 编码可以存储
# 所以结构体实例的元数据占 49 个字节
s1 = &quot;hello&quot;
# 有 5 个字符，一个字符一个字节，所以加一起是 54 个字节
print(sys.getsizeof(s1))  # 54

# 出现了汉字，那么 Latin-1 肯定存不下，于是使用 UCS2
# 所以结构体实例的元数据占 74 个字节
# 但是别忘了此时的英文字符也是 UCS2，所以也是一个字符两字节
s2 = &quot;hello憨&quot;
# 6 个字符，74 + 6 * 2 = 86
print(sys.getsizeof(s2))  # 86

# 这个牛逼了，UCS2 也存不下，只能 UCS4 存储了
# 所以结构体实例的元数据占 76 个字节
s3 = &quot;hello憨🍌&quot;
# 此时所有字符一个占 4 字节，总共 7 个字符
# 76 + 7 * 4 = 104
print(sys.getsizeof(s3))  # 104
</code></pre>
<p>除此之外，我们再举一个例子更形象地证明这个现象。</p>
<pre><code class="language-python">import sys

s1 = &quot;a&quot; * 1000
s2 = &quot;a&quot; * 1000 + &quot;🍑&quot;

# 我们看到 s2 只比 s1 多了一个字符
# 但是两者占的内存，s2 却将近是 s1 的 4 倍。
print(sys.getsizeof(s1))  # 1049
print(sys.getsizeof(s2))  # 4080
</code></pre>
<p>s2 和 s1 的差别只是 s2 比 s1 多了一个字符，但就是这么一个字符导致 s2 比 s1 多占了 3031 个字节。然而这 3031 个字节不可能是多出来的字符所占的大小，什么字符一个会占到三千多个字节，这是不可能的。</p>
<p>尽管如此，它也是罪魁祸首，但前面的 1000 个字符也是共犯。我们说 Python 会根据字符串选择不同的编码，s1 全部是 ASCII 字符，所以 Latin1 能存下，因此一个字符只占一个字节，所以大小就是 <font color="blue">49 + 1000 = 1049</font>。</p>
<p>对于 s2，Python 发现前 1000 个字符 Latin1 能存下，但不幸的是最后一个字符存不下，于是只能使用 UCS4。而字符串的所有字符只能有一个编码，为了保证索引查找的时间复杂度为 O(1)，前面一个字节就能存下的字符，也需要用 4 字节来存储，这是 Python 的设计策略。</p>
<p>而使用 UCS4，结构体的元数据会占 76 个字节，因此 s2 的大小就是 <font color="blue">76 + 1001 * 4 = 4080</font>。</p>
<pre><code class="language-Python"># 74 + 7 * 2 = 88
&gt;&gt;&gt; sys.getsizeof(&quot;爷的青春回来了&quot;) 
88

# 76 + 7 * 4 = 104
&gt;&gt;&gt; sys.getsizeof(&quot;👴的青春回来了&quot;)
104
</code></pre>
<p>字符数量相同但是占用内存大小不同，相信原因你肯定能分析出来。</p>
<p>所以如果字符串中的所有字符都是 ASCII 字符，则使用 1 字节 Latin1 编码。Latin1 能表示前 256 个 unicode 字符，它支持多种拉丁语，如英语、瑞典语、意大利语、挪威语。但是它们不能存储非拉丁语言，比如汉语、日语、希伯来语、西里尔语。这是因为它们的码点（数字索引）定义在 1 字节（0 ~ 255）范围之外。</p>
<p>大多数自然语言的文字都采用 2 字节（UCS2）编码，但当字符串包含特殊符号、Emoji 或稀有语言时，则使用 4 字节（UCS4）编码。unicode 标准有将近 300 个块（范围），你可以在 0XFFFF 块之后找到 4 字节块。</p>
<p>假设我们有一个 10G 的 ASCII 文本，想把它加载到内存中，但如果在文本中插入一个表情符号，那么字符串的大小将增加 4 倍。这是一个巨大的差异，你可能会在实践当中遇到，比如处理 NLP 问题。</p>
<pre><code class="language-Python">print(ord(&quot;a&quot;))  # 97
print(ord(&quot;憨&quot;))  # 25000
print(ord(&quot;😁&quot;))  # 128513
</code></pre>
<p>所以最著名和最流行的 unicode 编码都是 utf-8，但 Python 不在内部使用它，而是使用 Latin1、UCS2、UCS4。至于原因我们上面已经解释的很清楚了，主要是字符串的索引是基于字符，而不是字节。</p>
<p>当一个字符串使用 utf-8 编码存储时，每个字符会根据自身选择一个合适的大小，这是一种存储效率很高的编码，但它有一个明显的缺点。由于每个字符的字节长度可能不同，就导致无法按照索引瞬间定位到单个字符，即便能定位，也无法定位准确。如果想准，那么只能逐个扫描所有字符。</p>
<p>假设要对使用 utf-8 编码的字符串执行一个简单的操作，比如 s[5]，就意味着解释器需要扫描每一个字符，直到找到需要的字符，这样效率是很低的。但如果是固定长度的编码就没有这样的问题，所以当 Latin1 存储的 <font color="blue">&quot;hello&quot;</font>，在和 UCS2 存储的 <font color="blue">&quot;古明地觉&quot;</font> 组合之后，整体每一个字符都会向大的方向扩展，变成 2 字节。</p>
<p>这样定位字符的时候，只需要将 <font color="blue">索引 * 2</font> 便可计算出偏移的字节数，然后跳转该字节数即可。但如果原来的  <font color="blue">&quot;hello&quot;</font> 还是 1字节，而汉字是 2 字节，那么只通过索引是不可能定位到准确字符的，因为不同类型的字符的大小不同，必须要扫描整个字符串才可以。但是扫描字符串，效率又比较低，所以 Python 内部才会使用这个方法，而不是使用 utf-8。</p>
<p>因此对于 Go 来讲，如果想像 Python 一样，那么需要这么做：</p>
<pre><code class="language-go">package main

import &quot;fmt&quot;

func main() {
    s := &quot;hello古明地觉&quot;
    // 我们看到长度为 17，因为使用 utf-8 编码，并且 len 函数统计的是字节的数量
    fmt.Println(s, len(s))  // hello古明地觉 17
    
    // 如果想像 Python 一样，那么可以使用 Go 提供的 rune，相当于 int32
    // 此时每个字符均使用 4 个字节，所以长度变成了 9
    r := []rune(s)
    fmt.Println(string(r), len(r))  // hello古明地觉 9
    // 虽然打印的内容是一样的，但此时每个字符都使用 4 字节存储
    
    // 此时跳转会偏移 5 * 4 个字节，然后获取也会获取 4 个字节，因为一个字符占 4 个字节
    fmt.Println(string(r[5]))  // 古
}
</code></pre>
<p>由于 utf-8 编码的 unicode 字符串里面的字符可能占用不同的字节，显然没办法实现 Python 字符串的索引查找效果，因此 Python 没有使用 utf-8 编码。</p>
<p>Python 的做法是让字符串的所有字符都占用相同的字节，先使用占用内存最少的 Latin1，不行的话再使用 UCS2，还不行则使用 UCS4。但不管使用哪种编码，都会确保每个字符占用的字节是一样的。至于原因上面分析的很透彻了，因为无论是索引还是切片，还是计算长度等等，都是基于字符来的，显然这也符合人类的思维习惯。</p>
<h2 id="小结-24"><a class="header" href="#小结-24">小结</a></h2>
<p>以上就是 Python 字符串的存储策略，它并没有使用最为流行的 utf-8，归根结底就在于这种编码不适合 Python 字符串。当然，我们在将字符串转成字节序列的时候，一般使用的都是 utf-8 编码。</p>
<p>下一篇文章来介绍字符串的底层实现，看看字符串在底层是如何设计的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-23"><a class="header" href="#楔子-23">楔子</a></h2>
<p>我们之前提到，字符串采用不同的编码，底层的结构体实例的元数据所占用的内存是不一样的。其实本质上是，字符串会根据编码的不同，而选择不同的存储结构。</p>
<ul>
<li>PyASCIIObject：字符串仅包含 ASCII 字符；</li>
<li>PyCompactUnicodeObject：字符串包含非 ASCII 字符，但可以紧凑表示；</li>
<li>PyUnicodeObject：通用结构，可以表达所有类型的字符串（该结构不做讨论）；</li>
</ul>
<p>需要强调的是，虽然 ASCII 字符占一字节，但只有码点小于 128 的字符才叫 ASCII 字符。</p>
<p>下面我们来分析一下。</p>
<h2 id="unicode-分类"><a class="header" href="#unicode-分类">unicode 分类</a></h2>
<p>unicode 会根据编码的不同而分为以下几类。</p>
<pre><code class="language-C">// Include/cpython/unicodeobject.h
enum PyUnicode_Kind {
    // 所有字符的码点均位于 U+0000 ~ U+00FF 
    PyUnicode_1BYTE_KIND = 1,
    // 所有字符的码点均位于 U+0000 ~ U+FFFF 
    // 且至少有一个大于 U+00FF
    PyUnicode_2BYTE_KIND = 2,
    // 所有字符的码点均位于 U+0000 ~ U+10FFFF
    // 且至少有一个大于 U+FFFF
    PyUnicode_4BYTE_KIND = 4
};
</code></pre>
<p>而采用不同的编码，每个字符的大小也是不同的。</p>
<pre><code class="language-c">// Include/unicodeobject.h
typedef uint32_t Py_UCS4;
typedef uint16_t Py_UCS2;
typedef uint8_t Py_UCS1;
</code></pre>
<p>Python 有一个内置函数 ord，可以查看字符的码点。</p>
<ul>
<li>如果码点位于 0 ~ 255，那么使用 Py_UCS1，占 1 字节；</li>
<li>如果码点位于 256 ~ 65535，那么使用 Py_UCS2，占 2 字节；</li>
<li>如果码点大于 65535，那么使用 Py_UCS4，占 4 字节；</li>
</ul>
<p>通过字符的范围，选择一个最合适的存储单元，从而节省内存。</p>
<h2 id="pyasciiobject"><a class="header" href="#pyasciiobject">PyASCIIObject</a></h2>
<p>如果字符串只包含 ASCII 字符，即字符的码点均小于 128，那么底层使用 PyASCIIObject 进行存储。</p>
<pre><code class="language-C">// Include/cpython/unicodeobject.h
typedef struct {
    // 对象的公共头部
    PyObject_HEAD
    // 字符串的长度，充当了 ob_size
    Py_ssize_t length;
    // 哈希值，初始为 -1   
    Py_hash_t hash;
    struct {
        // 字符串是否开启 intern 机制，后续介绍
        unsigned int interned:2;
        // 类型，标识每个存储单元的大小，可以有以下几种
        // PyUnicode_1BYTE_KIND
        // PyUnicode_2BYTE_KIND
        // PyUnicode_4BYTE_KIND
        unsigned int kind:3;
        // 字符串是否紧凑表示，它是针对内存分配方案而言的
        /* 紧凑的字符串由 PyASCIIObject 和 PyCompactUnicodeObject 表示
           它的特点是对象和文本缓冲区是结合的，只需要一个内存块 */
        /* 非紧凑的字符串由 PyUnicodeObject 表示（不是本文的重点）
           它的特点是对象和文本缓冲区是分离的，需要两个内存块 
           一个负责存储 PyUnicodeObject 对象，另一个负责存储文本缓冲区 */
        unsigned int compact:1;
        // 字符串是否只包含 ASCII 字符，如果是则为 1, 否则为 0
        // 虽然一个字节可表示的范围是 0 ~ 255，但只有 0 ~ 127 之间的才是 ASCII 字符
        unsigned int ascii:1;
        // 对象布局是否已完全初始化，不用关注
        unsigned int ready:1;
        // 注意上面的字段名后面跟着 :数字，这是 C 语言的位域
        // 比如 interned:2 表示使用 unsigned int 的前 2 个位
        // 所以 struct state 结构体总共占 4 字节，因为所有字段共用 4 字节内存
        // 上面总共使用了 8 个位，显然这里的 :24 负责占满 32 个位
        unsigned int :24;
    } state;
    // 缓存宽字符格式（wide character）的字符串，无需关注，在之后的版本会被移除
    wchar_t *wstr;
} PyASCIIObject;
</code></pre>
<p>那么问题来了，实际的字符串文本数据存在了什么地方，我们没看到结构体里面有哪个字段负责存储文本啊。答案很简单，字符串文本会直接跟在 PyASCIIObject 结构体实例的后面，也就是紧凑表示。</p>
<p>我们以字符串 &quot;miu&quot; 为例，看一下它的底层结构。</p>
<p><img src="./images/90.png" alt="" /></p>
<p>注：为优化内存访问效率，结构体字段会进行内存对齐，所以 state 后面会多出一个 4 字节的空洞。</p>
<p>再来分析一下为什么一个空字符串会占 49 个字节，因为 ob_refcnt、ob_type、length、hash、wstr 都是 8 字节，加起来 40 字节。而 state 是 4 字节，但又留下了 4 字节的空洞，加起来也是 8 字节，所以总共占 40 + 8 = 48 个字节。然后还有一个 '\0'，所以还要加上一个 1，总共 49 字节。</p>
<p>而对于 &quot;miu&quot; 这个 unicode 字符串来说，占的总字节数就是 49 + 3 = 52。</p>
<pre><code class="language-Python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.getsizeof(&quot;abc&quot;)
52
</code></pre>
<p>当字符串只包含 ASCII 字符时，由 PyASCIIObject 结构体表示，大小等于 <font color="blue">49 + 字符串长度</font>。当然啦，我们也可以认为大小等于 <font color="blue">48 + (字符串长度 + 1)</font>，这样理解起来更直观一些。</p>
<h2 id="pycompactunicodeobject"><a class="header" href="#pycompactunicodeobject">PyCompactUnicodeObject</a></h2>
<p>如果字符串包含了非 ASCII 字符，那么由 PyCompactUnicodeObject 结构体表示，假设字符串中码点最大的字符的码点为 maxchar。</p>
<pre><code class="language-python">if maxchar &lt; 128:
    struct = PyASCIIObject
    kind = PyUnicode_1BYTE_KIND  # 1
    ascii = 1
elif maxchar &lt; 256:
    struct = PyCompactUnicodeObject
    kind = PyUnicode_1BYTE_KIND  # 1
    ascii = 0
elif maxchar &lt; 65536:
    struct = PyCompactUnicodeObject
    kind = PyUnicode_2BYTE_KIND  # 2
    ascii = 0
else:
    struct = PyCompactUnicodeObject
    kind = PyUnicode_4BYTE_KIND  # 4
    ascii = 0
</code></pre>
<p>看一下 PyCompactUnicodeObject 的底层结构。</p>
<pre><code class="language-C">// Include/cpython/unicodeobject.h
typedef struct {
    PyASCIIObject _base;
    // 字符串的 utf-8 编码长度
    Py_ssize_t utf8_length;
    // 字符串使用 utf-8 编码的结果，这里是缓存起来从而避免重复的编码运算
    char *utf8;
    // 宽字符的数量
    Py_ssize_t wstr_length;
} PyCompactUnicodeObject;
</code></pre>
<p>PyCompactUnicodeObject 相当于在 PyASCIIObject 的基础上增加了 3 个字段，那么它实例的大小是多少呢？由于新增的三个字段，每个都是 8 字节，并且字符串文本会紧跟在 PyCompactUnicodeObject 的后面，所以大小一目了然。</p>
<blockquote>
<p>PyCompactUnicodeObject 实例的大小等于 <font color="blue">48 + 24 + (字符串长度 + 1) * 每个字符的大小</font>，即 <font color="blue">72 + (字符串长度 + 1) * 每个字符的大小</font></p>
</blockquote>
<p>因此以后在看到一个字符串时，我们可以很轻松地计算出它的大小。</p>
<pre><code class="language-Python">import sys
# 只包含 ASCII 字符，那么结构体使用 PyASCIIObject
# 这样的字符串所占的内存大小为 48 + (字符串长度 + 1)
only_ascii = &quot;satori&quot;
# 所以结果是 48 + (6 + 1) = 55 字节
print(sys.getsizeof(only_ascii))
&quot;&quot;&quot;
55
&quot;&quot;&quot;

# 包含非 ASCII 字符，结构体使用 PyCompactUnicodeObject
# 但所有字符的码点均小于 256，因此编码仍使用 Py_UCS1
# 这样的字符串所占的内存大小为 72 + (字符串长度 + 1)
non_ascii_with_ucs1 = &quot;sator¡&quot;
# 所以结果是 72 + (6 + 1) = 79 字节
print(sys.getsizeof(non_ascii_with_ucs1))
&quot;&quot;&quot;
79
&quot;&quot;&quot;

# 字符的码点达到了 256，但小于 65536，因此编码使用 Py_UCS2
# 这样的字符串所占的内存大小为 72 + (字符串长度 + 1) * 2
# 注意：因为编码使用 Py_UCS2，那么 \0 也要占两个字节
non_ascii_with_ucs2 = &quot;憨pi&quot;
# 所以结果是 72 + (3 + 1) * 2 = 80
print(sys.getsizeof(non_ascii_with_ucs2))
&quot;&quot;&quot;
80
&quot;&quot;&quot;

# 字符的码点达到了 65536，因此编码使用 Py_UCS4
# 这样的字符串所占的内存大小为 72 + (字符串长度 + 1) * 4
# 因为编码使用 Py_UCS4，那么 \0 也要占 4 个字节
non_ascii_with_ucs4 = &quot;🍌君&quot;
# 所以结果是 72 + (2 + 1) * 4 = 84
print(sys.getsizeof(non_ascii_with_ucs4))
&quot;&quot;&quot;
84
&quot;&quot;&quot;
</code></pre>
<p>所以随着编码的不同，一个 Python 字符串的元数据（包含 '\0'）会占据不同的大小，假设字符串中码点最大的字符的码点为 maxchar。</p>
<ul>
<li>如果 maxchar &lt; 128，那么采用 Latin-1 编码，结构体为 PyASCIIObject，元数据的大小为 48 + 1 = 49。</li>
<li>如果 128 &lt;= maxchar &lt; 256，那么采用 Latin-1 编码，结构体为 PyCompactUnicodeObject，元数据的大小为 72 + 1 = 73。</li>
<li>如果 256 &lt;= maxchar &lt; 65536，那么采用 USC2 编码，结构体为 PyCompactUnicodeObject，元数据的大小为 72 + 2 = 74。</li>
<li>如果 maxchar &gt;= 65536，那么采用 USC4 编码，结构体为 PyCompactUnicodeObject，元数据的大小为 72 + 4 = 76。</li>
</ul>
<p>所以我们之前说根据编码的不同，字符串的额外部分可能占据 49、74、76字节，这个结论其实不够准确，还漏掉了一个 73。因为 <font color="blue">128 &lt;= maxchar &lt; 256</font> 的字符串虽然不是 ASCII 字符串，但它仍然使用 Latin-1 编码，所以 '\0' 占的是 1 字节，而不是 2 字节和 4 字节。</p>
<p>下面通过画图来描述一下这几个字符串的底层结构，由于 ASCII 字符串已经说过了，这里就不再赘述了。</p>
<p><font color="darkblue"><strong>non_ascii_with_ucs1 = &quot;sator¡&quot;</strong></font></p>
<p>注意结尾的是字符 ¡，不是 i。</p>
<p><img src="./images/91.png" alt="" /></p>
<p>每个字符占一字节，所以大小是 72 + 7= 79 字节，然后 kind 为 PyUnicode_1BYTE_KIND。</p>
<pre><code class="language-python">import sys

print(sys.getsizeof(&quot;sator¡&quot;))  # 79
</code></pre>
<p>只有所有的字符的码点都小于 128，才叫 ASCII 字符串。而 ¡ 的码点是 161，所以 &quot;sator¡&quot; 不是 ASCII 字符串，但它的每个字符仍然只需一个字节存储。</p>
<p><font color="darkblue"><strong>non_ascii_with_ucs2 = &quot;憨pi&quot;</strong></font></p>
<p><img src="./images/92.png" alt="" /></p>
<p>每个字符占两字节，所以大小是 72 + 4 * 2 = 80 字节，然后 kind 为 PyUnicode_2BYTE_KIND。</p>
<pre><code class="language-python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; print(sys.getsizeof(&quot;憨pi&quot;))
80
</code></pre>
<p><font color="darkblue"><strong>non_ascii_with_ucs4 = &quot;🍌君&quot;</strong></font></p>
<p><img src="./images/93.png" alt="" /></p>
<p>每个字符占四字节，所以大小是 72 + 3 * 4 = 84 字节，然后 kind 为 PyUnicode_4BYTE_KIND。</p>
<pre><code class="language-python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; print(sys.getsizeof(&quot;🍌君&quot;))
84
</code></pre>
<p>以上我们就讨论了不同编码的字符串的底层结构，以及内存计算方式。</p>
<h2 id="字符串的内存申请"><a class="header" href="#字符串的内存申请">字符串的内存申请</a></h2>
<p>我们再来看一下解释器是怎么为字符串申请内存的，这个过程会调用 PyUnicode_New 函数。</p>
<p>该函数接收一个 size 参数和 maxchar 参数，负责申请容纳 size 个字符的 unicode 对象。而 maxchar 表示所有字符的码点中最大的那一个，对象的每个字符占多大空间，则基于 maxchar 进行判断。</p>
<pre><code class="language-C">// Objects/unicodeobject.c

PyObject *
PyUnicode_New(Py_ssize_t size, Py_UCS4 maxchar)
{   
    // 声明相关变量
    PyObject *obj;
    PyCompactUnicodeObject *unicode;
    void *data;
    enum PyUnicode_Kind kind;
    int is_sharing, is_ascii;
    Py_ssize_t char_size;
    Py_ssize_t struct_size;

    // 如果 size 为 0，返回空字符串，注：空字符串是单例的
    if (size == 0 &amp;&amp; unicode_empty != NULL) {
        Py_INCREF(unicode_empty);
        return unicode_empty;
    }

    is_ascii = 0;
    is_sharing = 0;
    struct_size = sizeof(PyCompactUnicodeObject);
    // 如果 maxchar 小于 128，说明全部是 ASCII 字符
    // 此时结构体使用 PyASCIIObject 
    if (maxchar &lt; 128) {
        kind = PyUnicode_1BYTE_KIND;  // kind 为 1
        char_size = 1;  // 字符大小为 1
        is_ascii = 1;  // 是 ASCII 字符串
        struct_size = sizeof(PyASCIIObject);   // 结构体大小
    }
    // 否则说明字符串包含非 ASCII 字符，那么 is_ascii 为 0
    // 此时结构体一律使用 PyCompactUnicodeObject
    else if (maxchar &lt; 256) {
        // 如果 maxchar 小于 256，那么 kind 依旧为 1，字符大小为 1
        kind = PyUnicode_1BYTE_KIND;
        char_size = 1;
    }
    else if (maxchar &lt; 65536) {
        // 如果 maxchar 小于 65536，那么 kind 为 2，字符大小为 2
        kind = PyUnicode_2BYTE_KIND;
        char_size = 2;
        if (sizeof(wchar_t) == 2)
            is_sharing = 1;
    }
    else {
        // 否则说明要采用 4 字节存储，此时 kind 为 4，字符大小为 4
        // 注意：maxchar 也是有范围的，不能超过 0x10ffff
        // 不过目前也没有哪个字符的码点能超过这个值
        if (maxchar &gt; MAX_UNICODE) {
            PyErr_SetString(PyExc_SystemError,
                            &quot;invalid maximum character passed to PyUnicode_New&quot;);
            return NULL;
        }
        kind = PyUnicode_4BYTE_KIND;
        char_size = 4;
        if (sizeof(wchar_t) == 4)
            is_sharing = 1;
    }

    // size 不能小于 0
    if (size &lt; 0) {
        PyErr_SetString(PyExc_SystemError,
                        &quot;Negative size passed to PyUnicode_New&quot;);
        return NULL;
    }
    // (size + 1) * char_size + struct_size 不能超过 PY_SSIZE_T_MAX
    if (size &gt; ((PY_SSIZE_T_MAX - struct_size) / char_size - 1))
        return PyErr_NoMemory();

    // 为 Unicode 对象申请内存，如果返回 NULL 则说明申请失败
    // 申请的内存不仅包含结构体本身，还有 size + 1 个字符，每个字符大小为 char_size
    // 从这里就体现出 &quot;紧凑&quot; 的含义了，因为结构体和字符串文本是结合的
    obj = (PyObject *) PyObject_MALLOC(struct_size + (size + 1) * char_size);
    if (obj == NULL)
        return PyErr_NoMemory();
    // 初始化引用计数和类型
    obj = PyObject_INIT(obj, &amp;PyUnicode_Type);
    if (obj == NULL)
        return NULL;
    // 将 obj 转成 PyCompactUnicodeObject *
    unicode = (PyCompactUnicodeObject *)obj;
    // 注：存储字符串文本的内存（可以理解为一个数组）紧跟在结构体后面
    // 而下面的变量 data 会指向数组的首元素
    // 那么问题来了，这是怎么做到的呢？我们解释一下，顺便回顾一下 C 的指针
    // 假设有一个 int * 类型的指针 a，即 a 指向一个 int
    // 而 C 指针是可以运算的，a + 1 会指向下一个 int
    // 当然更准确的说，a + 1 会向后偏移 sizeof(int) 个字节
    // 同理，如果 a 的类型是 ssize_t *，那么 a + 1 会向后偏移 sizeof(ssize_t) 个字节
    if (is_ascii)
        // 此时我们就知道这里的代码是做什么的了，如果 is_ascii 等于 1
        // 说明结构体是 PyASCIIObject，将泛型指针 obj 转成 PyASCIIObject *
        // 加 1 之后会向后偏移 sizeof(PyASCIIObject) 个字节
        // 正好指向跟在 PyASCIIObject 结构体实例尾部的首个字符
        data = ((PyASCIIObject*)obj) + 1;
    else
        // 否则说明结构体是 PyCompactUnicodeObject
        // 那么 unicode + 1 之后会向后偏移 sizeof(PyCompactUnicodeObject) 个字节
        // 同样指向跟在 PyCompactUnicodeObject 结构体实例尾部的首个字符
        data = unicode + 1;
    
    // 将 length 字段设置为 size
    _PyUnicode_LENGTH(unicode) = size;
    // 将 hash 字段初始化为 -1
    _PyUnicode_HASH(unicode) = -1;
    // 将 state.interned 字段设置为 0
    _PyUnicode_STATE(unicode).interned = 0;
    // 将 state.kind 字段设置为 kind
    _PyUnicode_STATE(unicode).kind = kind;
    // 将 state.compact 字段设置为 1
    _PyUnicode_STATE(unicode).compact = 1;
    // 将 state.ready 字段设置为 1
    _PyUnicode_STATE(unicode).ready = 1;
    // 将 state.ascii 字段设置为 is_ascii
    _PyUnicode_STATE(unicode).ascii = is_ascii;
    
    // 如果 is_ascii 等于 1，即字符串为 ASCII 字符串
    // 将字符数组索引为 size 的元素设置为 '\0'
    if (is_ascii) {
        ((char*)data)[size] = 0;
        _PyUnicode_WSTR(unicode) = NULL;
    }
    // 否则说明结构体是 PyCompactUnicodeObject，还要多初始化两个字段
    // 将 utf8 设置为 NULL，将 utf8_length 设置为 0
    else if (kind == PyUnicode_1BYTE_KIND) {
        ((char*)data)[size] = 0;
        _PyUnicode_WSTR(unicode) = NULL;
        _PyUnicode_WSTR_LENGTH(unicode) = 0;
        unicode-&gt;utf8 = NULL;
        unicode-&gt;utf8_length = 0;
    }
    // 结构体是 PyCompactUnicodeObject，并且 kind 不等于 PyUnicode_1BYTE_KIND
    else {
        unicode-&gt;utf8 = NULL;
        unicode-&gt;utf8_length = 0;
        // 如果 kind 等于 PyUnicode_2BYTE_KIND，说明每个字符要占 2 字节
        // 将 data 转成 Py_UCS2 *，此时会用两个字节存储 '\0'
        if (kind == PyUnicode_2BYTE_KIND)
            ((Py_UCS2*)data)[size] = 0;
        // 否则说明 kind 等于 PyUnicode_4BYTE_KIND，每个字符要占 4 字节
        // 将 data 转成 Py_UCS4 *，此时会用四个字节存储 '\0'
        else
            ((Py_UCS4*)data)[size] = 0;
        if (is_sharing) {
            _PyUnicode_WSTR_LENGTH(unicode) = size;
            _PyUnicode_WSTR(unicode) = (wchar_t *)data;
        }
        else {
            _PyUnicode_WSTR_LENGTH(unicode) = 0;
            _PyUnicode_WSTR(unicode) = NULL;
        }
    }
#ifdef Py_DEBUG
    unicode_fill_invalid((PyObject*)unicode, 0);
#endif
    assert(_PyUnicode_CheckConsistency((PyObject*)unicode, 0));
    // 最后返回泛型指针 PyObject *
    return obj;
}
</code></pre>
<p>通过字符串的内存申请，我们应该对底层结构有了更深刻的认识，说白了就是采用不同的编码，每个字符占用不同数量的字节。</p>
<p>另外 PyUnicode_New 主要负责申请内存，包括结构体本身以及指定数量的字符，至于具体的字符是什么则不得而知。因此 PyUnicode_New 一般会被其它 API 调用，当调用 PyUnicode_New 申请完内存之后，再对字符数组初始化。</p>
<h2 id="小结-25"><a class="header" href="#小结-25">小结</a></h2>
<p>以上就是字符串的底层结构，虽然字符串作为最基础的数据结构被大量使用，但它的底层实现却并不简单。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>上一篇文章我们介绍了字符串的底层结构，看到里面有一个 state 字段，该字段也是一个结构体，内部定义了很多的标志位。</p>
<p><img src="./images/94.png" alt="" /></p>
<p>如果字符串的 interned 标志位大于 0，那么虚拟机将为其开启 intern 机制。那什么是 intern 机制呢？在 Python 中，某些字符串也可以像小整数对象池里的整数一样，共享给所有变量使用，从而通过避免重复创建来降低内存使用、减少性能开销，这便是 intern 机制。</p>
<p>Python 的做法是在虚拟机内部维护一个全局字典，所有开启 intern 机制的字符串均会保存在这里，后续如果需要使用的话，会尝试在全局字典中获取，从而实现避免重复创建的功能。</p>
<p>另外 intern 机制也分为多种。</p>
<pre><code class="language-C">// Include/cpython/unicode.h
#define SSTATE_NOT_INTERNED 0
#define SSTATE_INTERNED_MORTAL 1
#define SSTATE_INTERNED_IMMORTAL 2
</code></pre>
<p>解释一下这几个字段：</p>
<ul>
<li>SSTATE_NOT_INTERNED：字符串未开启 intern 机制；</li>
<li>SSTATE_INTERNED_MORTAL：字符串开启了 intern 机制，但它不是永久驻留的，在某些情况下可能会被回收；</li>
<li>SSTATE_INTERNED_IMMORTAL：字符串开启了 intern 机制，会永远存活于内存中；</li>
</ul>
<p>这些字段定义了字符串在内存管理中的不同驻留状态，从未驻留、短暂驻留到永久驻留，帮助优化字符串的内存使用和管理。</p>
<p>而当一个字符串要开启 intern 机制时，会调用 PyUnicode_InternInPlace 函数，看一下它的逻辑。</p>
<pre><code class="language-c">// Objects/unicodeobject.c

void
PyUnicode_InternInPlace(PyObject **p)
{
    PyObject *s = *p;
    PyObject *t;
    // 类型检查，因为 intern 共享机制只能用在字符串对象上
    // PyUnicode_Check(s) -&gt; isinstance(s, str)
    // PyUnicode_CheckExact(s) -&gt; type(s) is str
    if (s == NULL || !PyUnicode_Check(s))
        return;
    if (!PyUnicode_CheckExact(s))
        return;
    // 执行到这儿，说明 s 一定指向字符串，那么检测它是否已经开启了 intern 机制
    // 这个函数的逻辑很简单，内部会获取 state.interned，看它是否大于 0
    // 如果已经被 intern 机制处理了，那么直接返回
    if (PyUnicode_CHECK_INTERNED(s))
        return;
    // 所有开启 intern 机制的字符串，都会保存在 interned 字典中
    // 如果 interned 字典为空，那么创建
    if (interned == NULL) {
        interned = PyDict_New();
        if (interned == NULL) {
            PyErr_Clear(); /* Don't leave an exception */
            return;
        }
    }
    // 将字符串同时作为 key 和 value 保存在 interned 字典中，即开启 intern 机制
    // PyDict_SetDefault 对应字典的 setdefault 方法
    t = PyDict_SetDefault(interned, s, s);
    if (t == NULL) {
        PyErr_Clear();
        return;
    }
    // 注意这里有一个让人混淆的地方，首先 t 和 s 都是 C 指针
    // 如果 t != s，说明它们指向了不同的字符串，如果 t == s，说明它们指向的是同一个字符串
    // 由于 s 同时作为 key 和 value，那么不管 s 指向的字符串是否在字典中已存在
    // PyObject_RichCompare(t, s, Py_EQ) 永远为真，也就是 t 和 s 指向的字符串的值是相等的
    // 只是当 t != s 时，说明它们指向的不是同一个字符串，但值相等
    // 这也意味着字典中已经存在某个 key，它指向的字符串维护了相同的文本数据
    // 那么增加 t 指向的字符串的引用计数，减少 s 指向的字符串的引用计数
    if (t != s) {
        Py_INCREF(t);
        Py_SETREF(*p, t);
        return;
    }
    // 否则说明 t == s，即 s 在字典中不存在，那么开启 interned 机制
    Py_REFCNT(s) -= 2;
    _PyUnicode_STATE(s).interned = SSTATE_INTERNED_MORTAL;
}
</code></pre>
<p>估计很多人都以为 Python 在创建字符串时，会先检测该字符串是否已经存在，如果有，就不用创建新的，这样可以节省空间。但其实不是这样的，事实上节省内存空间是没错的，可 Python 并不是在创建字符串的时候就通过 intern 机制实现了节省空间的目的。</p>
<p>对于任何一个字符串，Python 总是会为它申请内存，尽管创建出来的字符串在 interned 字典中已经存在了（有另外的字符串对象维护了相同的文本）。而这正是关键所在，通常 Python 在运行时创建了一个字符串对象（假设叫 temp）之后，基本上都会调用 PyUnicode_InternInPlace 对 temp 进行处理。</p>
<p>如果维护的值已经存在于 interned 字典中，那么 temp 指向的对象的引用计数就会减 1，然后会因引用计数为 0 而被销毁，只是昙花一现，然后归于湮灭。</p>
<blockquote>
<p>所以现在我们就明白了 intern 机制，并不是说先判断是否存在，如果存在，就不创建。而是先创建，然后发现已经有其它的字符串维护了一个与之相同的文本数据，于是 intern 机制再将引用计数减一，导致引用计数为 0，最终被回收。</p>
</blockquote>
<p>然后关于字符串对象的 intern 机制，还有一点需要注意。实际上，被 intern 机制处理过后的字符串分为两类，一类处于 SSTATE_INTERNED_IMMORTAL 状态，另一类处于 SSTATE_INTERNED_MORTAL 状态，这两种状态的区别在 unicode_dealloc 中可以清晰的看到。SSTATE_INTERNED_IMMORTAL 状态的字符串是永远不会被销毁的，它与解释器共存亡。</p>
<p>而 PyUnicode_InternInPlace 只能创建 SSTATE_INTERNED_MORTAL 的字符串对象，如果想创建 SSTATE_INTERNED_IMMORTAL 对象，必须通过另外的接口来强制改变 intern 状态。</p>
<pre><code class="language-C">void
PyUnicode_InternImmortal(PyObject **p)
{
    PyUnicode_InternInPlace(p);
    if (PyUnicode_CHECK_INTERNED(*p) != SSTATE_INTERNED_IMMORTAL) {
        _PyUnicode_STATE(*p).interned = SSTATE_INTERNED_IMMORTAL;
        Py_INCREF(*p);
    }
}
</code></pre>
<p>但是问题来了，什么样的字符串才会开启 intern 机制呢？</p>
<p><font color="blue"><strong>1）如果字符串为 ASCII 字符串，并且长度不超过 4096，那么会开启 intern 机制。</strong></font></p>
<pre><code class="language-python">&gt;&gt;&gt; s1 = &quot;a&quot; * 4096
&gt;&gt;&gt; s2 = &quot;a&quot; * 4096
# 会开启 intern 机制，s1 和 s2 指向同一个字符串
&gt;&gt;&gt; s1 is s2
True

# 长度超过了 4096，所以不会开启 intern 机制
&gt;&gt;&gt; s1 = &quot;a&quot; * 4097
&gt;&gt;&gt; s2 = &quot;a&quot; * 4097
&gt;&gt;&gt; s1 is s2
False
</code></pre>
<p><font color="blue"><strong>2）如果一个字符串只有一个字符，并且码点小于 256（一个字节可以表示），那么也会开启 intern 机制。</strong></font></p>
<pre><code class="language-python">&gt;&gt;&gt; hex(128)
'0x80'
# s1 和 s2 指向同一个字符串，因为开启了 intern 机制
&gt;&gt;&gt; s1 = chr(128)
&gt;&gt;&gt; s2 = &quot;\x80&quot;
&gt;&gt;&gt; s1 is s2
True

# ASCII 字符指的是码点小于 128 的字符，显然 s1 和 s2 不是 ASCII 字符串
# 虽然码点小于 256，但长度不等于 1，所以不会开启 intern 机制
&gt;&gt;&gt; s1 = chr(128) + &quot;x&quot;
&gt;&gt;&gt; s2 = chr(128) + &quot;x&quot;
&gt;&gt;&gt; s1 is s2
False
</code></pre>
<p>实际上，存储单个字符这种方式有点类似于 bytes 对象的缓存池。是的，正如整数有小整数对象池、bytes 对象有字符缓存池一样，字符串也有其对应的缓存池。</p>
<p>总之 intern 机制并不是大家想的那样：先检测字符串是否已经存在，如果有，就不用创建新的，从而节省内存。但其实不是这样的，节省内存空间是没错的，可 Python 并不是在创建字符串的时候就通过 intern 机制实现了节省空间的目的。对于任何一个字符串，解释器总是会为它创建对应的结构体实例，但如果发现创建出来的实例在 intern 字典中已经存在了，那么再将它销毁。</p>
<p>最后关于 intern 机制，在 Python 里面可以通过 sys.intern 函数强制开启。</p>
<pre><code class="language-Python">&gt;&gt;&gt; s1 = &quot;憨pi-_-||&quot;
&gt;&gt;&gt; s2 = &quot;憨pi-_-||&quot;
&gt;&gt;&gt; s1 is s2
False
&gt;&gt;&gt; 
&gt;&gt;&gt; s1 = sys.intern(&quot;憨pi-_-||&quot;)
&gt;&gt;&gt; s2 = sys.intern(&quot;憨pi-_-||&quot;)
&gt;&gt;&gt; s1 is s2
True
</code></pre>
<p>以上就是字符串的 intern 机制，下一篇文章来介绍字符串的相关操作是怎么实现的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-24"><a class="header" href="#楔子-24">楔子</a></h2>
<p>本文来说一说字符串的操作，字符串支持哪些操作，取决于类型对象 str，所以我们来看看 str 在底层的定义。</p>
<pre><code class="language-c">// Objects/unicodeobject.c
PyTypeObject PyUnicode_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;str&quot;,                        /* tp_name */
    sizeof(PyUnicodeObject),      /* tp_basicsize */
    0,                            /* tp_itemsize */
    /* Slots */
    (destructor)unicode_dealloc,  /* tp_dealloc */
    0,                            /* tp_vectorcall_offset */
    0,                            /* tp_getattr */
    0,                            /* tp_setattr */
    0,                            /* tp_as_async */
    unicode_repr,                 /* tp_repr */
    &amp;unicode_as_number,           /* tp_as_number */
    &amp;unicode_as_sequence,         /* tp_as_sequence */
    &amp;unicode_as_mapping,          /* tp_as_mapping */
    // ...
}        
</code></pre>
<p>bytes 对象和 str 对象的很多行为都是相似的，str 对象可以 encode 成 bytes 对象，bytes 对象可以 decode 成 str 对象。</p>
<p>看一下三个操作簇，字符串都支持，但根据 bytes 对象的经验，我们猜测 tp_as_number 里面实现的函数只有取模，也就是格式化。</p>
<pre><code class="language-c">// Objects/unicodeobject.c

// 不出所料，只实现了一个取模
static PyNumberMethods unicode_as_number = {
    0,              /*nb_add*/
    0,              /*nb_subtract*/
    0,              /*nb_multiply*/
    unicode_mod,    /*nb_remainder*/
};

// 我们看到和 bytes 对象是几乎一样的
// 因为 str 对象和 bytes 都是不可变的变长对象，并且可以相互转化
// 因此它们的行为是高度相似的
static PySequenceMethods unicode_as_sequence = {
    (lenfunc) unicode_length,        /* sq_length */
    PyUnicode_Concat,                /* sq_concat */
    (ssizeargfunc) unicode_repeat,   /* sq_repeat */
    (ssizeargfunc) unicode_getitem,  /* sq_item */
    0,                               /* sq_slice */
    0,                               /* sq_ass_item */
    0,                               /* sq_ass_slice */
    PyUnicode_Contains,              /* sq_contains */
};

//也和 bytes 对象一样
static PyMappingMethods unicode_as_mapping = {
    (lenfunc)unicode_length,        /* mp_length */
    (binaryfunc)unicode_subscript,  /* mp_subscript */
    (objobjargproc)0,           /* mp_ass_subscript */
};
</code></pre>
<p>下面我们就通过源码来考察一下。</p>
<h2 id="获取字符串的长度"><a class="header" href="#获取字符串的长度">获取字符串的长度</a></h2>
<p>获取字符串的长度会执行 unicode_length 函数。</p>
<pre><code class="language-C">// Objects/unicodeobject.c
static Py_ssize_t
unicode_length(PyObject *self)
{
    if (PyUnicode_READY(self) == -1)
        return -1;
    return PyUnicode_GET_LENGTH(self);
}

// Include/cpython/unicodeobject.h
#define PyUnicode_GET_LENGTH(op)                \
    (assert(PyUnicode_Check(op)),               \
     assert(PyUnicode_IS_READY(op)),            \
     ((PyASCIIObject *)(op))-&gt;length)
</code></pre>
<p>比较简单，没什么可说的，length 字段维护的是字符串的长度。</p>
<h2 id="字符串的相加"><a class="header" href="#字符串的相加">字符串的相加</a></h2>
<p>字符串相加会执行 PyUnicode_Concat 函数，将两个字符串组合成一个新的字符串。</p>
<pre><code class="language-C">// Objects/unicodeobject.c
PyObject *
PyUnicode_Concat(PyObject *left, PyObject *right)
{   
    // 参数 left 和 right 指向两个要相加的字符串
    // result 则指向相加之后的字符串
    PyObject *result;
    // 还记得这个 Py_UCS4 吗，它是一个无符号 32 位整型
    Py_UCS4 maxchar, maxchar2;
    // left 的长度、right 的长度、相加之后的长度
    Py_ssize_t left_len, right_len, new_len;
    // 必须是两个字符串相加
    if (ensure_unicode(left) &lt; 0)
        return NULL;

    if (!PyUnicode_Check(right)) {
        PyErr_Format(PyExc_TypeError,
                     &quot;can only concatenate str (not \&quot;%.200s\&quot;) to str&quot;,
                     right-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
    if (PyUnicode_READY(right) &lt; 0)
        return NULL;

    // 如果 left 指向空字符串，直接返回 right
    if (left == unicode_empty)
        return PyUnicode_FromObject(right);
    // 如果 right 指向空字符串，直接返回 left
    if (right == unicode_empty)
        return PyUnicode_FromObject(left);
    // 获取两个字符串的长度
    left_len = PyUnicode_GET_LENGTH(left);
    right_len = PyUnicode_GET_LENGTH(right);
    // 如果相加的之后的长度超过了 PY_SSIZE_T_MAX，那么报错
    if (left_len &gt; PY_SSIZE_T_MAX - right_len) {
        PyErr_SetString(PyExc_OverflowError,
                        &quot;strings are too large to concat&quot;);
        return NULL;
    }
    // 计算相加之后的字符串的长度
    new_len = left_len + right_len;
    // 解释一下 PyUnicode_MAX_CHAR_VALUE，它的逻辑很简单
    /* 如果是 ASCII 字符串，返回 0x7f
     * 如果 kind 等于 PyUnicode_1BYTE_KIND，返回 0xff
     * 如果 kind 等于 PyUnicode_2BYTE_KIND，返回 0xffff
     * 如果 kind 等于 PyUnicode_1BYTE_KIND，返回 0x10ffff */
    // 所以该函数计算的就是字符串使用的编码所能表示的最大范围
    maxchar = PyUnicode_MAX_CHAR_VALUE(left);
    maxchar2 = PyUnicode_MAX_CHAR_VALUE(right);
    // 显然要取 maxchar 和 maxchar2 之间两者较大的那一个
    maxchar = Py_MAX(maxchar, maxchar2);

    // PyUnicode_New 我们之前介绍过，它负责为字符串申请内存
    // new_len 表示要容纳多少个字符
    // maxchar 表示字符的最大码点，内部会基于 maxchar 选择一个合适的编码
    result = PyUnicode_New(new_len, maxchar);
    if (result == NULL)
        return NULL;
    // _PyUnicode_FastCopyCharacters 负责字符串之间的拷贝，它的原型如下：
    /* void
       _PyUnicode_FastCopyCharacters(PyObject *to, 
                                     Py_ssize_t to_start,
                                     PyObject *from, 
                                     Py_ssize_t from_start, 
                                     Py_ssize_t how_many)
       如果用 Python 代码举例的话，那么该函数所做的事情就等价于如下：
       for i in range(how_many):
           to[to_start + i] = from[from_start + i] */
    // 相当于 result[0: left_len] = left[0: left_len]
    _PyUnicode_FastCopyCharacters(result, 0, left, 0, left_len);
    // 相当于 result[left_len: left_len + right_len] = right[0: right_len]
    _PyUnicode_FastCopyCharacters(result, left_len, right, 0, right_len);
    assert(_PyUnicode_CheckConsistency(result, 1));
    return result;
}
</code></pre>
<p>可以看到逻辑还是很清晰的，不过和 bytes 对象不同，字符串没有实现缓冲区。但是在操作上，和 bytes 对象是类似的，如果有大量的字符串相加，那么效率会非常低下，官方建议是通过 join 的方式。</p>
<h2 id="字符串的自定义方法"><a class="header" href="#字符串的自定义方法">字符串的自定义方法</a></h2>
<p>序列型对象除了拥有 tp_as_sequence 里面的方法之外，还可以有很多自定义方法，比如字符串可以转大小写，列表可以追加元素等等。下面来聊一聊字符串的自定义方法，在介绍类型对象的时候说过，实例对象的自定义方法都会放在类型对象的 tp_methods 字段里面。</p>
<p><img src="./images/95.png" alt="" /></p>
<p>tp_methods 字段的类型是 PyMethodDef 结构体数组，一个 PyMethodDef 结构体实例对应一个可调用方法。那么 PyMethodDef 长什么样子呢？</p>
<pre><code class="language-C">// Include/methodobject.h
struct PyMethodDef {
    // 暴露给 Python 的方法名
    const char  *ml_name;   
    // 包含具体实现的 C 函数
    PyCFunction ml_meth;   
    // 函数的参数类型
    // 比如函数接收多少参数，是否支持关键字参数，
    // 是不是静态方法、类方法等等，这些都需要通过 ml_flags 指定
    int         ml_flags;   
    // 函数的 docstring
    const char  *ml_doc;    
};
</code></pre>
<p>字符串的自定义方法非常多，我们先从 Python 的角度罗列一下，然后再挑几个看一下源码实现。</p>
<pre><code class="language-python"># 字符串转小写
print(&quot;ABC&quot;.lower())  # abc

# 字符串转大写
print(&quot;abc&quot;.upper())  # ABC

# 每个单词首字母大写，其它字母小写
print(&quot;my GRIL&quot;.title())  # My Gril

# 第一个单词首字母大写，其它字母小写
print(&quot;MY GIRL&quot;.capitalize())  # My girl

# 从字符两端开始去除指定的字符，比如位于 &quot;001&quot; 的字符会被去除
print(&quot;001古明地觉 1 号001&quot;.strip(&quot;001&quot;))  # 古明地觉 1 号
# 也可以只从一端去除
print(&quot;001古明地觉 1 号001&quot;.lstrip(&quot;001&quot;))  # 古明地觉 1 号001
print(&quot;001古明地觉 1 号001&quot;.rstrip(&quot;001&quot;))  # 001古明地觉 1 号

# 查找指定的子串，返回子串第一次出现的位置
print(&quot;abcabcabc&quot;.index(&quot;bca&quot;))  # 1
# 查找时也支持指定范围，比如从索引为 2 的位置开始查找
print(&quot;abcabcabc&quot;.index(&quot;bca&quot;, 2))  # 4

# index 方法如果在没有找到指定的子串时，会抛出 ValueError:
# 如果不希望报错，那么可以使用 find，当字符串不存在时会返回 -1
print(&quot;hello&quot;.find(&quot;ll&quot;))  # 2
print(&quot;hello&quot;.find(&quot;lll&quot;))  # -1
# find 也支持指定查找范围，并且是从左往右查找
# 如果使用 rfind，则可以实现从右往左查找，同理还有 rindex
print(&quot;abc abc&quot;.find(&quot;abc&quot;))  # 0
print(&quot;abc abc&quot;.rfind(&quot;abc&quot;))  # 4

# 统计指定子串的数量
print(&quot;abc abc abc&quot;.count(&quot;abc&quot;))  # 3

# 是否以某个字符串开头
print(&quot;Hello&quot;.startswith(&quot;Hel&quot;))  # True
print(&quot;Hello&quot;.startswith(&quot;hel&quot;))  # False

# 是否以某个字符串结尾
print(&quot;world&quot;.endswith(&quot;rld&quot;))  # True
print(&quot;world&quot;.endswith(&quot;rlD&quot;))  # False

# 按照指定字符串进行分割，并支持传入 maxsplit 参数指定最大分割次数
print(&quot;a-b-c-d-e&quot;.split(&quot;-&quot;))  # ['a', 'b', 'c', 'd', 'e']
print(&quot;a-b-c-d-e&quot;.split(&quot;-&quot;, 2))  # ['a', 'b', 'c-d-e']
# 如果不传递参数，那么会默认按照空白符（包含空格、Tab、换行等等）分隔
print(&quot;a  \n b \tc&quot;.split())  # ['a', 'b', 'c']
# 还可以从右向左分割，当然在不指定 maxsplit 参数时，效果和 split 一样
print(&quot;a-b-c-d-e&quot;.rsplit(&quot;-&quot;))  # ['a', 'b', 'c', 'd', 'e']
print(&quot;a-b-c-d-e&quot;.rsplit(&quot;-&quot;, 2))  # ['a-b-c', 'd', 'e']

# 等价于 .split(&quot;\n&quot;)
print(&quot;a b\nc&quot;.splitlines())  # ['a b', 'c']

# 按照指定子串进行分割，返回一个三元组：(子串之前的部分, 子串, 子串之后的部分)
print(&quot;abcxxdef&quot;.partition(&quot;xx&quot;))  # ('abc', 'xx', 'def')
# 当子串不存在时，会返回 (字符串本身, &quot;&quot;， &quot;&quot;)
print(&quot;abc&quot;.partition(&quot;xx&quot;))  # ('abc', '', '')

# 大小写交换
print(&quot;Hello World&quot;.swapcase())  # hELLO wORLD

# 对指定子串进行替换
print(&quot;abc abc abc&quot;.replace(&quot;abc&quot;, &quot;ABC&quot;))  # ABC ABC ABC
# 也可以指定最大替换次数
print(&quot;abc abc abc&quot;.replace(&quot;abc&quot;, &quot;ABC&quot;, 2))  # ABC ABC abc

# 和 replace 作用相似，也是用来替换字符串指定部分
# 将 a 替换成 abc，将 x 替换成 xyz
trans = str.maketrans({&quot;a&quot;: &quot;abc&quot;, &quot;x&quot;: &quot;xyz&quot;})
print(&quot;aaxx&quot;.translate(trans))  # abcabcxyzxyz
# 如果给 str.maketrans 只传一个参数，那么要传字典，并且 key 必须是单字符
# 如果给 str.maketrans 传递两个参数，那么两个参数必须是等长的字符串
trans = str.maketrans(&quot;abc&quot;, &quot;ABC&quot;)
# a -&gt; A，b -&gt; B，c -&gt; C
print(&quot;abccc&quot;.translate(trans))  # ABCCC
# 如果传三个参数，那么第三个参数也要是字符串
# 此时在替换的时候，还会去除掉位于 &quot;def&quot; 中的字符
trans = str.maketrans(&quot;abc&quot;, &quot;ABC&quot;, &quot;def&quot;)
print(&quot;abcdefabc&quot;.translate(trans))  # ABCABC
</code></pre>
<p>这些都属于基础内容了，我们挑几个看一下源码实现。</p>
<h2 id="字符串的-join"><a class="header" href="#字符串的-join">字符串的 join</a></h2>
<p>字符串在相加时会创建一个新的字符串，所以如果有大量的字符串相加，那么效率会很低下。面对这种情况，官方的建议是通过 join 方法。</p>
<p>字符串的 join 方法在底层对应 PyUnicode_Join 函数。</p>
<pre><code class="language-C">// Objects/unicodeobject.c
PyObject *
PyUnicode_Join(PyObject *separator, PyObject *seq)
{
    PyObject *res;  // 拼接结果
    PyObject *fseq;  // 拼接的字符串的数量
    Py_ssize_t seqlen;  // 总长度
    PyObject **items;  // PyObject * 数组首元素的地址
    
    // 遍历参数 seq，将里面的每个字符串拿出来放在列表中
    // 如果 seq 本身就是列表或元组，那么直接返回 seq
    fseq = PySequence_Fast(seq, &quot;can only join an iterable&quot;);
    if (fseq == NULL) {
        return NULL;
    }

    // 列表或元组对应的结构体内部都有一个 ob_item 字段
    // 该字段是一个 PyObject * 类型的数组，负责保存具体的元素
    // 该函数会拿到 ob_item 数组，并赋值给 items
    items = PySequence_Fast_ITEMS(fseq);
    // 获取要拼接的字符串的数量
    seqlen = PySequence_Fast_GET_SIZE(fseq);
    // 调用 _PyUnicode_JoinArray 进行拼接
    res = _PyUnicode_JoinArray(separator, items, seqlen);
    Py_DECREF(fseq);
    return res;
}
</code></pre>
<p>核心在 _PyUnicode_JoinArray 函数里面，该函数的逻辑很长，但很简单。就是获取要拼接的每一个字符串的长度，然后加在一起，并取最大的存储单元，然后一次性申请对应的内存空间，再逐一进行拷贝。所以拷贝是避免不了的，<font color="blue">+</font> 这种方式导致低效率的主要原因就在于大量临时字符串的创建和销毁。</p>
<h2 id="字符串的-encode"><a class="header" href="#字符串的-encode">字符串的 encode</a></h2>
<p>在 Python 里面可以调用字符串的 encode 方法，得到 bytes 对象。那么它在底层是如何实现的呢？</p>
<pre><code class="language-c">// Objects/unicodeobject.c
PyObject *
PyUnicode_AsEncodedString(PyObject *unicode,
                          const char *encoding,
                          const char *errors)
{
    PyObject *v;
    char buflower[11];
    
    // unicode 参数要指向一个字符串
    if (!PyUnicode_Check(unicode)) {
        PyErr_BadArgument();
        return NULL;
    }
    // 如果不指定编码，那么使用 UTF-8
    if (encoding == NULL) {
        return _PyUnicode_AsUTF8String(unicode, errors);
    }

    // 如果指定了编码，那么进行判断
    if (_Py_normalize_encoding(encoding, buflower, sizeof(buflower))) {
        char *lower = buflower;

        /* Fast paths */
        // 快分支，判断是否是 UTF-* 系列
        if (lower[0] == 'u' &amp;&amp; lower[1] == 't' &amp;&amp; lower[2] == 'f') {
            lower += 3;
            if (*lower == '_') {
                /* Match &quot;utf8&quot; and &quot;utf_8&quot; */
                lower++;
            }
            // 如果是 UTF-8
            if (lower[0] == '8' &amp;&amp; lower[1] == 0) {
                return _PyUnicode_AsUTF8String(unicode, errors);
            }
            // 如果是 UTF-16
            else if (lower[0] == '1' &amp;&amp; lower[1] == '6' &amp;&amp; lower[2] == 0) {
                return _PyUnicode_EncodeUTF16(unicode, errors, 0);
            }
            // 如果是 UTF-32
            else if (lower[0] == '3' &amp;&amp; lower[1] == '2' &amp;&amp; lower[2] == 0) {
                return _PyUnicode_EncodeUTF32(unicode, errors, 0);
            }
        }
        // 否则判断是否是 ascii、latin1、iso8859-1 等编码
        else {
            if (strcmp(lower, &quot;ascii&quot;) == 0
                || strcmp(lower, &quot;us_ascii&quot;) == 0) {
                return _PyUnicode_AsASCIIString(unicode, errors);
            }
#ifdef MS_WINDOWS
            else if (strcmp(lower, &quot;mbcs&quot;) == 0) {
                return PyUnicode_EncodeCodePage(CP_ACP, unicode, errors);
            }
#endif
            else if (strcmp(lower, &quot;latin1&quot;) == 0 ||
                     strcmp(lower, &quot;latin_1&quot;) == 0 ||
                     strcmp(lower, &quot;iso_8859_1&quot;) == 0 ||
                     strcmp(lower, &quot;iso8859_1&quot;) == 0) {
                return _PyUnicode_AsLatin1String(unicode, errors);
            }
        }
    }

    // 如果以上编码都不是，那么执行通用逻辑 _PyCodec_EncodeText
    v = _PyCodec_EncodeText(unicode, encoding, errors);
    if (v == NULL)
        return NULL;

    /* The normal path */
    if (PyBytes_Check(v))
        return v;

    /* If the codec returns a buffer, raise a warning and convert to bytes */
    if (PyByteArray_Check(v)) {
        int error;
        PyObject *b;

        error = PyErr_WarnFormat(PyExc_RuntimeWarning, 1,
            &quot;encoder %s returned bytearray instead of bytes; &quot;
            &quot;use codecs.encode() to encode to arbitrary types&quot;,
            encoding);
        if (error) {
            Py_DECREF(v);
            return NULL;
        }

        b = PyBytes_FromStringAndSize(PyByteArray_AS_STRING(v),
                                      PyByteArray_GET_SIZE(v));
        Py_DECREF(v);
        return b;
    }

    PyErr_Format(PyExc_TypeError,
                 &quot;'%.400s' encoder returned '%.400s' instead of 'bytes'; &quot;
                 &quot;use codecs.encode() to encode to arbitrary types&quot;,
                 encoding,
                 Py_TYPE(v)-&gt;tp_name);
    Py_DECREF(v);
    return NULL;
}
</code></pre>
<p>由于现在的主流编码是 utf-8，所以绝大部分情况都会执行 _PyUnicode_AsUTF8String 函数，我们看一下它的逻辑。</p>
<pre><code class="language-c">// Objects/unicodeobject.c
PyObject *
_PyUnicode_AsUTF8String(PyObject *unicode, const char *errors)
{
    return unicode_encode_utf8(unicode, _Py_ERROR_UNKNOWN, errors);
}

static PyObject *
unicode_encode_utf8(PyObject *unicode, _Py_error_handler error_handler,
                    const char *errors)
{
    enum PyUnicode_Kind kind;
    void *data;
    Py_ssize_t size;

    if (!PyUnicode_Check(unicode)) {
        PyErr_BadArgument();
        return NULL;
    }

    if (PyUnicode_READY(unicode) == -1)
        return NULL;
    // 如果是 ASCII 字符串，那么直接获取每个字符的码点，创建 bytes 对象
    if (PyUnicode_UTF8(unicode))
        return PyBytes_FromStringAndSize(PyUnicode_UTF8(unicode),
                                         PyUnicode_UTF8_LENGTH(unicode));
    // 获取字符串的 kind
    kind = PyUnicode_KIND(unicode);
    // 获取首字符的地址，首字符紧跟在结构体后面
    data = PyUnicode_DATA(unicode);
    // 获取字符串的长度
    size = PyUnicode_GET_LENGTH(unicode);
    
    // 判断 kind 种类
    switch (kind) {
    default:
        Py_UNREACHABLE();
    case PyUnicode_1BYTE_KIND:
       // 基于不同 kind 调用不同的函数
        assert(!PyUnicode_IS_ASCII(unicode));
        return ucs1lib_utf8_encoder(unicode, data, size, error_handler, errors);
    case PyUnicode_2BYTE_KIND:
        return ucs2lib_utf8_encoder(unicode, data, size, error_handler, errors);
    case PyUnicode_4BYTE_KIND:
        return ucs4lib_utf8_encoder(unicode, data, size, error_handler, errors);
    }
}
</code></pre>
<p>整个过程还是我们之前说的，通过 utf-8 编码将每个字符转成对应的编号，组合起来得到的就是 bytes 对象。</p>
<h2 id="小结-26"><a class="header" href="#小结-26">小结</a></h2>
<p>到目前为止，我们就说完了字符串相关的内容。必须要强调的是，字符串没有想象中的那么简单，而在 CPython 里面，字符串的源码将近两万行。</p>
<p>如果你还对字符串的其它操作感兴趣，想看看它的具体实现，可以自己深入源码探索一番。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-25"><a class="header" href="#楔子-25">楔子</a></h2>
<p>本篇文章来分析一下列表，在初学列表的时候，可能书上会告诉你列表就是一个大仓库，什么都可以存放。但在最开始的几个章节中，我们花了很大的笔墨介绍了 Python 的对象，并明白了变量的本质。所以到现在列表已经没有什么好神秘的了，它里面存放的元素其实都是泛型指针 PyObject *。</p>
<p>并且根据我们使用列表的经验，可以得出以下两个结论：</p>
<ul>
<li>每个列表的元素个数可以不一样，所以它是一个变长对象</li>
<li>可以对列表进行添加、删除、修改等操作，所以它是一个可变对象</li>
</ul>
<h2 id="列表的底层结构"><a class="header" href="#列表的底层结构">列表的底层结构</a></h2>
<p>列表在底层由 PyListObject 结构体表示，看一下它长什么样子。</p>
<pre><code class="language-C">// Include/listobject.h
typedef struct {
    PyObject_VAR_HEAD
    /* Vector of pointers to list elements.  list[0] is ob_item[0], etc. */
    PyObject **ob_item;

    /* ob_item contains space for 'allocated' elements.  The number
     * currently in use is ob_size.
     * Invariants:
     *     0 &lt;= ob_size &lt;= allocated
     *     len(list) == ob_size
     *     ob_item == NULL implies ob_size == allocated == 0
     * list.sort() temporarily sets allocated to -1 to detect mutations.
     *
     * Items must normally not be NULL, except during construction when
     * the list is not yet visible outside the function that builds it.
     */
    Py_ssize_t allocated;
} PyListObject;
</code></pre>
<p>我们看到里面有如下字段：</p>
<ul>
<li>PyObject_VAR_HEAD：变长对象的公共头部信息；</li>
<li>ob_item：一个二级指针，指向 PyObject * 数组的首元素，这个指针数组保存的便是对象的指针，而操作数组都是通过 ob_item 来进行操作的；</li>
<li>allocated：容量，我们知道列表底层使用了 C 的数组，而底层数组的长度就是列表的容量；</li>
</ul>
<p>列表之所以要有容量的概念，是因为列表可以动态添加元素，但底层的数组在创建完毕之后，其长度却是固定的。所以当添加新元素时，发现数组已经满了，这个时候只能申请一个更长的数组，同时把原来数组中的元素依次拷贝到新数组里面（这一过程就是列表的扩容），然后再将新元素添加进去。</p>
<p>但是问题来了，总不可能每添加一个元素，就申请一次数组、将所有元素都拷贝一次吧。所以列表在扩容的时候，会将数组申请的长一些，从而在添加元素的时候不用每次都申请新的数组。</p>
<p><img src="./images/96.png" alt="" /></p>
<p>这便是列表的结构示意图，我们看到底层数组的长度为 4，说明此时列表的容量为 4。但是里面有 3 个 PyObject * 指针，说明列表的 ob_size 是 3，或者说列表里面有 3 个元素。</p>
<p>如果这个时候我们往列表中 append 一个元素，那么会将这个新元素设置在数组索引为 ob_size 的位置、或者说第四个位置。一旦设置完，ob_size 会自动加 1，因为 ob_size 要和列表的长度保持一致。</p>
<p><img src="./images/97.png" alt="" /></p>
<p>列表的容量是 4，但此时长度也达到了 4，所以列表的长度、或者说元素个数已经达到了容量。这说明当下一次 append 的时候，已经没有办法再容纳新的元素了。当然最直观的还是这里的底层数组，很明显全都占满了。那这个时候如果想再接收新的元素的话，要怎么办呢？显然只能扩容了。</p>
<p><img src="./images/98.png" alt="" /></p>
<p>原来的容量是 4，长度也是 4，当再来一个新元素的时候由于没有位置了，所以要扩容。但扩容的时候肯定会将容量申请的大一些、即底层数组申请的长一些，具体申请多长，Python 内部有一个公式，我们后面会说。总之申请的新的底层数组长度是 8，那么说明列表的容量就变成了 8。</p>
<p>新数组申请之后，将原来旧数组中的 PyObject * 按照顺序依次拷贝过去，再让 ob_item 指向新数组。然后把要添加的元素设置在新数组中索引为 ob_size 的位置、即第 5 个位置，并将 ob_size 加 1。最后将旧数组释放掉。</p>
<p>以上便是列表底层在扩容的时候所经历的过程。</p>
<blockquote>
<p>由于扩容会申请新数组，然后将旧数组的元素拷贝到新数组中，所以这是一个时间复杂度为 O(n) 的操作。而 append 可能会导致列表扩容，因此 append 最坏情况下也是一个 O(n) 的操作，只不过扩容不会频繁发生，所以 append 方法的平均时间复杂度还是 O(1)。</p>
</blockquote>
<p>另外我们还可以看到一个现象，那就是列表在底层是分开存储的，因为 PyListObject 结构体实例并没有存储相应的指针数组，而是存储了指向这个指针数组首元素的二级指针。显然我们添加、删除、修改元素等操作，都是通过 ob_item 二级指针来间接操作指针数组。</p>
<p>至于这么做的原因，我们在介绍 Python 对象的时候就说过了，不记得了的话，可以回去翻一翻。</p>
<p>所以底层对应的 PyListObject 实例的大小其实是不变的，因为指针数组没有存在 PyListObject 里面。但 Python 在计算内存大小的时候是会将这个指针数组也算进去的，所以列表的大小是可变的。</p>
<p>而且我们知道，列表在 append 之后地址是不变的，至于原因上面的几张图已经解释得很清楚了。</p>
<p>如果长度没有达到容量，那么 append 其实就是往底层数组中设置了一个新元素。如果达到容量了，那么会扩容，但扩容只是申请一个新的指针数组，然后让 ob_item 重新指向罢了。所以底层的指针数组会变，但是 PyListObject 结构体实例本身是没有变化的，因此列表在执行 append、extend、pop、insert 等操作时，地址不会发生变化。</p>
<p>下面再来看看列表所占的内存大小是怎么算的，首先 PyListObject 里面的 PyObject_VAR_HEAD 占 24 字节，ob_item 占 8 字节，allocated 占 8 字节，总共 40 字节。但是不要忘记，在计算列表大小的时候，ob_item 指向的指针数组也要算在内。所以：<font color="blue">列表的大小 = 40 + 8 * 指针数组长度（或者说列表容量）</font>。注意是指针数组长度，可不是列表长度，因为数组一旦申请了，不管你用没用，大小就摆在那里了。就好比你租了间房子，就算不住，房租该交还是得交。</p>
<pre><code class="language-Python"># 显然一个空数组占 40 个字节
print([].__sizeof__())  # 40

# 40 + 3 * 8 = 64
print([1, 2, &quot;x&quot; * 1000].__sizeof__())  # 64
# 虽然里面有一个长度为 1000 的字符串
# 但我们说列表存放的都是指针，所以大小都是 8 字节

# 注意：我们通过 lst = [1, 2, 3] 这种方式创建列表的话
# 不管内部元素有多少个, 其 ob_size 和 allocated 都是一样的
# 只有当列表在添加元素的时候发现容量不够了才会扩容
lst = list(range(10))
# 40 + 10 * 8 = 120
print(lst.__sizeof__())  # 120

# 长度为 4，此时容量也是 4
lst = [&quot;巭&quot;, &quot;孬&quot;, &quot;嫑&quot;, &quot;睡觉&quot;]
# 大小为 40 + 4 * 8 = 72
print(lst.__sizeof__())  # 72
# 添加一个元素
lst.append(&quot;觉得睡啊&quot;)
# 大小变成了 40 + 8 * 8 = 104
# 说明当发生扩容时，底层数据可以容纳 8 个元素
print(lst.__sizeof__())  # 104
</code></pre>
<p>关于列表的长度和容量的关系，以及扩容的规则，我们后续再聊。总之目前我们知道列表的大小是怎么计算的，以及为什么列表在通过索引定位元素的时候，时间复杂度是 O(1)。因为列表存储的都是对象的指针，不管对象有多大，其指针大小是固定的，都是 8 字节，通过索引可以瞬间计算出偏移量。</p>
<pre><code class="language-Python">print([1, 2, 3].__sizeof__())  # 64
print([[1, 2, 3]].__sizeof__())  # 48
</code></pre>
<p>相信上面这个结果，你肯定能分析出原因。因为第一个列表中有 3 个指针，所以大小是 <font color="blue">40 + 24 = 64</font>。而第二个列表中有一个指针，所以是 <font color="blue">40 + 8 = 48</font>。用一张图来展示一下 <font color="blue">[1, 2, 3]</font> 和 <font color="blue">[[1, 2, 3]]</font> 的底层结构，看看它们之间的区别：</p>
<p><img src="./images/99.png" alt="" /></p>
<p>到此相信你已经彻底掌握列表的结构了，那么下一篇文章我们来介绍一下列表的长度和容量之间的关系，以及扩容是怎么实现的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>本篇文章来说一说列表的扩容，我们知道列表在添加元素时，如果发现底层的指针数组已经满了，那么会进行扩容，申请一个更大的数组。</p>
<p>下面就来看看底层是怎么实现的，相关操作都位于 Objects/listobject.c 中。</p>
<pre><code class="language-C">static int
list_resize(PyListObject *self, Py_ssize_t newsize)
{   
    // 参数 self 就是列表，newsize 指的是元素在添加之后的 ob_size
    // 比如列表的 ob_size 和容量都是 4，append 的时候发现容量不够
    // 所以会扩容，那么这里的 newsize 就是 5
    // 如果是 extend 添加 3 个元素，那么这里的 newsize 就是 7
    // 当然 list_resize 这个函数不仅可以扩容，也可以缩容
    // 假设列表原来有 1000 个元素，这个时候将列表清空了，那么容量肯定缩小，不然会浪费内存
    // 如果清空了列表，那么这里的 newsize 显然就是 0

    // 二级指针，指向指针数组的首元素
    PyObject **items;
    // 新的容量，以及新的指针数组的内存大小
    size_t new_allocated, num_allocated_bytes;
    // 获取原来的容量
    Py_ssize_t allocated = self-&gt;allocated;

    // 如果 newsize 达到了容量的一半，但还没有超过容量
    // 那么意味着 newsize、或者新的 ob_size 和容量是匹配的
    // 所以容量不会变化，直接将列表的 ob_size 设置为 newsize 即可
    if (allocated &gt;= newsize &amp;&amp; newsize &gt;= (allocated &gt;&gt; 1)) {
        assert(self-&gt;ob_item != NULL || newsize == 0);
        Py_SIZE(self) = newsize;
        return 0;
    }

    // 走到这里说明容量和 newsize 不匹配了，所以要进行扩容或者缩容
    // 因此要申请新的底层数组，那么长度是多少呢？
    // 这里给出了公式，一会儿我们可以通过 Python 进行测试
    new_allocated = (size_t)newsize + (newsize &gt;&gt; 3) + (newsize &lt; 9 ? 3 : 6);
    // 容量也是有范围的，乘上 8 字节不能超过 PY_SSIZE_T_MAX
    if (new_allocated &gt; (size_t)PY_SSIZE_T_MAX / sizeof(PyObject *)) {
        PyErr_NoMemory();
        return -1;
    }
    // 如果 newsize 为 0，那么容量也为 0
    if (newsize == 0)
        new_allocated = 0;
    // 分配内存
    num_allocated_bytes = new_allocated * sizeof(PyObject *);
    items = (PyObject **)PyMem_Realloc(self-&gt;ob_item, num_allocated_bytes);
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }
    // 将 ob_items 字段设置为 items
    self-&gt;ob_item = items;
    // 将 ob_size 字段设置为 newsize
    Py_SIZE(self) = newsize;
    // 将 allocated 字段设置为 new_allocated
    self-&gt;allocated = new_allocated;
    return 0;
}
</code></pre>
<p>我们看到还是很简单的，没有什么黑科技。然后是列表扩容的时候，容量和元素个数之间的规律。其实在 list_resize 函数中是有注释的，其中有这么一行。</p>
<p><img src="./images/100.png" alt="" /></p>
<p>说明我们往一个空列表中不断 append 元素的时候，容量会按照上面的规律进行变化，我们来试一下。</p>
<pre><code class="language-python">lst = []
allocated = 0
print(&quot;此时容量是: 0&quot;)

for item in range(100):
    lst.append(item)  # 添加元素
    # 计算 ob_size
    ob_size = len(lst)
    # 判断 ob_size 和当前的容量
    if ob_size &gt; allocated:
        # 列表的大小减去空列表的大小，再除以 8 显然就是容量
        allocated = (lst.__sizeof__() - [].__sizeof__()) // 8
        print(f&quot;列表扩容啦, 新的容量是: {allocated}&quot;)
&quot;&quot;&quot;
此时容量是: 0
列表扩容啦, 新的容量是: 4
列表扩容啦, 新的容量是: 8
列表扩容啦, 新的容量是: 16
列表扩容啦, 新的容量是: 25
列表扩容啦, 新的容量是: 35
列表扩容啦, 新的容量是: 46
列表扩容啦, 新的容量是: 58
列表扩容啦, 新的容量是: 72
列表扩容啦, 新的容量是: 88
列表扩容啦, 新的容量是: 106
&quot;&quot;&quot;        
</code></pre>
<p>我们看到和官方给的结果是一样的，显然这是毫无疑问的，根据底层的公式也能算出来。</p>
<pre><code class="language-Python">ob_size = 0
allocated = 0

print(allocated, end=&quot; &quot;)
for item in range(100):
    newsize = ob_size + 1
    if newsize &gt; allocated:
        allocated = (newsize + (newsize &gt;&gt; 3) + 6) &amp; ~3
        print(allocated, end=&quot; &quot;)
    ob_size = newsize
&quot;&quot;&quot;
0 4 8 16 24 32 40 52 64 76 92 108 
&quot;&quot;&quot;
</code></pre>
<p>注：扩容是在添加元素的时候发现容量不够发生的，也就是底层数组存储的实际元素的个数（列表长度）等于数组长度，没办法再容纳新的元素了，所以要扩容。</p>
<p>如果我们直接通过 lst = [] 这种形式创建列表的话，那么其长度和容量是一样的。</p>
<pre><code class="language-python">lst = [0] * 1000
# 长度和容量一致
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 1000 1000

# 但再添加一个元素的话, 那么 ob_size 会变成 1001，大于容量 1000
# 所以此时列表就要扩容了, 执行 list_resize，里面的 new_size 就是 1001
# 然后是怎么分配容量来着，new_allocated = (size_t)newsize + (newsize &gt;&gt; 3) + (newsize &lt; 9 ? 3 : 6)
print(
    &quot;新容量:&quot;, 1001 + (1001 &gt;&gt; 3) + (3 if 1001 &lt; 9 else 6)
)  # 新容量: 1132

# append 一个元素，列表扩容
lst.append(123)
# 计算容量
print((lst.__sizeof__() - [].__sizeof__()) // 8)  # 1132
</code></pre>
<p>结果是一样的，因为底层就是这么实现的，所以结果必须一样。只不过我们通过这种测试的方式证明了这一点，也加深了对列表的认识。</p>
<p>需要注意的是，会影响列表元素个数的操作（append、extend、insert、pop 等等），在执行前都会先执行一下 list_resize 进行容量检测。如果计算之后的 newsize 和 allocated 之间的关系是匹配的，即 <font color="blue">allocated//2 &lt;= newsize &lt;= allocated</font>，那么只需要将 ob_size 的大小更新为 newsize 即可。如果不匹配，那么还要进行扩容，此时是一个 O(n) 的操作。</p>
<p>介绍完扩容，再来介绍缩容，因为列表元素个数要是减少到和容量不匹配的话，也要进行缩容。</p>
<p>举个生活中的例子，假设你租了 10 间屋子用于办公，显然你要付 10 间屋子的房租，不管你有没有用，一旦租了肯定是要付钱的。同理底层数组也是一样，只要你申请了，不管有没有元素，内存已经占用了。但有一天你用不到 10 间屋子了，假设要用 8 间或者 9 间，那么会让剩余的屋子闲下来。但由于退租比较麻烦，并且只闲下来一两间屋子，所以干脆就不退了，还是会付 10 间屋子的钱，这样没准哪天又要用的时候就不用重新租了。</p>
<p>对于列表也是如此，在删除元素（相当于屋子不用了）的时候，如果发现长度还没有低于容量的一半，那么也不会缩容。但反之就要缩容了，比如屋子闲了 8 间，也就是只需要两间屋子就足够了，那么此时肯定要退租了，闲了 8 间，可能会退掉 6 间。</p>
<pre><code class="language-Python">lst = [0] * 1000
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 1000 1000

# 删除 500 个元素, 此时长度或者说 ob_size 就为 500
lst[500:] = []
# 但 ob_size 还是达到了容量的一半, 所以不会缩容
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 500 1000

# 如果再删除一个元素的话, 那么不好意思, 显然就要进行缩容了
# 因为 ob_size 变成了 499, 小于 1000 // 2
# 缩容之后容量怎么算呢? 还是之前那个公式
print(499 + (499 &gt;&gt; 3) + (3 if 499 &lt; 9 else 6))  # 567

# 测试一下, 删除一个元素, 看看会不会按照我们期待的规则进行缩容
lst.pop()
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 499 567
</code></pre>
<p>一切都和我们想的是一样的，另外在代码中我们还看到一个 if 语句，就是如果 newsize 是 0，那么容量也是 0，来测试一下。</p>
<pre><code class="language-Python">lst = [0] * 1000
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 1000 1000

lst[:] = []
print(
    len(lst), (lst.__sizeof__() - [].__sizeof__()) // 8
)  # 0 0

# 如果按照之前的容量变化公式的话, 会发现结果应该是 3
# 但实际结果是 0, 就是因为多了 if 判断
# 如果 newsize 是 0, 就把容量也设置为 0
print(0 + (0 &gt;&gt; 3) + (3 if 0 &lt; 9 else 6))  # 3
</code></pre>
<p>为什么要这么做呢？因为 Python 认为，列表长度为 0 的话，说明你不想用这个列表了，所以多余的 3 个也没有必要申请了。</p>
<p>还以租房为栗，如果你一间屋子都不用了，说明你可能不用这里的屋子办公了，因此直接全部退掉。</p>
<p><strong>以上就是列表在改变容量时所采用的策略，我们从头到尾全部分析了一遍。下一篇文章来看一下列表的创建，以及缓存池。</strong></p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-26"><a class="header" href="#楔子-26">楔子</a></h2>
<p>前面我们分析了列表的底层结构和扩容机制，本篇文章来聊一聊列表的创建和销毁，以及缓存池。</p>
<h2 id="列表的创建"><a class="header" href="#列表的创建">列表的创建</a></h2>
<p>创建列表，解释器只提供了唯一的一个 Python/C API，也就是 PyList_New。这个函数接收一个 size 参数，允许我们在创建 PyListObject 对象时指定底层的 PyObject * 数组的长度。</p>
<pre><code class="language-C">//Objects/listobject.c
PyObject *
PyList_New(Py_ssize_t size)
{
    // 声明一个 PyListObject * 变量
    // 指向即将创建的 PyListObject 对象
    PyListObject *op;
    // 底层数组的长度必须大于等于 0
    if (size &lt; 0) {
        PyErr_BadInternalCall();
        return NULL;
    }
    // numfree 表示缓存池中已缓存的元素个数
    // 如果大于 0，证明有可用元素，那么会从缓存池中获取
    if (numfree) {
        // 可用元素的数量减一
        numfree--;
        // 获取缓存的列表指针，并将指向的列表的引用计数设置为 1
        op = free_list[numfree];
        _Py_NewReference((PyObject *)op);
    } else {
        // 如果缓存池中没有可用元素，那么通过 PyObject_GC_New 申请内存
        // 问题来了，之前申请内存不是用的 PyObject_New 吗
        // 这里为啥换成 PyObject_GC_New 呢？我们稍后再说
        op = PyObject_GC_New(PyListObject, &amp;PyList_Type);
        if (op == NULL)
            return NULL;
    }
    // 如果 size &lt;= 0，那么一定等于 0，此时列表不包含任何元素
    if (size &lt;= 0)
        // 那么 ob_item 直接设置为 NULL
        op-&gt;ob_item = NULL;
    else {
        // 否则为底层数组申请内存，因为存储的都是指针
        // 所以大小为 size * sizeof(PyObject *)
        op-&gt;ob_item = (PyObject **) PyMem_Calloc(size, sizeof(PyObject *));
        if (op-&gt;ob_item == NULL) {
            Py_DECREF(op);
            return PyErr_NoMemory();
        }
    }
    // 将 ob_size 和 allocated 均设置为 size
    Py_SIZE(op) = size;
    op-&gt;allocated = size;
    // 让列表被 GC 跟踪
    _PyObject_GC_TRACK(op);
    // 转成泛型指针之后返回
    return (PyObject *) op;
}
</code></pre>
<p>整个过程非常好理解，就是先创建一个 PyListObject 对象，然后再为底层数组申请内存，最后通过 ob_item 字段将两者关联起来。当然这个过程中会使用缓存池，关于缓存池一会儿再聊。</p>
<p>然后还要说一下内存申请函数，在这之前我们看到申请内存用的是 PyObject_New 函数，它和这里的 PyObject_GC_New 有什么区别呢？由于涉及到 Python 的内存管理，我们暂时先不聊那么深，大家先有个基本了解即可，等到介绍内存管理和垃圾回收的时候会详细剖析。</p>
<p>我们知道 Python 对象在底层都是一个结构体，并且结构体内部嵌套了 PyObject。但对于那些能够产生循环引用的可变对象来说，它们除了 PyObject 之外，还包含了一个 PyGC_Head，用于垃圾回收。</p>
<p>所以 PyObject_New 和 PyObject_GC_New 接收的参数是一样的，但后者会多申请 16 字节的内存，这 16 字节是为 PyGC_Head 准备的。那么问题来了，PyGC_Head 在什么地方呢？</p>
<p><img src="./images/101.png" alt="" /></p>
<p>PyGC_Head 就在 PyObject 的前面，但是注意：虽然为 PyGC_Head 申请了内存，但返回的是 PyObject 的地址。至于这里面的更多细节，后续在剖析内存管理和垃圾回收的时候细说，目前先简单了解一下即可。</p>
<p>然后再说一下计算内存的两种方式：</p>
<pre><code class="language-Python">import sys

lst = []
# 可以调用 __sizeof__ 方法计算对象的内存
print(lst.__sizeof__())  # 40
# 也可以通过 sys.getsizeof 函数
print(sys.getsizeof(lst))  # 56
</code></pre>
<p>我们看到 sys.getsizeof 算出的结果会多出 16 字节，相信你能猜到原因，因为它将 PyGC_Head 也算进去了，而对象的 __sizeof__ 方法则不会算在内。</p>
<p>不过对于字符串、整数、浮点数这种不会产生循环引用的对象来说，由于没有 PyGC_Head，所以两种方式计算的结果是一样的。</p>
<pre><code class="language-Python">import sys

print(&quot;&quot;.__sizeof__())  # 49
print(sys.getsizeof(&quot;&quot;))  # 49

print((123).__sizeof__())  # 28
print(sys.getsizeof(123))  # 28
</code></pre>
<p>以上就是列表的创建，整个过程不难理解。</p>
<h2 id="列表的销毁"><a class="header" href="#列表的销毁">列表的销毁</a></h2>
<p>创建 PyListObject 对象时，会先检测缓存池 free_list 里面是否有可用的对象，有的话直接拿来用，否则通过 malloc 在系统堆上申请。列表的缓存池是使用数组实现的，里面最多维护 80 个 PyListObject 对象。</p>
<pre><code class="language-C">// Objects/listobject.c
#ifndef PyList_MAXFREELIST
#define PyList_MAXFREELIST 80
#endif
// free_list 是一个 PyListObject * 数组，容量为 80
// 添加元素时会从数组的尾部添加，获取元素时也会从数组的尾部获取
static PyListObject *free_list[PyList_MAXFREELIST];
// 缓存池中可用元素数量
static int numfree = 0;
</code></pre>
<p>根据之前的经验我们知道，既然创建的时候能从缓存池中获取，那么在执行析构函数的时候也要把列表放到缓存池里面。看一下列表的析构函数，它由 PyList_Type 的 tp_dealloc 字段负责，而该字段被设置为 list_dealloc。</p>
<pre><code class="language-C">// Objects/listobject.c
static void
list_dealloc(PyListObject *op)
{
    Py_ssize_t i;
    // 列表可能会产生循环引用，因此创建之后要被 GC 跟踪
    // 而现在要被回收了，所以也要取消 GC 跟踪
    PyObject_GC_UnTrack(op);
    // 这一步的作用，稍后再说
    Py_TRASHCAN_BEGIN(op, list_dealloc)
    // 先释放底层数组
    if (op-&gt;ob_item != NULL) {
        // 但是释放之前，还有一件重要的事情
        // 要将底层数组中每个指针指向的对象的引用计数都减去 1
        // 因为它们不再持有对&quot;对象&quot;的引用
        i = Py_SIZE(op);
        while (--i &gt;= 0) {
            Py_XDECREF(op-&gt;ob_item[i]);
        }
        // 然后释放底层数组所占的内存
        PyMem_FREE(op-&gt;ob_item);
    }
    // 如果已缓存的元素个数小于 80 个，并且 op 指向的是列表
    // 那么将 op 追加到数组中，并将 numfree 自增 1
    if (numfree &lt; PyList_MAXFREELIST &amp;&amp; PyList_CheckExact(op))
        free_list[numfree++] = op;
    else
        // 否则将列表的内存释放掉
        Py_TYPE(op)-&gt;tp_free((PyObject *)op);
    Py_TRASHCAN_END
}
</code></pre>
<p>我们知道创建一个 PyListObject 对象会分为两步，先创建 PyListObject 对象，然后创建底层数组，最后让 PyListObject 对象的 ob_item 字段指向底层数组的首元素。同理，在销毁一个 PyListObject 对象时，会先释放 ob_item 维护的底层数组，然后在缓存池已满的情况下再释放 PyListObject 对象自身。</p>
<p>现在我们算是明白了缓存池的机制，本来在销毁列表时，要将它的内存释放。但因为缓存池机制，解释器并没有这么做，而是将它的指针放在了缓存池里，至于列表对象则依旧驻留在堆上，只是我们已经无法再访问了。</p>
<p>当以后创建新的 PyListObject 对象时，解释器会首先唤醒这些已经死去的 PyListObject 对象，给它们一个洗心革面、重新做人的机会。但需要注意的是，这里缓存的仅仅是 PyListObject 对象，至于底层数组，其 ob_item 已经不再指向了。</p>
<p>从 list_dealloc 中我们可以看到，PyListObject 对象的指针在放进缓存池之前，ob_item 指向的数组就已经被释放掉了，同时数组中指针指向的对象的引用计数会减 1。所以最终数组中这些指针指向的对象也大难临头各自飞了，或生存、或毁灭，总之此时和 PyListObject 之间已经没有任何联系了。</p>
<p>但是为什么要这么做呢？为什么不连底层数组也一起维护呢？可以想一下，如果继续维护的话，数组中指针指向的对象永远不会被释放，那么很可能会产生悬空指针的问题。</p>
<p>但实际上是可以将底层数组进行保留的，做法是只将数组中指针指向的对象的引用计数减 1，然后将数组中的指针都设置为 NULL，不再指向之前的对象，但并不释放底层数组本身所占用的内存空间。这样一来释放的内存不会交给系统堆，那么再次分配的时候，速度会快很多。但这样会带来两个问题。</p>
<ul>
<li>1）这些内存没人用也会一直占着，并且只能供 PyListObject 对象的 ob_item 指向的底层数组使用。</li>
<li>2）基于缓存池获取的列表的容量，和新创建的列表的容量不一定匹配。比如底层数组长度为 6 的 PyListObject * 被放入了缓存池，那么表示列表最多容纳 6 个元素，但如果我们要创建一个长度为 8 的列表怎么办？此时依旧要重新为底层数组申请内存。</li>
</ul>
<p>因此基于以上两个原因，Python 选择将底层数组所占的内存交还给了系统堆，当然也节省了内存。</p>
<pre><code class="language-Python">lst1 = [1, 2, 3]
print(id(lst1))  # 139672412671360
# 扔到缓存池中，放在数组的尾部
del lst1

# 从缓存池中获取，也会从数组的尾部开始拿
lst2 = [1, 2, 3]
print(id(lst2))  # 139672412671360

# 因此打印的地址是一样的
</code></pre>
<p>以上就是列表的创建和销毁，以及它的缓存池原理。</p>
<h2 id="trashcan-机制"><a class="header" href="#trashcan-机制">trashcan 机制</a></h2>
<p>在看列表的销毁过程时，我们注意到里面有这么一行代码。</p>
<pre><code class="language-C">Py_TRASHCAN_BEGIN(op, list_dealloc)
</code></pre>
<p>这是做什么的呢，首先在 Python 中，我们可以创建具有深度递归的对象，比如：</p>
<pre><code class="language-python">L = None

for i in range(2 ** 20):
    L = [L]

del L
</code></pre>
<p>此时的 L 就是一个嵌套了 2 ** 20 层的列表，当我们删除 L 的时候，会先销毁 L[0]、然后销毁 L[0][0]，以此类推，直到递归深度为 2 ** 20。而这样的深度毫无疑问会溢出 C 的调用栈，导致解释器崩溃。但事实上我们在 <font color="blue">del L</font> 的时候解释器并没有崩溃，原因就是 CPython 发明了一种名为 trashcan 的机制，它通过延迟销毁的方式来限制销毁的递归深度。关于这一特性，我们知道就好了，不用太关注。</p>
<p>下一篇文章来聊一聊列表的操作在底层是怎么实现的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-27"><a class="header" href="#楔子-27">楔子</a></h2>
<p>列表拥有非常多的方法，比如添加元素、查询元素等，这些都属于列表的自定义方法。当然不光是列表，任何对象都可以有自己的自定义方法，而这些方法会保存在类型对象的 tp_methods 里面。</p>
<p>当然列表除了拥有自定义的方法之外，还拥有作为序列型对象所共有的方法，比如合并、基于索引和切片获取元素、基于索引和切片设置元素等等。这些方法会基于种类被抽象成三个方法簇，分别是：</p>
<ul>
<li>tp_as_number：数值型对象拥有的方法；</li>
<li>tp_as_sequence：序列型对象拥有的方法；</li>
<li>tp_as_mapping：映射型对象拥有的方法；</li>
</ul>
<p>每个方法簇都包含了大量的 C 函数，每个 C 函数一般会对应 Python 里的一个魔法方法和操作符。比如 tp_as_sequence 的 sq_concat 对应序列型对象的 __add__ 方法，tp_as_number 的 nb_subtract 对应数值型对象的 __sub__ 方法。</p>
<p>那么接下来我们就详细剖析一下这些方法的具体实现过程。</p>
<h2 id="列表的相加"><a class="header" href="#列表的相加">列表的相加</a></h2>
<p>序列型对象都实现了加法运算，比如列表，两个列表相加可以合并为一个新的列表。</p>
<pre><code class="language-Python">print([1, 2, 3] + [4, 5])  
&quot;&quot;&quot;
[1, 2, 3, 4, 5]
&quot;&quot;&quot;
</code></pre>
<p>虽然使用了 + 操作符，但它在底层是由 tp_as_sequence 的 sq_concat 负责实现的，该字段被赋值为 list_concat 函数，看一下它的内部逻辑。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
list_concat(PyListObject *a, PyObject *bb)
{   
    // 两个列表相加之后的新列表的长度
    Py_ssize_t size;
    Py_ssize_t i;
    PyObject **src, **dest;
    PyListObject *np;
    // 如果 bb 不是列表，抛出 TypeError
    if (!PyList_Check(bb)) {
        PyErr_Format(PyExc_TypeError,
                  &quot;can only concatenate list (not \&quot;%.200s\&quot;) to list&quot;,
                  bb-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
#define b ((PyListObject *)bb)
    // 两个列表的长度相加一定小于 PY_SSIZE_T_MAX
    if (Py_SIZE(a) &gt; PY_SSIZE_T_MAX - Py_SIZE(b))
        return PyErr_NoMemory();
    // 新列表的长度，等于相加的两个列表的长度之和
    size = Py_SIZE(a) + Py_SIZE(b);
    // 为 PyListObject 和底层数组申请空间（空间大小为 8 * size）
    np = (PyListObject *) list_new_prealloc(size);
    if (np == NULL) {
        return NULL;
    }
    // 将第一个列表的元素增加引用计数之后，拷贝到新列表中
    src = a-&gt;ob_item;
    dest = np-&gt;ob_item;
    for (i = 0; i &lt; Py_SIZE(a); i++) {
        PyObject *v = src[i];
        Py_INCREF(v);
        dest[i] = v;
    }
    // 将第二个列表的元素增加引用计数之后，拷贝到新列表中
    src = b-&gt;ob_item;
    dest = np-&gt;ob_item + Py_SIZE(a);
    for (i = 0; i &lt; Py_SIZE(b); i++) {
        PyObject *v = src[i];
        Py_INCREF(v);
        dest[i] = v;
    }
    // 将新列表的 ob_size 设置为 size
    Py_SIZE(np) = size;
    // 转成泛型指针之后返回
    return (PyObject *)np;
#undef b
}
</code></pre>
<p>逻辑非常简单，假设两个列表 a 和 b 相加，过程如下。</p>
<ul>
<li>先申请一个新列表，长度为 len(a) + len(b)；</li>
<li>将列表 a 的元素拷贝到新列表中；</li>
<li>将列表 b 的元素拷贝到新列表中；</li>
</ul>
<p>说白了就是两个 for 循环。</p>
<h2 id="列表的重复"><a class="header" href="#列表的重复">列表的重复</a></h2>
<p>列表可以乘上一个整数，将自身重复指定次数，该过程会返回一个新列表。</p>
<pre><code class="language-python">print([1, 2, 3] * 3)
&quot;&quot;&quot;
[1, 2, 3, 1, 2, 3, 1, 2, 3]
&quot;&quot;&quot;
</code></pre>
<p>虽然使用了 * 操作符，但它在底层是由 tp_as_sequence 的 sq_repeat 负责实现的，该字段被赋值为 list_repeat 函数，看一下它的内部逻辑。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
list_repeat(PyListObject *a, Py_ssize_t n)
{
    Py_ssize_t i, j;
    Py_ssize_t size;
    PyListObject *np;
    PyObject **p, **items;
    PyObject *elem;
    // 如果 n 小于 0，那么将 n 设置为 0
    if (n &lt; 0)
        n = 0;
    // 长度有限制，不能超过 PY_SSIZE_T_MAX
    if (n &gt; 0 &amp;&amp; Py_SIZE(a) &gt; PY_SSIZE_T_MAX / n)
        return PyErr_NoMemory();
    // 新列表的长度
    size = Py_SIZE(a) * n;
    // 如果列表长度为 0，那么直接返回空列表即可
    if (size == 0)
        return PyList_New(0);
    // 为新列表和底层数组申请空间，底层数组的长度为 size
    np = (PyListObject *) list_new_prealloc(size);
    if (np == NULL)
        return NULL;
    // 如果原始列表的长度为 1，比如 a = [1]，n = 3
    // 那么新列表就是 [1, 1, 1]
    if (Py_SIZE(a) == 1) {
        // 指向新列表的底层数组的首元素
        items = np-&gt;ob_item;
        // 拿到原始列表的第一个元素
        elem = a-&gt;ob_item[0];
        // 将新列表的底层数组的元素全部设置为 elem
        for (i = 0; i &lt; n; i++) {
            items[i] = elem;
            Py_INCREF(elem);
        }
    }
    // 如果原始列表的长度不为 1
    else {
        // 指向新列表的底层数组的首元素
        p = np-&gt;ob_item;
        // 指向原始列表的底层数组的首元素
        items = a-&gt;ob_item;
        // 两层 for 循环
        // 内层循环遍历原始数组，将元素拷贝到新数组，外层循环则是循环 n 次
        for (i = 0; i &lt; n; i++) {
            for (j = 0; j &lt; Py_SIZE(a); j++) {
                *p = items[j];
                Py_INCREF(*p);
                p++;
            }
        }
    }
    // 将新列表的 ob_size 设置为 size
    Py_SIZE(np) = size;
    return (PyObject *) np;
}
</code></pre>
<p>整个过程非常朴实无华。</p>
<h2 id="基于索引和切片获取元素-1"><a class="header" href="#基于索引和切片获取元素-1">基于索引和切片获取元素</a></h2>
<p>列表可以基于索引和切片截取元素。</p>
<pre><code class="language-Python">data = [1, 2, 3, 4, 5]
print(data[1])  # 2
print(data[1: 4])  # [2, 3, 4]
</code></pre>
<p>在底层它由 tp_as_mapping 的 mp_subscript 实现，该字段被赋值为 list_subscript 函数，看一下它的内部逻辑。</p>
<pre><code class="language-C">// Objects/listobject.c

static PyObject *
list_subscript(PyListObject* self, PyObject* item)
{
    // 在基于索引和切片截取时，所有序列型对象的逻辑都差不多
    if (PyIndex_Check(item)) {
        Py_ssize_t i;
        // 如果 item 是索引，那么转成 Py_ssize_t 整数
        i = PyNumber_AsSsize_t(item, PyExc_IndexError);
        if (i == -1 &amp;&amp; PyErr_Occurred())
            return NULL;
        // 如果 i 小于 0，那么加上列表长度，转成正数索引
        if (i &lt; 0)
            i += PyList_GET_SIZE(self);
        // 调用 list_item 获取 ob_item 中索引为 i 的元素
        return list_item(self, i);
    }
    // 如果 item 是切片
    else if (PySlice_Check(item)) {
        // start, stop, step 分别表示起始位置、终止位置、步长
        // slicelength 表示切片截取的长度，也就是要截取多少个元素
        Py_ssize_t start, stop, step, slicelength, cur, i;
        PyObject* result;
        PyObject* it;
        PyObject **src, **dest;
        // 获取切片的 start、stop、step
        if (PySlice_Unpack(item, &amp;start, &amp;stop, &amp;step) &lt; 0) {
            return NULL;
        }
        // 传入原始列表的长度，对 start 和 stop 进行调整，并返回 slicelength
        slicelength = PySlice_AdjustIndices(Py_SIZE(self), &amp;start, &amp;stop,
                                            step);
        // 如果 slicelength &lt;= 0，说明截取不到任何元素
        // 比如 data[5: 1] 或者 data[1: 5: -1]，那么直接返回空列表
        if (slicelength &lt;= 0) {
            return PyList_New(0);
        }
        // 如果步长为 1，那么直接将列表中 start 到 stop 之间的元素拷过去即可
        else if (step == 1) {
            return list_slice(self, start, stop);
        }
        // 否则说明步长不为 1
        else {
            // 为创建的新列表和底层数组申请空间
            result = list_new_prealloc(slicelength);
            if (!result) return NULL;
            src = self-&gt;ob_item;
            // 从 start 处开始遍历，将元素拷贝过去
            // 然后 cur 每次增加 step，遍历次数为 slicelength
            dest = ((PyListObject *)result)-&gt;ob_item;
            for (cur = start, i = 0; i &lt; slicelength;
                 cur += (size_t)step, i++) {
                it = src[cur];
                Py_INCREF(it);
                dest[i] = it;
            }
            // 将新列表的 ob_size 设置为 slicelength
            Py_SIZE(result) = slicelength;
            return result;
        }
    }
    // 否则说明 item 既不是索引也不是切片，那么报错
    else {
        PyErr_Format(PyExc_TypeError,
                     &quot;list indices must be integers or slices, not %.200s&quot;,
                     item-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
}
</code></pre>
<p>这个和之前介绍的 bytes 对象有点像，因为它们都是序列型对象，在基于索引和切片截取元素时的逻辑也是类似的。但 bytes 对象只能截取元素，却不能设置元素，而列表是可以的，因为列表是可变对象。</p>
<h2 id="基于索引和切片设置元素"><a class="header" href="#基于索引和切片设置元素">基于索引和切片设置元素</a></h2>
<p>列表是可变对象，因为它支持设置元素，即对内部元素进行修改。基于索引设置元素就不说了，我们主要看切片，它背后还是有一些复杂的。</p>
<pre><code class="language-Python">data = [1, 2, 3, 4, 5, 6, 7, 8]

# 通过切片设置元素，右值一定是一个可迭代对象
data[0: 3] = [11, 22, 33]
# 会将 data[0] 设置为 11，将 data[1] 设置为 22，将 data[2] 设置为 33
print(data)
&quot;&quot;&quot;
[11, 22, 33, 4, 5, 6, 7, 8]
&quot;&quot;&quot;

# 而且它们的长度是可以不相等的，这里表示将 [0: 3] 的元素设置为 [1, 2]
# 即 data[0] 设置成 1，data[1] 设置成 2，那么问题来了，data[2] 咋办？
# 由于右值中已经没有元素与之匹配了，那么 data[2] 就会被删掉
data[0: 3] = [1, 2]
print(data)
&quot;&quot;&quot;
[1, 2, 4, 5, 6, 7, 8]
&quot;&quot;&quot;

# 所以如果想删除 [0: 3] 的元素，那么只需要执行 data[0: 3] = [] 即可
# 因为 [] 里面没有元素能与之匹配，所以 data 中 [0: 3] 的位置由于匹配不到
# 那么相当于执行了删除操作，当然由于 Python 的动态特性，还可以像下面这么做
# data[0: 3] = []、data[0: 3] = ()、data[0: 3] = &quot;&quot; 等等也是没问题的
data[0: 3] = &quot;&quot;
print(data)
&quot;&quot;&quot;
[5, 6, 7, 8]
&quot;&quot;&quot;
# 实际上执行 del data[0] 的时候，就是执行了 data[0: 1] = []
# 当然，如果右值元素多的话也是可以的，相当于插入
# 比如这里的 data[0] 匹配 1，然后左边就结束了
# 于是右侧剩余的元素会依次插在后面
data[0: 1] = [1, 2, 3, 4]
print(data)
&quot;&quot;&quot;
[1, 2, 3, 4, 6, 7, 8]
&quot;&quot;&quot;
# 重点来了，如果切片的步长不等于 1 的话，那么两边一定要匹配
# 由于 data[:: 2] 会得到 4 个元素，那么右边的可迭代对象的长度就必须也是 4
data[:: 2] = ['a', 'b', 'c', 'd']
print(data)
&quot;&quot;&quot;
['a', 2, 'b', 4, 'c', 7, 'd']
&quot;&quot;&quot;

# 但如果长度不一致，那么会报错
try:
    data[:: 2] = ['a', 'b', 'c']
except Exception as e:
    # 显然会报错
    print(e)  
&quot;&quot;&quot;
attempt to assign sequence of size 3 to extended slice of size 4
&quot;&quot;&quot;
</code></pre>
<p>至于它的源码有兴趣可以自己看一下，在底层它由 tp_as_mapping 的 mp_ass_subscript 负责实现，该字段被赋值为 list_ass_subscript 函数。逻辑比较长，但不难理解，我们总结一下。</p>
<p>list_subscript 用于获取元素，list_ass_subscript 用于设置元素。调用这两个函数，我们即可以传入索引，也可以传入切片。</p>
<ul>
<li>获取元素时传入的是索引，那么 list_subscript 内部会调用 list_item，传入的是切片，那么会调用 list_slice。</li>
<li>设置元素时传入的是索引，那么 list_ass_subscript 内部会调用 list_ass_item，传入的是切片，那么会调用 list_ass_slice。并且 list_ass_slice 虽然是设置元素，但删除元素也是调用的它，比如通过 <font color="blue">data[n: n+1]=[]</font> 便可删除索引为 n 的元素。事实上 remove 和 pop 方法都只是计算出待删除元素的索引，真正的删除操作还是通过 list_ass_slice 来执行的。</li>
<li>另外，当传入切片时，只有步长为 1，才会调用 list_slice 和 list_ass_slice。如果步长不为 1，那么就采用循环的方式逐个遍历。</li>
</ul>
<h2 id="小结-27"><a class="header" href="#小结-27">小结</a></h2>
<p>以上我们就介绍了列表作为序列型对象拥有的方法，但除了这些它还有很多自定义的方法。由于列表用得非常广泛，关于它的方法我们都来详细地说上一说，下一篇文章介绍列表的自定义方法。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-28"><a class="header" href="#楔子-28">楔子</a></h2>
<p>上一篇文章我们介绍了列表作为序列型对象支持的方法，但列表还有很多的自定义方法。作为一名优秀的 Python 工程师，我们必须要知道这些方法的实现过程，以及相应的时间复杂度。</p>
<p>实例对象能够调用的方法都定义在类型对象中，类型对象无一例外都是 PyTypeObject 结构体实例，该结构体有一个 tp_methods 字段，负责维护实例对象能够调用的方法。由于 tp_methods 指向 PyMethodDef 结构体类型的数组，所以一个 PyMethodDef 结构体实例，就是 Python 实例对象能够调用的一个方法。</p>
<pre><code class="language-C">// Include/methodobject.h
struct PyMethodDef {
    // 暴露给 Python 的方法名
    const char  *ml_name;   
    // 承载了具体逻辑的 C 函数
    PyCFunction ml_meth;  
    // 指示函数的调用方式和传递参数的方式，比如 
    /* METH_NOARGS: 表示函数不接收任何参数
     * METH_O: 函数只接收一个参数
     * METH_VARARGS: 函数支持以元组的形式接收多个位置参数
     * METH_KEYWORDS: 函数支持关键字参数
     * METH_CLASS: 函数是一个类方法，等价于 Python 里的 @classmethod
     * METH_STATIC: 函数是一个静态方法，即 @staticmethod
     * METH_FASTCALL: 函数使用优化的快速调用协议，Python 3.7 及以上版本可用
                      传递参数时使用 C 数组，而不是 Python 元组
     * METH_COEXIST: 如果希望存在两个同名函数，但类和实例分别调用不同的函数
                     那么便可以指定 METH_COEXIST
     */
    int         ml_flags;   
    // 函数的 docstring
    const char  *ml_doc;    
};
</code></pre>
<p>而 list 在底层对应 PyList_Type，它的 tp_methods 字段被赋值为 list_methods。</p>
<p><img src="./images/102.png" alt="" /></p>
<p>里面定义了列表可以调用的方法，相信当你以后想查看某个对象的方法的底层实现时，已经知道该怎么定位了，下面我们就来看看这些方法的实现过程。</p>
<h2 id="append在尾部追加元素"><a class="header" href="#append在尾部追加元素">append：在尾部追加元素</a></h2>
<p>append 方法可以往列表尾部追加元素。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_APPEND_METHODDEF    \
    {&quot;append&quot;, (PyCFunction)list_append, METH_O, list_append__doc__},
</code></pre>
<p>它由 list_append 函数实现。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
list_append(PyListObject *self, PyObject *object)
{
    // 调用 app1 添加元素，并返回 None
    if (app1(self, object) == 0)
        Py_RETURN_NONE;
    return NULL;
}

static int
app1(PyListObject *self, PyObject *v)
{
    // 获取当前列表的长度
    Py_ssize_t n = PyList_GET_SIZE(self);
    assert (v != NULL);
    if (n == PY_SSIZE_T_MAX) {
        PyErr_SetString(PyExc_OverflowError,
            &quot;cannot add more objects to list&quot;);
        return -1;
    }
    // 追加元素之后 ob_size 会变成 n + 1
    // 调用 list_resize 函数，判断 n + 1 和容量之间的关系
    // 只要涉及到列表元素个数的改变，都要调用 list_resize 函数
    if (list_resize(self, n+1) &lt; 0)
        return -1;
    // 增加引用计数
    Py_INCREF(v);
    // 将元素设置在索引为 n 的位置
    PyList_SET_ITEM(self, n, v);
    return 0;
}
</code></pre>
<p>所谓往尾部追加元素，本质上就是将元素设置在索引为 len 的位置。</p>
<h2 id="insert在任意位置插入元素"><a class="header" href="#insert在任意位置插入元素">insert：在任意位置插入元素</a></h2>
<p>接下来是列表的 insert 方法。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_INSERT_METHODDEF    \
    {&quot;insert&quot;, (PyCFunction)(void(*)(void))list_insert, METH_FASTCALL, list_insert__doc__},
</code></pre>
<p>它由 list_insert 函数负责实现。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
static PyObject *
list_insert(PyListObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    // 函数的返回值，但只会返回 None
    PyObject *return_value = NULL;
    // 插入的位置
    Py_ssize_t index;
    // 插入的元素
    PyObject *object;
    // insert 方法精确接收两个参数
    if (!_PyArg_CheckPositional(&quot;insert&quot;, nargs, 2, 2)) {
        goto exit;
    }
    if (PyFloat_Check(args[0])) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;integer argument expected, got float&quot; );
        goto exit;
    }
    {
        // 参数 args 是一个元组，里面包含了插入位置和元素
        Py_ssize_t ival = -1;
        // 插入位置，对象必须实现 __index__
        PyObject *iobj = PyNumber_Index(args[0]);
        if (iobj != NULL) {
            // 转成 Py_ssize_t
            ival = PyLong_AsSsize_t(iobj);
            Py_DECREF(iobj);
        }
        if (ival == -1 &amp;&amp; PyErr_Occurred()) {
            goto exit;
        }
        // 赋值给 index
        index = ival;
    }
    // 拿到待插入的元素
    object = args[1];
    // 调用 list_insert_impl 执行元素插入逻辑
    return_value = list_insert_impl(self, index, object);

exit:
    // 虽然这里返回了 return_value，但我们知道 insert 方法是没有返回值的
    // 或者说返回值为 None，所以上面的 list_insert_impl 一定返回了 None
    return return_value;
}

// Objects/listobject.c
static PyObject *
list_insert_impl(PyListObject *self, Py_ssize_t index, PyObject *object)
{
    // 调用 ins1 插入元素，插入成功之后返回 None
    if (ins1(self, index, object) == 0)
        Py_RETURN_NONE;
    return NULL;
}

static int
ins1(PyListObject *self, Py_ssize_t where, PyObject *v)
{
    // 初始化循环变量 i，n 为列表长度
    Py_ssize_t i, n = Py_SIZE(self);
    // 指向 ob_item 数组的首元素
    PyObject **items;
    if (v == NULL) {
        PyErr_BadInternalCall();
        return -1;
    }
    if (n == PY_SSIZE_T_MAX) {
        PyErr_SetString(PyExc_OverflowError,
            &quot;cannot add more objects to list&quot;);
        return -1;
    }
    // 只要涉及到元素个数的改变，比如添加和删除元素
    // 都会先调用 list_resize，在里面检测一下容量
    // 比如这里，如果发现 (容量 &gt;= n + 1) &amp;&amp; (容量 / 2 &lt;= n + 1)
    // 那么说明容量目前是合理的，不需要做任何的扩容或缩容操作（如果条件不满足则需要）
    // 然后将列表的 ob_size 修改为 n + 1，直接返回
    if (list_resize(self, n+1) &lt; 0)
        return -1;
    // 判断插入位置，如果 where 小于 0，那么加上列表长度
    if (where &lt; 0) {
        where += n;
        // 加上列表长度之后如果还小于 0，那么让其等于 0
        if (where &lt; 0)
            where = 0;
    }
    // 如果插入位置大于列表长度 n，那么让其等于 n，此时相当于 append
    if (where &gt; n)
        where = n;
    items = self-&gt;ob_item;
    // 将 where 以及之后的元素依次向右移动一个位置
    for (i = n; --i &gt;= where; )
        items[i+1] = items[i];
    // 将待插入元素 v 的引用计数加 1，并设置在底层数组中索引为 where 的位置
    Py_INCREF(v);
    items[where] = v;
    return 0;
}
</code></pre>
<p>以上就是 insert 函数的底层逻辑，列表在插入数据的时候是非常灵活的，不管你在什么位置插入，都是合法的。它会自己调整，在确定待插入位置 where 之后，会将 where 以及之后的所有元素都向后挪动一个位置，空出来的地方设置为待插入的值。</p>
<p>另外我们看到 append 和 insert 其实非常像，都是基于索引设置元素。只不过对于 append 来说，索引就是列表长度，而对于 insert 来说，索引是由外界指定的，但函数内部会进行边界调整。</p>
<p>并且由于 insert 会涉及元素的移动，所以它的时间复杂度是 O(n)，而 append 则不会，它的时间复杂度是 O(1)。当然在极端情况下（发生扩容），append 也会退化成 O(n)，只不过这个过程不会频繁发生，所以 append 的复杂度仍然是 O(1) 的。</p>
<h2 id="pop从尾部弹出一个元素"><a class="header" href="#pop从尾部弹出一个元素">pop：从尾部弹出一个元素</a></h2>
<p>pop 默认会从尾部弹出一个元素，当然我们也可以指定索引，弹出指定索引对应的元素。如果不指定索引，那么默认是 -1。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_POP_METHODDEF    \
    {&quot;pop&quot;, (PyCFunction)(void(*)(void))list_pop, METH_FASTCALL, list_pop__doc__},
</code></pre>
<p>它由 list_pop 函数负责实现。</p>
<pre><code class="language-c">// Objects/clinic/listobject.c.h
static PyObject *
list_pop(PyListObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    // 返回值
    PyObject *return_value = NULL;
    Py_ssize_t index = -1;
    // pop 接收 0 ~ 1 个参数
    if (!_PyArg_CheckPositional(&quot;pop&quot;, nargs, 0, 1)) {
        goto exit;
    }
    // 如果参数个数小于 1，说白了就是没有传参，直接跳转到 skip_optional 标签
    if (nargs &lt; 1) {
        goto skip_optional;
    }
    if (PyFloat_Check(args[0])) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;integer argument expected, got float&quot; );
        goto exit;
    }
    {
        // 如果传参了，那么拿到指定的索引
        Py_ssize_t ival = -1;
        PyObject *iobj = PyNumber_Index(args[0]);
        if (iobj != NULL) {
            ival = PyLong_AsSsize_t(iobj);
            Py_DECREF(iobj);
        }
        if (ival == -1 &amp;&amp; PyErr_Occurred()) {
            goto exit;
        }
        index = ival;
    }
skip_optional:
    // 将列表和 index 作为参数传进去，如果不指定索引，那么 index 默认为 -1
    return_value = list_pop_impl(self, index);

exit:
    // 返回弹出的元素
    return return_value;
}

// Objects/listobject.c
static PyObject *
list_pop_impl(PyListObject *self, Py_ssize_t index)
{
    PyObject *v;
    int status;
    // 如果列表为空，那么抛出 IndexError: pop from empty list
    if (Py_SIZE(self) == 0) {
        PyErr_SetString(PyExc_IndexError, &quot;pop from empty list&quot;);
        return NULL;
    }
    // 如果 index 小于 0，那么加上列表长度
    if (index &lt; 0)
        index += Py_SIZE(self);
    // 检测索引是否合法，如果索引小于 0 或大于等于列表长度
    // 那么抛出 IndexError: pop index out of range
    if (!valid_index(index, Py_SIZE(self))) {
        PyErr_SetString(PyExc_IndexError, &quot;pop index out of range&quot;);
        return NULL;
    }
    // 拿到索引为 index 的元素，这也是一会儿要返回的元素
    v = self-&gt;ob_item[index];
    // 快分支，如果 index == Py_SIZE(self) - 1，证明弹出的是列表的最后一个元素
    // 那么说明不涉及元素的移动，直接更新 ob_size 即可
    if (index == Py_SIZE(self) - 1) {
        status = list_resize(self, Py_SIZE(self) - 1);
        if (status &gt;= 0)
            return v;
        else
            return NULL;
    }
    Py_INCREF(v);
    // 删除的不是最后一个元素，那么需要调用 list_ass_slice 进行删除
    // 等价于 self[index: index + 1] = []，即删除索引为 index 的元素
    status = list_ass_slice(self, index, index+1, (PyObject *)NULL);
    if (status &lt; 0) {
        Py_DECREF(v);
        return NULL;
    }
    return v;
}
</code></pre>
<p>以上就是 pop 方法。</p>
<h2 id="index查询元素首次出现的位置"><a class="header" href="#index查询元素首次出现的位置">index：查询元素首次出现的位置</a></h2>
<p>index 方法可以接收一个元素，然后返回该元素首次出现的位置。当然还可以额外指定一个 start 和 end，表示查询的范围。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_INDEX_METHODDEF    \
    {&quot;index&quot;, (PyCFunction)(void(*)(void))list_index, METH_FASTCALL, list_index__doc__},
</code></pre>
<p>它由 list_index 负责实现。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
static PyObject *
list_index(PyListObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    PyObject *return_value = NULL;
    PyObject *value;
    Py_ssize_t start = 0;
    Py_ssize_t stop = PY_SSIZE_T_MAX;
    // index 方法接收 1 ~ 3 个参数
    if (!_PyArg_CheckPositional(&quot;index&quot;, nargs, 1, 3)) {
        goto exit;
    }
    // args[0] 表示查找的元素
    value = args[0];
    if (nargs &lt; 2) {
        goto skip_optional;
    }
    // args[1] 表示查找的起始位置
    if (!_PyEval_SliceIndexNotNone(args[1], &amp;start)) {
        goto exit;
    }
    if (nargs &lt; 3) {
        goto skip_optional;
    }
    // args[2] 表示查找的结束位置
    if (!_PyEval_SliceIndexNotNone(args[2], &amp;stop)) {
        goto exit;
    }
skip_optional:
    // 调用 list_index_impl 查找元素
    return_value = list_index_impl(self, value, start, stop);

exit:
    // 返回
    return return_value;
}

// Objects/listobject.c
static PyObject *
list_index_impl(PyListObject *self, PyObject *value, Py_ssize_t start,
                Py_ssize_t stop)
{
    Py_ssize_t i;
    // 如果 start 小于 0，那么加上列表长度
    if (start &lt; 0) {
        start += Py_SIZE(self);
        // 如果相加之后还小于 0，那么等于 0
        if (start &lt; 0)
            start = 0;
    }
    // 如果结束位置小于 0，那么加上列表长度，所以它们都支持负数索引
    if (stop &lt; 0) {
        stop += Py_SIZE(self);
        // 如果相加之后还小于 0，那么等于 0
        if (stop &lt; 0)
            stop = 0;
    }
    // 从 start 开始遍历
    for (i = start; i &lt; stop &amp;&amp; i &lt; Py_SIZE(self); i++) {
        // 获取对应元素
        PyObject *obj = self-&gt;ob_item[i];
        Py_INCREF(obj);
        // 然后进行比较，这个函数我们之前说过
        // 它会先比较地址是否相同，如果地址相同，那么直接判定为相等
        // 如果地址不同，那么比较值是否相等
        int cmp = PyObject_RichCompareBool(obj, value, Py_EQ);
        Py_DECREF(obj);
        // 相等返回 1，不相等返回 0，比较失败返回 -1
        // 如果 cmp 大于 0，表示两者相等，返回索引
        if (cmp &gt; 0)
            return PyLong_FromSsize_t(i);
        else if (cmp &lt; 0)
            return NULL;
    }
    // 到这里说明元素不存在，那么抛出 ValueError: x is not in list
    PyErr_Format(PyExc_ValueError, &quot;%R is not in list&quot;, value);
    return NULL;
}
</code></pre>
<p>所以列表 index 方法的时间复杂度为 O(n)，因为它在底层要循环整个列表，如果运气好，可能第一个元素就是；运气不好，就只能循环整个列表了。</p>
<p>然后需要注意的是，在比较的时候，会先判断地址是否相同，然后再比较值是否相等。</p>
<pre><code class="language-Python">class A:

    def __eq__(self, other):
        return False


a = A()
data = [a]

print(a == data[0])  # False
print(data.index(a))  # 0
</code></pre>
<p>a 和 data[0] 指向的对象不相等，但 data.index(a) 却返回了相应的索引，因为两者保存的地址是相同的。</p>
<p>同理 <font color="blue">if v in data</font> 这种也是类似的，先比较地址，地址不同再比较维护的值。</p>
<h2 id="count查询元素出现的次数"><a class="header" href="#count查询元素出现的次数">count：查询元素出现的次数</a></h2>
<p>列表有一个 count 方法，可以计算出某个元素出现的次数。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_COUNT_METHODDEF    \
    {&quot;count&quot;, (PyCFunction)list_count, METH_O, list_count__doc__},
</code></pre>
<p>它由 list_count 函数负责实现。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
list_count(PyListObject *self, PyObject *value)
{
    Py_ssize_t count = 0;
    Py_ssize_t i;
    // 遍历每一个元素
    for (i = 0; i &lt; Py_SIZE(self); i++) {
        // 如果地址相同，直接判定为相等，count 自增 1
        PyObject *obj = self-&gt;ob_item[i];
        if (obj == value) {
           count++;
           continue;
        }
        Py_INCREF(obj);
        // 地址不同（a is b 不成立），则比较维护的值是否相等（看 a == b 是否成立）
        int cmp = PyObject_RichCompareBool(obj, value, Py_EQ);
        Py_DECREF(obj);
        if (cmp &gt; 0)
            count++;
        else if (cmp &lt; 0)
            return NULL;
    }
    // 返回元素出现的次数
    return PyLong_FromSsize_t(count);
}
</code></pre>
<p>毫无疑问，count 方法无论在什么情况下，它都是一个时间复杂度为 O(n) 的操作，因为列表必须要从头遍历到尾。</p>
<p>但还是要注意里面判断相等的方式，因为变量只是一个指针，所以 C 的 == 相当于 Python 的 is，但 Python 的 == 则对应 PyObject_RichCompare 函数。而源码里面在比较的时候先执行 ==，所以会先判断两者是不是指向同一个对象。</p>
<pre><code class="language-python">class A:

    def __eq__(self, other):
        return False

a = A()
data = [a, a, a]
print(data[0] == a)  # False
print(data[1] == a)  # False
print(data[2] == a)  # False

print(data.count(a))  # 3
</code></pre>
<p>我们看到列表里的三个元素和 a 都不相等，但计算数量的时候，结果是 3。原因就是比较的时候是先比较地址，如果地址一样，那么认为元素相同。</p>
<p>当然 PyObject_RichCompareBool 函数里面已经包含了比较地址的逻辑，该函数会先比较地址是否一样，如果一样则认为相等，不一样再比较对象维护的值是否相等。但在 count 方法里面，将比较地址的逻辑又单独拿了出来，可以理解为快分支。当然即遍没有也无所谓，因为在函数 PyObject_RichCompareBool 里面还是会先对地址进行比较。</p>
<h2 id="remove删除指定元素"><a class="header" href="#remove删除指定元素">remove：删除指定元素</a></h2>
<p>除了根据索引删除元素之外，也可以根据值来删除元素，会删除第一个出现的元素。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_REMOVE_METHODDEF    \
    {&quot;remove&quot;, (PyCFunction)list_remove, METH_O, list_remove__doc__},
</code></pre>
<p>它由 list_remove 函数实现。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
list_remove(PyListObject *self, PyObject *value)
{
    Py_ssize_t i;
    // 遍历每一个元素
    for (i = 0; i &lt; Py_SIZE(self); i++) {
        PyObject *obj = self-&gt;ob_item[i];
        Py_INCREF(obj);
        // 比较是否相等，如果地址相同，那么认为相等
        int cmp = PyObject_RichCompareBool(obj, value, Py_EQ);
        Py_DECREF(obj);
        // 如果相等，那么进行删除
        if (cmp &gt; 0) {
            // 可以看到在删除元素的时候，调用了 list_ass_slice
            // 等价于 self[i: i + 1] = []
            if (list_ass_slice(self, i, i+1,
                               (PyObject *)NULL) == 0)
                Py_RETURN_NONE;
            return NULL;
        }
        else if (cmp &lt; 0)
            return NULL;
    }
    // 否则说明元素不在列表中，抛出 ValueError: list.remove(x): x not in list
    PyErr_SetString(PyExc_ValueError, &quot;list.remove(x): x not in list&quot;);
    return NULL;
}
</code></pre>
<p>以上就是 remove 函数的底层实现，说白了就是一层 for 循环，依次比较列表的每个元素和待删除元素是否相等。如果出现了相等的元素，则删除，然后直接返回，因为只删除一个；但如果整个循环遍历结束也没有发现满足条件的元素，那么报错，待删除元素不存在。</p>
<p>所以背后的逻辑并没有我们想象中的那么神秘。</p>
<h2 id="reverse翻转列表"><a class="header" href="#reverse翻转列表">reverse：翻转列表</a></h2>
<p>如果是你的话，你会怎么对列表进行翻转呢？显然是采用双指针，头指针指向列表的第一个元素，尾指针指向列表的最后一个元素，然后两两交换。交换完毕之后，头指针后移一位、尾指针前移一位，继续交换。当两个指针相遇时，停止交换，而 Python 底层也是这么做的。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_REVERSE_METHODDEF    \
    {&quot;reverse&quot;, (PyCFunction)list_reverse, METH_NOARGS, list_reverse__doc__},
</code></pre>
<p>它由 list_reverse 负责实现。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
static PyObject *
list_reverse(PyListObject *self, PyObject *Py_UNUSED(ignored))
{
    return list_reverse_impl(self);
}

// Objects/listobject.c
static PyObject *
list_reverse_impl(PyListObject *self)
{   
    // 如果列表长度不大于 1，那么什么也不做，直接返回 None 即可
    if (Py_SIZE(self) &gt; 1)
        // 大于 1 的话，执行 reverse_slice，传递了两个参数
        // 第一个参数是底层数组首元素的地址
        // 而第二个参数则是底层数组中索引为 ob_size 的元素的地址
        // 但很明显能访问的最大索引应该是 ob_size - 1 才对啊
        // 别急，我们继续往下看，看一下 reverse_slice 函数的实现
        reverse_slice(self-&gt;ob_item, self-&gt;ob_item + Py_SIZE(self));
    Py_RETURN_NONE;
}

static void
reverse_slice(PyObject **lo, PyObject **hi)
{
    assert(lo &amp;&amp; hi);
    // 我们看到又执行了一次 --hi
    // 让二级指针 hi 指向了索引为 ob_size - 1 的元素
    --hi;
    // 数组元素的地址，从左往右是依次增大的
    // 如果 lo &lt; hi，证明 lo 依旧在 hi 的左边，那么交换指向的元素
    // 如果 lo &gt; hi，证明两者相遇了，交换结束
    while (lo &lt; hi) {
        // 交换指向的元素，下面三步等价于 *lo, *hi = *hi, *lo
        // 但 C 不支持这么写，它需要借助一个中间变量
        PyObject *t = *lo;
        *lo = *hi;
        *hi = t;
        // 两个指针继续靠近，指向的元素继续交换，直到两个指针相遇
        ++lo;
        --hi;
    }
}
</code></pre>
<p>所以到现在，你还认为 Python 的列表神秘吗？虽然我们很难自己写出一个 Python 解释器，但是底层的一些思想其实并没有那么难，作为一名程序猿很容易想的到。</p>
<h2 id="clear清空列表"><a class="header" href="#clear清空列表">clear：清空列表</a></h2>
<p>将列表中的元素全部清空，让列表回到初始状态。</p>
<pre><code class="language-c">// Objects/clinic/listobject.c.h
#define LIST_CLEAR_METHODDEF    \
    {&quot;clear&quot;, (PyCFunction)list_clear, METH_NOARGS, list_clear__doc__},
</code></pre>
<p>它由 list_clear 负责实现。</p>
<pre><code class="language-c">// Objects/clinic/listobject.c.h
static PyObject *
list_clear(PyListObject *self, PyObject *Py_UNUSED(ignored))
{
    return list_clear_impl(self);
}

// Objects/listobject.c
static PyObject *
list_clear_impl(PyListObject *self)
{
    _list_clear(self);
    Py_RETURN_NONE;
}

static int
_list_clear(PyListObject *a)
{
    Py_ssize_t i;
    PyObject **item = a-&gt;ob_item;
    if (item != NULL) {
        // 获取列表的长度
        i = Py_SIZE(a);
        // 将 ob_size 设置为 0
        Py_SIZE(a) = 0;
        // ob_item 设置为 NULL
        a-&gt;ob_item = NULL;
        // 将容量设置为 0
        a-&gt;allocated = 0;
        // 将列表中每个元素指向的对象的引用计数减 1
        while (--i &gt;= 0) {
            Py_XDECREF(item[i]);
        }
        // 释放底层数组所占的内存
        PyMem_FREE(item);
    }
    return 0;
}
</code></pre>
<p>过程非常简单，当列表为空时，除了将 ob_size 和 allocated 设置为 0 之外，还会将底层数组释放掉，减少内存占用。</p>
<h2 id="copy列表的拷贝"><a class="header" href="#copy列表的拷贝">copy：列表的拷贝</a></h2>
<p>调用列表的 copy 方法，可以将列表拷贝一份。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
#define LIST_COPY_METHODDEF    \
    {&quot;copy&quot;, (PyCFunction)list_copy, METH_NOARGS, list_copy__doc__},
</code></pre>
<p>它由 list_copy 负责实现。</p>
<pre><code class="language-C">// Objects/clinic/listobject.c.h
static PyObject *
list_copy(PyListObject *self, PyObject *Py_UNUSED(ignored))
{
    return list_copy_impl(self);
}

// Objects/listobject.c
static PyObject *
list_copy_impl(PyListObject *self)
{
    // 调用 list_slice，也就是基于切片获取元素
    // 所以 data.copy() 等价于 data[:]
    return list_slice(self, 0, Py_SIZE(self));
}

static PyObject *
list_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)
{
    // 指向创建的新列表
    PyListObject *np;
    // 指向列表的底层数组的首元素
    PyObject **src, **dest;
    Py_ssize_t i, len;
    // 创建的新列表的长度
    len = ihigh - ilow;
    // 创建底层数组长度为 len 的列表
    np = (PyListObject *) list_new_prealloc(len);
    if (np == NULL)
        return NULL;

    src = a-&gt;ob_item + ilow;
    dest = np-&gt;ob_item;
    // 将原始列表中的元素依次拷贝到新列表中
    for (i = 0; i &lt; len; i++) {
        PyObject *v = src[i];
        Py_INCREF(v);
        dest[i] = v;
    }
    // 将新列表的 ob_size 设置为 len
    Py_SIZE(np) = len;
    // 转成泛型指针之后返回
    return (PyObject *)np;
}
</code></pre>
<p>过程非常简单，但列表的 copy 方法或者说 data[:] 这种叫做列表的浅拷贝。关于列表的深浅拷贝也是初学者容易犯的错误之一，我们看一个 Python 的例子。</p>
<pre><code class="language-Python">data = [[]]

# 默认是浅拷贝，这个过程会创建一个新列表
# 但我们说列表里面的元素都是指针，因此只会将里面的指针拷贝一份
# 而指针指向的内存并没有拷贝
data_cp = data.copy()

# 两个对象的地址是一样的
print(id(data[0]), id(data[0]))  
&quot;&quot;&quot;
1338344668224 1338344668224
&quot;&quot;&quot;

# 操作 data[0], 会改变 data_cp[0]
data[0].append(123)
print(data, data_cp)
&quot;&quot;&quot;
[[123]] [[123]]
&quot;&quot;&quot;

# 操作 data_cp[0]，会改变 data[0]
data_cp[0].append(456)
print(data, data_cp)
&quot;&quot;&quot;
[[123, 456]] [[123, 456]]
&quot;&quot;&quot;
</code></pre>
<p>之所以会有这样的现象，是因为 Python 的变量、容器里面的元素都是泛型指针 PyObject *，在传递的时候会传递指针， 但是在操作的时候会操作指针指向的内存。所以 data.copy() 就是创建了一个新列表，然后把元素拷贝了过去，只不过元素都是指针。因为只是拷贝指针，没有拷贝指针指向的对象（内存），因此它们指向的是同一个对象。</p>
<p>但如果我们就想在拷贝指针的同时也拷贝指针指向的对象呢？答案是使用一个叫 copy 的模块。</p>
<pre><code class="language-Python">import copy

data = [[]]
# 此时拷贝的时候，会把指针指向的对象也给拷贝一份
data_cp1 = copy.deepcopy(data)
data_cp2 = data[:]

data[0].append(123)
print(data_cp1)  # [[]]
print(data_cp2)  # [[123]]

# data[:] 这种方式也是浅拷贝，所以修改 data[0]，会影响 data_cp2[0]
# 但是没有影响 data_cp1[0]，证明它们是相互独立的，因为指向的是不同的对象
</code></pre>
<p><font color="blue"><strong>浅拷贝示意图如下：</strong></font></p>
<p><img src="./images/103.png" alt="" /></p>
<p>里面的两个指针数组存储的元素是一样的，都是同一个对象的地址。</p>
<p><font color="blue"><strong>深拷贝示意图如下：</strong></font></p>
<p><img src="./images/104.png" alt="" /></p>
<p>里面的两个指针数组存储的元素是不一样的，因为是不同对象的地址。</p>
<p>注意：copy.deepcopy 虽然在拷贝指针的同时会将指针指向的对象也拷贝一份，但这仅仅是针对可变对象，而不可变对象是不会拷贝的。</p>
<pre><code class="language-python">import copy

data = [[], &quot;古明地觉&quot;]
data_cp = copy.deepcopy(data)

print(data[0] is data_cp[0])  # False
print(data[1] is data_cp[1])  # True
</code></pre>
<p>为什么会这样，其实原因很简单。因为不可变对象是不支持本地修改的，你若想修改只能创建新的对象并指向它。但这对其它的变量而言则没有影响，其它变量该指向谁就还指向谁。</p>
<p>因为 b = a 只是将 <font color="blue">a 存储的对象的指针</font>拷贝一份给 b，然后 a 和 b 都指向了同一个对象，至于 a 和 b 本身则是没有任何关系的。如果此时 a 指向了新的对象，是完全不会影响 b 的，b 还是指向原来的对象。</p>
<p>因此，如果一个指针指向的对象不支持本地修改，那么深拷贝不会拷贝对象本身，因为指向的是不可变对象，所以不会有修改一个影响另一个的情况出现。</p>
<p><strong>关于列表还有一些陷阱：</strong></p>
<pre><code class="language-python">data = [[]] * 5
data[0].append(1)
print(data)  # [[1], [1], [1], [1], [1]]
# 列表乘上一个 n，等于把列表里面的元素重复 n 次
# 但列表里面存储的是指针，也就是将指针重复 n 次
# 所以上面的列表里面的 5 个指针存储的地址是相同的
# 也就是说，它们都指向了同一个列表

# 这种方式创建的话，里面的指针都指向了不同的列表
data = [[], [], [], [], []]
data[0].append(1)
print(data)  # [[1], [], [], [], []]


# 再比如字典，在后续系列中会说
d = dict.fromkeys([1, 2, 3, 4], [])
print(d)  # {1: [], 2: [], 3: [], 4: []}
d[1].append(123)
print(d)  # {1: [123], 2: [123], 3: [123], 4: [123]}
# 它们都指向了同一个列表
</code></pre>
<p>类似的陷阱还有很多，因此在工作中要注意，否则一不小心就会出现大问题。</p>
<p>总之记住三句话：</p>
<ul>
<li>虽然 Python 一切皆对象，但我们拿到的其实是指向对象的指针；</li>
<li>变量在传递的时候本质上是将对象的指针拷贝一份，所以 Python 是变量的赋值传递、对象的引用传递；</li>
<li>操作变量（指针）的时候，会自动操作变量（指针）指向的内存。</li>
</ul>
<h2 id="小结-28"><a class="header" href="#小结-28">小结</a></h2>
<p>到此关于列表的内容就介绍完了，作为 Python 中的万能容器，我们可以自由地添加、修改和删除元素。但在使用的时候要了解它的底层结构以及元素是如何存储的，应该在什么场景下使用列表，它的每个方法的时间复杂度是多少。</p>
<p>下一篇文章来介绍元组，或许你觉得自己在代码中很少创建元组，但其实它无处不在。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-29"><a class="header" href="#楔子-29">楔子</a></h2>
<p>本篇文章来聊一聊元组，元组可以简单理解为<font color="blue">不支持元素添加、修改、删除等操作的列表</font>，也就是在列表的基础上移除了<font color="blue">增删改</font>操作。</p>
<p>所以从功能上来讲，元组只是列表的子集，那元组存在的意义是什么呢？首先元组可以作为字典的 key 以及集合的元素，因为字典和集合使用的数据结构是哈希表，它存储的元素一定是可哈希的，关于字典和集合我们后续章节会说。</p>
<p>而列表可以动态改变，所以列表不支持哈希。因此当我们希望字典的 key 是一个序列时，显然元组再适合不过了。比如要根据年龄和身高统计人数，那么就可以将<font color="blue">年龄和身高</font>组成元组作为字典的 key，人数作为字典的 value。所以元组可哈希，能够作为哈希表的 key，是元组存在的意义之一。当然元组还有其它作用，我们稍后再说。</p>
<blockquote>
<p>元组如果可哈希，那么元组存储的元素必须都是可哈希的。只要有一个元素不可哈希，那么元组就会不可哈希。比如元组里面存储了一个列表，由于列表不可哈希，导致存储了列表的元组也会变得不可哈希。</p>
</blockquote>
<h2 id="元组的底层结构"><a class="header" href="#元组的底层结构">元组的底层结构</a></h2>
<p>根据我们使用元组的经验，可以得出元组是一个变长对象，但同时又是一个不可变对象。</p>
<pre><code class="language-c">// Include/cpython/tupleobject.h
typedef struct {
    PyObject_VAR_HEAD
    PyObject *ob_item[1];
} PyTupleObject;
</code></pre>
<p>以上是元组在底层对应的结构体，包含引用计数、类型、ob_size、指针数组。然后数组声明的长度虽然是 1，但我们可以当成 n 来用。然后我们再通过结构体的定义，来对比一下它和列表的区别。</p>
<ul>
<li>元组没有 allocated、也就是容量的概念，这是因为它是不可变的，不支持 resize 操作。</li>
<li>元组对应的指针数组是定义在结构体里面的，可以直接对数组进行操作。而列表对应的指针数组是定义在结构体外面的，两者通过二级指针进行关联，也就是通过二级指针来间接操作指针数组。</li>
</ul>
<p>至于为什么要这么定义，我们在最开始介绍对象模型的时候也说得很详细了。可变对象的具体元素不会保存在结构体内部，而是会维护一个指针，指针指向的内存区域负责存储元素。当发生扩容时，只需改变指针指向即可，从而方便内存管理。</p>
<p>基于结构体的定义，我们也能分析出元组所占的内存大小，显然它等于 <font color="blue">24 + 8 * 元组长度</font>。</p>
<pre><code class="language-python">&gt;&gt;&gt; ().__sizeof__()
24
&gt;&gt;&gt; (1,).__sizeof__()
32
&gt;&gt;&gt; (1, 2).__sizeof__()
40
</code></pre>
<p>结果没有问题。</p>
<h2 id="元组是怎么创建的"><a class="header" href="#元组是怎么创建的">元组是怎么创建的？</a></h2>
<p>元组支持的操作我们就不看了，因为它只支持查询操作，并且和列表是高度相似的。这里我们直接来看元组的创建过程。正如列表一样，解释器为创建 PyTupleObject 也提供了类似的初始化方法，即 PyTuple_New。</p>
<pre><code class="language-C">// Objects/tupleobject.c
PyObject *
PyTuple_New(Py_ssize_t size)
{
    // 参数 size 表示元组的长度
    // op 指向创建的元组
    PyTupleObject *op;
    // 循环变量
    Py_ssize_t i;
    // size 必须大于等于 0
    if (size &lt; 0) {
        PyErr_BadInternalCall();
        return NULL;
    }
    // PyTuple_MAXSAVESIZE 是一个宏，显然和缓存池相关
    // 关于缓存池我们一会儿再说
#if PyTuple_MAXSAVESIZE &gt; 0
    if (size == 0 &amp;&amp; free_list[0]) {
        op = free_list[0];
        Py_INCREF(op);
        return (PyObject *) op;
    }
    if (size &lt; PyTuple_MAXSAVESIZE &amp;&amp; (op = free_list[size]) != NULL) {
        free_list[size] = (PyTupleObject *) op-&gt;ob_item[0];
        numfree[size]--;
        _Py_NewReference((PyObject *)op);
    }
    else
#endif
    // 当不使用缓存池时，要在系统堆上申请内存
    {
        // size * sizeof(PyObject *) + sizeof(PyTupleObject) 便是元组大小
        // 该值不能超过 PY_SSIZE_T_MAX，否则报错
        if ((size_t)size &gt; ((size_t)PY_SSIZE_T_MAX - sizeof(PyTupleObject) -
                    sizeof(PyObject *)) / sizeof(PyObject *)) {
            return PyErr_NoMemory();
        }
        // 为 PyTupleObject 和长度为 size 的指针数组申请内存
        // 然后将它的类型设置为 &amp;PyTuple_Type，将 ob_size 设置为 size
        op = PyObject_GC_NewVar(PyTupleObject, &amp;PyTuple_Type, size);
        if (op == NULL)
            return NULL;
    }
    // 将指针数组中所有元素设置为 NULL
    for (i=0; i &lt; size; i++)
        op-&gt;ob_item[i] = NULL;
#if PyTuple_MAXSAVESIZE &gt; 0
    if (size == 0) {
        free_list[0] = op;
        ++numfree[0];
        Py_INCREF(op);          /* extra INCREF so that this is never freed */
    }
#endif
    // 让 GC 进行跟踪
    _PyObject_GC_TRACK(op);
    // 转成泛型指针之后返回
    return (PyObject *) op;
}
</code></pre>
<p>相信这种代码逻辑现在对你来说已经没有任何难度了，另外源码中还有几个宏，不过不重要，因此这里直接去掉了。</p>
<p>以上就是元组创建的过程，但里面隐藏了很多的细节没有说，下面我们来介绍元组的缓存池，然后将细节一一揭开。</p>
<h2 id="元组的缓存池"><a class="header" href="#元组的缓存池">元组的缓存池</a></h2>
<p>元组的缓存池也是通过数组来实现的。</p>
<pre><code class="language-C">// Objects/tupleobject.c

#define PyTuple_MAXSAVESIZE     20
#define PyTuple_MAXFREELIST  2000

static PyTupleObject *free_list[PyTuple_MAXSAVESIZE];
static int numfree[PyTuple_MAXSAVESIZE];
</code></pre>
<p>里面出现了两个宏：</p>
<ul>
<li>PyTuple_MAXSAVESIZE：缓存池的大小，默认为 20；</li>
<li>PyTuple_MAXFREELIST：缓存池的每个元素都对应一条链表，该宏表示每条链表最多容纳多少个节点（稍后解释）；</li>
</ul>
<p>从定义中可以看到，元组的缓存池大小是 20，而我们之前介绍的列表的缓存池大小是 80。但这里的 20 和 80 还稍微有些不同，80 指的是列表缓存池的大小，除此之外没有别的含义。而 20 除了表示元组缓存池的大小之外，它还表示只有当元组的长度小于 20，回收时才会被放入缓存池。</p>
<p>当元组的长度为 n 时（其中 n &lt; 20)，那么在回收的时候该元组就会放在缓存池中索引为 <font color="blue">n</font> 的位置。假设回收的元组长度为 6，那么就会放在缓存池索引为 6 的位置。</p>
<p>但是问题来了，如果要回收两个长度为 6 的元组该怎么办？很简单，像链表一样串起来就好了。所以 free_list 里面虽然存储的是 PyTupleObject *，但每个 <code>(PyTupleObject *)-&gt;ob_item[0]</code>都存储了下一个 PyTupleObject *。</p>
<p>因此你可以认为 free_list 存储了 20 条链表的头结点的指针，每条链表上面挂着具有相同 ob_size 的 PyTupleObject。比如 <font color="blue">free_list[n]</font> 便指向了长度为 n 的 PyTupleObject 组成的链表的头结点，至于每条链表的节点个数由 numfree 维护，并且最大不能超过 PyTuple_MAXFREELIST，默认是 2000。</p>
<p><img src="./images/105.png" alt="" /></p>
<p>这里再来重新捋一下，元组的缓存池是一个数组，并且索引为 <font color="blue">n</font> 的位置回收的是元素个数（ob_size）为 n 的元组，并且 n 不超过 20。但这样的话，具有相同长度的元组不就只能缓存一个了吗？比如我们有很多个长度为 2 的元组都要缓存怎么办呢？显然将它们以链表的形式串起来即可，正如图中显示的那样。至于长度为 n 的元组究竟缓存了多少个，则由 <font color="blue">numfree[n]</font> 负责维护。假设 free_list[2] 这条链表上挂了 1000 个 PyTupleObject，那么 numfree[2] 就等于 1000，即长度为 2 的元组被缓存了 1000 个。</p>
<p>当再回收一个长度为 2 的元组时，那么会让该元组的 ob_item[0] 等于 free_list[2]，然后 free_list[2] 等于该元组、numfree[2]++。所以这里的每一条链表和浮点数缓存池是类似的，也是采用的头插法。</p>
<p>我们看一下放入缓存池的具体过程，显然这一步发生在元组销毁的时候。</p>
<pre><code class="language-C">// Objects/tupleobject.c
static void
tupledealloc(PyTupleObject *op)
{
    // 循环变量
    Py_ssize_t i;
    // 回收的元组的长度
    Py_ssize_t len =  Py_SIZE(op);
    // 让 GC 不再跟踪
    PyObject_GC_UnTrack(op);
    // 延迟释放，和列表是类似的
    Py_TRASHCAN_BEGIN(op, tupledealloc)
    
    if (len &gt; 0) {
        i = len;
        // 减少内部元素指向对象的引用计数，因为元组不再持有对它们的引用
        while (--i &gt;= 0)
            Py_XDECREF(op-&gt;ob_item[i]);
#if PyTuple_MAXSAVESIZE &gt; 0
        // 回收的元组的长度必须小于 20，即元组长度不超过 20
        // 并且 numfree[index] 必须小于 2000，即每条链表最多缓存 2000 个元组
        if (len &lt; PyTuple_MAXSAVESIZE &amp;&amp;
            numfree[len] &lt; PyTuple_MAXFREELIST &amp;&amp;
            Py_TYPE(op) == &amp;PyTuple_Type)
        {
            // ob_item[0] 充当了链表的 next 指针
            // 这里让 op-&gt;ob_item[0] 等于 free_list[index]
            // 然后让 free_list[index] 等于 op
            // 这样元组就缓存起来了，并成为链表新的头结点，即 free_list[index]
            op-&gt;ob_item[0] = (PyObject *) free_list[len];
            // 然后维护一下链表的节点个数
            numfree[len]++;
            free_list[len] = op;
            goto done; /* return */
        }
#endif
    }
    // 如果元组长度大于等于 20，或者缓存池已满，那么释放内存
    Py_TYPE(op)-&gt;tp_free((PyObject *)op);
done:
    Py_TRASHCAN_END
}
</code></pre>
<p>tupledealloc 函数在销毁元组时，会尝试放入缓存池中。那么同理，在创建元组时，也会尝试从缓存池中获取。我们再回过头看一下 PyTuple_New 这个函数，重新解释一下里面的细节。</p>
<pre><code class="language-C">// Objects/tupleobject.c
PyObject *
PyTuple_New(Py_ssize_t size)
{
    // ...
#if PyTuple_MAXSAVESIZE &gt; 0
    // 回收的元组的长度为 0 时比较特殊，一会单独说
    if (size == 0 &amp;&amp; free_list[0]) {
        op = free_list[0];
        Py_INCREF(op);
        return (PyObject *) op;
    }
    // 当 0 &lt; size &lt; 20 时，直接通过 op = free_list[size] 从缓存池获取 
    if (size &lt; PyTuple_MAXSAVESIZE &amp;&amp; (op = free_list[size]) != NULL) {
        // 元组取走后，别忘记让 free_list[size] 指向下一个元素
        // 也就是 (PyTupleObject *) op-&gt;ob_item[0]
        free_list[size] = (PyTupleObject *) op-&gt;ob_item[0];
        // 维护对应的链表长度    
        numfree[size]--;
        // 引用计数初始化为 1
        _Py_NewReference((PyObject *)op);
    }
    else
#endif
    // ...
#if PyTuple_MAXSAVESIZE &gt; 0
    if (size == 0) {
        free_list[0] = op;
        ++numfree[0];
        Py_INCREF(op); 
    }
#endif
    _PyObject_GC_TRACK(op);
    return (PyObject *) op;
}
</code></pre>
<p>到此，相信你已经明白元组的缓存池到底是怎么一回事了，说白了就是有 20 条链表，索引为 n 的链表存放长度为 n 的元组，因此可回收的元组的最大长度是 19。然后每条链表的长度小于 2000，也就是具有相同长度的元组最多回收 2000 个。至于链表的 next 指针，则由元组的 ob_item[0] 来充当，通过 ob_item[0] 来获取下一个元素。</p>
<pre><code class="language-Python">&gt;&gt;&gt; tpl = (1, 2, 3)
&gt;&gt;&gt; print(id(tpl))
2279295395264
&gt;&gt;&gt;
&gt;&gt;&gt; del tpl  # 放入缓存池
&gt;&gt;&gt;
&gt;&gt;&gt; tpl = (&quot;古明地觉&quot;, &quot;古明地恋&quot;, &quot;芙兰朵露&quot;)
&gt;&gt;&gt; print(id(tpl))
2279295395264
</code></pre>
<p>可以看到打印的地址是一样的，因为第一次创建的元组被重复利用了。</p>
<p>另外我们说缓存池的长度为 20，会缓存长度为 0 ~ 19 的元组，每种规格的元组最多缓存 2000 个。其实这个说法不太严谨，应该说长度为 1 ~ 19 的元组会缓存 2000 个。如果元组长度为 0，那么它对应的链表只会容纳一个元素，这也说明了不管我们创建多少个空元组，最终在内存中只会存在一个。</p>
<pre><code class="language-python">tpl1 = ()
tpl2 = ()
tpl3 = ()

print(id(tpl1) == id(tpl2) == id(tpl3))  # True
</code></pre>
<p>再来看看 PyTuple_New 这个函数：</p>
<p><img src="./images/106.png" alt="" /></p>
<p>从缓存池中获取之后只是增加了引用计数，因为长度为 0 的元组只会缓存一个。所以空元组可以认为是单例的，只有一份。</p>
<p>那么问题来了，为什么元组缓存池可以缓存的元组个数会这么多，每个链表缓存 2000 个，有 20 条链表，总共可以缓存将近 40000 个。这么做的原因就是，元组的使用频率远比我们想象的广泛，主要是它大量使用在我们看不到的地方。比如多元赋值：</p>
<pre><code class="language-Python">a, b, c, d = 1, 2, 3, 4
</code></pre>
<p>在编译时，上面的 <font color="blue">1, 2, 3, 4</font> 实际上是作为元组被加载的，整个赋值相当于元组的解包。再比如函数、方法的返回值，如果是多返回值，本质上也是包装成一个元组之后再返回。</p>
<p>所以元组缓存池能缓存的对象个数，要远大于其它对象的缓存池。可以想象一个大型项目，里面的函数、方法不计其数，只要是多返回值，就会涉及到元组的创建，因此每种长度的元组缓存 2000 个是很合理的。当然如果长度达到了 20，就不会缓存了，这种元组的使用频率没有那么高。</p>
<p>然后再回顾一下元组的回收过程，会发现它和列表有一个很大的不同。列表在被回收时，它的指针数组会被释放；但元组不同，它在被回收时，底层的指针数组会保留，并且还巧妙地通过索引来记录了回收的元组的大小规格。元组的这项技术也被称为<font color="blue">静态资源缓存</font>，因为元组在执行析构函数时，<font color="blue">不仅对象本身没有被回收，连底层的指针数组也被缓存起来了</font>。那么当再次分配时，速度就会快一些。</p>
<pre><code class="language-Python">from timeit import timeit

t1 = timeit(stmt=&quot;x1 = [1, 2, 3, 4, 5]&quot;, number=1000000)
t2 = timeit(stmt=&quot;x2 = (1, 2, 3, 4, 5)&quot;, number=1000000)

print(round(t1, 2))  # 0.05
print(round(t2, 2))  # 0.01
</code></pre>
<p>可以看到耗时，元组只是列表的五分之一。这便是元组的另一个优势，可以将资源缓存起来。而缓存的原因还是如上面所说，因为涉及大量的创建和销毁，所以这一切都是为了加快内存分配。</p>
<blockquote>
<p>由于对象都在堆区，为了效率，Python 不得不大量使用缓存的技术。</p>
</blockquote>
<h2 id="小结-29"><a class="header" href="#小结-29">小结</a></h2>
<p>以上就是元组相关的内容，因为有了列表相关的经验，再来看元组就会快很多。当然啦，元组的一些操作我们没有说，因为和对应的列表操作是类似的。</p>
<p>最后再补充一下，列表是有 __init__ 方法的，而元组没有。</p>
<p><img src="./images/107.png" alt="" /></p>
<p>元组的 __init__ 直接继承 object.__init__。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-30"><a class="header" href="#楔子-30">楔子</a></h2>
<p>Python 的字典是一种映射型容器对象，保存了键（key）到值（value）的映射关系。通过字典，我们可以实现快速查找，JSON 这种数据结构也是借鉴了 Python 的字典。另外字典是经过高度优化的，因为 Python 底层也在大量地使用字典。</p>
<p>在 Python 里面我们要如何创建一个字典呢？</p>
<pre><code class="language-python"># 创建一个字典
d = {&quot;a&quot;: 1, &quot;b&quot;: 2}
print(d)  # {'a': 1, 'b': 2}

# 或者我们还可以调用 dict，传入关键字参数即可
d = dict(a=1, b=2, c=3, d=4)
print(d)  # {'a': 1, 'b': 2, 'c': 3, 'd': 4}

# 当然 dict 里面还可以接收位置参数，但是最多接收一个
d1 = dict({&quot;a&quot;: 1, &quot;b&quot;: 2}, c=3, d=4)
d2 = dict([(&quot;a&quot;, 1), (&quot;b&quot;, 2)], c=3, d=4)
print(d1)  # {'a': 1, 'b': 2, 'c': 3, 'd': 4}
print(d2)  # {'a': 1, 'b': 2, 'c': 3, 'd': 4}


# 还可以根据已有字典创建新的字典
d = {**{&quot;a&quot;: 1, &quot;b&quot;: 2}, &quot;c&quot;: 3, **{&quot;d&quot;: 4}}
print(d)  # {'a': 1, 'b': 2, 'c': 3, 'd': 4}

# 当然通过调用 dict 也是可以的
# 但是注意：** 这种方式本质上是把字典变成多个关键字参数
# 所以里面的 key 一定要符合 Python 的变量命名规范
d = dict(**{&quot;a&quot;: 1, &quot;b&quot;: 2}, c=3, **{&quot;d&quot;: 4})
print(d)  # {'a': 1, 'b': 2, 'c': 3, 'd': 4}

try:
    # 这种是不合法的，因为 **{1: 1} 等价于 1=1
    d = dict(**{1: 1})
except Exception as e:
    print(e)  # keywords must be strings
# 但下面是合法的
d = {**{1: 1, 2: 2}}
print(d)  # {1: 1, 2: 2}
</code></pre>
<p>字典的底层是借助哈希表实现的，关于哈希表我们一会儿说，总之字典添加元素、删除元素、查找元素等操作的平均时间复杂度是 O(1)。</p>
<p>我们来测试一下字典的执行效率吧，看看它和列表之间的区别。</p>
<pre><code class="language-Python">import time
import numpy as np

def test(count: int, value: int):
    &quot;&quot;&quot;
    :param count: 循环次数
    :param value: 查询的元素
    :return:
    &quot;&quot;&quot;
    # 包含一千个随机数的列表
    lst = list(np.random.randint(0, 2 ** 30, size=1000))
    # 基于列表构建一个字典
    d = dict.fromkeys(lst)

    # 查询元素 value 是否在列表中，循环 count 次，并统计时间
    t1 = time.perf_counter()
    for _ in range(count):
        value in lst
    t2 = time.perf_counter()
    print(&quot;列表查询耗时:&quot;, round(t2 - t1, 2))

    # 查询元素 value 是否在字典中，循环 count 次，并统计时间
    t1 = time.perf_counter()
    for _ in range(count):
        value in d
    t2 = time.perf_counter()
    print(&quot;字典查询耗时:&quot;, round(t2 - t1, 2))


# 分别查询一千次、一万次、十万次、二十万次
test(10 ** 3, 22333)
&quot;&quot;&quot;
列表查询耗时: 0.13
字典查询耗时: 0.0
&quot;&quot;&quot;
test(10 ** 4, 22333)
&quot;&quot;&quot;
列表查询耗时: 1.22
字典查询耗时: 0.0
&quot;&quot;&quot;
test(10 ** 5, 22333)
&quot;&quot;&quot;
列表查询耗时: 12.68
字典查询耗时: 0.01
&quot;&quot;&quot;
test(10 ** 5 * 2, 22333)
&quot;&quot;&quot;
列表查询耗时: 25.72
字典查询耗时: 0.01
&quot;&quot;&quot;
</code></pre>
<p>字典的查询速度非常快，从测试中我们看到，随着循环次数越来越多，列表所花费的总时间越来越长。但是字典由于查询所花费的时间极少，查询速度非常快，所以即便循环 50 万次，花费的总时间也不过才 0.01 秒左右。</p>
<p>此外字典还有一个特点，就是它的<font color="blue">快</font>不会受到数据量的影响，从含有一万个键值对的字典中查找，和从含有一千万个键值对的字典中查找，两者花费的时间几乎是没有区别的。</p>
<p>那么哈希表到底是什么样的数据结构，为什么能这么快呢？下面来分析一下。</p>
<h2 id="什么是哈希表"><a class="header" href="#什么是哈希表">什么是哈希表</a></h2>
<p>映射型容器的使用场景非常广泛，基本上所有的主流语言都支持。例如 C++ 里面的 map 就是一种映射型容器，但它是基于红黑树实现的。红黑树是一种平衡二叉树，元素的插入、删除、查询等操作的时间复杂度均为 O(logN)，另外 Linux 的 epoll 也使用了红黑树。</p>
<p>而对于 Python 来讲，映射型容器指的就是字典，我们说字典在 Python 内部是被高度优化的。因为不光我们在用，虚拟机在运行时也在大量使用，比如类对象、自定义类的实例对象都有自己的属性字典，还有全局变量也是通过字典存储的。因此基于以上种种原因，Python 对字典的性能要求会更加苛刻。</p>
<p>所以 Python 字典采用的数据结构，在添加、删除、查询元素等方面肯定是要优于红黑树的，没错，就是哈希表。其原理是将 key 通过哈希函数进行运算，得到一个哈希值，再将这个哈希值映射成索引。</p>
<p>我们举例说明：</p>
<p><img src="./images/108.png" alt="" /></p>
<p>我们发现除了 key、value 之外，还有一个 index，因为哈希表本质上也是使用了索引。虽然数组在遍历的时候是个时间复杂度为 O(n) 的操作，但通过索引定位元素则是一个 O(1) 的操作，不管数组有多长，通过索引总是能瞬间定位到指定元素。</p>
<p>所以哈希表本质上就是一个数组，通过将 key 映射成一个数值，作为数组的索引，然后将键值对存在数组里面。至于它是怎么映射的，我们后面再谈，现在就假设是按照我们接下来说的方法映射的。</p>
<p>比如这里有一个能容纳 8 个元素的字典，如上图所示。我们先设置 <font color="blue">d[&quot;koishi&quot;]=79</font>，那么会对 &quot;koishi&quot; 这个字符串进行哈希运算，得到一个哈希值，然后再让哈希值对当前的总容量进行取模，这样的话是不是能够得到一个小于 8 的数呢？假设是 3，那么就存在索引为 3 的位置。</p>
<p>然后 <font color="blue">d[&quot;scarlet&quot;]=95</font>，按照同样的规则运算得到 6，那么就存在索引为 6 的位置；同理第三次设置 <font color="blue">d[&quot;satori&quot;]=80</font>，对字符串 satori 进行哈希、取模，得到 1，那么存储在索引为 1 的位置。</p>
<p>同理当我们根据键来获取值的时候，比如：<font color="blue">d[&quot;satori&quot;]</font>，那么同样会对字符串 &quot;satori&quot; 进行哈希、取模，得到索引发现是1，然后就把索引为 1 的 value 给取出来。</p>
<p>当然这种方式肯定存在缺陷，比如：</p>
<ul>
<li>不同的 key 进行哈希、取模运算之后得到的结果一定是不同的吗？</li>
<li>在运算之后得到索引的时候，发现这个位置已经有人占了怎么办？</li>
<li>取值的时候，索引为 1，可如果索引为 1 对应的 key 和我们指定的 key 不一致怎么办？</li>
</ul>
<p>所以哈希运算是会冲突的，如果冲突，那么 Python 底层会改变策略重新映射，直到映射出来的索引没有人用。比如我们设置一个新的键值对 <font color="blue">d[&quot;tomoyo&quot;]=88</font>，可是 &quot;tomoyo&quot; 这个 key 映射之后得到的结果也是 1，而索引为 1 的地方已经被 key 为 &quot;satori&quot; 的键值对给占了，那么 Python 就会改变规则来对 &quot;tomoyo&quot; 重新映射，直到找到一个空位置。</p>
<p>但如果我们再次设置 <font color="blue">d[&quot;satori&quot;]=100</font>，那么对 satori 映射得到的结果也是 1，而 key 是一致的，那么就会把对应的值进行修改。</p>
<p>同理，当我们获取值的时候，比如 <font color="blue">d[&quot;tomoyo&quot;]</font>，那么对 key 进行映射，得到索引。但是发现该索引对应的 key 不是 &quot;tomoyo&quot; 而是 &quot;satori&quot;，于是改变规则（这个规则跟设置 key 冲突时，采用的规则是一样的），重新映射，得到新的索引，然后发现 key 是一致的，于是将值取出来。</p>
<p>所以从这里就已经能说明问题了，就是把 key 转换成数组的索引。可能有人问，这些键值对貌似不是连续的啊。对的，肯定不是连续的。并不是说你先存，你的索引就小、就在前面，这是由 key 进行哈希运算之后的结果决定的。</p>
<p>另外哈希表、或者说字典也会扩容，并且它还不是像列表那样，容量不够才扩容，而是当键值对个数达到容量的三分之二的时候就会扩容。</p>
<p>因为字典不可能会像列表那样，键值对之间是连续、一个一个挨在一起的。既然是哈希运算，得到的哈希值肯定是随机的，再根据哈希值映射出的索引也是随机的。那么在键值对个数达到容量三分之二的时候，计算出来的索引发生碰撞的概率会非常大，不可能等到容量不够了再去扩容，而是在键值对个数达到容量的三分之二时就要扩容，也就是申请一个更大的哈希表。</p>
<p><font color="#ac39ff"><strong>一句话总结：哈希表就是一种空间换时间的方法。</strong></font></p>
<p>假设容量为 1024，那么就相当于数组有 1024 个位置，每个 key 都会映射成索引，找到自己的位置，将键值对存在里面。但很明显各自的位置是不固定的，肯定会空出来很多，但是无所谓，只要保证通过索引能在相应的位置找到它即可。</p>
<p>大量的文字会有些枯燥，我们用两张图来解释一下设置元素和获取元素的整个过程。</p>
<p><img src="./images/109.png" alt="" /></p>
<p>以上是设置元素，还是比较清晰的，果然图像是个好东西。再来看看获取元素：</p>
<p><img src="./images/110.png" alt="" /></p>
<p>以上就是哈希表的基本原理，说白了它就是个数组。存储键值对的时候，先将 key 映射成索引，然后基于索引找到数组中的指定位置，将键值对存进去。</p>
<h2 id="小结-30"><a class="header" href="#小结-30">小结</a></h2>
<p>目前介绍的正是 Python 早期所采用的哈希表，但是它有一个严重的问题，就是内存浪费严重。下一篇文章我们就来看看字典的底层结构，以及 Python 是如何对哈希表进行优化的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-31"><a class="header" href="#楔子-31">楔子</a></h2>
<p>本篇文章来剖析一下字典的底层结构，看看它是怎么设计的，以及在设计的过程中都需要做哪些考量。另外字典是基于哈希表实现的，而传统的哈希表存在内存浪费的问题，那么字典又是如何优化的呢？带着这些问题，开始今天的内容。</p>
<h2 id="字典的底层结构"><a class="header" href="#字典的底层结构">字典的底层结构</a></h2>
<p>Python 一切皆对象，字典也不例外，它在底层也由某个结构体表示。</p>
<pre><code class="language-C">// Include/cpython/dictobject.h
typedef struct {
    PyObject_HEAD
    Py_ssize_t ma_used;
    uint64_t ma_version_tag;
    PyDictKeysObject *ma_keys;
    PyObject **ma_values;
} PyDictObject;
</code></pre>
<p>解释一下里面的字段的含义：</p>
<ul>
<li>PyObject_HEAD：对象的头部信息，里面包含了对象的引用计数和类型。</li>
<li>ma_used：字典的长度，它充当了 ob_size。</li>
<li>ma_version_tag：字典的版本号，对字典的每一次修改都会导致其改变。该字段主要用于字典的迭代器，以检测字典在迭代过程中是否被修改。</li>
<li>ma_keys：从定义上来看它是一个指针，指向了 PyDictKeysObject。而 Python 里面的哈希表分为两种，分别是 <font color="blue">combined table</font> 和 <font color="blue">split table</font>，即结合表和分离表。如果是结合表，那么键值对全部由 ma_keys 维护，此时 ma_values 为 NULL。</li>
<li>ma_values：如果是分离表，那么键由 ma_keys 维护，值由 ma_values 维护。而 ma_values 是一个二级指针，指向 PyObject * 类型的指针数组的首元素。</li>
</ul>
<p>这里先解释一下结合表和分离表的由来。结合表的话，键和值会存在一起；分离表的话，键和值会存在不同的地方。那么问题来了，为什么要将哈希表分为两种呢？事实上，早期的哈希表只有结合表这一种，并且现在创建一个字典使用的也是结合表。</p>
<pre><code class="language-Python">from ctypes import *

class PyObject(Structure):
    _fields_ = [(&quot;ob_refcnt&quot;, c_ssize_t),
                (&quot;ob_type&quot;, c_void_p)]

class PyDictObject(PyObject):
    _fields_ = [(&quot;ma_used&quot;, c_ssize_t),
                (&quot;ma_version_tag&quot;, c_uint64),
                (&quot;ma_keys&quot;, c_void_p),
                (&quot;ma_values&quot;, c_void_p)]


d = {&quot;a&quot;: 1, &quot;b&quot;: 2}
print(
    PyDictObject.from_address(id(d)).ma_values
)  # None
</code></pre>
<p>我们看到 ma_values 打印的结果是一个 None，证明是结合表，值不是由 ma_values 维护，而是和键一起，都由 ma_keys 负责维护。</p>
<p>而分离表是在 PEP-0412 中被引入的，主要是为了提高内存使用率，也就是让不同的字典共享相同的一组 key。比如自定义类的实例对象，它们默认都有自己的属性字典，如果对某个类多次实例化，那么改成分离表会更有效率。因为它们的属性名称是相同的，完全可以共享同一组 key；如果是结合表，那么每个实例的属性字典都要将相同的 key 单独保存一次，这显然是一种浪费。</p>
<pre><code class="language-Python">from ctypes import *

class PyObject(Structure):
    _fields_ = [(&quot;ob_refcnt&quot;, c_ssize_t),
                (&quot;ob_type&quot;, c_void_p)]

class PyDictObject(PyObject):
    _fields_ = [(&quot;ma_used&quot;, c_ssize_t),
                (&quot;ma_version_tag&quot;, c_uint64),
                (&quot;ma_keys&quot;, c_void_p),
                (&quot;ma_values&quot;, c_void_p)]

class A:
    pass

a1 = A()
a2 = A()

# 因为类型指定的是 void *，所以打印的结果是一串地址
# 但我们看到输出不为 None，说明采用的确实是分离表
print(
    PyDictObject.from_address(id(a1.__dict__)).ma_values,
    PyDictObject.from_address(id(a2.__dict__)).ma_values
)  # 139672411587664 139672411587280

# 然后再查看 ma_keys，既然是共享同一组 key
# 那么打印的地址应该是一样的
print(
    PyDictObject.from_address(id(a1.__dict__)).ma_keys,
    PyDictObject.from_address(id(a2.__dict__)).ma_keys
)  # 139672411702528 139672411702528

# 结果确实是一样的，不同实例对象的属性字典里面的 key 是共享的
# 因为是同一个类的实例对象，属性字典的 key 是相同的，所以没必要将同一组 key 保存多次
</code></pre>
<p>以上就是结合表和分离表之间的区别，只需要知道分离表是 Python 为了提高内存使用率而专门引入的即可。我们平时自己创建的字典，使用的都是结合表，因此我们的重点也将会放在结合表身上。</p>
<p>而结合表的话，键值都由 ma_keys 维护，它是一个指向 PyDictKeysObject 的指针，因此玄机就隐藏在这个结构体里面。</p>
<pre><code class="language-C">// Include/cpython/dictobject.h
typedef struct _dictkeysobject PyDictKeysObject;

// Objects/dict-common.h
struct _dictkeysobject {
    // key 的引用计数，也就是 key 被多少个字典所使用
    // 如果是结合表，那么该字段始终是 1，因为结合表独占一组 key
    // 如果是分离表，那么该字段大于等于 1，因为分离表可以共享一组 key
    Py_ssize_t dk_refcnt;

    // 哈希表的大小、或者说长度，注意：dk_size 满足 2 的 n 次方
    // 这样可将取模运算优化成按位与运算，也就是将 num % dk_size 优化成 num &amp; (dk_size - 1)
    Py_ssize_t dk_size;

    // 哈希函数，用于计算 key 的哈希值，然后映射成索引
    // 一个好的哈希函数应该尽可能少的产生冲突，并且哈希函数对哈希表的性能起着至关重要的作用
    // 所以底层的哈希函数有很多种，会根据对象的种类选择最合适的一个
    dict_lookup_func dk_lookup;

    // 键值对数组还可以添加多少个 entry（键值对）
    // 关于什么是键值对数组，以及它和哈希索引数组之间有什么区别，稍后会解释
    Py_ssize_t dk_usable;

    // 键值对数组里面已经添加了多少个键值对
    Py_ssize_t dk_nentries;

    // 哈希索引数组
    char dk_indices[];
    
    // 注：dk_indices 后面其实还有一个字段 dk_entries，只不过没有写在结构体里面
    // 从字段名也可以看出，它表示键值对数组，因此它的类型就是个数组
    // 然后数组里面存储的是键值对（entry），而键值对在底层由 PyDictKeyEntry 结构体实现
    // 所以你可以认为 char dk_indices[] 的下面还有一个 PyDictKeyEntry dk_entries[]
};
</code></pre>
<p>字典的定义还是稍微有点复杂的，如果目前感到困惑，没有关系，稍后我们会一点点解释清楚。这里再来看看键值对长什么样子。</p>
<pre><code class="language-C">// Objects/dict-common.h
typedef struct {
    Py_hash_t me_hash;
    PyObject *me_key;
    PyObject *me_value;
} PyDictKeyEntry;
</code></pre>
<p>显然 me_key 和 me_value 指向了键和值，我们之前说 Python 的变量、以及容器内部的元素都是泛型指针 PyObject *，这里也得到了证明。但是我们看到 entry 除了有键和值之外，还有一个 me_hash，它表示键对应的哈希值，这样可以避免重复计算。</p>
<p>至此，字典的整个底层结构就非常清晰了，我们画一张图，然后再来从头解释一下，并解答之前留下的疑问。</p>
<p><img src="./images/111.png" alt="" /></p>
<p>字典的真正实现藏在 PyDictKeysObject 中，它的内部包含两个关键数组：一个是哈希索引数组 dk_indices，另一个是键值对数组 dk_entries。</p>
<p>字典维护的键值对（entry）会按照先来后到的顺序保存在键值对数组中，而哈希索引数组则保存<font color="blue">键值对</font>在<font color="blue">键值对数组</font>中的索引。另外，哈希索引数组中的一个位置我们称之为一个<font color="blue">槽</font>，比如图中的哈希索引数组便有 8 个槽，其数量由 dk_size 字段维护。</p>
<p>假设我们创建一个空字典，注意：虽然字典是空的，但是容量已经有了，然后往里面插入键值对 <font color="blue">&quot;komeiji&quot;: 99</font> 的时候，Python 会执行以下步骤：</p>
<ul>
<li>将键值对保存在 dk_entries 中，由于初始字典是空的，所以会保存在 dk_entries 数组中索引为 0 的位置。</li>
<li>通过哈希函数计算出 &quot;komeiji&quot; 的哈希值，然后将哈希值映射成索引，假设是 6。</li>
<li>将 &quot;键值对&quot; 在 &quot;键值对数组&quot; 中的索引 0，保存在哈希索引数组中索引为 6 的槽里面。</li>
</ul>
<p>然后当我们在查找键 &quot;komeiji&quot; 对应的值的时候，便可瞬间定位。过程如下：</p>
<ul>
<li>通过哈希函数计算出 &quot;komeiji&quot; 的哈希值，然后映射成索引。因为在设置的时候索引是 6，所以在获取时，映射出来的索引肯定也是 6。</li>
<li>找到哈希索引数组中索引为 6 的槽，得到其保存的 0，这里的 0 对应键值对数组的索引。</li>
<li>找到键值对数组中索引为 0 的位置存储的 entry，然后判断 <code>entry-&gt;me_key</code> 和查找的 key 是否一致，不一致则重新映射。如果一致，则取出 me_value，然后返回。</li>
</ul>
<p>由于<font color="blue">哈希值计算</font>以及<font color="blue">数组索引查找</font>均是 O(1) 的时间复杂度，所以字典的查询速度才会这么快。</p>
<p>另外前面介绍哈希表的时候，为了避免牵扯太多，说得相对简化了。比如 <font color="blue">&quot;xxx&quot;: 80</font>，假设 &quot;xxx&quot; 映射出来的索引是 2，那么键值对就直接存在索引为 2 的地方。这实际上是简化了，因为这相当于把<font color="blue">哈希索引数组</font>和<font color="blue">键值对数组</font>组合在一块了，而早期的 Python 也确实是这么做的。</p>
<p>但是从上面字典的结构图中我们看到，实际上是先将键值对按照先来后到的顺序存在一个数组（<font color="blue">键值对数组</font>）中，然后再将它在键值对数组中的索引存放在另一个数组（<font color="blue">哈希索引数组</font>）的某个槽里面，因为 &quot;xxx&quot; 映射出来的是 2，所以就存在索引为 2 的槽里面。</p>
<p>而在查找的时候，映射出来的索引其实是哈希索引数组的索引。然后索引为 <font color="blue">2</font> 的槽又存储了一个<font color="red">索引</font>，这个索引是键值对数组的<font color="red">索引</font>，会再根据该索引从键值对数组里面获取指定的 entry。最后比较 key 是否相同、如果相同则返回指定的 value。</p>
<p>所以能看出两者整体思想是基本类似的，理解起来区别不大，甚至第一种方式实现起来还更简单一些。但为什么要采用后者这种实现方式，以及这两者之间的区别，我们下面来专门分析，之所以采用后者主要是基于内存的考量。</p>
<h2 id="哈希表的内存优化"><a class="header" href="#哈希表的内存优化">哈希表的内存优化</a></h2>
<p>在早期，哈希表并没有分成两个数组实现，而是只由一个键值对数组实现，这个数组也承担哈希索引数组的角色。</p>
<p><img src="./images/112.png" alt="" /></p>
<p>我们看到这种结构不正是我们在介绍哈希表时说的吗？键值对数组不仅负责存储 entry，同时也负责承载映射后的索引，而无需分成两个数组，这种方式似乎更简单、更直观。没错，Python 在早期确实是通过这种方式实现的哈希表，只是这种实现方式有一个弊端，就是太耗费内存了。</p>
<p>前面说了，基于 key 映射出的索引是随机的，所以肯定会存在索引冲突的情况，即不同的 key 映射到了同一个槽。并且随着存储的 entry 增多，冲突也会越频繁，性能也就越差。因此哈希表必须要预留一定的空间，而经过实践表明，预留的空间至少要占总容量的 1/3。换句话说，哈希表存储的 entry 的数量不能超过总容量的 2/3。</p>
<pre><code class="language-C">// Objects/dictobject.c
#define USABLE_FRACTION(n) (((n) &lt;&lt; 1)/3)
</code></pre>
<p>宏 USABLE_FRACTION 会根据哈希表的长度，或者说容量，计算出哈希表可存储的元素个数。以长度为 8 的哈希表为例，最多可以保存 5 个键值对，超出则需要扩容，显然这存在严重的内存浪费。</p>
<p>所以 Python 为了节省内存，想出了一个妙招。既然只能用 2/3，那就将键值对数组的空间变为原来的 2/3，只用来存储键值对（entry），而对 key 进行映射得到的索引则由另一个数组（哈希索引数组）来承载。假设映射出的索引是 4，那么就去找哈希索引数组中索引为 4 的槽，该槽存储的便是键值对在键值对数组中的索引。</p>
<p>之所以这么设计，是因为键值对数组里面一个元素要占用 24 字节，而哈希索引数组在容量不超过 255 的时候，里面一个元素只占一个字节，容量不超过 65535 的时候，里面一个元素只占两个字节，其它以此类推。所以哈希索引数组里面的元素大小比键值对数组要小很多，将哈希表分成两个数组（<font color="blue">避免键值对数组的浪费</font>）来实现会更加节省内存。我们可以举个例子计算一下，假设有一个容量为 65535 的哈希表。</p>
<p>如果是通过第一种方式，只用一个数组来存储的话：</p>
<pre><code class="language-python"># 总共需要 1572840 字节
&gt;&gt;&gt; 65535 * 24
1572840  
# 除以 3, 会浪费 524280 字节
&gt;&gt;&gt; 65535  * 24 // 3
524280
&gt;&gt;&gt;
</code></pre>
<p>如果是通过第二种方式，使用两个数组来存储的话：</p>
<pre><code class="language-Python"># 容量虽然是 65535
# 但键值对数组是容量的 2 / 3
# 然后加上哈希索引数组的大小
&gt;&gt;&gt; 65535 * 24 * 2 // 3 + 65535 * 2
1179630
&gt;&gt;&gt;
</code></pre>
<p>所以一个数组存储比两个数组存储要多用 393210 字节的内存，因此 Python 选择使用两个数组来存储。</p>
<p>我们再以长度为 8 的哈希表为例，画一张图对比一下，由于哈希表长度为 8，那么它最多存储 5 个键值对。</p>
<p><img src="./images/113.png" alt="" /></p>
<p>如果哈希表只使用一个键值对数组，那么基于 key 映射出的索引就是键值对数组的索引，这种方式简单直观，但内存浪费严重，因为要浪费掉 1/3 的空间。于是为了解决这个问题，哈希表选择使用两个数组实现，分别是<font color="blue">哈希索引数组</font>和<font color="blue">键值对数组</font>。</p>
<p>哈希索引数组的长度就是哈希表的长度，key 映射之后的索引也是哈希索引数组的索引，只不过它存储的不再是键值对，而是<font color="blue">键值对</font>在<font color="blue">键值对数组</font>中的索引。那么问题来了，明明多了一个数组，为啥内存占用反而变少了呢？很明显，由于引入了哈希索引数组，键值对数组的长度可以减少到原来的 2/3。</p>
<p>因为相比键值对数组，哈希索引数组的内存占用非常低，<font color="blue">引入它需要的成本</font>远小于<font color="blue">避免键值对数组浪费 1/3 所带来的收益</font>，所以使用两个数组来实现哈希表是更加合理的。</p>
<p>总结：</p>
<ul>
<li>哈希表本质上就是个数组，只不过 Python 选择使用两个数组实现，其中哈希索引数组的长度便是哈希表的容量，而该长度由 dk_size 字段维护。</li>
<li>由于哈希表最多使用 2/3，那么就只为键值对数组申请 2/3 容量的空间。对于容量为 8 的哈希表，那么哈希索引数组的长度就是 8，键值对数组的长度就是 5。</li>
<li>dk_usable 字段表示键值对数组还可以容纳的 entry 的个数，所以它的初始值也是 5。</li>
<li>dk_nentries 字段表示当前已存在的 entry 的数量，假设哈希表，或者说键值对数组存储了 3 个键值对，那么 dk_nentries 就是 3。而 dk_usable 则会变成 5 - 3 等于 2，因为它表示键值对数组还可以容纳多少 entry。</li>
</ul>
<p>咦，前面介绍 PyDictObject 的时候，看到里面有一个 ma_used 字段，表示字典的长度。那么 dk_nentries 和 ma_used 有啥区别呢，从字面意思上看，两者的含义貌似是等价的，关于这一点后续再解释。</p>
<p>最后就是 dk_indices 和 dk_entries，它们表示哈希索引数组和键值对数组。到此我们就把每个字段的含义又重新回顾了一遍，现在再来看是不是就清晰多了呢。</p>
<h2 id="字典遍历的有序性"><a class="header" href="#字典遍历的有序性">字典遍历的有序性</a></h2>
<p>我们知道 Python 从 3.6 开始，字典的遍历是有序的，那么这是怎么实现的呢？</p>
<p>其实很简单，在存储时，虽然映射之后的索引是随机的，但键值对本身始终是按照先来后到的顺序被添加进键值对数组中。而字典在 for 循环时，会直接遍历键值对数组，所以遍历的结果是有序的。但即便如此，我们也不应该依赖此特性。</p>
<p>还是以之前的图为例，我们顺序写入三个键值对，key 分别是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot;：</p>
<p><img src="./images/113.png" alt="" /></p>
<p>早期的哈希表只有一个键值对数组，而键值对在存储时本身就是无序的，那么遍历的结果自然也是无序的。对于当前来说，遍历的结果就是 &quot;b&quot;、&quot;a&quot;、&quot;c&quot;。</p>
<p>但从 3.6 开始，键值对数组中的键值对，和添加顺序是一致的。而遍历时，会直接遍历键值对数组，因此遍历的结果是有序的。对于当前来说，遍历的结果就是 &quot;a&quot;、&quot;b&quot;、&quot;c&quot;。</p>
<p>当然，如果你是 Python 的设计者，希望遍历依旧不保持有序的话，那么该怎么做呢？很简单，可以先遍历哈希索引数组，将存储的有效索引依次取出，对于当前来说就是 1、0、2。然后基于这些索引，从键值对数组中获取键值对，那么遍历的结果也是 &quot;b&quot;、&quot;a&quot;、&quot;c&quot;。</p>
<h2 id="字典的内存大小"><a class="header" href="#字典的内存大小">字典的内存大小</a></h2>
<p>下面来分析一下字典占用的内存大小，首先字典和列表一样都有容量的概念，由于空间已经申请了，不管有没有使用，大小都必须算进去。而字典的容量策略相比列表要简单很多，因为大小要满足 2 的 n 次方，所以容量一定按照 8、16、32、64、······ 进行变化。</p>
<p>注意：字典的容量（或者说哈希表的容量）指的是内部哈希索引数组的长度，它要满足 2 的 n 次方，从而将取模运算优化成按位与运算。当哈希索引数组存储的元素（键值对数组的索引）个数达到了总长度的 2/3，同时也意味着键值对数组已经满了，那么说明字典（哈希表）该扩容了。</p>
<p>知道了容量规则，我们来看一下字典的内存大小怎么计算。</p>
<pre><code class="language-C">typedef struct {
    PyObject_HEAD               // 16 字节
    Py_ssize_t ma_used;         // 8 字节
    uint64_t ma_version_tag;    // 8 字节
    PyDictKeysObject *ma_keys;  // 8 字节
    PyObject **ma_values;       // 8 字节
} PyDictObject;
// 所以 PyDictObject 实例占 48 字节

struct _dictkeysobject {
    Py_ssize_t dk_refcnt;        // 8 字节
    Py_ssize_t dk_size;          // 8 字节
    dict_lookup_func dk_lookup;  // 8 字节
    Py_ssize_t dk_usable;        // 8 字节
    Py_ssize_t dk_nentries;      // 8 字节
    char dk_indices[];
    // 隐藏字段 dk_entries
};

// 如果不算哈希索引数组 dk_indices 和键值对数组 dk_entries
// 那么 PyDictKeysObject 实例占 40 个字节
</code></pre>
<p>然后是剩余的两个数组，一个是哈希索引数组 dk_indices，里面 1 个元素可能占 1 字节、2 字节、或 4 字节；还有一个键值对数组 dk_entries，里面一个元素占 24 字节。所以对于容量为 n 的字典来说：</p>
<ul>
<li>如果 n &lt; 256，字典大小等于 48 + 40 + n + n * 2 // 3 * 24</li>
<li>如果 256 &lt;= n &lt; 65536，字典大小等于 48 + 40 + n * 2 + n * 2 // 3 * 24</li>
<li>如果 n &gt;= 65536，字典大小等于 48 + 40 + n * 4 + n * 2 // 3 * 24</li>
</ul>
<p>所以对于一个容量为 8 的字典，它的大小就是 48 + 40 + 8 + 120 = 216。</p>
<pre><code class="language-Python"># 字典的初始容量为 8，所以大小为 216
&gt;&gt;&gt; dict().__sizeof__()
216

# 注：如果你是通过字面量的方式创建空字典，那么容量是 0
# 显然大小就是 48 字节，因为此时 ma_keys 为 NULL
&gt;&gt;&gt; {}.__sizeof__()
48
</code></pre>
<p>那么问题来了，如果一个字典包含 78 个键值对，那么这个字典占多大内存呢？既然有 78 个键值对，那么键值对数组 dk_entries 的长度至少为 78，而它又等于哈希表容量的 2/3，所以哈希表的长度至少为 117。由于哈希表的长度满足 2 的 n 次幂，所以我们只需找到大于等于 117 的最小 2 的幂次方数即可，显然这个数是 128。</p>
<p>所以大小有了，包含 78 个键值对的字典所占的内存大小等于 48 + 40 + 128 + 128 * 2 // 3 * 24。</p>
<pre><code class="language-Python">&gt;&gt;&gt; 48 + 40 + 128 + 128 * 2 // 3 * 24
2256
&gt;&gt;&gt; dict.fromkeys(range(78)).__sizeof__()
2256
</code></pre>
<p>结果没有问题，再来个复杂点的，对于包含 12345 个键值对的字典，占用多大内存呢？</p>
<pre><code class="language-Python">&gt;&gt;&gt; import math
&gt;&gt;&gt; math.log2(12345 * 3 / 2)
14.1766017167513
&gt;&gt;&gt; 2 ** 15
32768
</code></pre>
<p>计算结果表明，对于包含 12345 个键值对的字典，哈希表的长度至少为 2 的 14.17... 次方，而实际的长度显然是 2 的 15 次方，那么大小就出来了。另外注意：因为长度超过了 255，所以哈希索引数组中的一个元素占两字节。</p>
<pre><code class="language-Python">&gt;&gt;&gt; 48 + 40 + 32768 * 2 + 32768 * 2 // 3 * 24
589904
&gt;&gt;&gt; dict.fromkeys(range(12345)).__sizeof__()
589904
</code></pre>
<p>结果和我们分析的一样，以上我们就计算出了字典的内存大小，你也可以自己创建个字典测试一下。</p>
<h2 id="小结-31"><a class="header" href="#小结-31">小结</a></h2>
<p>通过研究字典的具体实现，我们可以得出以下结论：</p>
<ul>
<li>字典是一种高效的映射型容器，能够以 O(1) 的时间复杂度执行查询和写入操作；</li>
<li>字典之所以这么快，是因为它由哈希表实现。但快是要付出代价的，哈希表必须保证一定的稀疏性，否则会频繁出现索引冲突，导致哈希表性能下降，因为索引映射是随机的；</li>
<li>既然哈希表要保证稀疏性，就意味着内存开销大，因为存在内存浪费。</li>
<li>但 Python 为优化内存使用，选择基于两个数组来实现哈希表，通过避免键值对数组的浪费，来减少内存占用；</li>
<li>键值对数组里的 entry 除了保存 key 和 value 之外，还保存了 key 的哈希值。</li>
</ul>
<p>以上就是字典的底层实现，但是还没有结束，哈希表的背后还隐藏了很多细节，我们就下一篇文章再聊吧。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>通过研究字典的底层实现，我们找到了字典快速且高效的秘密，就是哈希表。而提到哈希表，必然绕不开哈希值，因为它决定了映射之后的索引。</p>
<p>如果想计算对象的哈希值，那么要保证对象必须是可哈希的。如果不可哈希，那么它就无法计算哈希值，自然也就无法作为字典的 key。那什么样的对象是可哈希的呢？</p>
<ul>
<li>因为哈希值不能发生改变，所以对象必须是不可变对象；</li>
<li>当对象的哈希值相等时，要判断对象是否相等，所以对象必须实现 __eq__ 方法；</li>
</ul>
<p>所以如果对象满足不可变、并且实现了 __eq__  方法，那么它就是可哈希的，只有这样的对象才能作为字典的 key 或者集合的元素。</p>
<p>像整数、浮点数、字符串等内置的不可变对象都是可哈希的，可以作为字典的 key。而像列表、字典等可变对象则不是可哈希的，它们不可以作为字典的 key。然后关于元组需要单独说明，如果元组里面的元素都是可哈希的，那么该元组也是可哈希的，反之则不是。</p>
<pre><code class="language-python"># 键是可哈希的就行，值是否可哈希则没有要求
d = {1: 1, &quot;xxx&quot;: [1, 2, 3], 3.14: 333}

# 列表是可变对象，因此无法哈希
try:
    d = {[]: 123}
except TypeError as e:
    print(e)
    &quot;&quot;&quot;
    unhashable type: 'list'
    &quot;&quot;&quot;

# 元组也是可哈希的
d = {(1, 2, 3): 123}

# 但如果元组里面包含了不可哈希的对象
# 那么整体也会变成不可哈希对象
try:
    d = {(1, 2, 3, []): 123}
except TypeError as e:
    print(e)
    &quot;&quot;&quot;
    unhashable type: 'list'
    &quot;&quot;&quot;
</code></pre>
<p>而我们自定义类的实例对象也是可哈希的，并且哈希值是通过对象的地址计算得到的。</p>
<pre><code class="language-python">class Some:
    pass

s1 = Some()
s2 = Some()
print(hash(s1), hash(s2))
&quot;&quot;&quot;
8744065697364 8744065697355
&quot;&quot;&quot;
</code></pre>
<p>当然 Python 也支持我们重写哈希函数，比如：</p>
<pre><code class="language-Python">class Some:

    def __hash__(self):
        return 123

s1 = Some()
s2 = Some()
print(hash(s1), hash(s2))
&quot;&quot;&quot;
123 123
&quot;&quot;&quot;
print({s1: 1, s2: 2})
&quot;&quot;&quot;
{&lt;__main__.Some object at 0x0000029C0ED045E0&gt;: 1, 
 &lt;__main__.Some object at 0x0000029C5E116F20&gt;: 2}
&quot;&quot;&quot;
</code></pre>
<p>因为哈希值一样，映射出来的索引自然也是相同的，所以在作为字典的 key 时，会发生冲突。由于类的实例对象之间默认不相等，因此会改变规则重新映射，找一个可以写入的位置。</p>
<blockquote>
<p>如果两个对象相等，它们的哈希值一定也相等。</p>
</blockquote>
<p>注意：我们自定义类的实例对象默认都是可哈希的，但如果类里面重写了 __eq__，并且没有重写 __hash__ 的话，那么这个类的实例对象就不可哈希了。</p>
<pre><code class="language-python">class Some:

    def __eq__(self, other):
        return True

try:
    hash(Some())
except TypeError as e:
    print(e)
    &quot;&quot;&quot;
    unhashable type: 'Some'
    &quot;&quot;&quot;
</code></pre>
<p>为什么会有这种现象呢？首先上面说了，在没有重写 __hash__ 方法的时候，哈希值默认是根据对象的地址计算得到的。而且对象如果相等，那么哈希值一定是一样的，并且不可变。</p>
<p>但我们重写了 __eq__，相当于控制了 == 操作符的比较结果，两个对象是否相等就由我们来控制了，可哈希值却还是根据地址计算得到的。因为两个对象地址不同，所以哈希值不同，但是对象却可以相等、又可以不相等，这就导致了矛盾。所以在重写了 __eq__、但是没有重写 __hash__ 的情况下，其实例对象便不可哈希了。</p>
<p>但如果重写了 __hash__，那么哈希值就不再通过地址计算了，因此此时是可以哈希的。</p>
<pre><code class="language-Python">class Some:

    def __eq__(self, other):
        return True

    def __hash__(self):
        return 123

s1 = Some()
s2 = Some()
print({s1: 1, s2: 2})
&quot;&quot;&quot;
{&lt;__main__.Some object at 0x00000202D7D945E0&gt;: 2}
&quot;&quot;&quot;
</code></pre>
<p>我们看到字典里面只有一个元素，因为重写了 __hash__ 方法之后，计算得到的哈希值都是一样的。如果没有重写 __eq__，实例对象之间默认是不相等的，因此哈希值一样，但是对象不相等，那么会重新映射。但我们重写了 __eq__，返回的结果是 True，所以 Python 认为对象是相等的，那么由于 key 的不重复性，只会保留一个键值对。</p>
<p>但需要注意的是，在比较相等时，会先比较地址是否一样，如果地址一样，那么哈希表会直接认为相等。</p>
<pre><code class="language-python">class Some:

    def __eq__(self, other):
        return False

    def __hash__(self):
        return 123

    def __repr__(self):
        return &quot;Some Instance&quot;

s1 = Some()
# 我们看到 s1 == s1 为 False
print(s1 == s1)
&quot;&quot;&quot;
False
&quot;&quot;&quot;
# 但是只保留了一个 key，咦，两个 key 不相等，难道不应该重新映射吗？
# 原因就是刚才说的，在比较是否相等之前，会先判断地址是否一样
# 如果地址一样，那么认为是同一个 key，直接判定相等
print({s1: 1, s1: 2})
&quot;&quot;&quot;
{Some Instance: 2}
&quot;&quot;&quot;

s2 = Some()
# 此时会保留两个 key，因为 s1 和 s2 地址不同，s1 == s2 也为 False
# 所以哈希表认为这是两个不同的 key
# 但由于哈希值一样，那么映射出来的索引也一样
# 因此写入 s2: 2 时相当于发生了索引冲突，于是会重新映射
# 但总之这两个 key 都会被保留
print({s1: 1, s2: 2})  
&quot;&quot;&quot;
{Some Instance: 1, Some Instance: 2}
&quot;&quot;&quot;
</code></pre>
<p>同样的，我们再来看一个 Python 字典的例子。</p>
<pre><code class="language-Python">d = {1: 123}

d[1.0] = 234
print(d)  # {1: 234}

d[True] = 345
print(d)  # {1: 345}
</code></pre>
<p>天哪噜，这是咋回事？首先整数在计算哈希值的时候，得到的结果就是其本身；而浮点数显然不是，但如果浮点数的小数点后面是 0，那么它和整数是等价的。</p>
<p>因此 1 和 1.0 的哈希值一样，并且两者也是相等的，因此它们被视为同一个 key，所以相当于是更新。同理 True 也一样，因为 bool 继承自 int，所以它等价于 1，比如：9 + True = 10。因此 True 和 1 相等，并且哈希值也相等，那么索引 <font color="blue">d[True] = 345</font> 同样相当于更新。</p>
<p>但是问题来了，值更新了我们可以理解，字典里面只有一个元素也可以理解，可为什么 key 一直是 1 呢？理论上最终结果应该是 True 才对啊。其实这算是 Python 偷了个懒吧（开个玩笑），因为 key 的哈希值是一样的，并且也相等，所以只会更新 value，而不会修改 key。</p>
<p>为了加深理解，我们再举个例子：</p>
<pre><code class="language-Python">d = {&quot;高老师&quot;: 666}

class A:
    def __hash__(self):
        return hash(&quot;高老师&quot;)

    def __eq__(self, other):
        return True

# A() == &quot;高老师&quot; 为 True，两者哈希值也一样
# 所以相当于对 key 进行更新
d[A()] = 777
print(d)  # {'高老师': 777}

print(d[&quot;高老师&quot;])  # 777
print(d[A()])  # 777
</code></pre>
<p>只要两个对象相等，并且哈希值相等，那么对于哈希表来说，它们就是同一个 key。</p>
<p><strong>另外我们反复在提哈希值，而哈希值是通过哈希函数运算得到的，一个理想的哈希函数要保证哈希值尽量均匀地分布于整个哈希空间中，越是相近的值，其哈希值差别应该越大。还是那句话，哈希函数对哈希表的好坏起着至关重要的作用。</strong></p>
<p>以上我们就详细地聊了聊对象的哈希值，如果对象可以计算哈希值，那么它一定实现了 __hash__ 方法，而内置的不可变对象都实现了。另外内置的哈希函数 hash，本质上也是调用了 __hash__。</p>
<pre><code class="language-Python">print(hash(&quot;hello&quot;))
print(&quot;hello&quot;.__hash__())
&quot;&quot;&quot;
-7465190714692855315
-7465190714692855315
&quot;&quot;&quot;
</code></pre>
<p>下一篇文章来聊一聊索引冲突是怎么解决的？</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-32"><a class="header" href="#楔子-32">楔子</a></h2>
<p>两个对象的哈希值相等，那么映射出的索引肯定相同。而如果哈希值不相等，映射出的索引也有可能相同，因为与哈希值空间相比，哈希表的槽位是非常有限的。如果不同的对象在经过映射之后，生成的索引相同，或者说它们被映射到了同一个槽，那么便发生了<font color="blue">索引冲突</font>。</p>
<p><img src="./images/115.png" alt="" /></p>
<p>解决索引冲突的常用方法有两种：分离链接法和开放寻址法。</p>
<p>分离链接法比较简单，如果有多个键值对映射到同一槽位，那么就用链表将它们串起来。然后是开放寻址法，这也是 Python 使用的方法，我们详细介绍一下。</p>
<h2 id="开放寻址法"><a class="header" href="#开放寻址法">开放寻址法</a></h2>
<p>首先将 key 映射成索引，但如果发现该索引对应的哈希槽被占了，那么就尝试另一个。</p>
<p><img src="./images/116.png" alt="" /></p>
<p>new_key 被映射到了索引为 5 的槽，但是该槽已经存储了键值对数组的索引，即该槽被占了。如果是分离链接法，那么会使用链表将两个 entry 串起来，但开放寻址法则是选择一个新的槽，也就是重新找个坑。</p>
<p>那么问题来了，新的槽要怎么找呢？一般来说，会在首槽的基础上增加一个偏移量，得到新的槽，如果还冲突，那么继续增加偏移量，直到找到一个可用的槽。总的来说就是一个不断探测的过程，每一次探测都会尝试增加偏移量。</p>
<p>所以新的问题又产生了，每次增加的偏移量是多少呢？其实这个问题取决于具体实现，如果偏移量是线性增加的，我们称之为<font color="blue">线性探测</font>；如果偏移量是平方增加的，我们称之为<font color="blue">平方探测</font>。</p>
<p>但不管是线性探测，还是平方探测，其实都不够好。因为偏移量始终是以一种固定的模式增加，这就导致映射到同一槽位的两个 key 的探测序列是相同的。</p>
<p><img src="./images/117.png" alt="" /></p>
<p>比如这里的 key1 和 key2，它们的哈希值不同，但都映射到了索引为 2 的槽，这是完全正常的，因为哈希表的槽位有限。而由于偏移量的增加方式是固定的，比如这里每次都增加 2，再加上首槽相同，因此它们的探测序列也相同，显然这会导致后续出现多次冲突。</p>
<p>所以 Python 对此进行了优化，探测函数在发现索引冲突时，不会简单地增加一个偏移量，而是会参考对象的哈希值，计算下一个候选位置，这就大大降低了冲突的可能性。</p>
<p>Python 的这种做法被称为<font color="blue">迭代探测</font>，当然迭代探测也属于开放寻址法的一种。所以当出现索引冲突时，Python 并不是简简单单地加上一个偏移量，而是使用专门设计的探测函数进行二次探查，也就是之前说的<font color="blue">改变规则、重新映射</font>，然后在函数内部会参考对象的哈希值来计算出一个新的索引。</p>
<p><img src="./images/118.png" alt="" /></p>
<p>在 dictobject.c 文件开头有着大量的注释，对字典进行了全局性的概括，当然具体细节我们都会详细说明。</p>
<h2 id="探测函数"><a class="header" href="#探测函数">探测函数</a></h2>
<p>当存储键值对时，要将 key 映射成索引，这个索引就是哈希索引数组的索引。至于具体的映射过程由探测函数负责，即 PyDictKeysObject 结构体内部的 dk_lookup 字段。</p>
<p>Python 为哈希表搜索提供了多种探测函数：</p>
<ul>
<li>lookdict_unicode：专门针对 key 为字符串的 entry。</li>
<li>lookdict_index：专门针对 key 为整数的 entry。</li>
<li>lookdict：通用逻辑，可以把 lookdict_unicode、lookdict_index 看成 lookdict 的特殊实现，只不过 key 是整数和字符串的场景非常常见，因此为其单独实现了一个函数。</li>
</ul>
<p>我们这里重点看一下 lookdict 的函数实现，不过在介绍之前，先来看几个宏。</p>
<pre><code class="language-c">// Objects/dictobject.c

// 获取哈希表的长度，或者说哈希索引数组的长度
#define DK_SIZE(dk) ((dk)-&gt;dk_size)

// 哈希表的长度减 1，将 key 的哈希值和它按位与，便可将 key 映射成索引
// 因为 dk_size 满足 2 的 n 次方，所以 hash % dk_size 等价于 hash &amp; (dk_size - 1)
#define DK_MASK(dk) (((dk)-&gt;dk_size)-1)

// 获取哈希索引数组中每个元素的大小，数组的长度不同，每个元素的大小不同
// dk_size &lt;= 255，每个元素 1 字节
// 256 &lt;= dk_size &lt;= 65535，每个元素 2 字节
// 65536 &lt;= dk_size &lt;= 4294967295，每个元素 4 字节
// dk_size &gt;= 4294967296，每个元素 8 字节
// 由于字典的键值对个数基本不会超过 4294967295，所以我们认为元素的大小就是 1、2 或者 4 字节
#define DK_IXSIZE(dk)                          \
    (DK_SIZE(dk) &lt;= 0xff ?                     \
        1 : DK_SIZE(dk) &lt;= 0xffff ?            \
            2 : DK_SIZE(dk) &lt;= 0xffffffff ?    \
                4 : sizeof(int64_t))

// 获取紧跟在 PyDictKeysObject 结构体后面的键值对数组
// 这个和前面介绍字符串时，获取 PyASCIIObject 结构体后面的字符数组是类似的
// 主要是利用 C 语言指针的技巧（甚至都不能算技巧），这里再来详细介绍一下
// 假设有一个 int *a，那么 a + 3 和 a[3] 是等价的，都会向后偏移 3 个 int，即 12 字节
// 那么问题来了，对于任意类型的指针 T *p，如果想向后偏移 n 个字节，该怎么做呢？
// 很简单，将 p 加上 n / sizeof(T) 即可，但问题是 n / sizeof(T) 不一定是个整数啊
// 因此我们可以将指针转成 int8_t *，然后再加上 n，这样就会偏移 sizeof(int8_t) * n 个字节，即 n 个字节
// 比如 ((int8_t *)p) + n 或者 ((int8_t *)p)[n]
// 然后再来看 DK_ENTRIES 这个宏的逻辑，由于键值对数组紧跟在哈希索引数组后面
// 所以通过 (dk)-&gt;dk_indices 获取哈希索引数组，然后转成 int8_t * 类型
// 而 DK_SIZE(dk) * DK_IXSIZE(dk) 显然是哈希索引数组所占的内存大小
// 然后让 (int8_t*)((dk)-&gt;dk_indices) 向后偏移这些字节，不就定位到键值对数组的首元素了吗
#define DK_ENTRIES(dk) \
    ((PyDictKeyEntry*)(&amp;((int8_t*)((dk)-&gt;dk_indices))[DK_SIZE(dk) * DK_IXSIZE(dk)]))

// Objects/dict-common.h
#define DKIX_EMPTY (-1)
#define DKIX_DUMMY (-2)  /* Used internally */
#define DKIX_ERROR (-3)
</code></pre>
<p>以上就是常用的几个宏，然后来看探测函数 lookdict 的逻辑。</p>
<pre><code class="language-c">// Objects/dictobject.c

#define PERTURB_SHIFT 5

// 基于哈希索引数组的索引，获取指定的哈希槽里面存储的键值对数组的索引
static inline Py_ssize_t
dictkeys_get_index(PyDictKeysObject *keys, Py_ssize_t i)
{
    // 哈希表的长度
    Py_ssize_t s = DK_SIZE(keys);
    // 键值对数组的索引
    Py_ssize_t ix;
    // 如果哈希表的长度小于 1 &lt;&lt; 8，哈希索引数组的每个元素占 1 字节
    if (s &lt;= 0xff) {
        int8_t *indices = (int8_t*)(keys-&gt;dk_indices);
        ix = indices[i];
    }
    // 如果哈希表的长度小于 1 &lt;&lt; 16，哈希索引数组的每个元素占 2 字节
    // 指针类型要转成 int16_t *，这样获取元素时会获取两个字节
    else if (s &lt;= 0xffff) {
        int16_t *indices = (int16_t*)(keys-&gt;dk_indices);
        ix = indices[i];
    }
    // 如果哈希表的长度大于等于 1 &lt;&lt; 32，哈希索引数组的每个元素占 8 字节（no way）
#if SIZEOF_VOID_P &gt; 4
    else if (s &gt; 0xffffffff) {
        int64_t *indices = (int64_t*)(keys-&gt;dk_indices);
        ix = indices[i];
    }
#endif
    // 否则哈希索引数组的每个元素占 4 字节
    else {
        int32_t *indices = (int32_t*)(keys-&gt;dk_indices);
        ix = indices[i];
    }
    assert(ix &gt;= DKIX_DUMMY);
    // 返回键值对数组的索引
    return ix;
}

// 探测函数
static Py_ssize_t _Py_HOT_FUNCTION
lookdict(PyDictObject *mp, PyObject *key,
         Py_hash_t hash, PyObject **value_addr)
{
    // 将 key 映射成索引，这个索引就是哈希索引数组的索引
    /* 参数 mp：指向字典的指针
     * 参数 key：指向键的指针
     * 参数 hash：键的哈希值
     * 参数 value_addr：值的二级指针
     */    
  
    size_t i, mask, perturb;
    PyDictKeysObject *dk;
    PyDictKeyEntry *ep0;

top:
    // 指向 PyDictKeysObject 对象
    dk = mp-&gt;ma_keys;
    // 获取 PyDictKeysObject 内部的 dk_entries，即键值对数组
    ep0 = DK_ENTRIES(dk);
    // 哈希表的长度减 1
    mask = DK_MASK(dk);
    // perturb，初始值等于参数 hash，即 key 的哈希值
    perturb = hash;
    // 将哈希值和 mask 按位与，计算出哈希索引数组的索引
    i = (size_t)hash &amp; mask;
    for (;;) {
        // 基于哈希索引数组的索引，从指定的哈希槽中获取键值对数组的索引
        Py_ssize_t ix = dictkeys_get_index(dk, i);
        // 哈希索引数组里面的元素初始为 -1，如果 ix == -1
        // 证明当前 key 映射出的哈希槽，还没有存储键值对数组的某个索引
        // 这就意味着当前要查找的 key 不存在，此时直接返回 -1 即可
        if (ix == DKIX_EMPTY) {
            *value_addr = NULL;
            return ix;
        }
        // 如果 ix &gt;= 0，说明确实存储了一个合法的键值对数组的索引
        if (ix &gt;= 0) {
            // ep0 是键值对数组，基于索引 ix 获取里面的键值对
            PyDictKeyEntry *ep = &amp;ep0[ix];
            assert(ep-&gt;me_key != NULL);
            // ep-&gt;me_key 和变量 key 都是指针
            // 如果这两者相等，说明指向了同一个对象（字符串），显然查找的 key 已在字典中
            if (ep-&gt;me_key == key) {
                // 该函数不光要返回索引，还要返回 value，但 C 是单返回值语言，怎么办呢？
                // 只需要在调用函数时传个指针过来即可，会在函数内部进行修改
                // 由于 Python 的变量、容器存储的元素本身就是指针，所以 value_addr 是个二级指针
                *value_addr = ep-&gt;me_value;
                // 返回键值对数组的索引
                return ix;
            }
            // 如果 ep-&gt;me_key != key，说明两者指向的不是同一个对象
            // 那么就比较两个对象本身以及哈希值是否相等，如果相等，也表示 key 已存在
            if (ep-&gt;me_hash == hash) {  // 先保证哈希值相等
                PyObject *startkey = ep-&gt;me_key;
                Py_INCREF(startkey);
                // cmp 大于 0 说明比较结果为真，等于 0 说明比较结果为假，小于 0 说明比较时出现错误
                int cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
                Py_DECREF(startkey);
                if (cmp &lt; 0) {
                    *value_addr = NULL;
                    return DKIX_ERROR;
                }     
                // 可能有人觉得这里的 if 是不是有点多余，这肯定百分百成立啊
                // 其实这一步主要是为了检测字典是否被修改（不用关注）
                if (dk == mp-&gt;ma_keys &amp;&amp; ep-&gt;me_key == startkey) {
                    // 如果 cmp &gt; 0，说明两个对象相等，那么修改 *value_addr，返回 ix
                    if (cmp &gt; 0) {
                        *value_addr = ep-&gt;me_value;
                        return ix;
                    }
                }
                else {
                    // 字典如果被修改，那么重头来，这里不用关注
                    goto top;
                }
            }
        }
        // 走到这里说明 ix 是合法的，但是对应的 entry-&gt;me_key 和当前要查找的 key 不相等
        // 显然出现了索引冲突，于是将哈希值右移 5 位
        perturb &gt;&gt;= PERTURB_SHIFT;
        // 然后加上 i*5 + 1，并重新和 mask 按位与，得到新的哈希索引数组的索引
        // 也就是之前说的，改变规则、重新映射
        i = (i*5 + perturb + 1) &amp; mask;
    }
    Py_UNREACHABLE();
}
</code></pre>
<p>以上就是 lookdict 函数的逻辑，至于 lookdict_index 和 lookdict_unicode 与之是类似的。</p>
<p>我们将逻辑再描述一遍，首先 perturb 初始等于 key 的哈希值，mask 等于哈希表的长度减一，然后执行 <font color="blue">perturb &amp; mask</font> 便可得到一个索引。这个过程就是我们说的索引映射，映射出的索引便是<font color="blue">哈希索引数组的索引</font>，然后该索引对应的哈希槽又存储了一个<font color="red">索引</font>，这个索引是<font color="red">键值对数组的索引</font>。</p>
<p><img src="./images/119.png" alt="" /></p>
<p>哈希索引数组里面的一个位置我们称之为一个槽，如果映射出来的索引对应的哈希槽中存储的<font color="blue">键值对数组的索引</font>小于 0，说明该 key 对应的键值对还没有被存储过，那么直接返回初始值 -1 即可。</p>
<p>如果存储的键值对数组的索引（源码中的 ix）大于等于 0，说明已经存储了一个键值对，它的 key 和查找的 key 映射出的索引是相同的。然后比较 key 是否相等，如果相等，说明已经找到了，那么直接返回 ix 即可。如果 key 不相等，说明出现索引冲突了，那么要改变策略，重新映射。</p>
<pre><code class="language-c">perturb &gt;&gt;= PERTURB_SHIFT;
i = mask &amp; (i*5 + perturb + 1);
</code></pre>
<p>变量 i 便是映射出的哈希索引数组的索引，但发生冲突了，于是将 perturb 右移 5 位，然后加上 <font color="blue">perturb + i * 5 + 1</font>，再和 mask 按位与计算出新的 i。至于为什么要选择这种做法，这是 Python 官方经过多次实践得出来的结论。</p>
<p>当 lookdict 执行完之后，外界就拿到了指定的 key 对应的键值对数组的索引，并且也能拿到 key 对应的 value（key 若不存在就是 NULL）。但是还没结束，我们看到 lookdict 返回的是变量 ix，而变量 i 才是我们需要的。</p>
<p><font color="blue">变量 i</font> 表示<font color="blue">槽</font>的索引，变量 ix 表示该<font color="blue">槽</font>存储的键值对数组的索引。由于我们是要寻找指定的槽，那么返回的应该是<font color="blue">槽的位置</font>、也就是<font color="blue">变量 i</font> 才对啊，为啥要返回<font color="blue">变量 ix</font> 呢？别急，往下看。</p>
<pre><code class="language-C">#define DKIX_EMPTY (-1)
</code></pre>
<p>初始状态下，槽存储的都是 -1，表示当前槽是可用的。如果存储的索引大于等于 0，则表示该槽已经被占用了，当 key 不相等时会改变规则重新映射。总之最终的结果是：</p>
<ul>
<li>如果 key 存在，那么返回的 ix 就是该 key 对应的键值对在键值对数组中的索引，此时 ix 大于等于 0；</li>
<li>如果 key 不存在，那么返回的 ix 就是哈希槽的初始值 -1。</li>
</ul>
<p>所以 lookdict 函数只是告诉我们当前 key 在哈希表中是否存在，如果要获取槽的索引，即 lookdict 里面的<font color="blue">变量 i</font>，那么还需要另外两个函数。</p>
<ul>
<li>find_empty_slot：如果 lookdict 返回的 ix 小于 0，说明 key 不存在，那么调用该函数返回槽的索引。</li>
<li>lookdict_index：如果 lookdict 返回的 ix 大于等于 0，说明 key 存在，那么调用该函数返回槽的索引。</li>
</ul>
<p>所以这两个函数做的事情是一样的，都是返回槽的索引，我们看一下具体实现。</p>
<pre><code class="language-C">// Objects/dictobject.c

static Py_ssize_t
find_empty_slot(PyDictKeysObject *keys, Py_hash_t hash)
{
    assert(keys != NULL);

    const size_t mask = DK_MASK(keys);
    // 获取槽的索引 i
    size_t i = hash &amp; mask;
    // 获取槽存储的索引 ix
    Py_ssize_t ix = dictkeys_get_index(keys, i);
    // 不停映射，直到 ix 小于 0
    // 因为调用该函数时已经说明 key 不存在了
    // 所以最终一定会映射到一个空槽
    for (size_t perturb = hash; ix &gt;= 0;) {
        perturb &gt;&gt;= PERTURB_SHIFT;
        // 映射的逻辑是相同的
        i = (i*5 + perturb + 1) &amp; mask;
        ix = dictkeys_get_index(keys, i);
    }
    // 当 ix 小于 0 时，便找到了槽的索引
    return i;
}

static Py_ssize_t
lookdict_index(PyDictKeysObject *k, Py_hash_t hash, Py_ssize_t index)
{
    size_t mask = DK_MASK(k);
    size_t perturb = (size_t)hash;
    size_t i = (size_t)hash &amp; mask;

    for (;;) {
        // 基于槽的索引 i，获取槽存储的索引 ix
        Py_ssize_t ix = dictkeys_get_index(k, i);
        // 参数 index 就是 lookdict 函数返回的 ix
        // 如果 ix 和 index 是相等的，说明此时的 i 就是要获取的槽的索引
        if (ix == index) {
            return i;
        }
        if (ix == DKIX_EMPTY) {
            return DKIX_EMPTY;
        }
        // 整个映射逻辑都是一样的
        // 因为在 lookdict 函数中只返回了 ix，即参数 index
        // 所以要按照相同的规则再映射一次，如果映射出的 ix 和 index 相等
        // 那么我们就找到了槽的索引 i，并且索引为 i 的槽存储的就是 index
        perturb &gt;&gt;= PERTURB_SHIFT;
        i = mask &amp; (i*5 + perturb + 1);
    }
    Py_UNREACHABLE();
}
</code></pre>
<p>所以我们说的探测函数应该是 lookdict 和 find_empty_slot、lookdict_index 的组合。</p>
<ul>
<li>lookdict 负责返回<font color="red">槽存储的索引</font>，用于判断 key 是否存在。</li>
<li>find_empty_slot、lookdict_index 则负责返回<font color="red">槽的索引</font>，即 key 最终被映射到了哪一个槽。</li>
</ul>
<p>另外还有一点，我们之前说索引冲突时，会执行探测函数计算新的存储位置。其实不管有没有发生冲突，即使存储键值对的时候哈希表是空的，也要执行探测函数，毕竟探测函数的目的就是基于哈希值映射出一个合适的槽。如果探测函数执行的时候发现索引冲突了，也就是槽里的索引 <font color="blue">ix &gt;= 0</font>，并且 key 还不相等，那么会改变规则重新映射。</p>
<p>因此在存储某个键值对时，无论索引冲突多少次，探测函数只会执行一次。在探测函数里面，会不断尝试解决冲突，直到映射出一个可用的槽。</p>
<h2 id="小结-32"><a class="header" href="#小结-32">小结</a></h2>
<p>以上就是索引映射的具体逻辑，以及出现冲突是怎么解决的。就是先用哈希函数计算出 key 的哈希值，然后作为参数传递到探测函数中。在探测函数里面，会将哈希值和 mask 按位与，得到索引。如果索引冲突了，那么会改变规则，这里的规则如下：</p>
<pre><code class="language-C">// 将哈希值右移 PERTURB_SHIFT 个位
perturb &gt;&gt;= PERTURB_SHIFT;
// 然后将哈希值加上 i*5 + 1，这个 i 就是当前冲突的索引
// 运算之后的结果再和 mask 按位与，得到一个新的 i
// 然后判断变量 i 对应的槽是否可用，不可用则重复当前逻辑，直到出现一个可用的槽
i = (i*5 + perturb + 1) &amp; mask;
</code></pre>
<p>所以 Python 在索引冲突时，并不像线性探测和平方探测那样，简单地加一个固定的偏移量，而是参考对象的哈希值计算出一个新的索引。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="哈希表能直接删除元素吗"><a class="header" href="#哈希表能直接删除元素吗">哈希表能直接删除元素吗</a></h2>
<p>通过前面的学习，我们知道哈希表这种数据结构的逻辑是先通过哈希函数计算出键（key）的哈希值，然后将哈希值传递到探测函数中，映射成一个索引，最终通过索引去访问连续的内存区域。而哈希表这种数据结构，最终目的就是加速键的搜索过程。</p>
<p>但索引会存在冲突，并且键值对数量越多，映射出的索引出现冲突的概率越高。而如果冲突了，就改变规则重新映射，这种做法叫做开放寻址法。当发生冲突时，在探测函数内部会参考哈希值以及冲突的索引，计算下一个候选位置，并判断是否可用。如果不可用，会继续重复此过程，直到找到一个可用的位置。</p>
<p>通过多次探测，会经过多个位置，我们认为这些位置就形成了一个<font color="blue">冲突探测链（探测序列）</font>，下面举例说明。</p>
<blockquote>
<p>为了描述方便，我们后续偶尔会用 dk_indices 表示哈希索引数组、用 dk_entries 表示键值对数组、用 entry 表示键值对（包含两个字段：me_key 和 me_value，分别表示键和值）。当然在源码中，它们也是这个名字。</p>
<p>key 映射之后的索引是哈希索引数组的索引，我们记作 i，该索引对应的哈希槽中又存储了一个索引（entry 在键值对数组中的索引），我们记作 ix。那么 <font color="blue">ix = dk_indices[i]</font>，对应的 <font color="blue">entry = dk_entries[ix]</font>。</p>
</blockquote>
<p>比如插入一个 key 等于 &quot;satori&quot; 的键值对，它映射到了索引为 a 的槽，但是该槽已经被占用了，那么 <font color="blue">dk_entries[dk_indices[a]]</font> 便是使用该槽的 entry，但它的 key 不等于 &quot;satori&quot;，说明出现了索引冲突。于是重新映射，映射到索引为 b 的槽，发现依旧不行。那么只能再次映射，映射到索引为 c 的槽，发现该槽存储的索引是 -1，说明该槽还没有人用，于是将键值对追加到 dk_entries 中，并把它在 dk_entries 中的索引存在该槽中。</p>
<p>那么经过以上流程，<code>a -&gt; b -&gt; c</code> 便形成了一条冲突探测链，同理我们查找的时候也会按照这个顺序进行查找。</p>
<p><img src="./images/120.png" alt="" /></p>
<p>显然上面这些东西，现在理解起来已经没什么难度了，我们基于 key 获取 value 时也是这个过程。</p>
<p>当执行 d[&quot;satori&quot;] 时，肯定会先映射到索引为 a 的槽，但 <font color="blue">dk_entries[dk_indices[a]].me_key</font> 不等于字符串 &quot;satori&quot;，于是重新映射。然后映射到索引为 b 的槽，发现还不相等，再映射到索引为 c 的槽，发现对应的键值对的 key 等于 &quot;satori&quot;，于是就把值取出来了。</p>
<p>显然以上符合我们的预期，但是，我要说但是了。如果我们把索引为 b 的槽对应的 entry 删掉呢？那么老规矩，映射成索引，先走到索引为 a 的槽，但是发现坑被占，于是又走到索引为 b 的槽，结果发现居然没有 entry，那么直接就报出了一个 KeyError。</p>
<p>所以继续寻找的前提是，哈希槽一定存储了某个 entry 在键值对数组中的索引，并且该 entry 的 key 和指定的 key 不相等。但如果发现没有 entry，直接 KeyError。</p>
<p>然而 &quot;satori&quot; 这个 key 确实是存在的，因此这种情况我们称之为<font color="red">探测链断裂</font>。本来应该走到位置 c 的，但是由于位置 b 没有对应 entry，导致探测函数在位置 b 就停止了。</p>
<p>因此我们发现，当一个 entry 只要位于任何一条探测链当中，在删除时都不能执行真正意义上的删除，而是要进行伪删除。那什么是伪删除呢？别着急，先往下看。</p>
<h2 id="哈希槽的几种状态"><a class="header" href="#哈希槽的几种状态">哈希槽的几种状态</a></h2>
<p>哈希槽有以下几种状态：</p>
<ul>
<li>Unused；</li>
<li>Active；</li>
<li>Dummy；</li>
</ul>
<p>来解释一下它们的含义。</p>
<pre><code class="language-C">// Objects/dict-common.h
#define DKIX_EMPTY (-1)
#define DKIX_DUMMY (-2)  /* Used internally */
#define DKIX_ERROR (-3)
</code></pre>
<p>上面几个宏非常重要，当然主要是前两个宏。</p>
<p><font color="darkblue"><strong>Unused 态</strong></font></p>
<p>如果没有 key 映射到指定的哈希槽，那么该哈希槽存储的索引就是 -1，即 DKIX_EMPTY，表示该槽尚未被使用，那么状态便是 Unused 态。比如一个刚初始化的哈希表，它的哈希索引数组存储的便都是 -1。</p>
<p><font color="darkblue"><strong>Active 态</strong></font></p>
<p>如果某个 key 映射到了指定的哈希槽，那么该槽便会存储对应 entry 在键值对数组中的索引，这个索引一定是大于等于 0 的，此时该槽就从 Unused 态变成了 Active 态。</p>
<p>后续如果又有 key 映射到了该槽，那么看它和已存在的 entry 的 key，即 <code>entry-&gt;me_key</code> 是否相等。如果不相等，那么要改变规则重新映射；如果相等，那么便找到了指定的 entry，此时便可以更新或返回 <code>entry-&gt;me_value</code>。</p>
<p><font color="darkblue"><strong>Dummy 态</strong></font></p>
<p>假设 key=&quot;abc&quot; 映射到了索引为 i 的哈希槽，该槽存储了对应的 entry 在键值对数组中的索引 ix，这时如果将 key=&quot;abc&quot; 的键值对给删掉，那么索引为 i 的哈希槽存储的值会变成多少呢？</p>
<p>可能有人觉得，键值对都删掉了，那么哈希槽也不用再存储它的索引了，应该会重置为 -1 吧。答案是不对的，原因就是我们刚才说的，这么做会导致探测链断裂。</p>
<p>当 entry 被删掉之后，哈希槽存储的值会变成 -2，即 DKIX_DUMMY，表示该槽之前存储过某个 entry 在键值对数组中的索引，但是该 entry 被删除了。注：删除 entry 也不是直接将它从键值对数组中删掉，而是将它的 me_key 和 me_value 字段设置为 NULL。</p>
<p><img src="./images/121.png" alt="" /></p>
<p>图中的 dk_indices 中有一个槽存储的是 -2，但很明显之前它存储的应该是 1，只是后续 dk_entries 中索引为 1 的 entry 被删除了。而删除一个 entry，会将它的 me_key 和 me_value 设置为 NULL，并将哈希槽存储的索引设置为 -2，这便是上面提到的伪删除技术。</p>
<p>所以一个哈希槽有三种状态，我们记哈希槽存储的索引为 ix。</p>
<ul>
<li>1）如果 ix == -1，说明该槽处于 Unused 态，还没有存储任何一个 entry 在键值对数组中的索引。
<ul>
<li>当添加一个 entry 并且 key 映射到了该槽，那么直接将 entry 追加到键值对数组，并让该槽保存它在键值对数组中的索引。</li>
<li>当基于 key 获取 value 并且 key 映射到了该槽，那么会 KeyError。</li>
</ul>
</li>
<li>2）如果 ix &gt;= 0，说明该槽处于 Active 态，已经保存了某个 entry 在键值对数组中的索引。
<ul>
<li>当添加一个 entry 并且 key 映射到了该槽，那么看已存在的 entry 的 key 和要添加的 entry 的 key 是否相等。如果不相等，索引冲突，要重新映射。如果相等，那么直接更新 value。</li>
<li>当基于 key 获取 value 并且 key 映射到了该槽，那么看已存在的 entry 的 key 和要搜索的 key 是否相等。如果不相等，索引冲突，要重新映射。如果相等，那么返回 entry 的 value。</li>
</ul>
</li>
<li>3）如果 ix == -2，说明该槽处于 Dummy 态，之前存储了某个 entry 在键值对数组中的索引，但之后该 entry 被删除了。
<ul>
<li>当添加一个 entry 并且 key 映射到了该槽，那么直接将 entry 追加到键值对数组，并让该槽保存它在键值对数组中的索引。</li>
<li>当基于 key 获取 value 并且 key 映射到了该槽，发现处于 Dummy 态，会明白虽然当前的槽是无效的，但它不是探测链的终点，所以不会报错，而是会继续搜索，这样就保证了探测链的连续性。至于报错，是发现映射出的哈希槽处于 Unused 态，没有存储任何一个 entry 的索引，这就说明 key 对应的 entry 不存在，此时才会 KeyError。</li>
</ul>
</li>
</ul>
<p>以上就是哈希槽的三种状态，它们之间可以进行转换，但 Unused 态只能转换为 Active 态；Active 态只能转换为 Dummy 态；Dummy 态只能转换为 Active 态。</p>
<p><img src="./images/122.png" alt="" /></p>
<p>如果哈希槽存储的 ix == DKIX_EMPTY，那么它处于 Unused 态。如果后续存储了 entry 在键值对数组中的索引，那么 ix &gt;= 0，此时哈希槽会从 Unused 态转换为 Active 态。如果哈希槽存储的索引对应的 entry 被删除，那么 ix 会变成 DKIX_DUMMY，此时哈希槽会从 Active 态转换为 Dummy 态。</p>
<p><strong>那么问题来了，Dummy 态转换为 Active 态，你能猜到会在什么时候发生吗？</strong></p>
<p>很容易想到，假设新来了一个 entry，它正好撞上了 Dummy 态的哈希槽，那么该槽会从 Dummy 态转为 Active 态。</p>
<p><font color="darkblue"><strong>总结：假设新增一个 entry，它的 key 映射到了索引为 i 的槽，该槽存储的索引为 ix。</strong></font></p>
<ul>
<li>如果 ix == -1，说明一上来就有位置可用，那么直接将 entry 追加到 dk_entries 中，并把它在 dk_entries 中的索引赋值给 dk_indices[i]。也就是说，Python 默认不关心是否有 Dummy 态的哈希槽。</li>
<li>如果 ix &gt;= 0，说明该槽已经有人用了，那么比较 dk_entries[ix].me_key 和要插入的 entry 的 key 是否相等，如果相等，那么更新键值对，不相等则重新映射。</li>
<li>如果 ix == -2，说明该槽之前被使用了，但使用它的 entry 后续又被删除了（伪删除，内存还在）。此时会复用该哈希槽，不过被伪删除的旧 entry 不会被复用，新增的 entry 依旧会追加到 dk_entries 中，并把它在 dk_entries 中的索引赋值给 dk_indices[i]。</li>
</ul>
<p><img src="./images/123.png" alt="" /></p>
<p>还是这张图，但做了一些修改。图中索引为 5 的哈希槽存储的索引 ix 等于 4，但它经历了以下几个过程。</p>
<ul>
<li>dk_indices[5] 初始为 -1，即 DKIX_EMPTY，此时处于 Unused 态。</li>
<li>来了一个 entry，映射到了索引为 5 的槽，发现该槽可用，于是将 dk_indices[5] 修改为 1（它在 dk_entries 中的索引），此时哈希槽变成 Active 态。</li>
<li>映射到索引为 5 的哈希槽的 entry 被删除，于是将 dk_indices[5] 修改为 DKIX_DUMMY，即 -2，并将 dk_entries[1] 的 me_key 和 me_value 设置为 NULL，此时哈希槽变成 Dummy 态。</li>
<li>后续又来了一个 entry，也映射到了索引为 5 的哈希槽，发现 dk_indices[5] 等于 -2，处于 Dummy 态。于是将新的 entry 追加到 dk_entries 中，并且在 dk_entries 中的索引为 4，然后再将 dk_indices[5] 修改为 4，此时哈希槽再次变成 Active 态。</li>
</ul>
<p>那么问题来了，被删除的旧 entry 怎么办？显然会留在那里，它是无法被复用的，当它被删除的那一刻，就和哈希索引数组失去了联系，因为对应的哈希槽存储的值被修改成了 -2。即使后续有新的 entry 映射到了同一个槽，它也不知道该槽在存储 -2 之前存储了什么，所以只能选择追加。</p>
<p>而那些被删除的旧 entry 会在哈希表执行扩缩容的时候被处理，比如哈希表满了，会申请新的存储单元，然后将处于 Active 态的哈希槽对应的 entry 搬过去，其它的则直接丢弃。</p>
<h2 id="哈希表删除元素源码解析"><a class="header" href="#哈希表删除元素源码解析">哈希表删除元素源码解析</a></h2>
<p>下面我们通过源码，来感受一下字典（哈希表）是如何删除元素的。字典有一个 pop 方法，可以基于 key 弹出指定的 entry，我们就来看一下它的源码实现。</p>
<pre><code class="language-C">// Objects/dictobject.c
#define DICT_POP_METHODDEF    \
    {&quot;pop&quot;, (PyCFunction)(void(*)(void))dict_pop, METH_FASTCALL, dict_pop__doc__},

static PyObject *
dict_pop(PyDictObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    // pop 方法的返回值
    PyObject *return_value = NULL;
    // 指定的 key
    PyObject *key;
    // pop 方法支持传入一个默认值
    // 当 key 不存在时，如果不指定默认值，pop 方法会报错，否则会返回默认值
    PyObject *default_value = NULL;
    // args 是由参数组成的元组，nargs 表示参数的个数
    // 显然参数的个数必须是 1 ~ 2 个
    if (!_PyArg_CheckPositional(&quot;pop&quot;, nargs, 1, 2)) {
        goto exit;
    }
    // args[0] 表示 key
    key = args[0];
    if (nargs &lt; 2) {
        goto skip_optional;
    }
    // args[1] 表示默认值，如果指定了的话
    default_value = args[1];
skip_optional:
    // 调用 dict_pop_impl 函数
    // 从字典中弹出具有指定 key 的 entry，并返回它的 value
    return_value = _PyDict_Pop((PyObject*)self, key, default_value);

exit:
    return return_value;
}
</code></pre>
<p>具体的逻辑由 _PyDict_Pop 承载，看看它长什么样子？</p>
<pre><code class="language-c">// Objects/dictobject.c
PyObject *
_PyDict_Pop(PyObject *dict, PyObject *key, PyObject *deflt)
{
    Py_hash_t hash;
    // 快分支，如果键值对的个数为 0
    if (((PyDictObject *)dict)-&gt;ma_used == 0) {
        // 那么当指定默认值时，直接返回默认值
        if (deflt) {
            Py_INCREF(deflt);
            return deflt;
        }
        // 否则抛出 KeyError
        _PyErr_SetKeyError(key);
        return NULL;
    }
    // 计算 key 的哈希值，这里分两种情况
    // key 不是字符串，那么调用 PyObject_Hash 函数进行计算
    // key 是字符串，那么直接获取，如果获取的结果为 -1（之前没有计算过），也要重新计算
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        // 如果计算的结果是 -1，说明 key 无法被哈希
        hash = PyObject_Hash(key);
        if (hash == -1)
            return NULL;
    }
    return _PyDict_Pop_KnownHash(dict, key, hash, deflt);
}

PyObject *
_PyDict_Pop_KnownHash(PyObject *dict, PyObject *key, Py_hash_t hash, PyObject *deflt)
{
    Py_ssize_t ix, hashpos;
    PyObject *old_value, *old_key;
    PyDictKeyEntry *ep;
    PyDictObject *mp;

    assert(PyDict_Check(dict));
    mp = (PyDictObject *)dict;
    
    // 如果字典为空，即键值对个数为 0
    // 那么当指定默认值时，直接返回默认值，否则抛出 KeyError
    if (mp-&gt;ma_used == 0) {
        if (deflt) {
            Py_INCREF(deflt);
            return deflt;
        }
        _PyErr_SetKeyError(key);
        return NULL;
    }
    // mp-&gt;ma_keys-&gt;dk_lookup 表示探测函数，负责将 key 映射成索引，找到对应的哈希槽
    // 然后返回哈希槽存储的 entry 在 dk_entries 中的索引
    // 并且在探测函数里面，还会对 old_value 进行修改
    ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;old_value);
    if (ix == DKIX_ERROR)
        return NULL;
    // 如果 ix == -1，说明映射之后的哈希槽处于 Unused 态
    // 说明该 key 对应的 entry 不存在，或者说 key 不存在
    if (ix == DKIX_EMPTY || old_value == NULL) {
        // 如果指定了默认值，返回默认值，否则抛出 KeyError
        if (deflt) {
            Py_INCREF(deflt);
            return deflt;
        }
        _PyErr_SetKeyError(key);
        return NULL;
    }

    // 到这里说明 ix &gt;= 0，即 key 在字典中存在
    // 然后检测字典是否是分离表，由于分离表不允许删除 key，所以要重构为结合表
    // 分离表就是为了节省内存引入的，因此它的限制较多，这里不做过多讨论
    if (_PyDict_HasSplitTable(mp)) {
        if (dictresize(mp, DK_SIZE(mp-&gt;ma_keys))) {
            return NULL;
        }
        ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;old_value);
        assert(ix &gt;= 0);
    }
    // 这个函数之前也见过，它负责基于哈希槽存储的 entry 的索引，返回哈希槽的索引
    hashpos = lookdict_index(mp-&gt;ma_keys, hash, ix);
    assert(hashpos &gt;= 0);
    assert(old_value != NULL);
    // 字典的长度减 1
    mp-&gt;ma_used--;
    // 更新字典的版本号
    mp-&gt;ma_version_tag = DICT_NEXT_VERSION();
    // 将索引为 hashpos 的哈希槽的值设置为 DKIX_DUMMY
    // 即 dk_indices[hashpos] = DKIX_DUMMY
    // 注意：不能设置为 DKIX_EMPTY，因为要保护冲突探测链不断裂
    dictkeys_set_index(mp-&gt;ma_keys, hashpos, DKIX_DUMMY);
    // 获取指定的 entry，即 dk_entries[ix]
    ep = &amp;DK_ENTRIES(mp-&gt;ma_keys)[ix];
    ENSURE_ALLOWS_DELETIONS(mp);
    // 将 me_key 和 me_value 设置为 NULL，伪删除
    // 并减少它们指向的对象的引用计数
    old_key = ep-&gt;me_key;
    ep-&gt;me_key = NULL;
    ep-&gt;me_value = NULL;
    Py_DECREF(old_key);

    ASSERT_CONSISTENT(mp);
    // 返回弹出的 value
    return old_value;
}
</code></pre>
<p>整个过程和我们之前的分析一样，这里为了更好地理解，我们再举个实际的例子，将整个流程给串一下。</p>
<p><img src="./images/124.png" alt="" /></p>
<p>字典存储了三个键值对，显然它们会按照先来后到的顺序存储在 dk_entries 中。然后 &quot;a&quot;: 1 映射到了索引为 4 的哈希槽，&quot;b&quot;: 2 映射到了索引为 0 的哈希槽，&quot;c&quot;: 3 映射到了索引为 6 的哈希槽。当然实际情况未必是这样，这里只是打个比方。</p>
<p>然后我们再添加一个键值对 mp[&quot;d&quot;] = 4，首先要将 &quot;d&quot; 映射成索引，假设映射出的索引为 0，由于 dk_indices[0] 的值为 1，而 dk_entries[1].me_key 不等于 &quot;d&quot;，所以出现冲突，于是哈希值右移 5 位，重新映射。</p>
<p>第二次映射出的索引为 6，由于 dk_indices[6] 的值为 2，而 dk_entries[2].me_key 也不等于 &quot;d&quot;，说明第二次映射出的索引也冲突了，那么哈希值继续右移 5 位，重新映射。</p>
<p>第三次映射出的索引为 4，由于 dk_indices[4] 的值为 0，而 dk_entries[0].me_key 也不等于 &quot;d&quot;，说明第三次映射出的索引也冲突了，那么哈希值继续右移 5 位，重新映射。</p>
<p>第四次映射出的索引为 2，而 dk_indices[2] 的值为 -1，说明该槽没有人用，于是将 entry 追加到键值对数组中，并将它在 dk_entries 中的索引赋值给 dk_indices[2]。还是那句话，实际情况并不一定是这样，这里只是为了方便解释而刻意举的例子。</p>
<p><img src="./images/125.png" alt="" /></p>
<p>所以对于 &quot;d&quot;: 4 这个键值对来说，<code>0 -&gt; 6 -&gt; 4 -&gt; 2</code> 就是它的冲突探测链，在查找的时候也会按照这个顺序进行查找。比如我们获取 mp[&quot;d&quot;]，那么会经历如下过程。</p>
<ul>
<li>将 key=&quot;d&quot; 映射成索引，得到 0，但 dk_entries[dk_indices[0]].me_key 不等于 &quot;d&quot;，所以改变策略，重新映射。</li>
<li>第二次映射得到索引 6，但 dk_entries[dk_indices[6]].me_key 依旧不等于 &quot;d&quot;，所以改变策略，重新映射。</li>
<li>第三次映射得到索引 4，但 dk_entries[dk_indices[4]].me_key 依旧不等于 &quot;d&quot;，所以改变策略，重新映射。</li>
<li>第四次映射得到索引 2，发现 dk_entries[dk_indices[2]].me_key 等于 &quot;d&quot;，说明找到了指定的 entry，于是返回它的 value。</li>
</ul>
<p>以上就是查找的整个过程，这时如果将 key=&quot;c&quot; 的 entry 删掉，比如执行 mp.pop(&quot;c&quot;)，那么会发生什么呢？</p>
<p><img src="./images/126.png" alt="" /></p>
<p>因为 &quot;c&quot; 映射到了索引为 6 的槽，当它被删除时，要将 dk_entries[dk_indices[6]] 的 me_key 和 me_value 都设置为 NULL，以及将 dk_indices[6] 设置为 DKIX_DUMMY。然后我们再获取 mp[&quot;d&quot;]，第二次映射会得到索引 6，发现该槽存储的值为 -2，就知道该槽并不是探测链的终点，于是会继续映射。</p>
<h2 id="ma_used-和-dk_nentries-的区别"><a class="header" href="#ma_used-和-dk_nentries-的区别">ma_used 和 dk_nentries 的区别</a></h2>
<p>回顾一下字典的结构：</p>
<p><img src="./images/127.png" alt="" /></p>
<p>我们说 ma_used 字段表示字典的长度，它充当了 ob_size，而 dk_nentries 字段表示键值对数组中存储的键值对的个数，那么问题来了，这两个字段啥区别呢？从字面意思来看，这两者似乎是等价的。</p>
<p>相信这个问题对你来说没有任何难度，假设当前添加了 4 个键值对，那么 ma_used 和 dk_nentries 就都是 4。但如果再删除一个键值对，那么 ma_used 会变成 3，而 dk_nentries 还是 4。</p>
<p>所以 ma_used 会随着键值对的删除而减少，但 dk_nentries 保持不变，我们验证一下。</p>
<pre><code class="language-python">from ctypes import *

class PyDictKeysObject(Structure):
    _fields_ = [(&quot;dk_refcnt&quot;, c_ssize_t),
                (&quot;dk_size&quot;, c_ssize_t),
                (&quot;dk_lookup&quot;, c_void_p),
                (&quot;dk_usable&quot;, c_ssize_t),
                (&quot;dk_nentries&quot;, c_ssize_t),
                (&quot;dk_indices&quot;, c_char * 8)]

class PyObject(Structure):
    _fields_ = [(&quot;ob_refcnt&quot;, c_ssize_t),
                (&quot;ob_type&quot;, c_void_p)]

class PyDictObject(PyObject):
    _fields_ = [(&quot;ma_used&quot;, c_ssize_t),
                (&quot;ma_version_tag&quot;, c_uint64),
                (&quot;ma_keys&quot;, POINTER(PyDictKeysObject)),
                (&quot;ma_values&quot;, c_void_p)]

d = {1: 1, 2: 2, 3: 3, 4: 4}
obj = PyDictObject.from_address(id(d))
print(obj.ma_used)  # 4
print(obj.ma_keys.contents.dk_nentries)  # 4
# 删除一个键值对
d.pop(1)
print(obj.ma_used)  # 3
print(obj.ma_keys.contents.dk_nentries)  # 4
# 再删除一个
d.pop(2)
print(obj.ma_used)  # 2
print(obj.ma_keys.contents.dk_nentries)  # 4
</code></pre>
<p>结果和我们分析的一样，这就是 ma_used 和 dk_nentries 的区别。</p>
<h2 id="小结-33"><a class="header" href="#小结-33">小结</a></h2>
<p>以上我们就介绍了哈希表是怎么删除元素的，以及相关的具体细节，下一篇文章来说一说字典的创建，以及它的一些方法。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-33"><a class="header" href="#楔子-33">楔子</a></h2>
<p>到目前为止，我们对字典应该已经有了非常细致的了解了，本篇文章来聊一聊字典的创建和相关操作，通过底层的源码实现，来进一步剖析字典。</p>
<h2 id="字典的创建"><a class="header" href="#字典的创建">字典的创建</a></h2>
<p>字典在底层对应 PyDictObject 实例，它是怎么创建的呢？解释器提供了 PyDict_New 函数，会创建一个容量为 8 的字典。</p>
<pre><code class="language-C">// Objects/dictobject.c

// 对于结合表，键值对均由 PyDictKeysObject 维护
// 它一旦被创建，那么 dk_indices 的长度至少是 8
// 至于 dk_indices 里面的元素初始为 -1，表示哈希槽尚未被使用
static PyDictKeysObject empty_keys_struct = {
        1, /* dk_refcnt */
        1, /* dk_size */
        lookdict_split, /* dk_lookup */
        0, /* dk_usable (immutable) */
        0, /* dk_nentries */
        {DKIX_EMPTY, DKIX_EMPTY, DKIX_EMPTY, DKIX_EMPTY,
         DKIX_EMPTY, DKIX_EMPTY, DKIX_EMPTY, DKIX_EMPTY}, /* dk_indices */
};

#define Py_EMPTY_KEYS &amp;empty_keys_struct
static PyObject *empty_values[1] = { NULL };

PyObject *
PyDict_New(void)
{
    dictkeys_incref(Py_EMPTY_KEYS);
    return new_dict(Py_EMPTY_KEYS, empty_values);
}

static PyObject *
new_dict(PyDictKeysObject *keys, PyObject **values)
{
    PyDictObject *mp;
    assert(keys != NULL);
    // 字典也有缓存池，关于缓存池我们之后再说，这里先不管
    if (numfree) {
        mp = free_list[--numfree];
        assert (mp != NULL);
        assert (Py_TYPE(mp) == &amp;PyDict_Type);
        _Py_NewReference((PyObject *)mp);
    }
    else {
        // 为字典申请内存
        mp = PyObject_GC_New(PyDictObject, &amp;PyDict_Type);
        if (mp == NULL) {
            // 由于是先为 PyDictKeysObject 申请内存
            // 所以当 PyDictObject 的内存申请失败时，还要处理 PyDictKeysObject
            dictkeys_decref(keys);
            if (values != empty_values) {
                free_values(values);
            }
            return NULL;
        }
    }
    // 字段初始化，而 keys 和 values 都是外界提前创建好，然后传过来的
    mp-&gt;ma_keys = keys;
    mp-&gt;ma_values = values;
    mp-&gt;ma_used = 0;
    mp-&gt;ma_version_tag = DICT_NEXT_VERSION();
    ASSERT_CONSISTENT(mp);
    return (PyObject *)mp;
}
</code></pre>
<p>所以整个过程分为两步：</p>
<ul>
<li>先创建 PyDictKeysObject 实例，底层默认提供了一个 Py_EMPTY_KEYS。</li>
<li>再创建 PyDictObject 实例，然后通过 ma_keys 字段使两者建立联系。</li>
</ul>
<p>PyDictObject 实例的创建过程我们已经知道了，接下来是 PyDictKeysObject 实例的创建，只有它创建了，才能作为参数传递给 new_dict 函数。</p>
<pre><code class="language-C">// Objects/dictobject.c

static PyDictKeysObject *new_keys_object(Py_ssize_t size)
{
    PyDictKeysObject *dk;
    Py_ssize_t es, usable;

    assert(size &gt;= PyDict_MINSIZE);
    assert(IS_POWER_OF_2(size));
    
    // USABLE_FRACTION(size) 表示键值对数组的长度
    // 它等于哈希索引数组长度的 2/3
    usable = USABLE_FRACTION(size);
    // 基于哈希索引数组的长度，计算每个元素的大小
    if (size &lt;= 0xff) {
        es = 1;
    }
    else if (size &lt;= 0xffff) {
        es = 2;
    }
#if SIZEOF_VOID_P &gt; 4
    else if (size &lt;= 0xffffffff) {
        es = 4;
    }
#endif
    else {
        es = sizeof(Py_ssize_t);
    }
    // 不仅是 PyDictObject，PyDictKeysObject 同样也有自己的缓存池
    // 关于它的缓存池，同样之后再聊，这里先不关心
    if (size == PyDict_MINSIZE &amp;&amp; numfreekeys &gt; 0) {
        dk = keys_free_list[--numfreekeys];
    }
    // 为 PyDictKeysObject 申请内存，当然还包括两个数组
    // 哈希索引数组的内存大小为 es * size
    // 键值对数组的大小为 sizeof(PyDictKeyEntry) * usable
    else {
        dk = PyObject_MALLOC(sizeof(PyDictKeysObject)
                             + es * size
                             + sizeof(PyDictKeyEntry) * usable);
        if (dk == NULL) {
            PyErr_NoMemory();
            return NULL;
        }
    }
    _Py_INC_REFTOTAL;
    // 字段初始化
    dk-&gt;dk_refcnt = 1;
    dk-&gt;dk_size = size;
    dk-&gt;dk_usable = usable;
    dk-&gt;dk_lookup = lookdict_unicode_nodummy;
    dk-&gt;dk_nentries = 0;
    // memset 是一个 C 库函数：memset(p, val, size)
    // 作用是从指针 p 开始，将之后的 size 个字节的值全部初始化为 val
    // 显然这里是将哈希索引数组的元素都设置为 -1，注：(char)0xff == -1
    memset(&amp;dk-&gt;dk_indices[0], 0xff, es * size);
    // 将键值对数组中每个 entry 的字段都设置为 0
    // entry 的内存已经申请了，但还没有保存任何的键值对
    // 所以将 me_hash、me_key、me_value 全部设置为 0
    // 注：对于指针类型来说，赋值为 0 和 NULL 是等价的，因为 NULL 保存的地址就是 0
    memset(DK_ENTRIES(dk), 0, sizeof(PyDictKeyEntry) * usable);
    return dk;
}
</code></pre>
<p>以上就是 PyDictKeysObject 实例的创建，当它创建完毕后，再作为参数传递给 new_dict 函数创建 PyDictObject 实例，整个过程还是比较简单的。</p>
<h2 id="字典都有哪些方法"><a class="header" href="#字典都有哪些方法">字典都有哪些方法？</a></h2>
<p>首先类型对象定义了三个方法簇：</p>
<ul>
<li>tp_as_number：实例对象作为数值型对象拥有的方法；</li>
<li>tp_as_sequence：实例对象作为序列型对象拥有的方法；</li>
<li>tp_as_mapping：实例对象作为映射型对象拥有的方法；</li>
</ul>
<p>当然啦，这三个方法簇对实例对象的类型要求并不严格，比如字符串作为序列型对象，也可以实现 tp_as_number，像字符串实现了里面的取模运算符，用于格式化。</p>
<p>那么字典呢，它的这几个方法簇都定义了哪些方法呢？</p>
<pre><code class="language-C">// Objects/dictobject.c

static PySequenceMethods dict_as_sequence = {
    0,                          /* sq_length */
    0,                          /* sq_concat */
    0,                          /* sq_repeat */
    0,                          /* sq_item */
    0,                          /* sq_slice */
    0,                          /* sq_ass_item */
    0,                          /* sq_ass_slice */
    PyDict_Contains,            /* sq_contains */
    0,                          /* sq_inplace_concat */
    0,                          /* sq_inplace_repeat */
};

static PyMappingMethods dict_as_mapping = {
    (lenfunc)dict_length,        /*mp_length*/
    (binaryfunc)dict_subscript,  /*mp_subscript*/
    (objobjargproc)dict_ass_sub, /*mp_ass_subscript*/
};
</code></pre>
<p>以上就是字典的几个方法簇，我们从 Python 的角度来演示一下。</p>
<pre><code class="language-Python">d = {&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3, &quot;d&quot;: 4}

# dict_as_sequence.sq_contains：判断 key 是否存在
print(&quot;a&quot; in d)  # True

# dict_as_mapping.dict_length：返回字典长度
print(len(d))  # 4

# dict_as_mapping.dict_subscript：基于 key 获取 value
print(d[&quot;a&quot;])  # 1

# dict_as_mapping.dict_ass_sub：设置 key、value
d[&quot;高老师&quot;] = &quot;美男子&quot;
print(d[&quot;高老师&quot;])  # 美男子
</code></pre>
<p>接下来我们就从源码的角度，来看看这些方法是怎么实现的。</p>
<h2 id="设置键值对"><a class="header" href="#设置键值对"><strong>设置键值对</strong></a></h2>
<p>设置键值对，比如 d[&quot;a&quot;] = 1，那么会调用 dict_as_mapping 的 mp_ass_subscript，看一下它的具体逻辑。</p>
<pre><code class="language-C">// Objects/dictobject.c

static int
dict_ass_sub(PyDictObject *mp, PyObject *v, PyObject *w)
{
    // 参数 mp 指向字典，参数 v 指向 key，参数 w 指向 value
    // 虽然是设置键值对，但如果 w == NULL，那么也可以实现删除的效果
    if (w == NULL)
        return PyDict_DelItem((PyObject *)mp, v);
    else
        return PyDict_SetItem((PyObject *)mp, v, w);
}

int
PyDict_SetItem(PyObject *op, PyObject *key, PyObject *value)
{
    PyDictObject *mp;
    Py_hash_t hash;
    if (!PyDict_Check(op)) {
        PyErr_BadInternalCall();
        return -1;
    }
    assert(key);
    assert(value);
    mp = (PyDictObject *)op;
    // 如果 key 不是字符串，或者 key 是字符串、但哈希值等于 -1（尚未计算）
    // 那么计算哈希值
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1)
    {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return -1;
    }
    // 如果是一个空字典，那么调用 insert_to_emptydict
    if (mp-&gt;ma_keys == Py_EMPTY_KEYS) {
        return insert_to_emptydict(mp, key, hash, value);
    }
    // 不是空字典，那么调用 insertdict
    return insertdict(mp, key, hash, value);
}
</code></pre>
<p>所以最终会调用 insert_to_emptydict 或 insertdict，这里我们直接看 insertdict 函数的具体实现。</p>
<pre><code class="language-C">// Objects/dictobject.c

static int
insertdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject *value)
{
    PyObject *old_value;
    PyDictKeyEntry *ep;

    Py_INCREF(key);
    Py_INCREF(value);
    // 字典有两种结构，分别是分离表和结合表
    // 如果是分离表，那么 key 必须全部是字符串，因为它是为对象的属性字典引入的，而属性肯定是字符串
    // 所以当字典使用的是分离表，并且插入的 key 不是字符串时，那么要重构为结合表
    if (mp-&gt;ma_values != NULL &amp;&amp; !PyUnicode_CheckExact(key)) {
        if (insertion_resize(mp) &lt; 0)
            goto Fail;
    }
    // 探测函数，将 key 的哈希值映射成索引，该索引是哈希槽的索引
    // 然后返回该哈希槽存储的键值对数组的索引，同时修改 old_value
    Py_ssize_t ix = mp-&gt;ma_keys-&gt;dk_lookup(mp, key, hash, &amp;old_value);
    if (ix == DKIX_ERROR)
        goto Fail;

    assert(PyUnicode_CheckExact(key) || mp-&gt;ma_keys-&gt;dk_lookup == lookdict);
    MAINTAIN_TRACKING(mp, key, value);

    // 分离表不仅要求 key 全部是字符串，并且不能删除，否则要重构为结合表
    if (_PyDict_HasSplitTable(mp) &amp;&amp;
        ((ix &gt;= 0 &amp;&amp; old_value == NULL &amp;&amp; mp-&gt;ma_used != ix) ||
         (ix == DKIX_EMPTY &amp;&amp; mp-&gt;ma_used != mp-&gt;ma_keys-&gt;dk_nentries))) {
        if (insertion_resize(mp) &lt; 0)
            goto Fail;
        ix = DKIX_EMPTY;
    }
    
    // 如果 ix == -1，说明 key 在字典中不存在
    if (ix == DKIX_EMPTY) {
        assert(old_value == NULL);
        // 如果键值对数组的长度小于等于 0，说明还没有为键值对数组分配内存
        // 那么依旧调用 insertion_resize，该函数后续解释
        if (mp-&gt;ma_keys-&gt;dk_usable &lt;= 0) {
            if (insertion_resize(mp) &lt; 0)
                goto Fail;
        }
        // 按照相同的规则对 key 的哈希值进行映射，并返回哈希槽的索引
        // 如果没有撞上 Dummy 态的哈希槽，那么 dk_indices[hashpos] 会等于 ix
        // 如果在映射的过程中，撞上了 Dummy 态的哈希槽，那么直接将该槽的索引返回
        // 但不管是哪一种情况，我们都找到了一个合法的槽
        Py_ssize_t hashpos = find_empty_slot(mp-&gt;ma_keys, hash);
        // dk_entries[dk_nentries] 便对应新的 entry，由于内存一开始便分配好了
        // 因此所谓添加，其实就是修改它的 me_key 和 me_value 字段
        // 将这两个字段的值，修改为参数 key 和参数 value
        ep = &amp;DK_ENTRIES(mp-&gt;ma_keys)[mp-&gt;ma_keys-&gt;dk_nentries];
        // 新的 entry 会添加在键值对数组中索引为 mp-&gt;ma_keys-&gt;dk_nentries 的位置
        // 因为键值对始终是按照先来后到的顺序追加的，然后调用 dictkeys_set_index
        // 将 entry 在键值对数组中的索引，赋值给 mp-&gt;ma_keys-&gt;dk_indices[hashpos]
        dictkeys_set_index(mp-&gt;ma_keys, hashpos, mp-&gt;ma_keys-&gt;dk_nentries);
        // 更新 me_key 和 me_value
        ep-&gt;me_key = key;
        ep-&gt;me_hash = hash;
        // 如果 mp-&gt;ma_values 不为空，证明字典使用的是分离表
        if (mp-&gt;ma_values) {
            // 分离表的话，value 统一由 mp-&gt;ma_values 维护
            // 至于 entry 里面的 me_value 字段则始终为 NULL
            assert (mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] == NULL);
            mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] = value;
        }
        // 否则说明字典使用的是结合表，将 entry-&gt;me_value 的值设置为 value
        else {
            ep-&gt;me_value = value;
        }
        mp-&gt;ma_used++;  // 字典长度加 1
        mp-&gt;ma_version_tag = DICT_NEXT_VERSION();  // 更新字典的版本号
        mp-&gt;ma_keys-&gt;dk_usable--;  // 键值对数组还可以容纳的 entry 个数减 1
        mp-&gt;ma_keys-&gt;dk_nentries++;  // 键值对已存储的 entry 个数加 1
        assert(mp-&gt;ma_keys-&gt;dk_usable &gt;= 0);
        ASSERT_CONSISTENT(mp);
        return 0;
    }
    // 如果程序走到这里，说明 ix &gt;= 0，即 key 已存在
    // 那么当 old_value != value 时，要对值进行更新
    if (old_value != value) {
        // 分离表，更新 mp-&gt;ma_values-&gt;values[ix]
        if (_PyDict_HasSplitTable(mp)) {
            mp-&gt;ma_values[ix] = value;
            if (old_value == NULL) {
                /* pending state */
                assert(ix == mp-&gt;ma_used);
                mp-&gt;ma_used++;
            }
        }
        else {
            // 结合表，获取 entry，更新它的 me_value 字段
            assert(old_value != NULL);
            DK_ENTRIES(mp-&gt;ma_keys)[ix].me_value = value;
        }
        mp-&gt;ma_version_tag = DICT_NEXT_VERSION();
    }
    Py_XDECREF(old_value); /* which **CAN** re-enter (see issue #22653) */
    ASSERT_CONSISTENT(mp);
    Py_DECREF(key);
    return 0;

Fail:
    Py_DECREF(value);
    Py_DECREF(key);
    return -1;
}
</code></pre>
<p>以上就是获取键值对，源码细节和我们之前分析哈希表时说的是一样的。</p>
<h2 id="基于-key-获取-value"><a class="header" href="#基于-key-获取-value">基于 key 获取 value</a></h2>
<p>如果是获取 value，比如 v = d[&quot;a&quot;]，那么会调用 dict_as_mapping 的 mp_subscript，看一下它的具体逻辑。</p>
<pre><code class="language-C">// Objects/dictobject.c
static PyObject *
dict_subscript(PyDictObject *mp, PyObject *key)
{
    Py_ssize_t ix;
    Py_hash_t hash;
    PyObject *value;
    // 如果 key 不是字符串，或者 key 是字符串、但哈希值为 -1，那么计算哈希值
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return NULL;
    }
    // 探测函数，将 key 映射成索引，并返回对应的哈希槽存储的键值对数组的索引
    // 并且在函数内部，还会对参数 value 进行修改，所以这里要传递二级指针
    // 如果键值对存在，那么参数 value 就是对应的值，否则 value 会等于 NULL
    ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;value);
    if (ix == DKIX_ERROR)
        return NULL;
    // 当 ix == -1 或 value == NULL 时，说明 key 对应的键值对不存在
    if (ix == DKIX_EMPTY || value == NULL) {
        if (!PyDict_CheckExact(mp)) {
            // 但如果 mp 不是字典，即 type(mp) is not dict
            // 那么说明 mp 的类型一定继承了 dict
            PyObject *missing, *res;
            _Py_IDENTIFIER(__missing__);
            // 检测 mp 是否定义了 __missing__ 方法，如果定义了则调用
            // 所以该方法要定义在继承了 dict 的子类中
            missing = _PyObject_LookupSpecial((PyObject *)mp, &amp;PyId___missing__);
            if (missing != NULL) {
                res = PyObject_CallFunctionObjArgs(missing,
                                                   key, NULL);
                Py_DECREF(missing);
                return res;
            }
            else if (PyErr_Occurred())
                return NULL;
        }
        // 到这里说明 key 不存在，并且也没有定义 __missing__，那么 KeyError
        _PyErr_SetKeyError(key);
        return NULL;
    }
    // 否则说明键值对存在，那么增加引用计数，返回 value
    Py_INCREF(value);
    return value;
}
</code></pre>
<p>所以获取 value 的话，也比较简单，关键在于里面有一个 __missing__ 方法，我们来解释一下。</p>
<pre><code class="language-Python">class Dict(dict):

    def __getitem__(self, item):
        return super().__getitem__(item)

    def __missing__(self, key):
        return f&quot;不存在的 key：{key}&quot;


d = Dict({&quot;a&quot;: 1, &quot;b&quot;: 2})
# 会执行 Dict.__getitem__(d, &quot;a&quot;)
# 在内部会调用字典的 __getitem__
print(d[&quot;a&quot;])  # 1
print(d[&quot;b&quot;])  # 2

# 而在调用字典的 __getitem__ 时，如果发现 key 不存在
# 那么会尝试寻找 __missing__ 方法
print(d[&quot;c&quot;])  # 不存在的 key：c
print(d[&quot;高老师&quot;])  # 不存在的 key：高老师
</code></pre>
<p>以上就是获取键值对。</p>
<h2 id="小结-34"><a class="header" href="#小结-34">小结</a></h2>
<p>关于字典是怎么创建的，以及它添加键值对、基于键获取值的源码细节，我们就分析完了。当然还没有结束，字典还有很多的自定义方法，我们下一篇文章来剖析这些自定义方法的实现细节。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-34"><a class="header" href="#楔子-34">楔子</a></h2>
<p>上一篇文章我们介绍了字典的创建过程，和一些基本操作，这些操作都对应一个魔法方法。但除了这些魔法方法之外，每个对象还可以单独定义很多自己的方法，这些方法统一由类型对象的 tp_methods 字段维护，当然这些之前已经说过了。</p>
<p><img src="./images/128.png" alt="" /></p>
<p>里面有很多的自定义方法，比如 get、pop、setdefault 等等，我们来剖析一下。</p>
<h2 id="字典的-get-方法"><a class="header" href="#字典的-get-方法">字典的 get 方法</a></h2>
<p>获取指定 key 对应的 value，如果 key 不存在，那么返回默认值。</p>
<pre><code class="language-Python">d = {&quot;name&quot;: &quot;古明地觉&quot;}
print(d.get(&quot;name&quot;))
&quot;&quot;&quot;
古明地觉
&quot;&quot;&quot;
# key 不存在，返回默认值 None
print(d.get(&quot;desc&quot;))
&quot;&quot;&quot;
None
&quot;&quot;&quot;
# 当然也可以指定默认值
print(d.get(&quot;desc&quot;, &quot;地灵殿美少女&quot;))
&quot;&quot;&quot;
地灵殿美少女
&quot;&quot;&quot;
</code></pre>
<p>下面看一下源码实现。</p>
<pre><code class="language-C">// Objects/clinc/dictobject.c.h
#define DICT_GET_METHODDEF    \
    {&quot;get&quot;, (PyCFunction)(void(*)(void))dict_get, METH_FASTCALL, dict_get__doc__},

static PyObject *
dict_get(PyDictObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    PyObject *return_value = NULL;  // 返回值
    PyObject *key;  // 指定的 key
    PyObject *default_value = Py_None;  // 默认值，默认为 None
    // get 方法接收 1 ~ 2 个参数
    if (!_PyArg_CheckPositional(&quot;get&quot;, nargs, 1, 2)) {
        goto exit;
    }
    // args[0] 便是指定的 key
    key = args[0];
    if (nargs &lt; 2) {
        goto skip_optional;
    }
    // args[1] 便是传入的默认值，如果有的话
    default_value = args[1];
skip_optional:
    // 调用 dict_get_impl
    return_value = dict_get_impl(self, key, default_value);

exit:
    return return_value;
}

// Objects/dictobject.c
static PyObject *
dict_get_impl(PyDictObject *self, PyObject *key, PyObject *default_value)
{
    PyObject *val = NULL;
    Py_hash_t hash;  // 哈希值
    Py_ssize_t ix;  // 哈希槽存储的键值对数组的索引
    // 计算哈希值
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return NULL;
    }
    // 获取 key 对应的哈希槽存储的键值对数组的索引
    ix = (self-&gt;ma_keys-&gt;dk_lookup) (self, key, hash, &amp;val);
    if (ix == DKIX_ERROR)
        return NULL;
    // key 不存在，那么将默认值赋值给 val
    if (ix == DKIX_EMPTY || val == NULL) {
        val = default_value;
    }
    // 增加 val 的引用计数，然后返回
    Py_INCREF(val);
    return val;
}
</code></pre>
<p>以上就是字典的 get 方法，非常简单。</p>
<h2 id="字典的-setdefault-方法"><a class="header" href="#字典的-setdefault-方法">字典的 setdefault 方法</a></h2>
<p>这是一个非常强大的方法，但是用的人不是很多。它和 get 方法类似，都是传入一个 key 和一个默认值，如果 key 存在，那么返回 key 对应的 value，否则返回默认值。但它和 get 方法不同的是，setdefault 在 key 不存在时，会将 key 和默认值添加到字典中。</p>
<pre><code class="language-Python">d = {&quot;name&quot;: &quot;古明地觉&quot;}
# 当 key 存在时，两个方法的效果是一样的，都等价于 d[key]
print(d.get(&quot;name&quot;))
print(d.setdefault(&quot;name&quot;))
&quot;&quot;&quot;
古明地觉
古明地觉
&quot;&quot;&quot;

# 但当 key 不存在时，就有差别了
# &quot;desc&quot; 这个 key 不存在，返回默认值
print(d.get(&quot;desc&quot;, &quot;地灵殿美少女&quot;))
&quot;&quot;&quot;
地灵殿美少女
&quot;&quot;&quot;
# 并且原始的字典不受影响
print(d)
&quot;&quot;&quot;
{'name': '古明地觉'}
&quot;&quot;&quot;

# 但对于 setdefault 来说，key 不存在时
# 会将 key 和默认值添加进去，然后返回默认值
print(d.setdefault(&quot;desc&quot;, &quot;地灵殿美少女&quot;))
&quot;&quot;&quot;
地灵殿美少女
&quot;&quot;&quot;
# 原始的字典会发生改变
print(d)
&quot;&quot;&quot;
{'name': '古明地觉', 'desc': '地灵殿美少女'}
&quot;&quot;&quot;
</code></pre>
<p>所以当获取的 key 不存在时，v = d.setdefault(key, value) 等价于如下。</p>
<ul>
<li>d[key] = value</li>
<li>v = d[key]</li>
</ul>
<p>那么 setdefault 一般用在什么地方呢？举个例子。</p>
<pre><code class="language-Python">data = [
    (&quot;古明地觉&quot;, &quot;2020&quot;, 5), (&quot;古明地觉&quot;, &quot;2020&quot;, 2),
    (&quot;古明地觉&quot;, &quot;2021&quot;, 1), (&quot;古明地觉&quot;, &quot;2021&quot;, 4), (&quot;古明地觉&quot;, &quot;2021&quot;, 3),

    (&quot;芙兰朵露&quot;, &quot;2022&quot;, 7), (&quot;芙兰朵露&quot;, &quot;2022&quot;, 3), (&quot;芙兰朵露&quot;, &quot;2022&quot;, 3),
    (&quot;芙兰朵露&quot;, &quot;2023&quot;, 4), (&quot;芙兰朵露&quot;, &quot;2023&quot;, 1)
]
# 对于上面这种数据，我们需要变成下面这个样子
&quot;&quot;&quot;
{
    '古明地觉': {
        '2020': [5, 2], 
        '2021': [1, 4, 3]
    }, 
    '芙兰朵露': {
        '2022': [7, 3, 3], 
        '2023': [4, 1]
    }
}
&quot;&quot;&quot;
# 如果使用 setdefault 方法，就非常好解决了
d = {}
for name, year, cnt in data:
    d.setdefault(name, {}).setdefault(year, []).append(cnt)
print(d)
</code></pre>
<p>下面来看一下源码实现。</p>
<pre><code class="language-C">// Objects/clinc/dictobject.c.h
#define DICT_SETDEFAULT_METHODDEF    \
    {&quot;setdefault&quot;, (PyCFunction)(void(*)(void))dict_setdefault, METH_FASTCALL, dict_setdefault__doc__},

static PyObject *
dict_setdefault(PyDictObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    // 这部分和 get 方法是类似的
    PyObject *return_value = NULL;
    PyObject *key;
    PyObject *default_value = Py_None;

    if (!_PyArg_CheckPositional(&quot;setdefault&quot;, nargs, 1, 2)) {
        goto exit;
    }
    key = args[0];
    if (nargs &lt; 2) {
        goto skip_optional;
    }
    default_value = args[1];
skip_optional:
    return_value = dict_setdefault_impl(self, key, default_value);
exit:
    return return_value;
}

// Objects/dictobject.c
static PyObject *
dict_setdefault_impl(PyDictObject *self, PyObject *key,
                     PyObject *default_value)
{
    PyObject *val;

    val = PyDict_SetDefault((PyObject *)self, key, default_value);
    Py_XINCREF(val);
    return val;
}
</code></pre>
<p>所以核心在于 PyDict_SetDefault 函数，这个函数比较长，但逻辑不难理解。</p>
<pre><code class="language-C">// Objects/dictobject.c
PyObject *
PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *defaultobj)
{
    PyDictObject *mp = (PyDictObject *)d;
    PyObject *value;
    Py_hash_t hash;

    if (!PyDict_Check(d)) {
        PyErr_BadInternalCall();
        return NULL;
    }
    // 获取哈希值
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return NULL;
    }
    // 如果 mp-&gt;ma_keys 等于 Py_EMPTY_KEYS，证明字典是空的，那么 key 肯定不存在
    // 将 key 和 defaultobj 添加进字典中，并返回 defaultobj
    if (mp-&gt;ma_keys == Py_EMPTY_KEYS) {
        if (insert_to_emptydict(mp, key, hash, defaultobj) &lt; 0) {
            return NULL;
        }
        return defaultobj;
    }
    // 如果字典使用的是分离表，并且 key 不是字符串
    // 意味着字典的结构要发生改变，重构为结合表
    if (mp-&gt;ma_values != NULL &amp;&amp; !PyUnicode_CheckExact(key)) {
        if (insertion_resize(mp) &lt; 0)
            return NULL;
    }
    // 获取哈希槽存储的键值对数组的索引
    Py_ssize_t ix = (mp-&gt;ma_keys-&gt;dk_lookup)(mp, key, hash, &amp;value);
    if (ix == DKIX_ERROR)
        return NULL;
    // 分离表不仅要求 key 全部是字符串，并且不能删除，否则要重构为结合表
    if (_PyDict_HasSplitTable(mp) &amp;&amp;
        ((ix &gt;= 0 &amp;&amp; value == NULL &amp;&amp; mp-&gt;ma_used != ix) ||
         (ix == DKIX_EMPTY &amp;&amp; mp-&gt;ma_used != mp-&gt;ma_keys-&gt;dk_nentries))) {
        if (insertion_resize(mp) &lt; 0) {
            return NULL;
        }
        ix = DKIX_EMPTY;
    }
    // 如果 ix == -1，说明 key 不存在，那么要先添加键值对
    if (ix == DKIX_EMPTY) {
        PyDictKeyEntry *ep, *ep0;
        value = defaultobj;
        // 是否还有可用空间，如果没有，调用 insertion_resize
        if (mp-&gt;ma_keys-&gt;dk_usable &lt;= 0) {
            if (insertion_resize(mp) &lt; 0) {
                return NULL;
            }
        }
        // 返回 key 映射之后的哈希槽的索引
        Py_ssize_t hashpos = find_empty_slot(mp-&gt;ma_keys, hash);
        // 新添加的 entry 在键值对数组中的索引为 mp-&gt;ma_keys-&gt;dk_nentries
        // 将该索引赋值给 dk_indices[hashpose]
        ep0 = DK_ENTRIES(mp-&gt;ma_keys);
        ep = &amp;ep0[mp-&gt;ma_keys-&gt;dk_nentries];
        dictkeys_set_index(mp-&gt;ma_keys, hashpos, mp-&gt;ma_keys-&gt;dk_nentries);
        Py_INCREF(key);
        Py_INCREF(value);
        MAINTAIN_TRACKING(mp, key, value);
        ep-&gt;me_key = key;
        ep-&gt;me_hash = hash;
        // 如果字典是分离表
        if (_PyDict_HasSplitTable(mp)) {
            // 值由 mp-&gt;ma_values 存储
            assert(mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] == NULL);
            mp-&gt;ma_values[mp-&gt;ma_keys-&gt;dk_nentries] = value;
        }
        // 如果字典是结合表，那么键和值均保存在 entry 中
        else {
            ep-&gt;me_value = value;
        }
        // 字典长度加 1
        mp-&gt;ma_used++;
        // 修改版本号
        mp-&gt;ma_version_tag = DICT_NEXT_VERSION();
        // 键值对数组还可以容纳的 entry 个数减 1
        mp-&gt;ma_keys-&gt;dk_usable--;
        // 键值对数组已经容纳的 entry 个数加 1
        mp-&gt;ma_keys-&gt;dk_nentries++;
        assert(mp-&gt;ma_keys-&gt;dk_usable &gt;= 0);
    }
    // ...
    ASSERT_CONSISTENT(mp);
    // 返回 value
    return value;
}
</code></pre>
<p>以上便是 setdefault 方法。</p>
<h2 id="字典的-popitem-方法"><a class="header" href="#字典的-popitem-方法">字典的 popitem 方法</a></h2>
<p>字典的 pop 方法之前已经说过了，这里来看一下 popitem 方法。</p>
<pre><code class="language-Python">d = {&quot;x&quot;: 1, &quot;y&quot;: 2, &quot;z&quot;: 3}
# pop 方法可以弹出指定的 key，并返回对应的 value
# 如果 key 不存在，并且没有指定默认值，会抛出 KeyError，否则返回默认值
print(d.pop(&quot;x&quot;))  # 1

# 而 popitem 方法则是弹出字典的最后一个键值对
d = {&quot;x&quot;: 1, &quot;y&quot;: 2, &quot;z&quot;: 3}
print(d.popitem())  # ('z', 3)
print(d)  # {'x': 1, 'y': 2}
</code></pre>
<p>下面看一下源码实现。</p>
<pre><code class="language-C">// Objects/clinc/dictobject.c.h
#define DICT_POPITEM_METHODDEF    \
    {&quot;popitem&quot;, (PyCFunction)dict_popitem, METH_NOARGS, dict_popitem__doc__},

static PyObject *
dict_popitem(PyDictObject *self, PyObject *Py_UNUSED(ignored))
{
    return dict_popitem_impl(self);
}

// Objects/dictobject.c
static PyObject *
dict_popitem_impl(PyDictObject *self)
{
    Py_ssize_t i, j;
    PyDictKeyEntry *ep0, *ep;
    PyObject *res;
    // 返回值，一个二元组，负责存储 key 和 value
    res = PyTuple_New(2);
    if (res == NULL)
        return NULL;
    // 如果字典的长度为 0，那么抛出 KeyError
    if (self-&gt;ma_used == 0) {
        Py_DECREF(res);
        PyErr_SetString(PyExc_KeyError, &quot;popitem(): dictionary is empty&quot;);
        return NULL;
    }
    // 如果字典使用分离表，那么当 popitem 之后，要重构为结合表
    // 分离表要求 key 必须全部是字符串，并且不能删除键值对
    if (self-&gt;ma_keys-&gt;dk_lookup == lookdict_split) {
        if (dictresize(self, DK_SIZE(self-&gt;ma_keys))) {
            Py_DECREF(res);
            return NULL;
        }
    }
    ENSURE_ALLOWS_DELETIONS(self);

    // 获取键值对数组
    ep0 = DK_ENTRIES(self-&gt;ma_keys);
    // ma_keys-&gt;dk_nentries 表示键值对数组中已使用的 entry 个数
    // 那么 entry 的最大索引就是 ma_keys-&gt;dk_nentries - 1
    i = self-&gt;ma_keys-&gt;dk_nentries - 1;
    // 从 i 开始往前遍历，找到第一个 me_value != NULL 的 entry
    // 因为被删除的 entry 依旧会驻留在键值对数组中，但 me_key、me_value 被设置为 NULL
    while (i &gt;= 0 &amp;&amp; ep0[i].me_value == NULL) {
        i--;
    }
    assert(i &gt;= 0);
    // 获取 entry
    ep = &amp;ep0[i];
    // 基于哈希槽存储的索引，获取哈希槽的索引
    j = lookdict_index(self-&gt;ma_keys, ep-&gt;me_hash, i);
    assert(j &gt;= 0);
    assert(dictkeys_get_index(self-&gt;ma_keys, j) == i);
    // 因为 entry 被删除了，所以对应的哈希槽存储的值要修改为 DKIX_DUMMY
    dictkeys_set_index(self-&gt;ma_keys, j, DKIX_DUMMY);
    // 将 key 和 value 保存在元组中
    PyTuple_SET_ITEM(res, 0, ep-&gt;me_key);
    PyTuple_SET_ITEM(res, 1, ep-&gt;me_value);
    // 因为被弹出了，所以 entry 的 me_key 和 me_value 要重置为 NULL
    ep-&gt;me_key = NULL;
    ep-&gt;me_value = NULL;
    // 这一步一会儿解释
    self-&gt;ma_keys-&gt;dk_nentries = i;
    // 键值对个数减 1
    self-&gt;ma_used--;
    self-&gt;ma_version_tag = DICT_NEXT_VERSION();
    ASSERT_CONSISTENT(self);
    return res;
}
</code></pre>
<p>以上就是 popitem 方法，但是里面有一行 <code>self-&gt;ma_keys-&gt;dk_nentries = i</code> 估计让人有些费解，我们解释一下。</p>
<p>首先当键值对数组的空间申请之后，entry 就已经存在了，初始状态下的 entry 的 me_key 和 me_value 均为 NULL。所以一个被伪删除的 entry 和初始的 entry 是等价的，下面假设有这么一个键值对数组。</p>
<p><img src="./images/129.png" alt="" /></p>
<p>对于一个容量为 16 的哈希表，它的键值对数组的长度为 10，由于 dk_nentries = 7，说明键值对数组使用了 7 个 entry。而在之后，第 2 个 entry 和第 7 个 entry 被删除了，一旦删除，那么它的 me_key 和 me_value 会被重置为 NULL，和初始 entry 是等价的。</p>
<p>这时候如果执行 popitem，那么会弹出最后一个 me_value 不为 NULL 的 entry，即没有被伪删除的 entry，对于当前来说就是第 6 个 entry。所以源码中的 i 初始等于 <font color="blue">dk_nentries - 1</font>，然后往前遍历，最终会找到索引为 5 的 entry，所以循环之后 i = 5。然后将索引为 5 的 entry 的 me_key 和 me_value 设置为 NULL，因为它被删除了。</p>
<p>注意：这里关键来了，既然变量 i 保存的是最后一个 me_value != NULL 的 entry 的索引，那么当它被删除之后，就意味着从索引 i 开始，后面所有的 entry 都相当于回归到了初始状态，那么直接将 dk_nentries 设置为 i。</p>
<p><img src="./images/130.png" alt="" /></p>
<p>由于 dk_nentries 被设置为 i，后续再添加键值对时，就会添加到索引为 i 的位置。对于当前来说，添加键值对时，修改的是 dk_entries[5] 的 me_key 和 me_value，而不是 dk_entries[7] 的 me_key 和 me_value。</p>
<p>所以通过 popitem 方法，被删除的 entry 是有可能实现复用的。</p>
<h2 id="小结-35"><a class="header" href="#小结-35">小结</a></h2>
<p>以上我们就简单分析了字典的几个自定义方法，下一篇文章来聊一聊字典的扩容。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>在介绍字典的底层结构时我们看到，当已使用的 entry 数量达到总容量的 2/3 时，会发生扩容。</p>
<p>而在早期，哈希表只使用一个键值对数组，这个键值对数组不仅要存储具体的 entry，还要承载哈希索引数组的功能。本来这个方式很简单，但是内存浪费严重，于是后面 Python 官方就将一个数组拆成两个数组来实现。</p>
<p>不是说只能用 2/3 吗？那就只给键值对数组申请 2/3 容量的空间，并且只负责存储键值对。至于索引，则由哈希索引数组来承载。通过将 key 映射成索引，找到指定的哈希槽，再根据槽里面存储的索引，找到键值对数组中存储的 entry。</p>
<blockquote>
<p>因此减少内存开销的核心就在于，避免键值对数组的浪费。</p>
</blockquote>
<p>所以哈希索引数组的长度就可以看成是哈希表的容量，而键值对数组的长度本身就是哈希索引数组长度的 2/3、或者说容量的 2/3。那么很明显，当键值对数组满了，就说明当前的哈希表要扩容了。</p>
<pre><code class="language-C">// Objects/dictobject.c
#define GROWTH_RATE(d) ((d)-&gt;ma_used*3)
</code></pre>
<p>扩容之后的新哈希表的容量要<font color="blue">大于等于 ma_used * 3</font>，注意是大于等于 <font color="blue">ma_used * 3</font>，不是 <font color="blue">dk_nentries * 3</font>。因为 dk_nentries 还包含了被删除的 entry，但哈希表在扩容的候会将其丢弃，所以扩容之后新哈希表的容量取决于 ma_used。</font></p>
<p>当然啦，哈希表的容量还要等于 2 的幂次方，所以有两个条件：</p>
<ul>
<li>大于等于 ma_used * 3；</li>
<li>等于 2 的幂次方；</li>
</ul>
<p>基于以上两个限制条件，取到的最小值便是扩容之后的容量。而扩容的具体过程我们稍后会介绍，目前先来回顾一下基础知识。</p>
<p><img src="./images/131.png" alt="" /></p>
<p>以上是字典的底层结构，假设变量 mp 指向了 PyDictObject 实例，那么可以得到如下信息。</p>
<ul>
<li><code>mp-&gt;ma_keys-&gt;dk_indices</code> 便是哈希索引数组，它的长度便是哈希表的容量。</li>
<li><code>mp-&gt;ma_keys-&gt;dk_entries</code> 便是键值对数组，里面的一个 entry 就是一个键值对。</li>
<li>如果字典使用的是结合表，那么 entry 的 me_key、me_value 字段负责存储键和值，此时 <code>mp-&gt;ma_values</code> 为 NULL。</li>
<li>如果字典使用的是分离表，那么 entry 的 me_key 字段负责存储键，me_value 字段则始终为 NULL，此时由 <code>mp-&gt;ma_values</code> 负责存储值，这种做法可以让多个字典共享一组 key，从而节省内存。</li>
</ul>
<p>因为分离表是 Python 针对实例对象的属性字典单独设计的，我们平时创建的都是结合表，所以一开始并没有讨论分离表。但分离表其实非常简单，这里来补充一下吧。现在假设有一个字典，里面有三个键值对 <font color="blue">&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3</font>，我们看一下分别使用结合表和分离表存储时，字典的结构是什么样子。</p>
<p><img src="./images/132.png" alt="" /></p>
<p>所以结合表是键和值存在一起，分离表是键和值分开存储，非常好理解。我们自己创建的字典，使用的都是结合表，分离表是为了减少对象属性字典的内存使用而专门引入的。因此对于一个分离表而言，它的 key 一定都是字符串，否则不可能是分离表。而如果 key 都是字符串，那么既可以是分离表，也可以是结合表。</p>
<p>接着是转换关系：分离表可以重构为结合表，但反过来不行。</p>
<p>好，下面我们来看一下扩容逻辑，它由 dictresize 函数负责。</p>
<pre><code class="language-C">// Objects/dictobject.c

#define PyDict_MINSIZE 8

static int
dictresize(PyDictObject *mp, Py_ssize_t minsize)
{
    // 参数 minsize 表示字典的 ma_used * 3，即长度 * 3
  
    Py_ssize_t newsize, numentries;
    // mp-&gt;ma_keys
    PyDictKeysObject *oldkeys;
    // mp-&gt;ma_values
    PyObject **oldvalues;
    // mp-&gt;ma_values-&gt;dk_entries
    PyDictKeyEntry *oldentries, *newentries;

    /* Find the smallest table size &gt; minused. */
    // 初始容量为 8，如果 newsize &lt; minsize，那么不断循环
    // 直到条件不满足时，便找到了大于等于 minsize 的最小 2 的幂次方数
    // newsize 便是字典扩容之后的新容量
    for (newsize = PyDict_MINSIZE;
         newsize &lt; minsize &amp;&amp; newsize &gt; 0;
         newsize &lt;&lt;= 1)
        ;
    if (newsize &lt;= 0) {
        PyErr_NoMemory();
        return -1;
    }
    // 获取扩容之前的 ma_keys
    oldkeys = mp-&gt;ma_keys;
    // 在介绍字典的创建时，我们说过这个函数，它负责为 PyDictKeysObject 实例申请内存
    mp-&gt;ma_keys = new_keys_object(newsize);
    if (mp-&gt;ma_keys == NULL) {
        mp-&gt;ma_keys = oldkeys;
        return -1;
    }
    assert(mp-&gt;ma_keys-&gt;dk_usable &gt;= mp-&gt;ma_used);
    // 设置探测函数
    if (oldkeys-&gt;dk_lookup == lookdict)
        mp-&gt;ma_keys-&gt;dk_lookup = lookdict;
    // 字典的长度
    numentries = mp-&gt;ma_used;
    // 扩容之前的键值对数组
    oldentries = DK_ENTRIES(oldkeys);
    // 扩容之后的键值对数组
    newentries = DK_ENTRIES(mp-&gt;ma_keys);
    // 扩容之前的 ma_values
    oldvalues = mp-&gt;ma_values;
    // 如果 oldvalues 不为 NULL，说明字典使用的是分离表
    // 那么当字典发生扩容时，要转成结合表
    if (oldvalues != NULL) {
        // 将旧的键值对数组的 entry 拷贝到新的键值对数组中
        for (Py_ssize_t i = 0; i &lt; numentries; i++) {
            assert(oldvalues[i] != NULL);
            PyDictKeyEntry *ep = &amp;oldentries[i];
            PyObject *key = ep-&gt;me_key;
            Py_INCREF(key);
            // key 始终存储在 entry 中
            newentries[i].me_key = key;
            // 设置哈希值
            newentries[i].me_hash = ep-&gt;me_hash;
            // 将 mp-&gt;ma_values 里面的值，赋值给 entry-&gt;me_value
            newentries[i].me_value = oldvalues[i];
        }
        // 旧的 ma_keys 和 ma_values 要释放掉
        dictkeys_decref(oldkeys);
        mp-&gt;ma_values = NULL;
        if (oldvalues != empty_values) {
            free_values(oldvalues);
        }
    }
    // 说明字典使用的是结合表，重构的结果依旧是结合表
    else {  // combined table.
        // 如果 entry 的数量等于字典的长度，说明没有被删除的 entry，那么直接 memcpy 过去即可
        if (oldkeys-&gt;dk_nentries == numentries) {
            memcpy(newentries, oldentries, numentries * sizeof(PyDictKeyEntry));
        }
        // 否则遍历 oldentries，将 me_value != NULL 的 entry 拷贝过去
        else {
            PyDictKeyEntry *ep = oldentries;
            for (Py_ssize_t i = 0; i &lt; numentries; i++) {
                while (ep-&gt;me_value == NULL)
                    ep++;
                newentries[i] = *ep++;
            }
        }

        assert(oldkeys-&gt;dk_lookup != lookdict_split);
        assert(oldkeys-&gt;dk_refcnt == 1);
        // 缓存池逻辑，后续聊
        if (oldkeys-&gt;dk_size == PyDict_MINSIZE &amp;&amp;
            numfreekeys &lt; PyDict_MAXFREELIST) {
            _Py_DEC_REFTOTAL;
            keys_free_list[numfreekeys++] = oldkeys;
        }
        else {
            _Py_DEC_REFTOTAL;
            PyObject_FREE(oldkeys);
        }
    }
    // 到此键值对数组的元素就拷贝完了，然后还要进行索引映射，并存储在哈希槽中
    build_indices(mp-&gt;ma_keys, newentries, numentries);
    // dk_usable 表示还可以容纳多少个键值对
    // dk_nentries 表示已经容纳了多少个键值对
    // 而 numentries 表示字典的长度，所以重构之后
    // dk_usable 的大小要减去 numentries，dk_nentries 直接等于 numentries
    mp-&gt;ma_keys-&gt;dk_usable -= numentries;
    mp-&gt;ma_keys-&gt;dk_nentries = numentries;
    return 0;
}
</code></pre>
<p>因为要对哈希表的种类分情况讨论，所以导致代码有点长，但逻辑不难理解：</p>
<ul>
<li>首先确定哈希表的容量，它要满足 2 的幂次方，并且大于等于 ma_used * 3。</li>
<li>为 ma_keys 重新申请内存。</li>
<li>根据哈希表的种类分情况讨论，但核心都是将旧的没有被删除的 entry 搬过去。</li>
<li>释放 ma_keys，如果字典之前是分离表，还要释放 ma_values。</li>
</ul>
<p>以上就是哈希表的扩容，或者说字典的扩容，我们就介绍到这儿，下一篇文章来介绍字典的缓存池。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-35"><a class="header" href="#楔子-35">楔子</a></h2>
<p>本篇文章来聊一聊字典的缓存池，我们知道字典有一个 ma_keys 字段和一个 ma_values 字段。当哈希表为分离表时，键由 ma_keys 维护，值由 ma_values 维护；当哈希表为结合表时，键和值均由 ma_keys 维护。</p>
<p>那么当我们销毁一个 PyDictObject 时，也肯定要先释放 ma_keys 和 ma_values。</p>
<ul>
<li>如果是分离表，会将每个 value 的引用计数减 1，然后释放 ma_values；再将每个 key 的引用计数减 1，然后释放 ma_keys。最后再释放 PyDictObject 本身。</li>
<li>如果是结合表，由于 key、value 都在 ma_keys 中，将每个 key、value 的引用计数减 1 之后，只需释放 ma_keys 即可。最后再释放 PyDictObject 本身。</li>
</ul>
<p>整个过程还是很清晰的，只不过这里面遗漏了点什么东西，没错，就是缓存池。在介绍浮点数的时候，我们说不同的对象都有自己的缓存池，当然字典也不例外。并且除了 PyDictObject 之外，PyDictKeysObject 也有相应的缓存池，毕竟它负责存储具体的键值对。</p>
<p>那么下面我们就来研究一下这两者的缓存池。</p>
<h2 id="pydictobject-缓存池"><a class="header" href="#pydictobject-缓存池">PyDictObject 缓存池</a></h2>
<p>字典的缓存池和列表的缓存池高度相似，都是采用数组实现的，并且容量也是 80 个。</p>
<pre><code class="language-C">// Objects/dictobject.c
#define PyDict_MAXFREELIST 80

static PyDictObject *free_list[PyDict_MAXFREELIST];
static int numfree = 0;
</code></pre>
<p>下面看一下字典的销毁过程，因为放入缓存池这个动作，一定是在对象销毁时发生的。</p>
<pre><code class="language-C">// Objects/dictobject.c

static inline void
dictkeys_decref(PyDictKeysObject *dk)
{
    assert(dk-&gt;dk_refcnt &gt; 0);
    _Py_DEC_REFTOTAL;
    // 将 dk_refcnt 减 1
    // 如果字典是结合表，那么 dk-&gt;dk_refcnt 减 1 之后一定为 0
    // 如果字典是分离表，那么 dk-&gt;dk_refcnt 减 1 之后则不一定为 0
    if (--dk-&gt;dk_refcnt == 0) {
        // 释放 ma_keys，该函数稍后再聊
        free_keys_object(dk);
    }
}

static void
dict_dealloc(PyDictObject *mp)
{
    PyObject **values = mp-&gt;ma_values;
    PyDictKeysObject *keys = mp-&gt;ma_keys;
    Py_ssize_t i, n;

    // 因为要被销毁，所以让 GC 不再跟踪
    PyObject_GC_UnTrack(mp);
    // 用于延迟释放
    Py_TRASHCAN_BEGIN(mp, dict_dealloc)
    // 如果 values 不为 NULL，说明是分离表  
    if (values != NULL) {
        if (values != empty_values) {
            // 将每个 value 的引用计数减 1
            for (i = 0, n = mp-&gt;ma_keys-&gt;dk_nentries; i &lt; n; i++) {
                Py_XDECREF(values[i]);
            }
            // 释放 ma_values
            free_values(values);
        }
        // 将 ma_keys-&gt;dk_refcnt 减 1，至于是否会释放 ma_keys
        // 则看是否还有其它组的 value 使用它
        dictkeys_decref(keys);
    }
    // 否则说明是结合表
    else if (keys != NULL) {
        // 结合表的话，dk_refcnt 一定等于 1，因为每组 value 都独占一组 key
        assert(keys-&gt;dk_refcnt == 1);
        // dk_refcnt 减 1 之后等于 0，内部会调用 free_keys_object
        // 在里面会先将每个 key、value 的引用计数减 1，然后再释放 ma_keys
        dictkeys_decref(keys);
    }
    // 如果 numfree 没达到 80，那么放入缓存池
    if (numfree &lt; PyDict_MAXFREELIST &amp;&amp; Py_TYPE(mp) == &amp;PyDict_Type)
        // PyDictObject 缓存池是一个数组，直接添加在数组的尾部即可，然后 numfree 自增 1
        free_list[numfree++] = mp;
    else
        // 否则将空间交还给系统堆
        Py_TYPE(mp)-&gt;tp_free((PyObject *)mp);
    Py_TRASHCAN_END
}
</code></pre>
<p>同理，当创建字典时，也会优先从缓存池里面获取。</p>
<pre><code class="language-C">// Objects/dictobject.c

static PyObject *
new_dict(PyDictKeysObject *keys, PyObject **values)
{
    PyDictObject *mp;
    assert(keys != NULL);
    // 如果 numfree != 0，证明缓存池有可用元素
    if (numfree) {
        // 从缓存池当中获取
        mp = free_list[--numfree];
        assert (mp != NULL);
        assert (Py_TYPE(mp) == &amp;PyDict_Type);
        // 将引用计数设置为 1
        _Py_NewReference((PyObject *)mp);
    }
    else {
        // 否则从堆区申请内存
        mp = PyObject_GC_New(PyDictObject, &amp;PyDict_Type);
        // ...
    }
    // 初始化字段，然后返回 (PyObject *)mp
    mp-&gt;ma_keys = keys;
    mp-&gt;ma_values = values;
    mp-&gt;ma_used = 0;
    mp-&gt;ma_version_tag = DICT_NEXT_VERSION();
    ASSERT_CONSISTENT(mp);
    return (PyObject *)mp;
}
</code></pre>
<p>因此在缓存池的实现上，字典和列表有着很高的相似性。不仅都由数组实现，在销毁的时候也会放在数组的尾部，创建的时候也会从数组的尾部获取。当然啦，因为这么做符合数组的特性，如果销毁和创建都是在数组的头部操作，那么时间复杂度就从 O(1) 变成了 O(n)。</p>
<p>我们用 Python 来测试一下：</p>
<pre><code class="language-Python">d1 = {k: 1 for k in &quot;abcdef&quot;}
d2 = {k: 1 for k in &quot;abcdef&quot;}
print(&quot;id(d1):&quot;, id(d1))
print(&quot;id(d2):&quot;, id(d2))
# 放到缓存池的尾部
del d1
del d2
# 缓存池：[d1, d2]

# 从缓存池的尾部获取
# 显然 id(d3) 和上面的 id(d2) 是相等的
d3 = {k: 1 for k in &quot;abcdefghijk&quot;}
# id(d4) 和上面的 id(d1) 是相等的
d4 = {k: 1 for k in &quot;abcdefghijk&quot;}
print(&quot;id(d3):&quot;, id(d3))
print(&quot;id(d4):&quot;, id(d4))
&quot;&quot;&quot;
id(d1): 140079181793600
id(d2): 140079181775488
id(d3): 140079181775488
id(d4): 140079181793600
&quot;&quot;&quot;
</code></pre>
<p>输出结果和我们的预期是相符合的，以上就是 PyDictObject 的缓存池。</p>
<h2 id="pydictkeysobject-缓存池"><a class="header" href="#pydictkeysobject-缓存池">PyDictKeysObject 缓存池</a></h2>
<p>PyDictKeysObject 也有自己的缓存池，同样基于数组实现，大小是 80。</p>
<pre><code class="language-C">// Objects/dictobject.c

#define PyDict_MAXFREELIST 80
// PyDictObject 缓存池以及容量
static PyDictObject *free_list[PyDict_MAXFREELIST];
static int numfree = 0;
// PyDictKeysObject 缓存池以及容量
static PyDictKeysObject *keys_free_list[PyDict_MAXFREELIST];
static int numfreekeys = 0;
</code></pre>
<p>来看一下 PyDictKeysObject 的销毁过程：</p>
<pre><code class="language-C">// Objects/dictobject.c

static inline void
dictkeys_decref(PyDictKeysObject *dk)
{
    assert(dk-&gt;dk_refcnt &gt; 0);
    _Py_DEC_REFTOTAL;
    // 分离表：多组 value 可以共享一组 key
    // 结合表：每组 value 独占一组 key
    // 因此要先将 dk_refcnt 减 1，如果结果为 0，那么才能释放 ma_keys
    if (--dk-&gt;dk_refcnt == 0) {
        free_keys_object(dk);
    }
}

static void
free_keys_object(PyDictKeysObject *keys)
{
    // 获取键值对数组
    PyDictKeyEntry *entries = DK_ENTRIES(keys);
    Py_ssize_t i, n;
    // 遍历 dk_entries，减少 key、value 的引用计数
    for (i = 0, n = keys-&gt;dk_nentries; i &lt; n; i++) {
        Py_XDECREF(entries[i].me_key);
        // 如果是分离表，那么 me_value == NULL
        // 而当参数为 NULL 时，Py_XDECREF 不做任何处理
        Py_XDECREF(entries[i].me_value);
    }
    // 放入缓存池，除了要保证缓存池没满之外，还要保证 dk_size = 8
    // 也就是说，只有容量为 8 的哈希表的 PyDictKeysObject 才会被缓存
    if (keys-&gt;dk_size == PyDict_MINSIZE &amp;&amp; numfreekeys &lt; PyDict_MAXFREELIST) {
        keys_free_list[numfreekeys++] = keys;
        return;
    }
    // 如果条件不满足，释放 ma_keys，将内存交还给系统堆
    PyObject_FREE(keys);
}
</code></pre>
<p>所以 PyDictKeysObject 的缓存池和列表的缓存池同样是高度相似的，只不过它想要被缓存，除了保证缓存池有剩余空间之外，还要满足哈希表的容量等于 8，这个限制是出于对内存方面的考量。</p>
<p>以上是 ma_keys 的销毁过程，再来看看它的创建过程。</p>
<pre><code class="language-C">// Objects/dictobject.c

// 为 PyDictKeysObject 实例申请内存
static PyDictKeysObject *new_keys_object(Py_ssize_t size)
{
    PyDictKeysObject *dk;
    Py_ssize_t es, usable;

    assert(size &gt;= PyDict_MINSIZE);
    assert(IS_POWER_OF_2(size));
    
    // 获取键值对数组的长度
    usable = USABLE_FRACTION(size);
    // 计算哈希索引数组中每个元素的大小
    if (size &lt;= 0xff) {
        es = 1;
    }
    else if (size &lt;= 0xffff) {
        es = 2;
    }
#if SIZEOF_VOID_P &gt; 4
    else if (size &lt;= 0xffffffff) {
        es = 4;
    }
#endif
    else {
        es = sizeof(Py_ssize_t);
    }
    // 如果容量等于 8，并且缓存池有可用元素，那么从缓存池中获取
    if (size == PyDict_MINSIZE &amp;&amp; numfreekeys &gt; 0) {
        dk = keys_free_list[--numfreekeys];
    }
    else {
        // 否则在堆区申请内存，而内存包含三部分
        // sizeof(PyDictKeysObject)：结构体 PyDictKeysObject 的大小
        // es * size：哈希索引数组的大小
        // sizeof(PyDictKeyEntry) * usable)：键值对数组的大小
        dk = PyObject_MALLOC(sizeof(PyDictKeysObject)
                             + es * size
                             + sizeof(PyDictKeyEntry) * usable);
        if (dk == NULL) {
            PyErr_NoMemory();
            return NULL;
        }
    }
    _Py_INC_REFTOTAL;
    // 初始化字段
    dk-&gt;dk_refcnt = 1;
    dk-&gt;dk_size = size;
    dk-&gt;dk_usable = usable;
    dk-&gt;dk_lookup = lookdict_unicode_nodummy;
    dk-&gt;dk_nentries = 0;
    // 将哈希索引数组中的每个元素都设置成 -1
    memset(&amp;dk-&gt;dk_indices[0], 0xff, es * size);
    // 将键值对数组中的每个元素（entry）的所有字段都设置成 0
    memset(DK_ENTRIES(dk), 0, sizeof(PyDictKeyEntry) * usable);
    return dk;
}
</code></pre>
<p>非常简单，我们来验证一下。</p>
<pre><code class="language-Python">from ctypes import *

class PyObject(Structure):
    _fields_ = [(&quot;ob_refcnt&quot;, c_ssize_t),
                (&quot;ob_type&quot;, c_void_p)]

class PyDictObject(PyObject):
    _fields_ = [(&quot;ma_used&quot;, c_ssize_t),
                (&quot;ma_version_tag&quot;, c_uint64),
                (&quot;ma_keys&quot;, c_void_p),
                (&quot;ma_values&quot;, c_void_p)]

d1 = {k: 1 for k in &quot;komeiji satori&quot;}
print(
    &quot;d1.ma_keys:&quot;, PyDictObject.from_address(id(d1)).ma_keys
)
# 键值对个数超过了 8，哈希表的容量必然也超过了 8
# 那么当销毁 d1 的时候，d1.ma_keys 不会被缓存，而是会直接释放掉
del d1

d2 = {k: 1 for k in &quot;abc&quot;}
print(
    &quot;d2.ma_keys:&quot;, PyDictObject.from_address(id(d2)).ma_keys
)
# 容量等于 8，所以 d2.ma_keys 会被缓存
del d2

d3 = {k: 1 for k in &quot;komeiji koishi&quot;}
print(
    &quot;d3.ma_keys:&quot;, PyDictObject.from_address(id(d3)).ma_keys
)
# 尽管 d2 的 ma_keys 被缓存起来了，但是 d3 的 dk_size 大于 8
# 因此它不会从缓存池中获取，而是重新创建

d4 = {k: 1 for k in &quot;abc&quot;}
print(
    &quot;d4.ma_keys:&quot;, PyDictObject.from_address(id(d4)).ma_keys
)
# d4 的 dk_size 等于 8，因此它会从缓存池中获取，从而复用被销毁的 d2.ma_keys
# 最终打印结果如下
&quot;&quot;&quot;
d1.ma_keys: 94324986272656
d2.ma_keys: 140165216613312
d3.ma_keys: 140165225069456
d4.ma_keys: 140165216613312
&quot;&quot;&quot;
</code></pre>
<p>从打印的结果来看，由于 d4.ma_keys 和 d2.ma_keys 是相同的，因此证实了我们的结论。不像列表和字典，它们是只要被销毁，就会放到缓存池里面，因为它们没有存储具体的数据，大小是固定的。但 PyDictKeysObject 不同，由于它存储了 entry，每个 entry 占 24 字节，如果内部的 entry 非常多，那么缓存起来会有额外的内存开销。因此 Python 的策略是，只有在哈希表容量等于 8 的时候，才会缓存。当然这三者在缓存池的实现上，是基本一致的。</p>
<blockquote>
<p>不难看出，Python 在性能和内存使用方面都做了考量。但如果你追求更高的效率，那么也可以自己定制 Python 解释器，比如增大缓存池的容量等等，用更多的空间去换取时间。</p>
</blockquote>
<h2 id="小结-36"><a class="header" href="#小结-36">小结</a></h2>
<p>到此，字典相关的内容就全部介绍完了。和元组一样，字典也在我们看不到的地方被大量使用，比如对象的属性字典、名字空间等等。正因为解释器内部也在大量使用字典，所以字典是一个被高度优化的数据结构，不仅要保证搜索效率，还要减少内存使用。</p>
<p>下一篇文章，我们来介绍 Python 的集合。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-36"><a class="header" href="#楔子-36">楔子</a></h2>
<p>本篇文章来聊一聊 Python 的集合是怎么实现的？前面我们介绍了字典的实现原理，它底层是基于哈希表实现的，而集合也是如此。</p>
<blockquote>
<p>事实上，集合就类似于没有 value 的字典。</p>
</blockquote>
<h2 id="集合的使用场景"><a class="header" href="#集合的使用场景">集合的使用场景</a></h2>
<p>那么集合都有哪些用处呢？</p>
<p><font color="darkblue"><strong>1）去重</strong></font></p>
<pre><code class="language-Python">chars = [&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;]

print(
    list(set(chars))
)  # ['b', 'a', 'c']
</code></pre>
<p>比如你需要监听一个队列，处理接收到的消息，但每一条消息都有一个编号，要保证具有相同编号的消息只能被处理一次，要怎么做呢？</p>
<p>显然集合此时就派上用场了，我们可以创建一个集合，每来一条消息，就检测它的编号是否在集合中。如果存在，则说明消息已经被处理过了，忽略掉；如果不存在，说明消息还没有被处理，那么就将它的编号添加到集合中，然后处理消息。</p>
<p><font color="darkblue"><strong>2）判断某个序列是否包含指定的多个元素</strong></font></p>
<pre><code class="language-Python">data = [&quot;S&quot;, &quot;A&quot;, &quot;T&quot;, &quot;O&quot;, &quot;R&quot;, &quot;I&quot;]

# 现在要判断 data 是否包含 &quot;T&quot;、&quot;R&quot; 和 &quot;I&quot;
# 如果使用列表的话
print(
    &quot;T&quot; in data and &quot;R&quot; in data and &quot;I&quot; in data
)  # True

# 显然使用列表比较麻烦，并且效率也不高，于是我们可以使用集合
print(
    set(data) &gt;= {&quot;T&quot;, &quot;R&quot;, &quot;I&quot;}
)  # True
</code></pre>
<p>同理，基于此方式，我们也可以检测一个字典是否包含指定的多个 key。</p>
<pre><code class="language-Python">data = {
    &quot;name&quot;: &quot;satori&quot;,
    &quot;age&quot;: 17,
    &quot;gender&quot;: &quot;female&quot;
}

# 判断字典是否包含 name、age、gender 三个 key
print(
    data.keys() &gt;= {&quot;name&quot;, &quot;age&quot;, &quot;gender&quot;}
)  # True

# 字典的 keys 方法会返回一个 dict_keys 对象
# 该对象具备集合的性质，可以直接和集合进行运算
</code></pre>
<p>显然对于这种需求，有了集合就方便多了。</p>
<h2 id="集合的-api"><a class="header" href="#集合的-api">集合的 API</a></h2>
<p>然后我们来罗列一下集合支持的 API，在使用集合的时候要做到心中有数。</p>
<pre><code class="language-python"># 如果是创建一个空集合，那么要使用 set()
# 写成 {} 的话，解释器会认为这是一个空字典
s = {1, 2, 3}

# 添加元素，时间复杂度是 O(1)
s.add(4)
print(s)  # {1, 2, 3, 4}

# 删除指定的元素，如果元素不存在，会抛出 KeyError
# 时间复杂度为 O(1)
s.remove(2)
print(s)  # {1, 3, 4}

# 删除指定的元素，如果元素不存在则什么也不做
# 时间复杂度为 O(1)
s.discard(666)
print(s)  # {1, 3, 4}

# 随机弹出一个元素并返回，如果集合为空，会抛出 KeyError
# 时间复杂度为 O(1)
print(s.pop())  # 1
print(s)  # {3, 4}

# 清空一个集合
s.clear()
print(s)  # set()

# 还有一些 API，但我们更推荐使用操作符的方式
# 两个集合取交集
print({1, 2} &amp; {2, 3})  # {2}

# 两个集合取并集
print({1, 2} | {2, 3})  # {1, 2, 3}

# 两个集合取差集
# s1 - s2，返回在 s1、但不在 s2 当中的元素
print({1, 2, 3} - {2, 3, 4})  # {1}

# 两个集合取对称差集
# s1 ^ s2，返回既不在 s1、也不在 s2 当中的元素
print({1, 2, 3} ^ {2, 3, 4})  # {1, 4}

# 判断两个集合是否相等，也就是内部的元素是否完全一致
# 顺序无所谓，只比较元素是否全部相同
print({1, 2, 3} == {3, 2, 1})  # True
print({1, 2, 3} == {1, 2, 4})  # False

# 判断一个集合是否包含另一个集合的所有元素
# 假设有两个集合 s1 和 s2：
#    如果 s1 的元素都在 s2 中，那么 s2 &gt;= s1；
#    如果 s2 的元素都在 s1 中，那么 s1 &gt;= s2；
#    如果 s1 和元素和 s2 全部相同，那么 s1 == s2；
print({1, 2, 3} &gt; {1, 2})  # True
print({1, 2, 3} &gt;= {1, 2, 3})  # True
</code></pre>
<p>以上就是集合支持的一些 API，还是很简单的。</p>
<h2 id="集合的底层结构"><a class="header" href="#集合的底层结构">集合的底层结构</a></h2>
<p>集合和字典的内部都使用了哈希表，但字典的哈希表采用两个数组实现，而集合的哈希表采用一个数组实现。因此对于集合来说，这个数组不仅要存储 entry，并且映射出的索引也是该数组的索引。</p>
<p>下面看一下集合的底层结构长什么样子。</p>
<pre><code class="language-C">// Include/setobject.h

typedef struct {
    // 定长对象的头部信息，但集合显然是一个变长对象
    // 所以和字典一样，肯定有其它字段充当 ob_size
    PyObject_HEAD
    // Active 态的 entry 数量加上 Dummy 态的 entry 数量
    // 一个 entry 就是哈希表里的一个元素，类型为 setentry
    // 因此在集合里面，一个 entry 就是一个 setentry 结构体实例
    // 当删除集合的 entry 时，也必须是伪删除，因为要保证探测链不断裂
    // 如果 entry 被伪删除了，那么它便处于 Dummy 态
    Py_ssize_t fill;
    // Active 态的 entry 数量，显然这个 used 充当了 ob_size，也就是集合的元素个数
    Py_ssize_t used;
    // 在看字典源码的时候，我们也见到了 mask，它用于和哈希值进行按位与、计算索引
    // 并且这个 mask 等于哈希表的容量减 1，为什么呢？
    // 假设哈希值等于 v，哈希表容量是 n，那么通过 v 对 n 取模即可得到一个位于 0 到 n-1 之间的数
    // 然而取模运算的效率不高，应该使用 v&amp;(n-1)，它的作用等价于 v%n，并且速度更快
    // 但是注意，只有在 n 为 2 的幂次方的时候，v&amp;(n-1) 和 v%n 才是完全等价的
    // 所以哈希表的容量要求是 2 的幂次方，就是为了将取模运算优化成按位与运算
    Py_ssize_t mask;
    // 指向 setentry 数组首元素的指针
    // 这个 setentry 数组可以是下面的 smalltable，也可以是单独申请的一块内存
    setentry *table;
    // 集合的哈希值，只适用于不可变集合
    Py_hash_t hash;
    // 用于 pop 方法
    Py_ssize_t finger;
    // 一个 setentry 类型的数组，集合的元素就存在里面，但记得我们前面说过
    // 变长对象的内部不会存储具体的元素，而是会存储一个指针，该指针指向的内存区域才是用来存储具体元素的
    // 这样当扩容的时候，只需要让指针指向新的内存区域即可，从而方便维护
    // 没错，对于集合而言，只有在容量不超过 8 的时候，元素才会存在里面
    // 而一旦超过了 8，那么会使用 malloc 单独申请内存
    setentry smalltable[PySet_MINSIZE];
    // 弱引用列表，不做深入讨论
    PyObject *weakreflist;
} PySetObject;
</code></pre>
<p>有了字典的经验，再看集合会简单很多。然后是 setentry，用于承载集合内的元素，那么它的结构长什么样呢？相信你能够猜到。</p>
<pre><code class="language-C">// Include/setobject.h

typedef struct {
    PyObject *key;
    Py_hash_t hash;
} setentry;
</code></pre>
<p>相比字典少了一个 value，这是显而易见的。</p>
<p>因此集合的结构很清晰了，假设有一个集合 <font color="blue">{3.14, &quot;abc&quot;, 666}</font>，那么它的结构如下：</p>
<p><img src="./images/133.png" alt="" /></p>
<p>由于集合里面只有三个元素，所以它们都会存在 smalltable 数组里面，我们通过 ctypes 来证明这一点。</p>
<pre><code class="language-python">from ctypes import *

class PyObject(Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
    ]

class SetEntry(Structure):
    _fields_ = [
        (&quot;key&quot;, POINTER(PyObject)),
        (&quot;hash&quot;, c_longlong)
    ]

class PySetObject(PyObject):
    _fields_ = [
        (&quot;fill&quot;, c_ssize_t),
        (&quot;used&quot;, c_ssize_t),
        (&quot;mask&quot;, c_ssize_t),
        (&quot;table&quot;, POINTER(SetEntry)),
        (&quot;hash&quot;, c_long),
        (&quot;finger&quot;, c_ssize_t),
        (&quot;smalltable&quot;, (SetEntry * 8)),
        (&quot;weakreflist&quot;, POINTER(PyObject)),
    ]


s = {3.14, &quot;abc&quot;, 666}
# 先来打印一下哈希值
print('hash(3.14) =', hash(3.14))
print('hash(&quot;abc&quot;) =', hash(&quot;abc&quot;))
print('hash(666) =', hash(666))
&quot;&quot;&quot;
hash(3.14) = 322818021289917443
hash(&quot;abc&quot;) = 2548892134347232650
hash(666) = 666
&quot;&quot;&quot;

# 获取 PySetObject 结构体实例
py_set_obj = PySetObject.from_address(id(s))
# 遍历 smalltable，打印索引和 key 的哈希值
for index, entry in enumerate(py_set_obj.smalltable):
    print(index, entry.hash)
&quot;&quot;&quot;
0 0
1 0
2 666
3 322818021289917443
4 0
5 0
6 2548892134347232650
7 0
&quot;&quot;&quot;
</code></pre>
<p>根据输出的哈希值我们可以断定，这三个元素确实存在了 smalltable 数组里面，并且 666 存在了数组索引为 2 的位置、3.14 存在了数组索引为 3 的位置、&quot;abc&quot; 存在了数组索引为 6 的位置。</p>
<p>当然，由于哈希值是随机的，所以每次执行之后打印的结果都可能不一样，但是整数除外，它的哈希值就是它本身。既然哈希值不一样，那么每次映射出的索引也可能不同，但总之这三个元素是存在 smalltable 数组里面的。</p>
<p>然后我们再考察一下其它字段：</p>
<pre><code class="language-python">s = {3.14, &quot;abc&quot;, 666}
py_set_obj = PySetObject.from_address(id(s))
# 集合里面有 3 个元素，所以 fill 和 used 都是 3
print(py_set_obj.fill)  # 3
print(py_set_obj.used)  # 3

# 将集合元素全部删除
# 这里不能用 s.clear()，原因一会儿说
for _ in range(len(s)):
    s.pop()
    
# 我们知道哈希表在删除元素的时候是伪删除
# 所以 fill 不变，但是 used 每次会减 1
print(py_set_obj.fill)  # 3
print(py_set_obj.used)  # 0
</code></pre>
<p>fill 字段维护的是 Active 态的 entry 数量加上 Dummy 态的 entry 数量，所以删除元素时它的大小是不变的。但 used 字段的值每次会减 1，因为它维护的是 Active 态的 entry 的数量。所以在不涉及元素的删除时，这两者的大小是相等的。</p>
<p>另外我们说上面不能用 s.clear()，因为该方法表示清空集合，此时会重置为初始状态，然后 fill 和 used 都会是 0，这样就观察不到想要的现象了。</p>
<p>删除集合所有元素之后，我们再往里面添加元素，看看是什么效果：</p>
<pre><code class="language-python">s = {3.14, &quot;abc&quot;, 666}
py_set_obj = PySetObject.from_address(id(s))
for _ in range(len(s)):
    s.pop()

# 添加一个元素
s.add(0)
print(py_set_obj.fill)  # 3
print(py_set_obj.used)  # 1
</code></pre>
<p>多次执行的话，会发现打印的结果可能是 3、1，也有可能是 4、1。至于原因，有了字典的经验，相信你肯定能猜到。</p>
<p>首先添加元素之后，used 肯定为 1。至于 fill，如果添加元素的时候，正好撞上了一个 Dummy 态的 entry，那么将其替换掉，此时 fill 不变，仍然是 3。但如果没有撞上 Dummy 态的 entry，而是添加在了新的位置，那么 fill 就是 4。</p>
<pre><code class="language-python">for i in range(1, 10):
    s.add(i)
print(py_set_obj.fill)  # 10
print(py_set_obj.used)  # 10
s.pop()
print(py_set_obj.fill)  # 10
print(py_set_obj.used)  # 9
</code></pre>
<p>在之前代码的基础上，继续添加 9 个元素，然后 used 变成了 10，这很好理解，因为此时集合有 10 个元素。但 fill 也是 10，这是为什么？很简单，因为哈希表扩容了，扩容时会删除 Dummy 态的 entry，所以 fill 和 used 是相等的。同理，如果再继续 pop，那么 fill 和 used 就又变得不相等了。</p>
<h2 id="集合的创建"><a class="header" href="#集合的创建">集合的创建</a></h2>
<p>集合的结构我们已经清楚了，再来看看它的初始化过程。我们调用类 set，传入一个可迭代对象，便可创建一个集合，这个过程是怎样的呢？</p>
<pre><code class="language-C">// Objects/setobject.c
PyObject *
PySet_New(PyObject *iterable)
{
    return make_new_set(&amp;PySet_Type, iterable);
}

static PyObject *
make_new_set(PyTypeObject *type, PyObject *iterable)
{
    PySetObject *so;
    // 为 PySetObject 申请内存，初始容量为 8
    so = (PySetObject *)type-&gt;tp_alloc(type, 0);
    if (so == NULL)
        return NULL;
    // 对字段做初始化
    so-&gt;fill = 0;
    so-&gt;used = 0;
    so-&gt;mask = PySet_MINSIZE - 1;
    // 哈希表容量为 8 时，元素会存在 smalltable 里面
    // 因此直接将 smalltable 赋值给 table
    so-&gt;table = so-&gt;smalltable;
    so-&gt;hash = -1;
    so-&gt;finger = 0;
    so-&gt;weakreflist = NULL;
    
    // 遍历 iterable，将迭代出的元素添加到集合中
    // 关于这个函数，我们之后再介绍
    if (iterable != NULL) {
        if (set_update_internal(so, iterable)) {
            Py_DECREF(so);
            return NULL;
        }
    }

    return (PyObject *)so;
}
</code></pre>
<p>可以看到，集合的创建过程非常简单。</p>
<h2 id="字典和集合的哈希表的差异"><a class="header" href="#字典和集合的哈希表的差异">字典和集合的哈希表的差异</a></h2>
<p>字典和集合都是采用哈希表实现的，但字典的哈希表使用了两个数组，而集合的哈希表使用了一个数组，我们对比一下两者的差异。</p>
<p>假设有一个字典和一个集合，字典包含三个键值对，分别是 <font color="blue">&quot;a&quot;: 1、&quot;b&quot;: 2、&quot;c&quot;: 3</font>，集合包含三个元素，分别是 <font color="blue">&quot;a&quot;、&quot;b&quot;、&quot;c&quot;</font>，然后映射出的索引分别是 2、5、3。</p>
<p><img src="./images/134.png" alt="" /></p>
<blockquote>
<p>注：为了方便，这里的图画得没有那么严谨。比如集合的哈希表，里面的元素直接用字符串代替了，但其实它存储的是 <font color="blue">setentry entry</font>，而 <font color="blue">entry 的 key 字段</font>指向的才是字符串。当然这里我们心里清楚就好。</p>
</blockquote>
<p>在介绍字典的时候我们说过，早期的字典内部的哈希表也是使用一个数组实现，除了 entry 会多存储一个 value 之外，其它和当前的集合是类似的。</p>
<p>但如果只使用一个数组实现，会导致内存浪费严重，因为哈希表必须要保证一定的稀疏性。所以后续字典内部的哈希表采用两个数组实现，将存储键值对的数组的长度压缩到原来的 2/3，至于映射出的索引则由另一个数组（哈希索引数组）来承载。虽然引入新的数组会带来额外的内存开销（假设大小为 m 字节），但存储键值对的数组不用再浪费 1/3 的空间（假设大小为 n 字节），只要 m 小于 n，那么使用两个数组就会更加节省内存。而在介绍字典的时候我们也看到了，m 是远小于 n 的。</p>
<p>那么问题来了，为什么集合不使用两个数组呢？很简单，因为使用一个数组实现哈希表会更简单，虽然也更加浪费内存。而集合和字典在哈希表的实现上之所以区别对待，还是使用频率的问题，解释器内部极度依赖字典，比如全局变量就是使用字典存储的。</p>
<p>可以说字典的效率高度影响着整个解释器的效率，字典的内存大小高度影响着解释器的内存占用。因此 Python 除了优化字典的搜索性能之外，还要尽可能地减少字典的内存大小。所以字典搞出了分离表、结合表，这一切操作都是为了将字典的内存占用降到最低。</p>
<p>至于集合，解释器对它的依赖就很小了，所以内部的哈希表，只采用了一个数组实现。虽然会有内存浪费，但无伤大雅。</p>
<p>好，回到上面的例子，如果将字典的键值对 <font color="blue">&quot;b&quot;: 2</font> 和集合的元素 <font color="blue">&quot;b&quot;</font> 删掉，那么它们的结构会发生什么变化呢？</p>
<p><img src="./images/135.png" alt="" /></p>
<p>&quot;b&quot; 映射出的索引为 5，因此对于字典来说，会将索引为 5 的哈希槽存储的值设置为 dummy。然后是键值对数组，会将指定的 entry 的 me_key 和 me_value 字段全部设置为 NULL，相当于回归到了初始状态。</p>
<blockquote>
<p>需要注意的是，数组一旦申请，那么 entry 的空间就已经有了，只是 me_key 和 me_value 字段均为 NULL。而所谓添加键值对，本质上也是修改指定 entry 的 me_key 和 me_value 字段。</p>
</blockquote>
<p>对于集合来说，它只有一个数组，这个数组不仅要存储键值对，它的索引还表示 key 映射出的索引，当然这里的 key 指的就是集合的元素。&quot;b&quot; 映射出的索引为 5，所以将数组中索引为 5 的 <code>entry-&gt;key</code> 设置为 dummy。</p>
<p>但要注意的是，字典的 dummy 是一个整数，值为 -2（DKIX_DUMMY），因为哈希索引数组存储的是<font color="blue">键值对数组的索引</font>，显然这是一个整数。然后 key 映射出的索引是哈希索引数组的索引，如果对应的哈希槽存储的值是 -2，说明当前搜索的 key 对应的 entry 被删除了，应该继续向后搜索。</p>
<p>而集合的 dummy 是一个结构体指针，定义如下：</p>
<pre><code class="language-C">// Objects/setobject.c
static PyObject _dummy_struct;
#define dummy (&amp;_dummy_struct)
</code></pre>
<p>因为集合内部的哈希表只使用了一个数组，该数组存储的是 setentry。如果在查找的时候，发现对应的 entry 的 key 等于 dummy，就知道该 entry 被删除了，应该继续向后搜索。</p>
<p>好，继续回到上面的例子，假设这时候再给字典添加一个键值对 <font color="blue">&quot;d&quot;: 4</font>，给集合添加一个元素 <font color="blue">&quot;d&quot;</font>，而字符串 &quot;d&quot; 映射出的索引也是 5，那么结构是怎样的呢？</p>
<p><img src="./images/136.png" alt="" /></p>
<p>对于字典来说，键值对始终按照先来后到的顺序添加在键值对数组中，然后将它在键值对数组中的索引保存在指定的哈希槽中。由于索引为 5 的哈希槽保存的是 -2，处于 Dummy 态，因此直接将它设置为 3。</p>
<p>同理对于集合来说也是类似的。数组索引为 5 的位置保存的值等于 dummy，处于 Dummy 态，说明该元素被删除了，那么直接替换掉。因此整个过程的逻辑很简单：由于索引会存在冲突，所以元素删除之后，需要写入一个特殊的墓碑值，也就是这里的 dummy，因为要保证探测链不断裂。但如果集合后续添加元素时，正好撞上了一个 Dummy 态的 entry，那么会直接替换掉。</p>
<p>所以不论是字典还是集合，只要处于 Dummy 态，都可以替换掉。因为 Dummy 态存在的目的就是为了保证探测链不断裂，而替换之后探测链依旧是完整的。</p>
<h2 id="小结-37"><a class="header" href="#小结-37">小结</a></h2>
<p>以上我们就剖析了集合的底层结构以及它的创建过程，不难发现集合的实现比字典要简单很多，并且集合没有自己的缓存池。</p>
<p>下一篇文章来介绍集合的相关操作。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-37"><a class="header" href="#楔子-37">楔子</a></h2>
<p>本篇文章来聊一聊集合支持的操作，比如元素的添加、删除，以及集合的扩容等等。并且集合还支持交集、并集、差集等运算，它们又是如何实现的呢？下面就一起来看一看。</p>
<h2 id="add-方法添加元素"><a class="header" href="#add-方法添加元素">add 方法：添加元素</a></h2>
<p>调用 add 方法可以向集合添加一个元素，在底层会执行 set_add 函数。</p>
<pre><code class="language-C">// Objects/setobject.c
static PyObject *
set_add(PySetObject *so, PyObject *key)
{
    // 调用了 set_add_key 函数
    if (set_add_key(so, key))
        return NULL;
    // 返回 None
    Py_RETURN_NONE;
}

static int
set_add_key(PySetObject *so, PyObject *key)
{
    Py_hash_t hash;

    // 计算哈希值，由于字符串内部会缓存自身的哈希值，因此需要判断一下
    // 如果 key 不是字符串，或者 key 是字符串、但哈希值为 -1（尚未计算过）
    // 那么计算哈希值，但如果计算之后的结果是 -1，说明对象不支持哈希
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return -1;
    }
    // 调用 set_add_entry
    return set_add_entry(so, key, hash);
}
</code></pre>
<p>假设有一个集合 so，那么 so.add(&quot;abc&quot;) 最终等价于 <font color="blue">set_add_entry(so, &quot;abc&quot;, hash(&quot;abc&quot;))</font>，所以核心逻辑位于 set_add_entry 里面，看一下它的实现，代码比较长。</p>
<pre><code class="language-C">// Objects/setobject.c
static int
set_add_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *table;
    setentry *freeslot;
    setentry *entry;
    size_t perturb;
    size_t mask;
    size_t i;
    size_t j;
    int cmp;

    // 增加 key 的引用计数，当然这里的 key 指的就是集合的元素
    Py_INCREF(key);

  restart:
    // mask 等于哈希表的容量减 1
    mask = so-&gt;mask;
    // 和字典一样，让 hash &amp; mask 计算出一个索引
    i = (size_t)hash &amp; mask;
    
    // 获取对应的 entry，里面包含了元素 key 和哈希值
    // 如果 key == NULL，说明该位置还没有存储元素
    // 此时就找到了合适的位置，跳转到 found_unused 标签
    entry = &amp;so-&gt;table[i];
    if (entry-&gt;key == NULL)
        goto found_unused;

    freeslot = NULL;
    // perturb 初始等于哈希值
    perturb = hash;

    while (1) {
        // 到这里说明指定的位置已经存储了元素，那么判断哈希值是否相同
        // 如果哈希值不同，那么 key 一定不相同
        // 如果哈希值相同，那么 key 不一定相同
        if (entry-&gt;hash == hash) {
            // 所以当哈希值相等时，还要比较新添加的 key 和已存在的 key 是否相同
            PyObject *startkey = entry-&gt;key;
            assert(startkey != dummy);
          、// 这里的 startkey 和 key 都是 C 的变量，它们都是指针
            // 如果两者相等，说明指向的是同一个对象，那么直接判定为相等，于是跳转到 found_active 标签
            if (startkey == key)  // 相当于 Python 的 is
                goto found_active;
            // 如果 startkey 和 key 不等，说明指向的不是同一个对象
            // 那么比较值是否相等，相当于 Python 的 ==
            // 这里是针对字符串的一个快分支
            if (PyUnicode_CheckExact(startkey)
                &amp;&amp; PyUnicode_CheckExact(key)
                &amp;&amp; _PyUnicode_EQ(startkey, key))
                goto found_active;
            table = so-&gt;table;
            Py_INCREF(startkey);
            // 如果 key 不是字符串，则执行通用比较逻辑
            cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
            Py_DECREF(startkey);
            // cmp &gt; 0，说明结果为真，即两个 key 的值相等
            // 跳转到 found_active 标签
            if (cmp &gt; 0)
                goto found_active;
            // cmp &lt; 0 表示执行比较操作时出现错误，基本不会发生
            if (cmp &lt; 0)
                goto comparison_error;
            // 到这里说明两个 key 虽然映射出的索引是一样的，但它们的值不相等
            // 那么要怎么办呢？显然要看下一个 entry 是否可用
            // 然后下面这三行代码估计让人有些费解，所做的事情如下
            // 如果在查询的过程中，哈希表扩容了，或者 key 发生了改变，那么跳转到 restart 标签重新执行
            // 但因为 GIL 的存在，实际不会发生
            if (table != so-&gt;table || entry-&gt;key != startkey)
                goto restart;
            mask = so-&gt;mask;
        }
        /* 如果是 Unused 态的 entry，那么 
         *     entry-&gt;key == NULL
         *     entry-&gt;hash == 0
         *
         * 如果是 Dummy 态的 entry，那么
         *     entry-&gt;key == dummy
         *     entry-&gt;hash == -1
         *
         * 如果是 Active 态的 entry，那么
         *     entry-&gt;key == some key
         *     entry-&gt;hash == some hash
         */
        // 说明 entry 处于 dummy 态，将它赋值给 freeslot
        else if (entry-&gt;hash == -1)
            freeslot = entry;
        // 关于这一步是做什么的，一会儿解释
        if (i + LINEAR_PROBES &lt;= mask) {
            for (j = 0 ; j &lt; LINEAR_PROBES ; j++) {
                entry++;
                if (entry-&gt;hash == 0 &amp;&amp; entry-&gt;key == NULL)
                    goto found_unused_or_dummy;
                if (entry-&gt;hash == hash) {
                    PyObject *startkey = entry-&gt;key;
                    assert(startkey != dummy);
                    if (startkey == key)
                        goto found_active;
                    if (PyUnicode_CheckExact(startkey)
                        &amp;&amp; PyUnicode_CheckExact(key)
                        &amp;&amp; _PyUnicode_EQ(startkey, key))
                        goto found_active;
                    table = so-&gt;table;
                    Py_INCREF(startkey);
                    cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
                    Py_DECREF(startkey);
                    if (cmp &gt; 0)
                        goto found_active;
                    if (cmp &lt; 0)
                        goto comparison_error;
                    if (table != so-&gt;table || entry-&gt;key != startkey)
                        goto restart;
                    mask = so-&gt;mask;
                }
                else if (entry-&gt;hash == -1)
                    freeslot = entry;
            }
        }
        // 到这里说明 (&amp;so-&gt;table[i])-&gt;key 和添加的 key 不相等，即出现了索引冲突
        // 那么要改变规则，重新映射，直到映射出一个可用的位置
        perturb &gt;&gt;= PERTURB_SHIFT;
        i = (i * 5 + 1 + perturb) &amp; mask;

        entry = &amp;so-&gt;table[i];
        if (entry-&gt;key == NULL)
            goto found_unused_or_dummy;
    }

  found_unused_or_dummy:
    // 如果 freeslot == NULL，说明没有撞上 Dummy 态的 entry
    // 跳转到 found_unused 标签
    if (freeslot == NULL)
        goto found_unused;
    // 否则说明撞上了 Dummy 态的 entry
    // 集合的长度加 1，或者说 Active 态的 entry 个数加 1
    so-&gt;used++;
    // 更新 key 和 hash
    freeslot-&gt;key = key;
    freeslot-&gt;hash = hash;
    return 0;

  found_unused:
    // 执行到这里，说明找到了新的可用位置
    // 那么不光 used 要加 1，fill 也要加 1
    so-&gt;fill++;
    so-&gt;used++;
    // 更新 key 和 hash
    entry-&gt;key = key;
    entry-&gt;hash = hash;
    // 如果哈希表的 entry 的个数（Active 态 + Dummy 态）没超过 mask * 3 / 5
    // 那么目前的容量是合理的，直接返回
    if ((size_t)so-&gt;fill*5 &lt; mask*3)
        return 0;
    // 否则进行扩容，因为扩容的时候会丢弃 Dummy 的 entry
    // 所以扩容之后的容量取决于 used，而不是 fill
    // 如果 used 大于 50000，那么 2 倍扩容，否则 4 倍扩容
    return set_table_resize(so, so-&gt;used&gt;50000 ? so-&gt;used*2 : so-&gt;used*4);

  found_active:
    // 执行到这里，说明添加的元素已经存在了
    // 那么减少 key 的引用计数，然后返回
    Py_DECREF(key);
    return 0;

  comparison_error:
    // 执行比较操作时出现错误，应该抛出异常，但这一步基本不会发生
    Py_DECREF(key);
    return -1;
}
</code></pre>
<p>所以整个过程和字典是类似的，依旧是将哈希值和 mask 按位与，得到索引，通过索引找到对应的 entry。接下来对 entry 分情况讨论。</p>
<p><font color="darkblue"><strong>如果 <code>entry-&gt;key == NULL</code>。</strong></font></p>
<p>说明找到了可用的 entry，那么直接跳转到 found_unused 标签，然后修改 entry 的 key 和 hash 字段，这样新元素就添加成功了。</p>
<p><font color="darkblue"><strong>如果 <code>entry-&gt;hash == hash</code>。</strong></font></p>
<p>说明找到的 entry 处于 Active 态，那么比较两个 key 是否相等。如果相等，证明添加的元素已存在，则不插入，直接减少引用计数，因为不是字典，不存在更新一说。但如果两个 key 不相等，说明出现索引冲突，那么要映射出一个新的索引，并且映射的方式和字典也是一样的。</p>
<pre><code class="language-C">perturb &gt;&gt;= PERTURB_SHIFT;
i = (i * 5 + 1 + perturb) &amp; mask;
</code></pre>
<p>但字典和集合有一处不同，就是集合这里多了一个 for 循环。</p>
<pre><code class="language-C">// Objects/setobject.c
#define LINEAR_PROBES 9

static int
set_add_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    // ...

    while (1) {
        // ...
        
        // 当前映射出的索引为 i，如果 i + 9 没有超过 mask，那么循环 9 次
        if (i + LINEAR_PROBES &lt;= mask) {
            for (j = 0 ; j &lt; LINEAR_PROBES ; j++) {
                entry++;
                if (entry-&gt;hash == 0 &amp;&amp; entry-&gt;key == NULL)
                    goto found_unused_or_dummy;
                if (entry-&gt;hash == hash) {
                    PyObject *startkey = entry-&gt;key;
                    assert(startkey != dummy);
                    if (startkey == key)
                        goto found_active;
                    if (PyUnicode_CheckExact(startkey)
                        &amp;&amp; PyUnicode_CheckExact(key)
                        &amp;&amp; _PyUnicode_EQ(startkey, key))
                        goto found_active;
                    table = so-&gt;table;
                    Py_INCREF(startkey);
                    cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
                    Py_DECREF(startkey);
                    if (cmp &gt; 0)
                        goto found_active;
                    if (cmp &lt; 0)
                        goto comparison_error;
                    if (table != so-&gt;table || entry-&gt;key != startkey)
                        goto restart;
                    mask = so-&gt;mask;
                }
                else if (entry-&gt;hash == -1)
                    freeslot = entry;
            }
        }
        // ...
    }

    // ...
}
</code></pre>
<p>当映射出的索引相同、但 key 不相同时，说明出现了索引冲突，对于字典来说，会立即重新映射，找到一个新的索引。而集合由于只用一个数组存储，可以有更好的做法。我们知道 CPU 是有缓存的，像 L1 Cache 加载数据会一次性加载 64 字节，称为一个 cache line。所以通过索引遍历包含 16 个 int32 的数组，每次 i++ 和每次 i += 4 的耗时是差不多的。</p>
<p>对于集合来说，因为映射出的索引是随机的，使得对应的 entry 可能不在 cache 中，从而导致 CPU 下一次要重新读取。所以 Python 引入了 LINEAR_PROBES，从当前的 entry 开始，向后查找 9 个 entry。如果还找不到可用位置，然后才重新计算，从而提高 cache 的稳定性。</p>
<p><font color="darkblue"><strong>如果 <code>entry-&gt;hash == -1</code>，或者说 <code>entry-&gt;key == dummy</code>。</strong></font></p>
<p>说明撞上了一个 Dummy 态的 entry，但估计有人又注意到了一个问题。</p>
<p><img src="./images/137.png" alt="" /></p>
<p>就是在发现 Dummy 态的 entry 之后，为啥没有立即跳转到 found_unused_or_dummy 标签，而是要继续循环呢？</p>
<p>很简单，我们假设在发现 Dummy 态的 entry 之后立即跳转，看看会有什么后果。首先向集合添加一个元素 x，再添加一个元素 y，但 y 和 x 映射出的索引相同，那么在添加 y 的时候，会形成一条探测链，对应的元素就是 <code>x-&gt;y</code>。然后再将 x 删除，那么 <code>x-&gt;y</code> 就变成了 <code>dummy-&gt;y</code>。这时候如果再重新添加一个元素 y，那么肯定会撞上 Dummy 态的 entry，于是 <code>dummy-&gt;y</code> 就变成了 <code>y-&gt;y</code>。</p>
<p>所以当发现 Dummy 态的 entry 之后，如果立即跳转，就会无法消除集合的重复元素。因此正确的做法是先用变量保存起来，这里赋值给了 freeslot，然后继续查找。如果找到了相同的元素，那么就不添加了，因为集合中的元素是唯一的。但如果最后找到的 entry 的 key 为空，说明元素不存在，此时才能跳转到 found_unused_or_dummy 标签，然后对 freeslot 进行判断。如果不为空，说明撞上了 Dummy 态的 entry，那么直接复用该 entry 即可。</p>
<p>以上就是集合添加元素的过程，当然如果找到的是 Unused 态的 entry，还要判断容量的问题。如果 <font color="blue">Active 态 + Dummy 态</font>的 entry 个数不小于 3/5*mask，那么扩容，扩容的规则是判断 Active 态的 entry 个数是否大于 50000，是的话就 2 倍扩容，否则 4 倍扩容；</p>
<h2 id="pop-方法弹出元素"><a class="header" href="#pop-方法弹出元素">pop 方法：弹出元素</a></h2>
<p>调用 pop 方法，可以从集合中弹出一个元素，在底层会执行 set_pop 方法。</p>
<pre><code class="language-C">// Objects/setobject.c

static PyObject *
set_pop(PySetObject *so, PyObject *Py_UNUSED(ignored))
{
    // so-&gt;table 是指向 entry 数组首元素的指针
    // so-&gt;finger 是做什么的，稍后解释，总之它是一个整数
    // so-&gt;mask 等于 entry 数组的长度减 1，用于将取模运算优化成按位与运算

    // 因此 so-&gt;finger &amp; so-&gt;mask 会得到一个 0 ~ mask 之间的整数，我们记为 n
    // 显然这里的变量 entry 会指向 entry 数组中索引 n 的元素
    setentry *entry = so-&gt;table + (so-&gt;finger &amp; so-&gt;mask);
    // 变量 limit 则指向 entry 数组中最后一个元素（索引为 mask）
    setentry *limit = so-&gt;table + so-&gt;mask;
    PyObject *key;
    // 如果集合长度为 0，那么 pop 方法会抛出 KeyError
    if (so-&gt;used == 0) {
        PyErr_SetString(PyExc_KeyError, &quot;pop from an empty set&quot;);
        return NULL;
    }
    // entry 有三种状态，但显然弹出的 entry 一定是 Active 态
    // 所以如果 entry 处于 Unused 或 Dummy 态，直接下一轮循环
    while (entry-&gt;key == NULL || entry-&gt;key==dummy) {
        entry++;
        // 我们记 so-&gt;finger &amp; so-&gt;mask 的结果为 n
        // 所以相当于从 entry 数组中索引为 n 的位置开始遍历
        // 如果遍历到最后一个位置，也没找到 Active 态的 entry，那么从头开始遍历
        if (entry &gt; limit)
            entry = so-&gt;table;  // 让变量 entry 指向 entry 数组的首元素
        // 所以不难发现，整个过程是先遍历 entry 数组中 [n: limit] 的部分
        // 如果没有找到 Active 态 entry，那么将 entry 重置为 so-&gt;table，从头开始遍历
        // 因为执行到这里，说明 so-&gt;used 大于 0，即集合的长度大于 0
        // 那么当 entry &gt; limit 时，在 entry 数组 [0: n] 的部分，一定存在 Active 态的 entry
    }
    // pop 方法会返回弹出的元素，所以获取 entry-&gt;key
    key = entry-&gt;key;
    // 元素被弹出了，对应的 entry 要进行伪删除，所谓的伪删除就是设置一个特殊的墓碑值
    // 所以将 entry-&gt;key 设置为 dummy，将 entry-&gt;hash 设置为 -1
    entry-&gt;key = dummy;
    entry-&gt;hash = -1;
    // 集合的长度减 1
    so-&gt;used--;
    // 将 finger 更新为被删除的 entry 在 entry 数组中的索引加 1
    so-&gt;finger = entry - so-&gt;table + 1;   /* next place to start */
    return key;
}
</code></pre>
<p>所以删除的过程还是很简单的，如果不考虑 finger 字段，你就可以简单理解为遍历整个 entry 数组，找到 Active 态的 entry，然后删除即可。只是这么做会导致每次 pop 时，都要重头开始遍历数组。</p>
<p>而当引入了 finger 字段之后，由于该字段初始为 0，所以第一次 pop 时，会从数组的头部开始遍历。假设删除的是数组中索引为 n 的 entry，那么删除之后 finger 字段会被赋值为 n + 1，那么下一次 pop 就会从数组中索引为 n + 1 的 entry 开始遍历。</p>
<p>我们通过 ctypes 来验证这一点：</p>
<pre><code class="language-python">from ctypes import *

class PyObject(Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_type&quot;, c_void_p),
    ]

class SetEntry(Structure):
    _fields_ = [
        (&quot;key&quot;, POINTER(PyObject)),
        (&quot;hash&quot;, c_longlong)
    ]

class PySetObject(PyObject):
    _fields_ = [
        (&quot;fill&quot;, c_ssize_t),
        (&quot;used&quot;, c_ssize_t),
        (&quot;mask&quot;, c_ssize_t),
        (&quot;table&quot;, POINTER(SetEntry)),
        (&quot;hash&quot;, c_long),
        (&quot;finger&quot;, c_ssize_t),
        (&quot;smalltable&quot;, (SetEntry * 8)),
        (&quot;weakreflist&quot;, POINTER(PyObject)),
    ]


s = {11, 22, 33, 44}
# 获取 PySetObject 结构体实例
py_set_obj = PySetObject.from_address(id(s))
# 遍历 smalltable，打印索引和 key 的哈希值
# 对于整数来说，它的哈希值等于自身
for index, entry in enumerate(py_set_obj.smalltable):
    print(index, entry.hash)
&quot;&quot;&quot;
0 0
1 33
2 0
3 11
4 44
5 0
6 22
7 0
&quot;&quot;&quot;
# finger 初始为 0，因此在 pop 元素的时候会从头开始遍历数组
# 找到第一个 Active 态的 entry
print(py_set_obj.finger)
&quot;&quot;&quot;
0
&quot;&quot;&quot;

# 显然第一次 pop 出的元素是 33
print(s.pop())
&quot;&quot;&quot;
33
&quot;&quot;&quot;
for index, entry in enumerate(py_set_obj.smalltable):
    print(index, entry.hash)
&quot;&quot;&quot;
0 0
1 -1
2 0
3 11
4 44
5 0
6 22
7 0
&quot;&quot;&quot;
# 因为被伪删除了
# 所以索引为 1 的 entry-&gt;key 会被设置为 NULL，entry-&gt;hash 被设置为 -1
# 至于 finger 则等于 1 + 1，下一次 pop 时，会从索引为 2 的位置开始遍历
print(py_set_obj.finger)
&quot;&quot;&quot;
2
&quot;&quot;&quot;

# 那么同理，再次 pop 的时候，会弹出 11，然后 finger 变为 3 + 1 = 4
print(s.pop())
&quot;&quot;&quot;
11
&quot;&quot;&quot;
print(py_set_obj.finger)
&quot;&quot;&quot;
4
&quot;&quot;&quot;
</code></pre>
<p>以上就是 finger 字段的作用，它避免了每次都要从头遍历 entry 数组。从这里也不难发现，当一个集合不断执行 pop 方法，将所有元素依次弹出时，这些元素的顺序和直接遍历 entry 数组拿到的元素的顺序是一致的。</p>
<pre><code class="language-Python">item1 = 22333
item2 = 177
item3 = 520
item4 = 10086
# 将它们映射成索引，由于是 4 个元素，因此哈希表容量为 8
index1 = item1 &amp; 7
index2 = item2 &amp; 7
index3 = item3 &amp; 7
index4 = item4 &amp; 7
print(index1, index2, index3, index4)
&quot;&quot;&quot;
5 1 0 6
&quot;&quot;&quot;
# 所以如果将 item1、item2、item3、item4 放到集合中
# 不管怎么排列，最终都是下面这个结果
# item3 会位于 entry 数组中索引为 0 的位置
# item2 会位于 entry 数组中索引为 1 的位置
# item1 会位于 entry 数组中索引为 5 的位置
# item4 会位于 entry 数组中索引为 6 的位置

# 所以不管是弹出元素，还是遍历元素，亦或是直接打印集合
# 元素顺序一定是 item3、item2、item1、item4
s1 = {item1, item2, item3, item4}
s2 = {item2, item1, item4, item3}
s3 = {item3, item1, item2, item4}
s4 = {item4, item3, item2, item1}
print(s1)  # {520, 177, 22333, 10086}
print(s2)  # {520, 177, 22333, 10086}
print(s3)  # {520, 177, 22333, 10086}
print(s4)  # {520, 177, 22333, 10086}
print(
    item3, item2, item1, item4
)  # 520 177 22333 10086
</code></pre>
<p>怎么样，是不是对集合又有了更深刻的认识了呢？</p>
<h2 id="remove-方法删除指定元素"><a class="header" href="#remove-方法删除指定元素">remove 方法：删除指定元素</a></h2>
<p>remove 方法可以接收参数，删除集合中指定的元素。除了 remove，还有一个 discard 方法，这两个方法的作用一模一样，都是用来删除指定元素。区别就是当删除的元素不存在时，remove 方法会抛出 KeyError，而 discard 方法不会。</p>
<p>remove 方法在底层对应 set_remove 函数，discard 方法在底层对应 set_discard 函数，而 set_remove 函数只比 set_discard 函数多了一个 if 判断，我们来看一下。</p>
<p><img src="./images/138.png" alt="" /></p>
<p>以上是 set_remove 函数，注意图中绿色方框的部分，如果要删除的元素不存在，那么 rv 会等于 DISCARD_NOTFOUND，于是抛出 KeyError。</p>
<p>如果将绿色方框里的 if 逻辑删掉，得到的就是 set_discard 函数的源码。所以这两个函数做的事情是一样的，区别就是 set_remove 会多做一层检测，当删除的元素不存在时，set_remove 会主动抛出一个 KeyError，而 set_discard 函数则什么也不做。</p>
<p>所以这里我们只看 set_remove 函数即可。</p>
<pre><code class="language-C">// Objects/setobject.c

#define DISCARD_NOTFOUND 0
#define DISCARD_FOUND 1

static PyObject *
set_remove(PySetObject *so, PyObject *key)
{
    // 要删除的 key，或者说元素
    // 当然啦，从 C 的层面来看，删除 key 其实就是删除数组中该 key 对应的 entry
    // 只不过这个删除是伪删除，即写入一个特殊的墓碑值
    PyObject *tmpkey;
    int rv;
    // rv 表示删除结果，显然删除逻辑由 set_discard_key 函数实现
    // 如果 rv &lt; 0，表示删除元素时出现错误，比如传入了一个不可哈希的对象
    // 如果 rv == 0，表示要删除的元素在集合中不存在
    // 如果 rv == 1，表示成功将元素从集合中删除
    rv = set_discard_key(so, key);
    if (rv &lt; 0) {
        // 当传入一个不可哈希对象时，会抛出 TypeError
        // 我们知道集合也是不可哈希的，但如果要删除的 key 是集合类型
        // 那么解释器会额外做一个兜底操作，我们一会儿通过 Python 代码演示
        if (!PySet_Check(key) || !PyErr_ExceptionMatches(PyExc_TypeError))
            return NULL;
        // 将回溯栈里的异常清空
        PyErr_Clear();
        // 基于集合里的元素创建不可变集合
        tmpkey = make_new_set(&amp;PyFrozenSet_Type, key);
        if (tmpkey == NULL)
            return NULL;
        // 然后尝试删除这个不可变集合，如果还删除失败，则报错
        rv = set_discard_key(so, tmpkey);
        Py_DECREF(tmpkey);
        if (rv &lt; 0)
            return NULL;
    }
    // 如果 rv == DISCARD_NOTFOUND，表示要删除的元素不存在
    if (rv == DISCARD_NOTFOUND) {
        _PyErr_SetKeyError(key);  // 抛出 KeyError
        return NULL;
    }
    Py_RETURN_NONE;
}
</code></pre>
<p>我们看到当元素删除失败时，如果 key 是集合类型，那么解释器会做一个兜底操作，这是什么意思呢？我们演示一遍。</p>
<pre><code class="language-python">try:
    s = {[1, 2, 3]}  # 列表不可哈希
except TypeError as e:
    print(e)
&quot;&quot;&quot;
unhashable type: 'list'
&quot;&quot;&quot;

try:
    s = {{1, 2, 3}}  # 同样，集合也不可哈希
except TypeError as e:
    print(e)
&quot;&quot;&quot;
unhashable type: 'set'
&quot;&quot;&quot;

# 当我们尝试 remove 列表时，依旧会抛出相同的错误
s = {1, 2, 3}
try:
    s.remove([])
except TypeError as e:
    print(e)
&quot;&quot;&quot;
unhashable type: 'list'
&quot;&quot;&quot;

# 但 remove 一个集合就不同了
s = {
    frozenset({1, 2, 3}),
    frozenset({4, 5, 6}),
}
# 不可变集合是可哈希对象，因此它可以放在集合中，也可以被删除
s.remove(frozenset({1, 2, 3}))
# 但删除可变集合理论上应该和删除列表一样，抛出 TypeError: unhashable type: 'set'
# 而事实上异常也确实产生了，保存在回溯栈中，但是从源码中我们看到，解释器会多做一个检测
# 如果删除的 key 是集合类型，并且栈里的异常是 TypeError，那么将异常清空
# 然后基于集合创建不可变集合，并尝试删除这个不可变集合
s.remove({4, 5, 6})
# 所以这里 s.remove({4, 5, 6}) 等价于 s.remove(frozenset({4, 5, 6}))
print(s)
&quot;&quot;&quot;
set()
&quot;&quot;&quot;
# 我们看到 s 里面的两个不可变集合被删除了
</code></pre>
<p>好，我们回到 set_remove 函数，它在删除元素时会调用 set_discard_key 函数，显然删除指定元素的核心逻辑位于此函数中，我们看一下它做了什么。</p>
<pre><code class="language-C">// Objects/setobject.c

static int
set_discard_key(PySetObject *so, PyObject *key)
{
    Py_hash_t hash;
    // 计算哈希值
    if (!PyUnicode_CheckExact(key) ||
        (hash = ((PyASCIIObject *) key)-&gt;hash) == -1) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            return -1;
    }
    // 调用 set_discard_entry 函数
    // 传入三个参数：集合、要删除的 key、以及 key 的哈希值
    return set_discard_entry(so, key, hash);
}

static int
set_discard_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *entry;
    PyObject *old_key;
    // 将 key 映射成索引，并获取该索引对应的 entry 的指针
    entry = set_lookkey(so, key, hash);
    // 因为 entry 数组申请好之后，内部的每个 entry 都拥有一块合法的内存
    // 所以指针不可能为 NULL，如果为 NULL，证明内部出问题了
    if (entry == NULL)  // 基本不会发生
        return -1;
    // 如果 entry-&gt;key 为 NULL，证明要删除的 key 不存在，返回 DISCARD_NOTFOUND
    // 当 set_remove 函数发现返回的是 DISCARD_NOTFOUND，会抛出 KeyError
    if (entry-&gt;key == NULL)
        return DISCARD_NOTFOUND;
    // 否则说明 key 存在
    old_key = entry-&gt;key;
    // 因为被删除了，所以将 entry-&gt;key、entry-&gt;hash 设置为 dummy 和 -1
    entry-&gt;key = dummy;
    entry-&gt;hash = -1;
    // 集合长度减 1
    so-&gt;used--;
    // 减少 key 指向对象的引用计数，因为集合不再持有对它的引用
    Py_DECREF(old_key);
    // 返回 DISCARD_FOUND
    return DISCARD_FOUND;
}
</code></pre>
<p>以上就是 set_remove 函数删除指定元素的具体细节，逻辑并不复杂。但是里面出现了一个 set_lookkey 函数，它的作用是将哈希值映射成索引，并返回指定的 entry。至于该函数的逻辑也很简单，它和 set_add 函数里面的逻辑是重复的。</p>
<pre><code class="language-C">static setentry *
set_lookkey(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *table;
    setentry *entry;
    size_t perturb;
    size_t mask = so-&gt;mask;
    size_t i = (size_t)hash &amp; mask; /* Unsigned for defined overflow behavior */
    size_t j;
    int cmp;

    entry = &amp;so-&gt;table[i];
    if (entry-&gt;key == NULL)
        return entry;

    perturb = hash;

    while (1) {
        if (entry-&gt;hash == hash) {
            PyObject *startkey = entry-&gt;key;
            /* startkey cannot be a dummy because the dummy hash field is -1 */
            assert(startkey != dummy);
            if (startkey == key)
                return entry;
            if (PyUnicode_CheckExact(startkey)
                &amp;&amp; PyUnicode_CheckExact(key)
                &amp;&amp; _PyUnicode_EQ(startkey, key))
                return entry;
            table = so-&gt;table;
            Py_INCREF(startkey);
            cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
            Py_DECREF(startkey);
            if (cmp &lt; 0)                                          /* unlikely */
                return NULL;
            if (table != so-&gt;table || entry-&gt;key != startkey)     /* unlikely */
                return set_lookkey(so, key, hash);
            if (cmp &gt; 0)                                          /* likely */
                return entry;
            mask = so-&gt;mask;                 /* help avoid a register spill */
        }

        if (i + LINEAR_PROBES &lt;= mask) {
            for (j = 0 ; j &lt; LINEAR_PROBES ; j++) {
                entry++;
                if (entry-&gt;hash == 0 &amp;&amp; entry-&gt;key == NULL)
                    return entry;
                if (entry-&gt;hash == hash) {
                    PyObject *startkey = entry-&gt;key;
                    assert(startkey != dummy);
                    if (startkey == key)
                        return entry;
                    if (PyUnicode_CheckExact(startkey)
                        &amp;&amp; PyUnicode_CheckExact(key)
                        &amp;&amp; _PyUnicode_EQ(startkey, key))
                        return entry;
                    table = so-&gt;table;
                    Py_INCREF(startkey);
                    cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);
                    Py_DECREF(startkey);
                    if (cmp &lt; 0)
                        return NULL;
                    if (table != so-&gt;table || entry-&gt;key != startkey)
                        return set_lookkey(so, key, hash);
                    if (cmp &gt; 0)
                        return entry;
                    mask = so-&gt;mask;
                }
            }
        }

        perturb &gt;&gt;= PERTURB_SHIFT;
        i = (i * 5 + 1 + perturb) &amp; mask;

        entry = &amp;so-&gt;table[i];
        if (entry-&gt;key == NULL)
            return entry;
    }
}
</code></pre>
<p>显然该函数的逻辑在介绍 set_add 函数的时候就说过了。</p>
<ul>
<li>如果 <code>entry-&gt;key</code> 为空，说明找到了 Unused 态的 entry，即 key 不存在，那么直接将 entry 返回即可。</li>
<li>如果 <code>entry-&gt;key</code> 不为空，那么比较 <code>entry-&gt;hash</code> 和传入的 hash 是否相等，如果哈希值不相等，那么 key 一定不相等，说明出现了索引冲突。当然啦，如果 entry 处于 Dummy 态，那么哈希值肯定也不相等，但不管哪一种，都要重新映射。</li>
<li>如果哈希值相等，那么比较 key 是否相等，如果 key 相等，说明查找的 key 存在于集合中，那么返回对应的 entry。如果 key 不相等，则重新映射。</li>
</ul>
<h2 id="copy-方法拷贝一个集合"><a class="header" href="#copy-方法拷贝一个集合">copy 方法：拷贝一个集合</a></h2>
<p>调用 copy 方法可以拷贝一个集合，在底层会执行 set_copy 方法。</p>
<pre><code class="language-C">// Objects/setobject.c

static PyObject *
set_copy(PySetObject *so, PyObject *Py_UNUSED(ignored))
{
    return make_new_set_basetype(Py_TYPE(so), (PyObject *)so);
}

static PyObject *
make_new_set_basetype(PyTypeObject *type, PyObject *iterable)
{
    if (type != &amp;PySet_Type &amp;&amp; type != &amp;PyFrozenSet_Type) {
        if (PyType_IsSubtype(type, &amp;PySet_Type))
            type = &amp;PySet_Type;
        else
            type = &amp;PyFrozenSet_Type;
    }
    return make_new_set(type, iterable);
}

static PyObject *
make_new_set(PyTypeObject *type, PyObject *iterable)
{
    PySetObject *so;
    // 为集合申请内存
    so = (PySetObject *)type-&gt;tp_alloc(type, 0);
    if (so == NULL)
        return NULL;
    // 字段初始化，显然刚创建的集合的容量为 8
    so-&gt;fill = 0;
    so-&gt;used = 0;
    so-&gt;mask = PySet_MINSIZE - 1;
    so-&gt;table = so-&gt;smalltable;
    so-&gt;hash = -1;
    so-&gt;finger = 0;
    so-&gt;weakreflist = NULL;
    // 调用 set_update_internal 函数，将可迭代对象的元素添加到集合中
    if (iterable != NULL) {
        if (set_update_internal(so, iterable)) {
            Py_DECREF(so);
            return NULL;
        }
    }

    return (PyObject *)so;
}

static int
set_update_internal(PySetObject *so, PyObject *other)
{   
    // 参数 so 表示集合，other 表示可迭代对象
    PyObject *key, *it;
    // 如果 other 的类型也是集合（或者不可变集合），那么调用 set_merge 函数
    if (PyAnySet_Check(other))
        return set_merge(so, other);
    // 否则检测 other 是否为字典
    if (PyDict_CheckExact(other)) {
        PyObject *value;
        Py_ssize_t pos = 0;
        Py_hash_t hash;
        Py_ssize_t dictsize = PyDict_GET_SIZE(other);

        // 判断 so-&gt;fill + dictsize 是否达到了 so-&gt;mask 的 3/5
        // 如果达到了，那么扩容
        if (dictsize &lt; 0)
            return -1;
        if ((so-&gt;fill + dictsize)*5 &gt;= so-&gt;mask*3) {
            if (set_table_resize(so, (so-&gt;used + dictsize)*2) != 0)
                return -1;
        }
        // 遍历字典，将字典的 key 和 hash 包装成 entry，添加到数组中，value 丢弃
        // 这里调用的是 set_add_entry 函数，我们介绍集合的 add 方法时说过
        while (_PyDict_Next(other, &amp;pos, &amp;key, &amp;value, &amp;hash)) {
            if (set_add_entry(so, key, hash))
                return -1;
        }
        return 0;
    }
    // 到这里说明 other 不是字典，那么迭代出来的整体就是 key
    // 基于可迭代对象创建迭代器
    it = PyObject_GetIter(other);
    if (it == NULL)
        return -1;
    // 将元素迭代出来
    while ((key = PyIter_Next(it)) != NULL) {
        // 调用 set_add_key 函数，它内部会先计算 key 的哈希值
        // 然后调用 set_add_entry 函数，添加元素
        if (set_add_key(so, key)) {
            Py_DECREF(it);
            Py_DECREF(key);
            return -1;
        }
        Py_DECREF(key);
    }
    Py_DECREF(it);
    if (PyErr_Occurred())
        return -1;
    return 0;
}
</code></pre>
<p>以上就是集合的 copy 方法的底层实现，非常简单。说白了就是先创建一个新的集合，然后调用 set_update_internal 函数将老集合里面的元素拷贝过去。当然啦，该函数可以拷贝任意可迭代对象里的元素，不仅仅是集合。只是当可迭代对象是集合时，会单独调用 set_merge 函数，如果不是集合，那么会直接遍历。</p>
<h2 id="update-方法合并多个可迭代对象"><a class="header" href="#update-方法合并多个可迭代对象">update 方法：合并多个可迭代对象</a></h2>
<p>调用 update 方法，可以合并多个可迭代对象，举例说明。</p>
<pre><code class="language-Python">s = {1, 2, 3}
s.update([4, 5, 6], (7, 8, 9))
print(s)
&quot;&quot;&quot;
{1, 2, 3, 4, 5, 6, 7, 8, 9}
&quot;&quot;&quot;
</code></pre>
<p>相信你已经知道底层是怎么做的了，获取每个可迭代对象，然后调用 set_update_internal 函数即可。那么底层是不是这么做的呢？我们来看一下，update 方法在底层对应 set_update 函数。</p>
<pre><code class="language-c">// Objects/setobject.c

static PyObject *
set_update(PySetObject *so, PyObject *args)
{
    Py_ssize_t i;

    for (i=0 ; i&lt;PyTuple_GET_SIZE(args) ; i++) {
        PyObject *other = PyTuple_GET_ITEM(args, i);
        if (set_update_internal(so, other))
            return NULL;
    }
    Py_RETURN_NONE;
}
</code></pre>
<p>跟我们分析的一样，非常简单。</p>
<p>另外集合还有一个 union 方法，功能和 update 方法类似，但它会返回一个新的集合。</p>
<pre><code class="language-Python">s1 = {1, 2, 3}
s1.update([4, 5, 6], (7, 8, 9))
print(s1)
&quot;&quot;&quot;
{1, 2, 3, 4, 5, 6, 7, 8, 9}
&quot;&quot;&quot;

s2 = {1, 2, 3}
s2_new = s2.union([4, 5, 6], (7, 8, 9))
print(s2)
print(s2_new)
&quot;&quot;&quot;
{1, 2, 3}
{1, 2, 3, 4, 5, 6, 7, 8, 9}
&quot;&quot;&quot;
</code></pre>
<p>update 方法会原地修改，而 union 方法会返回新的集合，不会影响原有的集合。</p>
<h2 id="其它的一些方法"><a class="header" href="#其它的一些方法">其它的一些方法</a></h2>
<p>集合还有一些常用的方法，只不过我们更倾向于使用操作符的形式。</p>
<ul>
<li>s1 &amp; s2：对两个集合做交集运算，返回新的集合，里面包含同时出现在 s1 和 s2 当中的元素；</li>
<li>s1 | s2：对两个集合做并集运算，返回新的集合，里面包含出现在 s1 或 s2 当中的元素；</li>
<li>s1 - s2：对两个集合做差集运算，返回新的集合，里面包含出现在 s1 当中、但没有出现在 s2 当中的元素；</li>
<li>s1 ^ s2：对两个集合做对称差集运算，返回新的集合，里面包含只出现在 s1 当中、或只出现在 s2 当中的元素；</li>
<li>s1 == s2：判断两个集合的元素是否完全相同；</li>
<li>s1 &gt;= s2：判断 s2 是否是 s1 的子集，如果是，那么 s2 - s1 == {}。</li>
<li>s1 &lt;= s2：判断 s1 是否是 s2 的子集，如果是，那么 s1 - s2 == {}。</li>
<li>s1 &gt; s2：判断 s2 是否是 s1 的真子集；</li>
<li>s1 &lt; s2：判断 s1 是否是 s2 的真子集；</li>
</ul>
<p>注意：在使用这些操作符时，两侧的 s1 和 s2 都要求是集合类型。但如果使用操作符对应的方法，那么则不要求 s2 是集合类型，只要是可迭代对象即可。</p>
<pre><code class="language-Python"># 做交集运算
s = {&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}
print(s.intersection(&quot;bcd&quot;))
&quot;&quot;&quot;
{'b', 'c'}
&quot;&quot;&quot;
# print(s &amp; &quot;bcd&quot;)  # TypeError
</code></pre>
<p>这些方法都非常的有用，可以自己测试一下，加深一遍印象。至于这些方法的底层实现，感兴趣也可以去 Objects/setobject.c 中探索一番，方法都定义在 set_methods 数组中。这里我们就以集合的交集运算为例，看一下实现过程。</p>
<pre><code class="language-C">// Objects/setobject.c

// 判断集合是否包含某个元素
static int
set_contains_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *entry;
    // 调用 set_lookkey，返回 entry
    // 如果 entry-&gt;key 不为空，证明元素存在，否则不存在
    entry = set_lookkey(so, key, hash);
    if (entry != NULL)
        return entry-&gt;key != NULL;
    return -1;
}

// 两个集合做交集运算，返回新的集合
static PyObject *
set_intersection(PySetObject *so, PyObject *other)
{
    PySetObject *result;
    PyObject *key, *it, *tmp;
    Py_hash_t hash;
    int rv;
    // 快分支：如果两个集合相等，那么直接把其中一个拷贝一份
    if ((PyObject *)so == other)
        return set_copy(so, NULL);
    // 否则创建一个新的空集合
    result = (PySetObject *)make_new_set_basetype(Py_TYPE(so), NULL);
    if (result == NULL)
        return NULL;
    // 如果 other 是集合
    if (PyAnySet_Check(other)) {
        Py_ssize_t pos = 0;
        setentry *entry;
        // 如果 len(other) &gt; len(so)，那么两者交换位置，也就是遍历元素较少的集合
        if (PySet_GET_SIZE(other) &gt; PySet_GET_SIZE(so)) {
            tmp = (PyObject *)so;
            so = (PySetObject *)other;
            other = tmp;
        }
        // 遍历集合 other
        while (set_next((PySetObject *)other, &amp;pos, &amp;entry)) {
            key = entry-&gt;key;
            hash = entry-&gt;hash;
            // 判断 key 是否存在于集合 so 中
            rv = set_contains_entry(so, key, hash);
            if (rv &lt; 0) {
                Py_DECREF(result);
                return NULL;
            }
            // 如果存在，那么添加到新集合 result 中
            if (rv) {
                if (set_add_entry(result, key, hash)) {
                    Py_DECREF(result);
                    return NULL;
                }
            }
        }
        return (PyObject *)result;
    }
    
    // 如果 other 不是集合，那么获取它的迭代器
    it = PyObject_GetIter(other);
    if (it == NULL) {
        Py_DECREF(result);
        return NULL;
    }
    // 直接迭代内部的元素，以下逻辑和上面类似
    while ((key = PyIter_Next(it)) != NULL) {
        hash = PyObject_Hash(key);
        if (hash == -1)
            goto error;
        // 如果 key 在 so 中存在，那么添加到 result 中
        rv = set_contains_entry(so, key, hash);
        if (rv &lt; 0)
            goto error;
        if (rv) {
            if (set_add_entry(result, key, hash))
                goto error;
        }
        Py_DECREF(key);
    }
    Py_DECREF(it);
    if (PyErr_Occurred()) {
        Py_DECREF(result);
        return NULL;
    }
    return (PyObject *)result;
  error:
    Py_DECREF(it);
    Py_DECREF(result);
    Py_DECREF(key);
    return NULL;
}
</code></pre>
<p>以上就是集合的交集运算，至于其它的运算操作也是类似的，感兴趣可以看一下。</p>
<h2 id="小结-38"><a class="header" href="#小结-38">小结</a></h2>
<p>关于集合相关的内容我们就介绍完了，当然到目前为止，Python 的内置数据结构也基本介绍完了。回顾一下我们介绍了哪些数据结构：</p>
<ul>
<li>浮点数；</li>
<li>整数；</li>
<li>复数；</li>
<li>布尔值</li>
<li>None；</li>
<li>切片；</li>
<li>bytes 对象；</li>
<li>bytearray 对象；</li>
<li>字符串；</li>
<li>列表；</li>
<li>元组；</li>
<li>字典；</li>
<li>集合；</li>
</ul>
<p>以上这些结构都是内置的，当然还有一些数据结构是定义在标准库里面的，我们后面再说。</p>
<p>下一篇文章来介绍迭代器。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-38"><a class="header" href="#楔子-38">楔子</a></h2>
<p>只要类型对象实现了 __iter__，那么它的实例对象就被称为可迭代对象（Iterable），比如字符串、元组、列表、字典、集合等等。而整数、浮点数，由于其类型对象没有实现 __iter__，所以它们不是可迭代对象。</p>
<pre><code class="language-python">from typing import Iterable

print(
    isinstance(&quot;&quot;, Iterable),
    isinstance((), Iterable),
    isinstance([], Iterable),
    isinstance({}, Iterable),
    isinstance(set(), Iterable),
)  # True True True True True

print(
    isinstance(0, Iterable),
    isinstance(0.0, Iterable),
)  # False False
</code></pre>
<p>可迭代对象的一大特点是可以被 for 循环遍历，但能被 for 循环遍历的则不一定是可迭代对象。我们举个例子：</p>
<pre><code class="language-Python">class A:

    def __getitem__(self, item):
        return f&quot;参数 item: {item}&quot;

a = A()
# 内部定义了 __getitem__
# 首先可以让实例对象像字典一样访问属性
print(a[&quot;name&quot;])  # 参数 item: name
print(a[&quot;satori&quot;])  # 参数 item: satori

# 此外还可以像可迭代对象一样被 for 循环
# 循环的时候会自动给 item 传值：0 1 2 3 ...
# 如果内部出现了 StopIteration，循环结束
# 否则会一直循环下去，这里我们手动 break
for idx, val in enumerate(a):
    print(val)
    if idx == 5:
        break
&quot;&quot;&quot;
参数 item: 0
参数 item: 1
参数 item: 2
参数 item: 3
参数 item: 4
参数 item: 5
&quot;&quot;&quot;
</code></pre>
<p>所以实现了 __getitem__ 的类的实例，也是可以被 for 循环的，但它并不是可迭代对象。</p>
<pre><code class="language-Python">from typing import Iterable
print(isinstance(a, Iterable))  # False
</code></pre>
<p>总之判断一个对象是否是可迭代对象，就看它的类型对象有没有实现 __iter__。可迭代对象我们知道了，那什么是迭代器呢？很简单，调用可迭代对象的 __iter__ 方法，得到的就是迭代器。</p>
<h2 id="迭代器的创建"><a class="header" href="#迭代器的创建">迭代器的创建</a></h2>
<p>不同类型的对象，都有自己的迭代器，举个栗子。</p>
<pre><code class="language-Python">data = [1, 2, 3]
# 底层调用的其实是 list.__iter__(data)
# 或者说 PyList_Type.tp_iter(data)
it = data.__iter__()
print(it)
&quot;&quot;&quot;
&lt;list_iterator object at 0x102c1cf10&gt;
&quot;&quot;&quot;
print(str.__iter__(&quot;&quot;))
&quot;&quot;&quot;
&lt;str_iterator object at 0x100e623b0&gt;
&quot;&quot;&quot;
print(tuple.__iter__(()))
&quot;&quot;&quot;
&lt;tuple_iterator object at 0x100e623b0&gt;
&quot;&quot;&quot;
# 不难发现，迭代器的种类非常多
# 比如 list_iterator、str_iterator、tuple_iterator 等等
</code></pre>
<p>迭代器也是可迭代对象，只不过迭代器内部的 __iter__ 返回的还是它本身。当然啦，在创建迭代器的时候，我们更常用内置函数 iter。</p>
<pre><code class="language-python">data = [1, 2, 3]
# 等价于 type(data).__iter__(data)
it = iter(data)
</code></pre>
<p>但是 iter 函数还有一个鲜为人知的用法，我们来看一下：</p>
<pre><code class="language-Python">val = 0

def foo():
    global val
    val += 1
    return val

# iter 可以接收一个参数: iter(可迭代对象)
# iter 也可以接收两个参数: iter(可调用对象, value)
for i in iter(foo, 5):
    print(i)
&quot;&quot;&quot;
1
2
3
4
&quot;&quot;&quot;
</code></pre>
<p>进行迭代的时候，会不停地调用<font color="blue">可调用对象</font>，直到返回值等于传递的第二个参数 value（在底层被称为哨兵），然后终止迭代。我们看一下 iter 函数的底层实现。</p>
<pre><code class="language-C">// Python/bltinmodule.c
static PyObject *
builtin_iter(PyObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    PyObject *v;
    // 内置函数 iter 接收 1 ~ 2 个参数
    if (!_PyArg_CheckPositional(&quot;iter&quot;, nargs, 1, 2))
        return NULL;
    // 如果 nargs 等于 1，那么 args[0] 是可迭代对象
    // 如果 nargs 等于 2，那么 args[0] 是可调用对象
    v = args[0];
    // nargs == 1，说明 v 是可迭代对象
    if (nargs == 1)
        // 调用 PyObject_GetIter 获取对象的迭代器
        return PyObject_GetIter(v);
    // 否则说明 nargs == 2，那么 v 是可调用对象
    // 这里进行检测，如果不是，抛出 TypeError
    if (!PyCallable_Check(v)) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;iter(v, w): v must be callable&quot;);
        return NULL;
    }
    // 获取哨兵
    PyObject *sentinel = args[1];
    // 一会儿单独解释
    return PyCallIter_New(v, sentinel);
}
</code></pre>
<p>以上就是 iter 函数的内部逻辑，既可以接收一个参数，也可以接收两个参数。这里我们只看接收一个可迭代对象的情况，所以核心就在 PyObject_GetIter 函数里面，它是根据可迭代对象生成迭代器的关键，我们来看一下它的逻辑是怎样的？</p>
<pre><code class="language-C">// Objects/abstract.c
PyObject *
PyObject_GetIter(PyObject *o)
{
    // 获取可迭代对象的类型对象，比如 o 是列表，那么 t 就是 list
    PyTypeObject *t = o-&gt;ob_type;
    // 我们说类型对象定义的操作，决定了实例对象的行为
    // 实例对象调用的那些方法都是定义在类型对象里面的
    // 还是那句话：obj.func() 等价于 type(obj).func(obj)
    getiterfunc f;
    
    // 所以这里是获取类型对象的 tp_iter 字段
    // 也就是 Python 中的 __iter__
    f = t-&gt;tp_iter;
    // 如果 f 为 NULL，说明类型对象的内部没有定义 __iter__ 
    // 像 str、tuple、list 等类型对象，它们的 tp_iter 字段都是不为 NULL 的
    if (f == NULL) {
        // 如果 tp_iter 为 NULL，那么解释器会退而求其次
        // 检测该类型对象中是否定义了 __getitem__
        // 如果定义了，那么直接调用 PySeqIter_New，创建 seqiterobject 对象
        // 下面的 PySequence_Check 函数负责检测类型对象是否实现了 __getitem__
        // __getitem__ 对应 tp_as_sequence-&gt;sq_item
        if (PySequence_Check(o))
            return PySeqIter_New(o);
        // 走到这里说明该类型对象既没有 __iter__、也没有 __getitem__
        // 因此它的实例对象不具备可迭代的性质，于是抛出异常
        return type_error(&quot;'%.200s' object is not iterable&quot;, o);
    }
    else {
        // 否则说明定义了 __iter__
        // 调用 o-&gt;ob_type-&gt;tp_iter(o) 返回对应的迭代器
        PyObject *res = (*f)(o);
        // 但如果返回值 res 不为 NULL、并且还不是迭代器
        // 证明 __iter__ 的返回值有问题，于是抛出异常
        if (res != NULL &amp;&amp; !PyIter_Check(res)) {
            PyErr_Format(PyExc_TypeError,
                         &quot;iter() returned non-iterator &quot;
                         &quot;of type '%.100s'&quot;,
                         res-&gt;ob_type-&gt;tp_name);
            Py_DECREF(res);
            res = NULL;
        }
        // 返回 res
        return res;
    }
}
</code></pre>
<p>以上便是 iter 函数的底层实现，还是很简单的。然后是里面的 __getitem__，我们说如果类型对象内部没有定义 __iter__，那么解释器会退而求其次，检测内部是否定义了 __getitem__。</p>
<p>因此以上就是迭代器的创建过程，每个可迭代对象都有自己的迭代器，而迭代器本质上就是对原始数据的一层封装罢了。</p>
<h2 id="迭代器的底层结构"><a class="header" href="#迭代器的底层结构">迭代器的底层结构</a></h2>
<p>由于迭代器的种类非常多，字符串、元组、列表等等，都有自己的迭代器，这里就不一一介绍了。我们就以列表的迭代器为例，看看迭代器在底层的结构是怎么样的。</p>
<pre><code class="language-c">// Objects/listobject.c

// 列表迭代器的类型对象为 &lt;class 'list_iterator'&gt;
// 但这个类，解释器并没有暴露给我们，所以需要通过 type 获取
// 然后它的 tp_basicsize 字段为 sizeof(listiterobject)
// 这就说明列表迭代器在底层由 listiterobject 结构体表示
PyTypeObject PyListIter_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;list_iterator&quot;,                            /* tp_name */
    sizeof(listiterobject),                     /* tp_basicsize */
    0,                                          /* tp_itemsize */
    // ...
};

typedef struct {
    PyObject_HEAD
    Py_ssize_t it_index;
    // 指向创建该迭代器的列表
    PyListObject *it_seq;
} listiterobject;
</code></pre>
<p>所以迭代器就是基于可迭代对象进行了一层简单的封装，所谓元素迭代本质上还是基于索引，并且每迭代一次，索引就自增 1。一旦出现索引越界，就将 it_seq 设置为 NULL，表示迭代器迭代完毕。</p>
<p>我们实际演示一下：</p>
<pre><code class="language-python">from ctypes import *

class PyObject(Structure):
    _fields_ = [
        (&quot;ob_refcnt&quot;, c_ssize_t),
        (&quot;ob_size&quot;, c_void_p)
    ]

class ListIterObject(PyObject):
    _fields_ = [
        (&quot;it_index&quot;, c_ssize_t),
        (&quot;it_seq&quot;, POINTER(PyObject))
    ]

it = iter([1, 2, 3])
it_obj = ListIterObject.from_address(id(it))

# it_seq 指向列表 [1, 2, 3]，it_index 初始为 0
print(it_obj.it_index)  # 0
# 进行迭代
next(it)
# 索引自增 1，此时 it_index 等于 1
print(it_obj.it_index)  # 1
# 再次迭代
next(it)
# 此时 it_index 等于 2
print(it_obj.it_index)  # 2
# 再次迭代
next(it)
# 此时 it_index 等于 3
print(it_obj.it_index)  # 3
</code></pre>
<p>当 it_index 为 3 的时候，如果再次迭代，那么底层会发现 it_index 已超过最大索引，于是知道迭代器已经迭代完毕了。因此会将 it_seq 设置为 NULL，并抛出 StopIteration。如果是 for 循环，那么会自动捕获此异常，然后停止循环。</p>
<p>所以这就是迭代器，真的没有想象中的那么神秘，甚至在知道它的实现原理之后，还觉得有点 low，因为就是将原始数据包了一层，加了一个索引而已。所谓的迭代仍然是基于索引来做的，并且每迭代一次，索引就自增 1。当索引超出范围时，证明迭代完毕了，于是将 it_seq 字段设置为 NULL，抛出 StopIteration。</p>
<h2 id="迭代器是怎么迭代元素的"><a class="header" href="#迭代器是怎么迭代元素的">迭代器是怎么迭代元素的</a></h2>
<p>迭代器的创建我们知道了，那么它是怎么迭代元素的呢？首先迭代元素可以通过 next 函数，当然它本质上也是调用了对象的 __next__ 方法。</p>
<pre><code class="language-C">// Python/bltinmodule.c
static PyObject *
builtin_next(PyObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    PyObject *it, *res;
    // 同样接收 1 ~ 2 个参数
    // 因为调用 next 函数时，可以传入一个默认值
    // 表示当迭代器没有元素可以迭代的时候，会返回指定的默认值
    if (!_PyArg_CheckPositional(&quot;next&quot;, nargs, 1, 2))
        return NULL;
    // 迭代器
    it = args[0];
    // 类型检测，如果不是迭代器，那么抛出异常
    if (!PyIter_Check(it)) {
        PyErr_Format(PyExc_TypeError,
            &quot;'%.200s' object is not an iterator&quot;,
            it-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
    // it-&gt;ob_type 表示获取类型对象，也就是该迭代器的类型
    // 当然具体类型是哪一种并不确定，可能是列表迭代器、元组迭代器、字符串迭代器等等
    // 然后再获取 tp_iternext 字段，相当于 __next__
    // 拿到函数指针之后，传入迭代器进行调用
    res = (*it-&gt;ob_type-&gt;tp_iternext)(it);
    // 如果 res 不为 NULL，那么证明迭代到值了，直接返回
    if (res != NULL) {
        return res;
    } else if (nargs &gt; 1) {
        // 否则的话，说明没有迭代到值（返回 NULL），而这时候有两种情况
        // 1）迭代器已耗尽，2）在迭代过程中出现异常
        // 那么判断 nargs 是否大于 1，如果大于 1，说明设置了默认值
        PyObject *def = args[1];
        // 检测异常是不是迭代完毕时（或者手动 raise）产生的 StopIteration 异常
        if (PyErr_Occurred()) {
            if(!PyErr_ExceptionMatches(PyExc_StopIteration))
                // 如果不是，说明程序的逻辑有问题，直接 return NULL，结束执行
                // 然后在 Python 里面我们会看到打印到 stderr 中的异常信息
                return NULL;
            // 如果异常是 StopIteration，证明迭代完毕了
            // 但我们设置了默认值，那么就应该返回默认值
            // 而不应该抛出 StopIteration，于是将异常回溯栈给清空
            PyErr_Clear();
        }
        // 增加默认值的引用计数，然后返回
        Py_INCREF(def);
        return def;
    } else if (PyErr_Occurred()) {
        // 走到这里说明 res == NULL，并且没有指定默认值
        // 那么当发生异常时，将异常直接抛出
        return NULL;
    } else {
        // 都不是的话，直接抛出 StopIteration
        PyErr_SetNone(PyExc_StopIteration);
        return NULL;
    }
}
</code></pre>
<p>以上就是 next 函数的背后逻辑，实际上还是调用了迭代器的 __next__ 方法。</p>
<pre><code class="language-Python">data = [1, 2, 3]
it = iter(data)
# 然后迭代，等价于 next(it)
print(type(it).__next__(it))  # 1
print(type(it).__next__(it))  # 2
print(type(it).__next__(it))  # 3
# 但是 next 可以指定默认值
# 如果不指定默认值，或者还是 type(it).__next__(it)
# 那么就会报错，抛出 StopIteration
print(next(it, 666))  # 666
</code></pre>
<p>以上就是元素的迭代，由于内置函数 next 还可以指定一个默认值，所以更强大一些。当然在不指定默认值的情况下，next(it) 和 type(it).__next__(it) 最终是殊途同归的。</p>
<p>我们仍以列表的迭代器为例，看看 __next__ 的具体实现。</p>
<p><img src="./images/139.png" alt="" /></p>
<p>由于 tp_iternext 字段指向了 listiter_next，证明迭代的时候调用的是这个函数。</p>
<pre><code class="language-C">// Objects/listobject.c
static PyObject *
listiter_next(listiterobject *it)
{
    // 迭代器只是对可迭代对象的一层封装
    // 如果是列表的迭代器，那么内部的 it_seq 字段便指向列表
    PyListObject *seq;
    PyObject *item;

    assert(it != NULL);
    // 如果 it-&gt;it_seq 等于 NULL，说明迭代器已经迭代完毕了
    // 从这里也能看出迭代器不能二次循环迭代
    seq = it-&gt;it_seq;
    if (seq == NULL)
        return NULL;
    assert(PyList_Check(seq));
    // 如果 it-&gt;it_index 小于列表的长度
    if (it-&gt;it_index &lt; PyList_GET_SIZE(seq)) {
        // 那么获取元素
        item = PyList_GET_ITEM(seq, it-&gt;it_index);
        // it_index 自增 1
        ++it-&gt;it_index;
        // 增加元素的引用计数，并返回
        Py_INCREF(item);
        return item;
    }
    // 否则说明 it_index 已经达到了列表的长度
    // 再迭代就索引越界了，而对于迭代器来说
    // 当 it_index 等于列表长度时，就证明所有元素都迭代完毕了
    it-&gt;it_seq = NULL;  // 将 it_seq 设置为 NULL
    Py_DECREF(seq);
    return NULL;
}
</code></pre>
<p>显然这和之前分析的是一样的，以上我们就以列表为例，考察了迭代器的实现原理和元素迭代的具体过程。当然其它对象也有自己的迭代器，有兴趣可以看一看，实现方式都大同小异。</p>
<h2 id="iter-函数接收两个参数"><a class="header" href="#iter-函数接收两个参数">iter 函数接收两个参数</a></h2>
<p>前面说了，iter 函数如果接收一个参数，那么这个参数必须是可迭代对象。如果接收两个参数，那么第一个参数要是 callable，第二个参数是哨兵。迭代时会调用 callable，当返回值等于哨兵时，迭代结束，那么它的底层是怎么实现的呢？这里简单补充一下。</p>
<pre><code class="language-C">// Python/bltinmodule.c
static PyObject *
builtin_iter(PyObject *self, PyObject *const *args, Py_ssize_t nargs)
{
    // ...
    PyObject *sentinel = args[1];
    // 如果参数个数等于 2，会调用 PyCallIter_New
    return PyCallIter_New(v, sentinel);
}

// Objects/iterobject.c
typedef struct {
    PyObject_HEAD
    PyObject *it_callable;
    PyObject *it_sentinel;
} calliterobject;

PyObject *
PyCallIter_New(PyObject *callable, PyObject *sentinel)
{  
    // iter(callable, value) 会返回一个 &lt;class 'callable_iterator'&gt; 实例
    // 在底层由 calliterobject 结构体实现
    calliterobject *it;
    // 为 calliterobject 实例申请内存
    it = PyObject_GC_New(calliterobject, &amp;PyCallIter_Type);
    if (it == NULL)
        return NULL;
    // 初始化字段
    Py_INCREF(callable);
    it-&gt;it_callable = callable;
    Py_INCREF(sentinel);
    it-&gt;it_sentinel = sentinel;
    _PyObject_GC_TRACK(it);
    return (PyObject *)it;
}

// 再来看看迭代过程
static PyObject *
calliter_iternext(calliterobject *it)
{
    PyObject *result;
    // 如果 it_callable 字段为空，说明迭代结束，不能再次迭代
    if (it-&gt;it_callable == NULL) {
        return NULL;
    }
    // 调用 it_callable，拿到返回值 result
    result = _PyObject_CallNoArg(it-&gt;it_callable);
    if (result != NULL) {
        int ok;
        // 如果 result 和哨兵相等，那么 ok == 1，否则 ok == 0
        ok = PyObject_RichCompareBool(it-&gt;it_sentinel, result, Py_EQ);
        // ok == 0，说明两者不相等，那么返回 result
        if (ok == 0) {
            return result;
        }
        // ok &gt; 0，说明返回值和哨兵相等，那么迭代结束
        // 减少引用计数，并将 it_callable 和 it_sentinel 字段设置为 NULL
        Py_DECREF(result);
        if (ok &gt; 0) {
            Py_CLEAR(it-&gt;it_callable);
            Py_CLEAR(it-&gt;it_sentinel);
        }
    }
    else if (PyErr_ExceptionMatches(PyExc_StopIteration)) {
        // 如果函数抛出了 StopIteration 异常，同样视为迭代结束
        PyErr_Clear();
        Py_CLEAR(it-&gt;it_callable);
        Py_CLEAR(it-&gt;it_sentinel);
    }
    return NULL;
}
</code></pre>
<p>还是比较简单的，就是不停地调用可迭代对象，当返回值和哨兵相等时，迭代结束。</p>
<h2 id="小结-39"><a class="header" href="#小结-39">小结</a></h2>
<p>通过探究迭代器，我们再次体会到了 Python 的设计哲学，虽然一切皆对象，但是拿到的都是对象的指针。像变量、函数参数等，它们存储的都不是对象本身，而是对象的泛型指针。而基于 PyObject * 和 ob_type，Python 巧妙地实现了多态。</p>
<p>不管变量 obj 指向什么样的可迭代对象，都可以交给 iter 函数，会调用类型对象内部的 __iter__（底层对应 tp_iter 字段），得到迭代器。不管变量 it 指向什么样的迭代器，都可以交给 next 函数进行迭代，会调用迭代器的类型对象的 __next__（底层对应 tp_iternext 字段），将值迭代出来。</p>
<p>至于 __iter__ 和 __next__ 本身，每个迭代器都会有，我们这里只以列表的迭代器为例。所以这是不是实现了多态呢？</p>
<p>这就是 Python 的设计哲学，变量只是一个指针，传递变量的时候相当于传递指针（将指针拷贝一份），但操作一个变量的时候会自动操作变量（指针）指向的内存。</p>
<p>以上就是 Python 迭代器的相关内容，当然你也完全可以自己封装一个迭代器，有兴趣可以试一下。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-39"><a class="header" href="#楔子-39">楔子</a></h2>
<p>当我们执行一个 py 文件的时候，只需要在命令行中输入 <font color="blue">python xxx.py</font> 即可，但你有没有想过这背后的流程是怎样的呢？</p>
<p>首先 py 文件不是一上来就直接执行的，而是会先有一个编译的过程，整个步骤如下：</p>
<p><img src="./images/140.png" alt="" /></p>
<p>这里我们看到了 Python 编译器、Python 虚拟机，而且我们平常还会说 Python 解释器，那么三者之间有什么区别呢？</p>
<p><img src="./images/141.png" alt="" /></p>
<p>Python 编译器负责将 Python 源代码编译成 PyCodeObject 对象，然后交给 Python 虚拟机来执行。</p>
<p>那么 Python 编译器和 Python 虚拟机都在什么地方呢？如果打开 Python 的安装目录，会发现有一个 python.exe，点击的时候会通过它来启动一个终端。但问题是这个文件大小还不到 100K，不可能容纳一个编译器加一个虚拟机，所以它下面还有一个 python38.dll。没错，编译器、虚拟机都藏身于 python38.dll 当中。</p>
<p>因此 Python 虽然是解释型语言，但也有编译的过程。源代码会被编译器编译成 PyCodeObject 对象，然后再交给虚拟机来执行。而之所以要存在编译，是为了让虚拟机能更快速地执行，比如在编译阶段常量都会提前分配好，而且还可以尽早检测出语法上的错误。</p>
<h2 id="pyc-文件是什么"><a class="header" href="#pyc-文件是什么">pyc 文件是什么</a></h2>
<p>在 Python 开发时，我们肯定都见过这个 pyc 文件，它一般位于 __pycache__ 目录中，那么 pyc 文件和 PyCodeObject 之间有什么关系呢？</p>
<p>首先我们都知道字节码，虚拟机的执行实际上就是对字节码不断解析的一个过程。然而除了字节码之外，还应该包含一些其它的信息，这些信息也是 Python 运行的时候所必需的，比如常量、变量名等等。</p>
<p>因此我们常听到 py 文件被编译成字节码，这句话其实不太严谨，因为字节码只是一个 PyBytesObject 对象、或者说一段字节序列。但很明显，光有字节码是不够的，还有很多的静态信息也需要被收集起来，它们整体被称为 PyCodeObject，然后 PyCodeObject 对象中有一个字段 co_code，它是一个指针，指向了这段字节序列。但是这个对象除了有指向字节码的 co_code 字段之外，还有很多其它字段，负责保存代码涉及到的常量、变量（名字、符号）等等。</p>
<p>所以虽然编写的是 py 文件，但虚拟机执行的是编译后的 PyCodeObject 对象。但是问题来了，难道每一次执行都要将源文件编译一遍吗？如果没有对源文件进行修改的话，那么完全可以使用上一次的编译结果。相信此时你能猜到 pyc 文件是干什么的了，它就是负责保存编译之后的 PyCodeObject 对象。</p>
<p>现在我们知道了，pyc 文件里面保存的内容是 PyCodeObject 对象。对于 Python 编译器来说，PyCodeObject 对象是对源代码编译之后的结果，而 pyc 文件则是这个对象在硬盘上的表现形式。</p>
<p>当下一次运行的时候，Python 解释器会根据 pyc 文件中记录的编译结果，直接建立内存中的 PyCodeObject 对象，而不需要再重新编译了，当然前提是没有对源文件进行修改。</p>
<h2 id="pycodeobject-底层结构"><a class="header" href="#pycodeobject-底层结构">PyCodeObject 底层结构</a></h2>
<p>既然 PyCodeObject 对象是源代码的编译结果，那么搞清楚它的底层结构就至关重要，下面来看一下它长什么样子。</p>
<pre><code class="language-C">// Include/cpython/code.h

typedef struct {
    PyObject_HEAD
    int co_argcount;
    int co_posonlyargcount;
    int co_kwonlyargcount;
    int co_nlocals;
    int co_stacksize;
    int co_flags;          
    int co_firstlineno;    
    PyObject *co_code;     
    PyObject *co_consts;   
    PyObject *co_names;    
    PyObject *co_varnames; 
    PyObject *co_freevars; 
    PyObject *co_cellvars; 
    Py_ssize_t *co_cell2arg;
    PyObject *co_filename;
    PyObject *co_name;
    PyObject *co_lnotab;
    void *co_zombieframe;
    PyObject *co_weakreflist;
    void *co_extra;
    unsigned char *co_opcache_map;
    _PyOpcache *co_opcache;
    int co_opcache_flag;
    unsigned char co_opcache_size;
} PyCodeObject;
</code></pre>
<p>这里面的每一个字段，我们一会儿都会详细介绍，并通过代码逐一演示。总之 Python 编译器在对源代码进行编译的时候，针对每一个 code block（代码块），都会创建一个 PyCodeObject 与之对应。但多少代码才算得上是一个 block 呢？事实上，Python 有一个简单而清晰的规则：当进入一个新的名字空间，或者说作用域时，就算是进入一个新的 block 了。举个例子：</p>
<pre><code class="language-python">class A:
    a = 123

def foo():
    a = []
</code></pre>
<p>我们仔细观察一下上面这段代码，它在编译完之后会有三个 PyCodeObject 对象，一个是对应整个 py 文件（模块）的，一个是对应 class A 的，一个是对应 def foo 的。因为这是三个不同的作用域，所以会有三个 PyCodeObject 对象。</p>
<p>所以一个 code block 对应一个作用域、同时也对应一个 PyCodeObject 对象。Python 的类、函数、模块都有自己独立的作用域，因此在编译时也都会有一个 PyCodeObject 对象与之对应。</p>
<h2 id="pycodeobject-字段解析"><a class="header" href="#pycodeobject-字段解析">PyCodeObject 字段解析</a></h2>
<p>PyCodeObject 我们知道它是干什么的了，那如何才能拿到这个对象呢？首先该对象在 Python 里面的类型是 &lt;class 'code'&gt;，但是底层没有将这个类暴露给我们，因此 code 这个名字在 Python 里面只是一个没有定义的变量罢了。</p>
<p>但我们可以通过其它的方式进行获取，比如函数。</p>
<pre><code class="language-Python">def func():
    pass

print(func.__code__)  # &lt;code object ......
print(type(func.__code__))  # &lt;class 'code'&gt;
</code></pre>
<p>我们可以通过函数的 __code__ 属性拿到底层对应的 PyCodeObject 对象，当然也可以获取里面的字段，下面就来演示一下，并详细介绍每个字段的含义。</p>
<p><font color="darkblue"><strong>PyObject_HEAD：对象的头部信息</strong></font></p>
<p>我们看到 Python 真的一切皆对象，源代码编译之后的结果也是一个对象。</p>
<p><font color="darkblue"><strong>co_argcount：可以通过位置参数传递的参数个数</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c=3):
    pass
print(foo.__code__.co_argcount)  # 3

def bar(a, b, *args):
    pass
print(bar.__code__.co_argcount)  # 2

def func(a, b, *args, c):
    pass
print(func.__code__.co_argcount)  # 2
</code></pre>
<p>函数 foo 中的参数 a、b、c 都可以通过位置参数传递，所以结果是 3。而函数 bar 则是两个，这里不包括 *args。最后函数 func 显然也是两个，因为参数 c 只能通过关键字参数传递。</p>
<p><font color="darkblue"><strong>co_posonlyargcount：只能通过位置参数传递的参数个数，Python3.8 新增</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c):
    pass
print(foo.__code__.co_posonlyargcount)  # 0

def bar(a, b, /, c):
    pass
print(bar.__code__.co_posonlyargcount)  # 2
</code></pre>
<p>注意：这里是只能通过位置参数传递的参数个数。对于 foo 而言，里面的三个参数既可以通过位置参数、也可以通过关键字参数传递，所以个数是 0。而函数 bar，里面的 a、b 只能通过位置参数传递，所以个数是 2。</p>
<p><font color="darkblue"><strong>co_kwonlyargcount：只能通过关键字参数传递的参数个数</strong></font></p>
<pre><code class="language-Python">def foo(a, b=1, c=2, *, d, e):
    pass
print(foo.__code__.co_kwonlyargcount)  # 2
</code></pre>
<p>这里是 d 和 e，它们必须通过关键字参数传递。</p>
<p><font color="darkblue"><strong>co_nlocals：代码块中局部变量的个数，也包括参数</strong></font></p>
<pre><code class="language-Python">def foo(a, b, *args, c, **kwargs):
    name = &quot;xxx&quot;
    age = 16
    gender = &quot;f&quot;
    c = 33

print(foo.__code__.co_varnames)
&quot;&quot;&quot;
('a', 'b', 'c', 'args', 'kwargs', 'name', 'age', 'gender')
&quot;&quot;&quot;
print(foo.__code__.co_nlocals)
&quot;&quot;&quot;
8
&quot;&quot;&quot;
</code></pre>
<p>co_varnames 保存的是代码块的局部变量，显然 co_nlocals 就是它的长度。并且我们看到在编译之后，函数的局部变量就已经确定了，因为它们是静态存储的。</p>
<p><font color="darkblue"><strong>co_stacksize：执行该段代码块所需要的栈空间</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c):
    name = &quot;xxx&quot;
    age = 16
    gender = &quot;f&quot;
    c = 33

print(foo.__code__.co_stacksize)  # 1
</code></pre>
<p>这个暂时不需要太关注，后续介绍栈帧的时候会详细说明。</p>
<p><font color="darkblue"><strong>co_flags：函数标识</strong></font></p>
<p>先来提出一个问题：</p>
<pre><code class="language-Python">def some_func():
    return &quot;hello world&quot;

def some_gen():
    yield
    return &quot;hello world&quot;

print(some_func.__class__)
print(some_gen.__class__)
&quot;&quot;&quot;
&lt;class 'function'&gt;
&lt;class 'function'&gt;
&quot;&quot;&quot;

print(some_func())
&quot;&quot;&quot;
hello world
&quot;&quot;&quot;
print(some_gen())
&quot;&quot;&quot;
&lt;generator object some_gen at 0x1028a80b0&gt;
&quot;&quot;&quot;
</code></pre>
<p>调用 some_func 会将代码执行完毕，调用 some_gen 会返回生成器，但问题是这两者都是函数类型，为什么执行的时候会有不同的表现呢？可能有人觉得这还不简单，Python 具有词法作用域，由于 some_func 里面没有出现 yield 关键字，所以是普通函数，而 some_gen 里面出现了 yield，所以是生成器函数。</p>
<p>从源代码来看确实如此，但源代码是要编译成 PyCodeObject 对象的，在编译之后，函数内部是否出现 yield 关键字这一信息要怎么体现呢？答案便是通过 co_flags 字段。</p>
<p>然后解释器内部定义了一系列的标志位，通过和 co_flags 字段按位与，便可判断函数是否具备指定特征。常见的标志位如下：</p>
<pre><code class="language-C">// Include/code.h

// 函数参数是否包含 *args
#define CO_VARARGS      0x0004
// 函数参数是否包含 **kwargs
#define CO_VARKEYWORDS  0x0008
// 函数是否是内层函数
#define CO_NESTED       0x0010
// 函数是否是生成器函数
#define CO_GENERATOR    0x0020
// 函数是否是协程函数
#define CO_COROUTINE            0x0080
// 函数是否是异步生成器函数
#define CO_ASYNC_GENERATOR      0x0200
</code></pre>
<p>我们实际测试一下，比如检测函数的参数类型：</p>
<pre><code class="language-python">CO_VARARGS = 0x0004
CO_VARKEYWORDS = 0x0008
CO_NESTED = 0x0010


def foo(*args):
    pass

def bar():
    pass

# 因为 foo 的参数包含 *args，所以和 CO_VARARGS 按位与的结果为真
# 而 bar 的参数不包含 *args，所以结果为假
print(foo.__code__.co_flags &amp; CO_VARARGS)  # 4
print(bar.__code__.co_flags &amp; CO_VARARGS)  # 0


def foo(**kwargs):
    pass

def bar():
    pass

print(foo.__code__.co_flags &amp; CO_VARKEYWORDS)  # 8
print(bar.__code__.co_flags &amp; CO_VARKEYWORDS)  # 0


def foo():
    def bar():
        pass
    return bar

# foo 是外层函数，所以和 CO_NESTED 按位与的结果为假
# foo() 返回的是内层函数，所以和 CO_NESTED 按位与的结果为真
print(foo.__code__.co_flags &amp; CO_NESTED)  # 0
print(foo().__code__.co_flags &amp; CO_NESTED)  # 16
</code></pre>
<p>当然啦，co_flags 还可以检测一个函数的类型。比如函数内部出现了 yield，那么它就是一个生成器函数，调用之后会得到一个生成器；使用 async def 定义，那么它就是一个协程函数，调用之后会得到一个协程。</p>
<p>这些在词法分析的时候就可以检测出来，编译之后会体现在 co_flags 字段中。</p>
<pre><code class="language-Python">CO_GENERATOR = 0x0020
CO_COROUTINE = 0x0080
CO_ASYNC_GENERATOR = 0x0200

# 如果是生成器函数，那么 co_flags &amp; 0x20 为真
def foo1():
    yield
print(foo1.__code__.co_flags &amp; 0x20)  # 32

# 如果是协程函数，那么 co_flags &amp; 0x80 为真
async def foo2():
    pass
print(foo2.__code__.co_flags &amp; 0x80)  # 128
# 显然 foo2 不是生成器函数，所以 co_flags &amp; 0x20 为假
print(foo2.__code__.co_flags &amp; 0x20)  # 0

# 如果是异步生成器函数，那么 co_flags &amp; 0x200 为真
async def foo3():
    yield
print(foo3.__code__.co_flags &amp; 0x200)  # 512
# 显然它不是生成器函数、也不是协程函数
# 因此和 0x20、0x80 按位与之后，结果都为假
print(foo3.__code__.co_flags &amp; 0x20)  # 0
print(foo3.__code__.co_flags &amp; 0x80)  # 0
</code></pre>
<p>在判断函数种类时，这种方式是最优雅的。</p>
<p><font color="darkblue"><strong>co_firstlineno：代码块的起始位置在源文件中的哪一行</strong></font></p>
<pre><code class="language-python">def foo(a, b, c):
    pass

# 显然是文件的第一行
# 或者理解为 def 所在的行
print(foo.__code__.co_firstlineno)  # 1
</code></pre>
<p>如果函数出现了调用呢？</p>
<pre><code class="language-Python">def foo():
    return bar

def bar():
    pass

print(foo().__code__.co_firstlineno)  # 4
</code></pre>
<p>如果执行 foo，那么会返回函数 bar，因此结果是 <font color="blue">def bar():</font> 所在的行数。所以每个函数都有自己的作用域，以及 PyCodeObject 对象。</p>
<p><font color="darkblue"><strong>co_code：指令集，也就是字节码，它是一个 bytes 对象</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c):
    name = &quot;satori&quot;
    age = 16
    gender = &quot;f&quot;
    print(name, age, gender)

# 字节码，一个 bytes 对象，它保存了要操作的指令
# 但光有字节码是肯定不够的，还需要其它的静态信息
# 显然这些信息连同字节码一样，都位于 PyCodeObject 中
print(foo.__code__.co_code)
&quot;&quot;&quot;
b'd\x01}\x03d\x02}\x04d\x03}\x05t\x00|\x03|\x04|\x05\x83\x03\x01\x00d\x00S\x00'
&quot;&quot;&quot;
</code></pre>
<p><font color="darkblue"><strong>co_consts：常量池，一个元组，保存代码块中创建的所有常量</strong></font></p>
<pre><code class="language-Python">def foo():
    a = 122 + 1
    b = &quot;hello&quot;
    c = (1, 2)
    d = [&quot;x&quot;, &quot;y&quot;]
    e = {&quot;p&quot;: &quot;k&quot;}
    f = {7, 8}

print(foo.__code__.co_consts)
&quot;&quot;&quot;
(None, 123, 'hello', (1, 2), 'x', 'y', 'p', 'k', 7, 8)
&quot;&quot;&quot;
</code></pre>
<p>co_consts 里面出现的都是编译阶段可以确定的常量，而 [&quot;x&quot;, &quot;y&quot;] 和 {&quot;p&quot;: &quot;k&quot;} 没有出现，由此我们可以得出，列表和字典绝不是在编译阶段构建的。编译时，只是收集了里面的元素，然后等到运行时再去动态构建。</p>
<p>不过问题来了，在构建的时候解释器怎么知道是要构建列表、还是字典、亦或是其它的什么对象呢？所以这就依赖于字节码了，解释字节码的时候，会判断到底要构建什么样的对象。因此解释器执行的是字节码，核心逻辑都体现在字节码中，但是光有字节码还不够，它包含的只是程序的主干逻辑，至于变量、常量，则从符号表和常量池里面获取。</p>
<p>另外函数里面的变量 a 等于 122 + 1，但常量池里面却存储了 123，这个过程叫做常量折叠。常量之间的加减乘除，结果依旧是一个常量，编译阶段就会计算好。</p>
<p><font color="darkblue"><strong>co_names：符号表，一个元组，保存代码块中引用的其它作用域的变量</strong></font></p>
<pre><code class="language-Python">c = 1

def foo(a, b):
    print(a, b, c)
    d = (list, int, str)

print(foo.__code__.co_names)
&quot;&quot;&quot;
('print', 'c', 'list', 'int', 'str')
&quot;&quot;&quot;
</code></pre>
<p>虽然一切皆对象，但看到的都是指向对象的变量，所以 print, c, list, int, str 都是变量，它们都不在当前 foo 函数的作用域中。</p>
<p><font color="darkblue"><strong>co_varnames：符号表，一个元组，保存当前作用域中创建的局部变量</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c):
    name = &quot;satori&quot;
    age = 16
    gender = &quot;f&quot;
    print(name, age, gender)
    
# 当前作用域中创建的变量，注意它和 co_names 的区别
# co_varnames 保存的是当前作用域中创建的局部变量
# 而 co_names 保存的是当前作用域中引用的其它作用域的变量
print(foo.__code__.co_varnames)
&quot;&quot;&quot;
('a', 'b', 'c', 'name', 'age', 'gender')
&quot;&quot;&quot;
print(foo.__code__.co_varnames)
&quot;&quot;&quot;
('print',)
&quot;&quot;&quot;
</code></pre>
<p><font color="darkblue"><strong>co_cellvars：一个元组，保存外层函数的作用域中被内层函数引用的变量</strong></font></p>
<p><font color="darkblue"><strong>co_freevars：一个元组，保存内层函数引用的外层函数的作用域中的变量</strong></font></p>
<pre><code class="language-Python">def foo(a, b, c):
    def bar():
        print(a, b, c)
    return bar

# co_cellvars：外层函数的作用域中被内层函数引用的变量
# co_freevars：内层函数引用的外层函数的作用域中的变量
print(foo.__code__.co_cellvars)
print(foo.__code__.co_freevars)
&quot;&quot;&quot;
('a', 'b', 'c')
()
&quot;&quot;&quot;
# foo 里面的变量 a、b、c 被内层函数 bar 引用了
# 所以它的 co_cellvars 是 ('a', 'b', 'c')
# 而 foo 不是内层函数，所以它的 co_freevars 是 ()

bar = foo(1, 2, 3)
print(bar.__code__.co_cellvars)
print(bar.__code__.co_freevars)
&quot;&quot;&quot;
()
('a', 'b', 'c')
&quot;&quot;&quot;
# bar 引用了外层函数 foo 里面的变量 a、b、c
# 所以它的 co_freevars 是 ('a', 'b', 'c')
# 而 bar 已经是最内层函数了，所以它的 co_cellvars 是 () 
</code></pre>
<p>当然目前的函数只嵌套了两层，但嵌套三层甚至更多层也是一样的。</p>
<pre><code class="language-Python">def foo(a, b, c):
    def bar(d, e):
        print(a)
        def func():
            print(b, c, d, e)
        return func
    return bar

# 对于 foo 而言，它的内层函数就是 bar
# 至于最里面的 func，由于定义在 bar 的内部，因此可以看做是 bar 函数体的一部分
# 而 foo 里面的变量 a、b、c 都被内层函数引用了
print(foo.__code__.co_cellvars)  # ('a', 'b', 'c')
print(foo.__code__.co_freevars)  # ()

bar = foo(1, 2, 3)
# 对于函数 bar 而言，它的内层函数就是 func
# 而显然 bar 里面的变量 d 和 e 被 func 引用了
print(bar.__code__.co_cellvars)  # ('d', 'e')
# 然后 bar 引用了外层函数 foo 里面的 a、b、c
print(bar.__code__.co_freevars)  # ('a', 'b', 'c')
# 所以 co_cellvars 和 co_freevars 这两个字段的关系有点类似镜像
</code></pre>
<p>co_cellvars 和 co_freevars 在后续介绍闭包的时候会用到。</p>
<p><font color="darkblue"><strong>co_filename：代码块所在的文件的路径</strong></font></p>
<pre><code class="language-python"># 文件名：main.py
def foo():
    pass


print(foo.__code__.co_filename)
&quot;&quot;&quot;
/Users/satori/Documents/testing_project/main.py
&quot;&quot;&quot;
</code></pre>
<p>如果你无法使用 IDE，那么便可通过该字段查看函数定义在哪个文件中。</p>
<p><font color="darkblue"><strong>co_name：代码块的名字</strong></font></p>
<pre><code class="language-Python">def foo():
    pass

print(foo.__code__.co_name)  # foo
</code></pre>
<p>对于函数来说，代码块的名字就是函数名。</p>
<p><font color="darkblue"><strong>co_lnotab：负责存储指令的偏移量和源代码行号之间的对应关系</strong></font></p>
<p>PyCodeObject 是源代码编译之后的产物，虽然两者的结构千差万别，但体现出的信息是一致的。像源代码具有行号，那么编译成 PyCodeObject 之后，行号信息也应该要有专门的字段来维护，否则报错时我们就无法快速定位到行号。</p>
<pre><code class="language-Python">def foo():
    name = &quot;古明地觉&quot;
    hobby = (
        &quot;sing&quot;,
        &quot;dance&quot;,
        &quot;rap&quot;,
        &quot;🏀&quot;
    )
    age = 16
</code></pre>
<p>我们通过 dis 模块反编译一下。</p>
<p><img src="./images/142.png" alt="" /></p>
<p>第一列数字表示行号，第二列数字表示字节码指令的偏移量，或者说指令在整个字节码指令集中的索引。我们知道字节码指令集就是一段字节序列，由 co_code 字段维护，并且每个指令都带有一个参数，所以偏移量（索引）为 0 2 4 6 8 ··· 的字节表示指令，偏移量为 1 3 5 7 9 ··· 的字节表示参数。</p>
<p>关于反编译的具体细节后续会说，总之一个字节码指令就是一个八位整数。对于当前函数来说，它的字节码偏移量和行号的对应关系如下：</p>
<p><img src="./images/143.png" alt="" /></p>
<p>偏移量和源代码行号的对应关系便由 co_lnotab（一个字节序列）维护，只不过 co_lnotab 并没有直接记录这些信息，而是记录的增量值。</p>
<ul>
<li>(0, 1) 到 (0, 2)：偏移量增加 0，行号增加 1；</li>
<li>(0, 2) 到 (4, 3)：偏移量增加 4，行号增加 1；</li>
<li>(4, 3) 到 (8, 9)：偏移量增加 4，行号增加 6；</li>
</ul>
<p>所以 co_lnotab 便是 0 1 4 1 4 6，我们验证一下。</p>
<p><img src="./images/144.png" alt="" /></p>
<p>结果和我们分析的一样。</p>
<p>以上就是 PyCodeObject 里面的字段的含义，至于剩下的几个字段就无需关注了。</p>
<h2 id="小结-40"><a class="header" href="#小结-40">小结</a></h2>
<ul>
<li>Python 解释器 = Python 编译器 + Python 虚拟机。</li>
<li>编译器先将 .py 源码文件编译成 PyCodeObject 对象，然后再交给虚拟机执行。</li>
<li>PyCodeObject 对象可以认为是源码文件的另一种等价形式，但经过编译，虚拟机可以更快速地执行。</li>
<li>为了避免每次都要对源文件进行编译，因此编译后的结果会序列化在 .pyc 文件中，如果源文件没有做改动，那么下一次执行时会直接从 .pyc 文件中读取。</li>
<li>Python 的函数、类、模块等，都具有各自的作用域，每个作用域对应一个独立的代码块，在编译时，Python 编译器会为每个代码块都创建一个 PyCodeObject 对象。</li>
</ul>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="/Users/satori/Documents/cpython-internal/src/images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-40"><a class="header" href="#楔子-40">楔子</a></h2>
<p>上一篇文章我们介绍了 PyCodeObject 对象，但是还遗漏了一些内容，这里再单独补充一下。</p>
<h2 id="内置函数-compile"><a class="header" href="#内置函数-compile">内置函数 compile</a></h2>
<p>之前通过函数的 __code__ 属性获取了该函数的 PyCodeObject 对象，但是还有没有其它的方法呢？显然是有的，答案是通过内置函数 compile，不过在介绍 compile 之前，先介绍一下 eval 和 exec。</p>
<p><font color="darkblue"><strong>eval：传入一个字符串，然后把字符串里面的内容当做表达式。</strong></font></p>
<pre><code class="language-Python">a = 1
# 所以 eval(&quot;a&quot;) 就等价于 a
print(eval(&quot;a&quot;))  # 1
print(eval(&quot;1 + 1 + 1&quot;))  # 3
</code></pre>
<p>注意：eval 是有返回值的，返回值就是字符串里面的内容。所以 eval 接收的字符串里面一定是一个表达式，表达式计算之后是一个具体的值，比如 <font color="blue">a = eval(&quot;1 + 2&quot;)</font>，等价于  <font color="blue">a = 3</font>。</p>
<p>但如果是语句的话，比如 <font color="blue">a = eval(&quot;b = 3&quot;)</font>，这样等价于 <font color="blue">a = (b = 3)</font>，显然这会出现语法错误。因此 eval 函数把字符串两边的引号剥掉之后，得到的一定是一个普通的值。</p>
<pre><code class="language-Python">try:
    print(eval(&quot;xxx&quot;))
except NameError as e:
    print(e)  # name 'xxx' is not defined
</code></pre>
<p>此时等价于 print(xxx)，但是 xxx 没有定义，所以报错。</p>
<pre><code class="language-Python"># 此时是合法的，等价于 print('xxx')
print(eval(&quot;'xxx'&quot;))  # xxx
</code></pre>
<p>以上就是 eval 函数，使用起来还是很方便的。</p>
<p><font color="darkblue"><strong>exec：传入一个字符串，把字符串里面的内容当成语句来执行，这个是没有返回值的，或者说返回值是 None。</strong></font></p>
<pre><code class="language-Python"># 相当于 a = 1
exec(&quot;a = 1&quot;)  
print(a)  # 1

statement = &quot;&quot;&quot;
a = 123
if a == 123:
    print(&quot;a 等于 123&quot;)
else:
    print(&quot;a 不等于 123&quot;)
&quot;&quot;&quot;
exec(statement)  # a 等于 123
</code></pre>
<p>注意：<font color="blue">a 等于 123</font> 并不是 exec 返回的，而是把上面那坨字符串当成普通代码执行的时候 print 出来的。这便是 exec 的作用，将字符串当成语句来执行。</p>
<p>所以使用 exec 可以非常方便地创建多个变量。</p>
<pre><code class="language-Python">import random

for i in range(1, 5):
    exec(f&quot;a{i} = {random.randint(1, 100)}&quot;)

print(a1)  # 72
print(a2)  # 21
print(a3)  # 38
print(a4)  # 32
</code></pre>
<p>那么 exec 和 eval 的区别就显而易见了，eval 是要求字符串里面的内容能够当成一个值，并且该值就是 eval 函数的返回值。而 exec 则是直接执行里面的内容，返回值是 None。</p>
<pre><code class="language-Python">print(eval(&quot;1 + 1&quot;))  # 2
print(exec(&quot;1 + 1&quot;))  # None

# 相当于 a = 2
exec(&quot;a = 1 + 1&quot;)
print(a)  # 2

try:
    # 相当于 a = 2，但很明显 a = 2 是一个语句
    # 它无法作为一个值，因此放到 eval 里面就报错了
    eval(&quot;a = 1 + 1&quot;)
except SyntaxError as e:
    print(e)  # invalid syntax (&lt;string&gt;, line 1)
</code></pre>
<p>还是很好区分的，但是 eval 和 exec 在生产中尽量要少用。另外，eval 和 exec 还可以接收第二个参数和第三个参数，我们在介绍名字空间的时候再说。</p>
<p><font color="darkblue"><strong>compile：关键来了，它执行后返回的就是一个 PyCodeObject 对象。</strong></font></p>
<p>这个函数接收哪些参数呢？</p>
<ul>
<li>参数一：当成代码执行的字符串</li>
<li>参数二：可以为这些代码起一个文件名</li>
<li>参数三：执行方式，支持三种，分别是 exec、single、eval</li>
</ul>
<p>我们演示一下。</p>
<pre><code class="language-Python"># exec：将源代码当做一个模块来编译
# single：用于编译一个单独的 Python 语句（交互式）
# eval：用于编译一个 eval 表达式
statement = &quot;a, b = 1, 2&quot;
# 这里我们选择 exec，当成一个模块来编译
co = compile(statement, &quot;古明地觉的编程教室&quot;, &quot;exec&quot;)

print(co.co_firstlineno)  # 1
print(co.co_filename)  # 古明地觉的编程教室
print(co.co_argcount)  # 0
# 我们是以 a, b = 1, 2 这种方式赋值
# 所以 (1, 2) 会被当成一个元组加载进来
# 因此从这里可以看出，元组在编译阶段就已经确定好了
print(co.co_consts)  # ((1, 2), None)

statement = &quot;&quot;&quot;
a = 1
b = 2
&quot;&quot;&quot;
co = compile(statement, &quot;&lt;file&gt;&quot;, &quot;exec&quot;)
print(co.co_consts)  # (1, 2, None)
print(co.co_names)  # ('a', 'b')
</code></pre>
<p>我们后面在分析 PyCodeObject 的时候，会经常使用 compile 函数。</p>
<p>然后 compile 还可以接收一个 flags 参数，也就是第四个参数，它的默认值为 0，表示按照标准模式进行编译，就是之前说的那几步。</p>
<ul>
<li>对文本形式的源代码进行分词，将其切分成一个个的 Token；</li>
<li>对 Token 进行语法解析，生成抽象语法树（AST）；</li>
<li>将 AST 编译成 PyCodeObject 对象，简称 code 对象或者代码对象；</li>
</ul>
<p>但如果将 flags 指定为 1024，那么 compile 函数在生成 AST 之后会直接停止，然后返回一个 _ast.Module 对象。</p>
<pre><code class="language-Python">print(
    compile(&quot;a = 1&quot;, &quot;&lt;file&gt;&quot;, &quot;exec&quot;).__class__
)  # &lt;class 'code'&gt;

print(
    compile(&quot;a = 1&quot;, &quot;&lt;file&gt;&quot;, &quot;exec&quot;, flags=1024).__class__
)  # &lt;class '_ast.Module'&gt;
</code></pre>
<p>_ast 模块是和 Python 的抽象语法树相关的，那么问题来了，这个 _ast.Module 对象能够干什么呢？别着急，我们后续在介绍栈帧的时候说。不过由于抽象语法树比较底层，因此知道 compile 的前三个参数的用法即可。</p>
<h2 id="字节码与反编译"><a class="header" href="#字节码与反编译">字节码与反编译</a></h2>
<p>关于 Python 的字节码，是后面剖析虚拟机的重点，现在先来看一下。我们知道执行源代码之前会先编译得到 PyCodeObject 对象，里面的 co_code 字段指向了字节码序列，或者说字节码指令集。</p>
<p>虚拟机会根据这些指令集来进行一系列的操作（当然也依赖其它的静态信息），从而完成对程序的执行。关于指令，解释器定义了 100 多种，我们大致看一下。</p>
<pre><code class="language-C">// Include/opcode.h
#define POP_TOP                   1
#define ROT_TWO                   2
#define ROT_THREE                 3
#define DUP_TOP                   4
#define DUP_TOP_TWO               5
#define ROT_FOUR                  6
#define NOP                       9
#define UNARY_POSITIVE           10
#define UNARY_NEGATIVE           11
#define UNARY_NOT                12
#define UNARY_INVERT             15
#define BINARY_MATRIX_MULTIPLY   16
#define INPLACE_MATRIX_MULTIPLY  17
#define BINARY_POWER             19
#define BINARY_MULTIPLY          20
#define BINARY_MODULO            22
#define BINARY_ADD               23
#define BINARY_SUBTRACT          24
#define BINARY_SUBSCR            25
#define BINARY_FLOOR_DIVIDE      26
#define BINARY_TRUE_DIVIDE       27
#define INPLACE_FLOOR_DIVIDE     28
#define INPLACE_TRUE_DIVIDE      29
#define GET_AITER                50
#define GET_ANEXT                51
#define BEFORE_ASYNC_WITH        52
#define BEGIN_FINALLY            53
#define END_ASYNC_FOR            54
#define INPLACE_ADD              55
#define INPLACE_SUBTRACT         56
#define INPLACE_MULTIPLY         57
#define INPLACE_MODULO           59
#define STORE_SUBSCR             60
#define DELETE_SUBSCR            61
#define BINARY_LSHIFT            62
#define BINARY_RSHIFT            63
#define BINARY_AND               64
#define BINARY_XOR               65
#define BINARY_OR                66
#define INPLACE_POWER            67
#define GET_ITER                 68
#define GET_YIELD_FROM_ITER      69
#define PRINT_EXPR               70
#define LOAD_BUILD_CLASS         71
#define YIELD_FROM               72
#define GET_AWAITABLE            73
#define INPLACE_LSHIFT           75
#define INPLACE_RSHIFT           76
// ...
</code></pre>
<p>所谓字节码指令其实就是个整数，多个指令组合在一起便是字节码指令集（字节码序列），它是一个 bytes 对象。当然啦，指令集里面不全是指令，索引（偏移量）为偶数的字节表示指令，索引为奇数的字节表示指令参数，后续会细说。</p>
<p>然后我们可以通过反编译的方式查看每行 Python 代码都对应哪些操作指令。</p>
<pre><code class="language-Python"># Python 的 dis 模块专门负责干这件事情
import dis

def foo(a, b):
    c = a + b
    return c

# 里面接收 PyCodeObject 对象
# 当然函数也是可以的，会自动获取 co_code
dis.dis(foo)
&quot;&quot;&quot;
  2           0 LOAD_FAST                0 (a)
              2 LOAD_FAST                1 (b)
              4 BINARY_ADD
              6 STORE_FAST               2 (c)

  3           8 LOAD_FAST                2 (c)
             10 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>字节码反编译后的结果多么像汇编语言，其中第一列是源代码行号，第二列是字节码偏移量，第三列是字节码指令（也叫操作码），第四列是指令参数（也叫操作数）。Python 的字节码指令都是成对出现的，每个指令会带有一个指令参数。</p>
<p>另外查看字节码也可以使用 opcode 模块：</p>
<pre><code class="language-Python">from opcode import opmap

opmap = {v: k for k, v in opmap.items()}

def foo(a, b):
    c = a + b
    return c

code = foo.__code__.co_code
for i in range(0, len(code), 2):
    print(&quot;操作码: {:&lt;12} 操作数: {}&quot;.format(
        opmap[code[i]], code[i+1]
    ))
&quot;&quot;&quot;
操作码: LOAD_FAST    操作数: 0
操作码: LOAD_FAST    操作数: 1
操作码: BINARY_ADD   操作数: 0
操作码: STORE_FAST   操作数: 2
操作码: LOAD_FAST    操作数: 2
操作码: RETURN_VALUE 操作数: 0
&quot;&quot;&quot;    
</code></pre>
<p>总之字节码就是一段字节序列，转成列表之后就是一堆数字。偶数位置表示指令本身，而每个指令后面都会跟一个指令参数，也就是奇数位置表示指令参数。</p>
<p>所以指令本质上只是一个整数，而虚拟机会根据不同的指令执行不同的逻辑。说白了 Python 虚拟机执行字节码的逻辑就是把自己想象成一颗 CPU，并内置了一个巨型的 switch case 语句，其中每个指令都对应一个 case 分支。然后遍历整条字节码，拿到每一个指令和指令参数。接着对指令进行判断，不同的指令进入不同的 case 分支，执行不同的处理逻辑，直到字节码全部执行完毕或者程序出错。</p>
<p>关于执行字节码的具体流程，等介绍栈帧的时候细说。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="pyc-文件的触发"><a class="header" href="#pyc-文件的触发">pyc 文件的触发</a></h2>
<p>上一篇文章我们介绍了字节码，当时提到，py 文件在执行的时候会先被编译成 PyCodeObject 对象，并且该对象还会被保存到 pyc 文件中。</p>
<p>然而事实并不总是这样，有时当我们运行一个简单的程序时，并没有产生 pyc 文件。因此我们猜测：有些 Python 程序只是临时完成一些琐碎的工作，这样的程序仅仅只会运行一次，然后就不会再使用了，因此也就没有保存至 pyc 文件的必要。</p>
<p>如果我们在代码中加上了一个 import abc 这样的语句，再执行你就会发现解释器为 abc.py 生成了 pyc 文件，这就说明 import 语句会触发 pyc 的生成。</p>
<p>实际上，在运行过程中，如果碰到 import abc 这样的语句，那么 Python 会在设定好的 path 中寻找 abc.pyc 或者 abc.pyd 文件。但如果没有这些文件，而是只发现了 abc.py，那么会先将 abc.py 编译成 PyCodeObject，然后写入到 pyc 文件中。</p>
<p>接下来，再对 abc.pyc 进行 import 动作。对的，并不是编译成 PyCodeObject 对象之后就直接使用，而是先写到 pyc 文件里，然后再将 pyc 文件里面的 PyCodeObject 对象重新在内存中复制出来。</p>
<p>当然啦，触发 pyc 文件生成不仅可以通过 import，还可以通过 py_compile 模块手动生成。比如当前有一个 tools.py，代码如下。</p>
<pre><code class="language-Python">a = 1
b = &quot;你好啊&quot;
</code></pre>
<p>如何将其编译成 pyc 呢？</p>
<pre><code class="language-Python">import py_compile

py_compile.compile(&quot;tools.py&quot;)
</code></pre>
<p>查看当前目录的 __pycache__ 目录，会发现 pyc 已经生成了。</p>
<p><img src="./images/145.png" alt="" /></p>
<p><font color="blue">py文件名.cpython-版本号.pyc</font> 便是编译之后的 pyc 文件名。</p>
<h2 id="pyc-文件的导入"><a class="header" href="#pyc-文件的导入">pyc 文件的导入</a></h2>
<p>如果有一个现成的 pyc 文件，我们要如何导入它呢？</p>
<pre><code class="language-Python">from importlib.machinery import SourcelessFileLoader

tools = SourcelessFileLoader(
    &quot;tools&quot;, &quot;__pycache__/tools.cpython-38.pyc&quot;
).load_module()

print(tools.a)  # 1
print(tools.b)  # 你好啊
</code></pre>
<p>以上我们就成功手动导入了 pyc 文件。</p>
<h2 id="pyc-文件都包含哪些内容"><a class="header" href="#pyc-文件都包含哪些内容">pyc 文件都包含哪些内容</a></h2>
<p>pyc 文件在创建的时候都会往里面写入哪些内容呢？</p>
<p><font color="darkblue"><strong>1）magic number</strong></font></p>
<p>这是解释器内部定义的一个值，不同版本的解释器会定义不同的 magic number，这个值是为了保证能够加载正确的 pyc，比如 Python3.8 不会加载 3.7 版本的 pyc。因为解释器在加载 pyc 文件的时候会检测该 pyc 的 magic number，如果和自身的 magic number 不一致，说明此 pyc 是由其它版本的解释器写入的，因此拒绝加载。</p>
<pre><code class="language-Python">from importlib.util import MAGIC_NUMBER
print(MAGIC_NUMBER)  # b'U\r\r\n'

with open(&quot;__pycache__/tools.cpython-38.pyc&quot;, &quot;rb&quot;) as f:
    magic_number = f.read(4)
print(magic_number)  # b'U\r\r\n'
</code></pre>
<p>pyc 文件的前 4 个字节便是 magic number。</p>
<p><font color="darkblue"><strong>2）py 文件的最后修改时间</strong></font></p>
<p>这个很好理解，在加载 pyc 的时候会比较源代码的实际修改时间和 pyc 文件中存储的修改时间。如果两者不相等，说明在生成 pyc 之后，源代码又被修改了，那么会重新编译并写入 pyc，而反之则会直接加载已存在的 pyc。</p>
<p><font color="darkblue"><strong>3）py 文件的大小</strong></font></p>
<p>py 文件的大小也会被记录在 pyc 文件中。</p>
<p><font color="darkblue"><strong>4）PyCodeObject 对象</strong></font></p>
<p>编译之后的 PyCodeObject 对象，这个不用说了，肯定是要存储的，并且是序列化之后再存储。</p>
<p><font color="blue">因此 pyc 文件的结构如下：</font></p>
<p><img src="./images/146.png" alt="" /></p>
<p>我们实际验证一下：</p>
<pre><code class="language-python">import struct
from importlib.util import MAGIC_NUMBER
from datetime import datetime

with open(&quot;__pycache__/tools.cpython-38.pyc&quot;, &quot;rb&quot;) as f:
    data = f.read()

# 0 ~ 4 字节是 MAGIC NUMBER
print(data[: 4])  # b'U\r\r\n'
print(MAGIC_NUMBER)  # b'U\r\r\n'

# 4 ~ 8 字节是 4 个 \x00
print(data[4: 8])  # b'\x00\x00\x00\x00'

# 8 ~ 12 字节是 py 文件的最后修改时间（小端存储），一个时间戳
ts = struct.unpack(&quot;&lt;I&quot;, data[8: 12])[0]
print(ts)  # 1734595934
print(datetime.fromtimestamp(ts))  # 2024-12-19 08:12:14

# 12 ~ 16 字节是 py 文件的大小
print(struct.unpack(&quot;&lt;I&quot;, data[12: 16])[0])  # 22
</code></pre>
<p>那么实际的 tools.py 是不是这样呢？我们查看一下。</p>
<p><img src="./images/147.png" alt="" /></p>
<p>结果没有问题，实际大小是 22 字节，和 pyc 文件记录的一样。然后是最后修改时间，由于在生成 pyc 之后，没有对源文件做修改，所以它的最后修改时间和 pyc 文件记录的一样，都是 08:12。但如果我们再对 tools.py 做修改的话，那么它的最后修改时间和 pyc 文件记录的就不一样了，此时如果再导入 tools.py 就会重新编译生成 pyc，并写入新的最后修改时间。</p>
<p>以上就是 pyc 文件的前 16 个字节，而 16 个字节往后就是 PyCodeObject 对象，并且是序列化之后的，因为该对象显然无法直接存在文件中。</p>
<pre><code class="language-Python">import marshal

with open(&quot;__pycache__/tools.cpython-38.pyc&quot;, &quot;rb&quot;) as f:
    data = f.read()

# 通过 marshal.loads 可以反序列化
# marshal.dumps 则表示序列化
code = marshal.loads(data[16:])
# 此时就拿到了 py 文件编译之后的 PyCodeObject
print(code)
&quot;&quot;&quot;
&lt;code object &lt;module&gt; at 0x..., file &quot;tools.py&quot;, line 1&gt;
&quot;&quot;&quot;
# 查看常量池
print(code.co_consts)  # (1, '你好啊', None)

# 符号表
print(code.co_names)  # ('a', 'b')
</code></pre>
<p>常量池和符号表都是正确的。</p>
<h2 id="pyc-文件的写入"><a class="header" href="#pyc-文件的写入">pyc 文件的写入</a></h2>
<p>下面通过源码来查看 pyc 文件的写入过程，既然要写入，那么肯定要有文件句柄。</p>
<pre><code class="language-C">// Python/marshal.c

// FILE 是 C 自带的文件句柄
// 可以把 WFILE 看成是 FILE 的包装
typedef struct {
    FILE *fp;
    // 下面的字段在写入数据的时候会看到
    int error;
    int depth;
    PyObject *str;
    char *ptr;
    char *end;
    char *buf;
    _Py_hashtable_t *hashtable;
    int version;
} WFILE;
</code></pre>
<p>首先是写入 magic number、创建时间和文件大小，它们会调用 PyMarshal_WriteLongToFile 函数进行写入：</p>
<pre><code class="language-C">// Python/marshal.c
void
PyMarshal_WriteLongToFile(long x, FILE *fp, int version)
{
    // magic number、创建时间和文件大小，只是一个 4 字节整数
    // 因此使用 char[4] 来保存
    char buf[4];
    // 声明一个 WFILE 类型的变量 wf
    WFILE wf;
    // 内存初始化
    memset(&amp;wf, 0, sizeof(wf));
    // 初始化内部字段
    wf.fp = fp;  // 文件句柄
    wf.ptr = wf.buf = buf;  // buf 数组首元素的地址
    wf.end = wf.ptr + sizeof(buf);  // buf 数组尾元素的地址
    wf.error = WFERR_OK;
    wf.version = version;
    // 调用 w_long 将信息写到 wf 里面
    // 写入的信息可以是 magic number、时间和文件大小
    w_long(x, &amp;wf);
    // 刷到磁盘上
    w_flush(&amp;wf);
}
</code></pre>
<p>所以该函数只是初始化了一个 WFILE 对象，真正写入则是调用的 w_long。</p>
<pre><code class="language-c">// Python/marshal.c
static void
w_long(long x, WFILE *p)
{
    w_byte((char)( x      &amp; 0xff), p);
    w_byte((char)((x&gt;&gt; 8) &amp; 0xff), p);
    w_byte((char)((x&gt;&gt;16) &amp; 0xff), p);
    w_byte((char)((x&gt;&gt;24) &amp; 0xff), p);
}
</code></pre>
<p>w_long 则是调用 w_byte 将 x 逐个字节地写到文件里面去。</p>
<p>当头信息写完之后，就该写 PyCodeObject 对象了，这个过程由 PyMarshal_WriteObjectToFile 函数负责。</p>
<pre><code class="language-C">// Python/marshal.c
void
PyMarshal_WriteObjectToFile(PyObject *x, FILE *fp, int version)
{
    char buf[BUFSIZ];
    WFILE wf;
    memset(&amp;wf, 0, sizeof(wf));
    wf.fp = fp;
    wf.ptr = wf.buf = buf;
    wf.end = wf.ptr + sizeof(buf);
    wf.error = WFERR_OK;
    wf.version = version;
    if (w_init_refs(&amp;wf, version))
        return; /* caller mush check PyErr_Occurred() */
    // 写入头信息由 PyMarshal_WriteLongToFile 负责，它内部会调用 w_long
    // 写入 PyCodeObject 由当前函数负责，它内部会调用 w_object
    w_object(x, &amp;wf);
    w_clear_refs(&amp;wf);
    w_flush(&amp;wf);
}
</code></pre>
<p>然后我们看一下 w_object 函数。</p>
<pre><code class="language-C">// Python/marshal.c
static void
w_object(PyObject *v, WFILE *p)
{
    char flag = '\0';

    p-&gt;depth++;

    if (p-&gt;depth &gt; MAX_MARSHAL_STACK_DEPTH) {
        p-&gt;error = WFERR_NESTEDTOODEEP;
    }
    else if (v == NULL) {
        w_byte(TYPE_NULL, p);
    }
    else if (v == Py_None) {
        w_byte(TYPE_NONE, p);
    }
    else if (v == PyExc_StopIteration) {
        w_byte(TYPE_STOPITER, p);
    }
    else if (v == Py_Ellipsis) {
        w_byte(TYPE_ELLIPSIS, p);
    }
    else if (v == Py_False) {
        w_byte(TYPE_FALSE, p);
    }
    else if (v == Py_True) {
        w_byte(TYPE_TRUE, p);
    }
    else if (!w_ref(v, &amp;flag, p))
        w_complex_object(v, flag, p);

    p-&gt;depth--;
}
</code></pre>
<p>可以看到 w_object 和 w_long 一样，本质上都是调用了 w_byte。当然 w_byte 只能写入一些简单数据，如果是列表、字典之类的数据，那么会调用 w_complex_object 函数，也就是代码中的最后一个 else if 分支。</p>
<p>w_complex_object 这个函数的源代码很长，我们看一下整体结构，具体逻辑就不贴了，后面会单独截取一部分进行分析。</p>
<pre><code class="language-C">// Python/marshal.c

static void
w_complex_object(PyObject *v, char flag, WFILE *p)
{
    Py_ssize_t i, n;
    // 如果是整数，执行整数的写入逻辑
    if (PyLong_CheckExact(v)) {
        // ...
    }
    // 如果是浮点数，执行浮点数的写入逻辑
    else if (PyFloat_CheckExact(v)) {
        // ...
    }
    // 如果是复数，执行复数的写入逻辑
    else if (PyComplex_CheckExact(v)) {
        // ...
    }
    // 如果是字节序列，执行字节序列的写入逻辑
    else if (PyBytes_CheckExact(v)) {
        // ...
    }
    // 如果是字符串，执行字符串的写入逻辑
    else if (PyUnicode_CheckExact(v)) {
        // ...
    }
    // 如果是元组，执行元组的写入逻辑
    else if (PyTuple_CheckExact(v)) {
        // ...
    }
    // 如果是列表，执行列表的写入逻辑
    else if (PyList_CheckExact(v)) {
        // ...
    }
    // 如果是字典，执行字典的写入逻辑
    else if (PyDict_CheckExact(v)) {
        // ...
    }
    // 如果是集合，执行集合的写入逻辑
    else if (PyAnySet_CheckExact(v)) {
        // ...
    }
    // 如果是 PyCodeObject 对象，执行 PyCodeObject 对象的写入逻辑
    else if (PyCode_Check(v)) {
        // ...
    }
    // 如果是 Buffer，执行 Buffer 的写入逻辑
    else if (PyObject_CheckBuffer(v)) {
        // ...
    }
    else {
        W_TYPE(TYPE_UNKNOWN, p);
        p-&gt;error = WFERR_UNMARSHALLABLE;
    }
}
</code></pre>
<p>源代码虽然长，但是逻辑非常单纯，就是对不同的对象、执行不同的写动作，然而其最终目的都是通过 w_byte 写到 pyc 文件中。了解完函数的整体结构之后，我们再看一下具体细节，看看它在写入对象的时候到底写入了哪些内容？</p>
<pre><code class="language-C">// Python/marshal.c
static void
w_complex_object(PyObject *v, char flag, WFILE *p)
{
    // ......
    else if (PyList_CheckExact(v)) {
        W_TYPE(TYPE_LIST, p);
        n = PyList_GET_SIZE(v);
        W_SIZE(n, p);
        for (i = 0; i &lt; n; i++) {
            w_object(PyList_GET_ITEM(v, i), p);
        }
    }
    else if (PyDict_CheckExact(v)) {
        Py_ssize_t pos;
        PyObject *key, *value;
        W_TYPE(TYPE_DICT, p);
        /* This one is NULL object terminated! */
        pos = 0;
        while (PyDict_Next(v, &amp;pos, &amp;key, &amp;value)) {
            w_object(key, p);
            w_object(value, p);
        }
        w_object((PyObject *)NULL, p);
    }
    // ......
}
</code></pre>
<p>以列表和字典为例，它们在写入的时候实际上写的是内部的元素，其它对象也是类似的。</p>
<pre><code class="language-python">def foo():
    lst = [1, 2, 3]

# 把列表内的元素写进去了
print(
    foo.__code__.co_consts
)  # (None, 1, 2, 3)
</code></pre>
<p>但很明显，如果只是将元素收集起来显然是不够的，否则 Python 在加载的时候怎么知道它是一个列表呢？所以在写入的时候不能光写数据，还要将类型信息也写进去。我们再看一下上面列表和字典的写入逻辑，里面都调用了 W_TYPE，它负责写入类型信息。</p>
<p>因此无论对于哪种对象，在写入具体数据之前，都会先调用 W_TYPE 将类型信息写进去。如果没有类型信息，那么当解释器加载 pyc 文件的时候，只会得到一坨字节流，而无法解析字节流中隐藏的结构和蕴含的信息。所以在往 pyc 文件里写入数据之前，必须先写入一个标识，比如 TYPE_LIST、TYPE_TUPLE、TYPE_DICT 等等，这些标识正是对应的类型信息。</p>
<p>如果解释器在 pyc 文件中发现了这样的标识，则预示着上一个对象结束，新的对象开始，并且也知道新对象是什么样的对象，从而也知道该执行什么样的构建动作。至于这些标识都是可以看到的，在底层已经定义好了。</p>
<p><img src="./images/148.png" alt="" /></p>
<p>到了这里可以看到，Python 对 PyCodeObject 对象的导出实际上是不复杂的。因为不管什么对象，最后都会归结为两种简单的形式，一种是数值写入，一种是字符串写入。</p>
<p>上面都是对数值的写入，比较简单，仅仅需要按照字节依次写入 pyc 即可。然而在写入字符串的时候，Python 设计了一种比较复杂的机制，有兴趣可以自己阅读源码，这里不再介绍。</p>
<h2 id="字节码混淆"><a class="header" href="#字节码混淆">字节码混淆</a></h2>
<p>最后再来说一下字节码混淆，我们知道 pyc 是可以反编译的，而且目前也有现成的工具。但这些工具会将每一个指令都解析出来，所以字节码混淆的方式就是往里面插入一些恶意指令（比如加载超出范围的数据），让反编译工具在解析的时候报错，从而失去作用。</p>
<p>但插入的恶意指令还不能影响解释器执行，因此还要插入一些跳转指令，从而让解释器跳过恶意指令。</p>
<p><img src="./images/149.png" alt="" /></p>
<p>混淆之后多了两条指令，其中偏移量为 8 的指令，参数为 255，表示加载常量池中索引为 255 的元素。如果常量池没有这么多元素，那么显然会发生索引越界，导致反编译的时候报错。</p>
<p>但对于解释器来说，是可以正常执行的，因为在执行到偏移量为 6 的指令时出现了一个相对跳转，直接跳到偏移量为 6 + 4 = 10 的指令了。</p>
<p>因此对于解释器执行来说，混淆前后是没有区别的，但对于反编译工具而言则无法正常工作，因为它会把每个指令都解析一遍。根据这个思路，我们可以插入很多很多的恶意指令，然后再利用跳转指令来跳过这些不合法的指令。当然混淆的手段并不止这些，我们还可以添加一些虚假的分支，然后在执行时跳转到真实的分支当中。</p>
<p>而这一切的目的，都是为了防止别人根据 pyc 文件反推出源代码。不过这种做法属于治标不治本，如果真的想要保护源代码的话，可以使用 Cython 将其编译成 pyd ，这是最推荐的做法。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-41"><a class="header" href="#楔子-41">楔子</a></h2>
<p>从现在开始，我们将剖析虚拟机运行字节码的原理。前面说了，Python 解释器可以分为两部分：Python 编译器和 Python 虚拟机。编译器将源代码编译成 PyCodeObject 对象之后，就由虚拟机接手整个工作。虚拟机会从 PyCodeObject 中读取字节码，并在当前的上下文中执行，直到所有的字节码都被执行完毕。</p>
<p>那么问题来了，既然源代码在经过编译之后，字节码指令以及静态信息都存储在 PyCodeObject 当中，那么是不是意味着虚拟机就在 PyCodeObject 对象上进行所有的动作呢？</p>
<p>很明显不是的，因为尽管 PyCodeObject 包含了关键的字节码指令以及静态信息，但有一个东西是没有包含、也不可能包含的，就是程序在运行时的<font color="blue">执行环境</font>，这个执行环境在 Python 里面就是<font color="blue">栈帧</font>。</p>
<h2 id="栈帧虚拟机的执行环境"><a class="header" href="#栈帧虚拟机的执行环境">栈帧：虚拟机的执行环境</a></h2>
<p>那什么是栈帧呢？我们举个例子。</p>
<pre><code class="language-Python">name = &quot;古明地觉&quot;

def some_func():
    name = &quot;八意永琳&quot;
    print(name)

some_func()
print(name)
</code></pre>
<p>上面的代码当中出现了两个 <font color="blue">print(name)</font>，它们的字节码指令相同，但执行的效果却显然是不同的，这样的结果正是执行环境的不同所产生的。因为环境的不同，name 的值也不同。</p>
<p>因此同一个符号在不同环境中可能指向不同的类型、不同的值，必须在运行时进行动态捕捉和维护，这些信息不可能在 PyCodeObject 对象中被静态存储。</p>
<p>所以可以得出结论，虚拟机并不是在 PyCodeObject 对象上执行操作的，而是在栈帧对象上。虚拟机在执行时，会根据 PyCodeObject 对象动态创建出栈帧对象，然后在栈帧里面执行字节码。所以栈帧是虚拟机执行的上下文，执行时依赖的所有信息都存储在栈帧中。</p>
<p>然后对于上面的代码，我们可以大致描述一下流程：</p>
<ul>
<li>首先基于模块的 PyCodeObject 创建一个栈帧，假设叫 A，所有的字节码都会在栈帧中执行，虚拟机可以从栈帧里面获取变量的值，也可以修改；</li>
<li>当发生函数调用的时候，这里是 some_func，那么虚拟机会在栈帧 A 之上，为 some_func 创建一个新的栈帧，假设叫 B，然后在栈帧 B 里面执行函数 some_func 的字节码指令；</li>
<li>在栈帧 B 里面也有一个名字为 name 的变量，但由于执行环境、或者说栈帧的不同，name 指向的对象也不同；</li>
<li>一旦函数 some_func 的字节码指令全部执行完毕，那么会将当前的栈帧 B 销毁（也可以保留），再回到调用者的栈帧中来。就像是递归一样，每当调用函数时，就会在当前栈帧之上创建一个新的栈帧，一层一层创建，一层一层返回；</li>
</ul>
<h2 id="虚拟机和操作系统"><a class="header" href="#虚拟机和操作系统">虚拟机和操作系统</a></h2>
<p>不难发现，Python 虚拟机执行字节码这个过程，就是在模拟操作系统运行可执行文件。比如：</p>
<p><font color="darkblue"><strong>程序加载</strong></font></p>
<ul>
<li>操作系统：加载可执行文件到内存，设置程序计数器。</li>
<li>Python 虚拟机：加载 .pyc 文件中的 PyCodeObject 对象，初始化字节码指令指针。</li>
</ul>
<p><font color="darkblue"><strong>内存管理</strong></font></p>
<ul>
<li>操作系统：为进程分配内存空间，管理堆和栈。</li>
<li>Python 虚拟机：创建和管理 Python 对象，处理内存分配和垃圾回收。</li>
</ul>
<p><font color="darkblue"><strong>指令执行</strong></font></p>
<ul>
<li>操作系统：CPU 逐条执行机器指令。</li>
<li>Python 虚拟机：虚拟机逐条执行字节码指令。</li>
</ul>
<p><font color="darkblue"><strong>资源管理</strong></font></p>
<ul>
<li>操作系统：管理文件句柄、网络连接等系统资源。</li>
<li>Python 虚拟机：管理文件对象、套接字等 Python 级别的资源。</li>
</ul>
<p><font color="darkblue"><strong>异常处理</strong></font></p>
<ul>
<li>操作系统：处理硬件中断和软件异常。</li>
<li>Python 虚拟机：捕获和处理 Python 异常。</li>
</ul>
<p>我们简单地画一张示意图，来看看在一台普通的 x64 机器上，可执行文件是以什么方式运行的，在这里主要关注栈帧的变化。假设有三个函数，函数 f 调用了函数 g，函数 g 又调用了函数 h。</p>
<p><img src="./images/150.png" alt="" /></p>
<p>首先 CPU 有两个关键的寄存器，它们在函数调用和栈帧管理中扮演关键角色。</p>
<ul>
<li>RSP（Stack Pointer）：栈指针，指向当前栈帧的顶部，或者说最后一个入栈的元素。因此随着元素的入栈和出栈，RSP 会动态变化。由于地址从栈底到栈顶是逐渐减小的，所以 RSP 会随着数据入栈而减小，随着数据出栈而增大。当然不管 RSP 怎么变，它始终指向当前栈的顶部。</li>
<li>RBP（Base Pointer）：基指针，指向当前栈帧的基址，它的作用是提供一个固定的参考点，用于访问当前函数的局部变量和参数。当新的帧被创建时，它的基址会保存上一个帧的基址，并由 RBP 指向。</li>
</ul>
<p>我们用一段 C 代码来解释一下。</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

int add(int a, int b) {
    int c = a + b;
    return c;
}

int main() {
    int a = 11;
    int b = 22;
    int result = add(a, b);
    printf(&quot;a + b = %d\n&quot;, result);
}
</code></pre>
<p>当执行函数 main 的时候，RSP 指向 main 栈帧的顶部，RBP 指向 main 栈帧的基址。然后在 main 里面又调用了函数 add，那么毫无疑问，系统会在地址空间中，在 main 的栈帧之上为 add 创建栈帧。然后让 RSP 指向 add 栈帧的顶部，RBP 指向 add 栈帧的基址，而 add 栈帧的基址保存了上一级栈帧（main 栈帧）的基址。</p>
<p>当函数 add 执行结束时，会销毁对应栈帧，再将 RSP 和 RBP 恢复为创建 add 栈帧之前的值，这样程序的执行流程就又回到了函数 main 里面，当然程序的运行空间也回到了函数 main 的栈帧中。</p>
<p>不难发现，通过两个 CPU 寄存器 RSP、RBP，以及栈帧中保存的上一级栈帧的基址，完美地维护了函数之间的调用链，这就是可执行文件在 x64 机器上的运行原理。</p>
<p>那么 Python 里面的栈帧是怎样的呢？</p>
<h2 id="栈帧的底层结构"><a class="header" href="#栈帧的底层结构">栈帧的底层结构</a></h2>
<p>相较于 x64 机器上看到的那个简简单单的栈帧，Python 的栈帧实际上包含了更多的信息。注：栈帧也是一个对象。</p>
<pre><code class="language-c">// Include/frameobject.h

typedef struct _frame {
    PyObject_VAR_HEAD
    struct _frame *f_back;
    PyCodeObject *f_code;
    PyObject *f_builtins;
    PyObject *f_globals;
    PyObject *f_locals;
    PyObject **f_valuestack;
    PyObject **f_stacktop;
    PyObject *f_trace;
    char f_trace_lines;
    char f_trace_opcodes;
    PyObject *f_gen;
    int f_lasti;
    int f_lineno;
    int f_iblock;
    char f_executing;
    PyTryBlock f_blockstack[CO_MAXBLOCKS];
    PyObject *f_localsplus[1];
} PyFrameObject;
</code></pre>
<p>下面来解释一下里面的每个字段都是啥含义，不过在解释之前，我们要先知道如何在 Python 中获取栈帧对象。</p>
<pre><code class="language-Python">import inspect

def foo():
    # 返回当前所在的栈帧
    # 这个函数实际上是调用了 sys._getframe(1)
    return inspect.currentframe()

frame = foo()
print(frame) 
&quot;&quot;&quot;
&lt;frame at 0x100de0fc0, file '.../main.py', line 6, code foo&gt;
&quot;&quot;&quot;
print(type(frame)) 
&quot;&quot;&quot;
&lt;class 'frame'&gt;
&quot;&quot;&quot;
</code></pre>
<p>我们看到栈帧的类型是 &lt;class 'frame'&gt;，正如 PyCodeObject 对象的类型是 &lt;class 'code'&gt; 一样，这两个类没有暴露给我们，所以不可以直接使用。</p>
<p>同理，还有 Python 的函数，类型是 &lt;class 'function'&gt;，模块的类型是 &lt;class 'module'&gt;。这些解释器都没有给我们提供，如果直接使用的话，那么 frame、code、function、module 只是几个没有定义的变量罢了，这些类我们只能通过这种间接的方式获取。</p>
<p>下面来看一下 PyFrameObject 里面每个字段的含义。</p>
<p><font color="darkblue"><strong>PyObject_VAR_HEAD</strong></font></p>
<p>变长对象的头部信息，所以栈帧也是一个对象。</p>
<p><font color="darkblue"><strong>struct _frame *f_back</strong></font></p>
<p>当前栈帧的上一级栈帧，也就是调用者的栈帧。所以 x64 机器是通过 RSP、RBP 两个指针维护函数的调用关系，而 Python 虚拟机则是通过栈帧的 f_back 字段。</p>
<pre><code class="language-Python">import inspect

def foo():
    return inspect.currentframe()

frame = foo()
print(frame)
&quot;&quot;&quot;
&lt;frame at 0x100de0fc0, file '.../main.py', line 6, code foo&gt;
&quot;&quot;&quot;
# foo 的上一级栈帧，显然对应的是模块的栈帧
print(frame.f_back)
&quot;&quot;&quot;
&lt;frame at 0x100adde40, file '.../main.py', line 12, code &lt;module&gt;&gt;
&quot;&quot;&quot;
# 相当于模块的上一级栈帧，显然是 None
print(frame.f_back.f_back)
&quot;&quot;&quot;
None
&quot;&quot;&quot;
</code></pre>
<p>因此通过栈帧，可以轻松地获取完整的函数调用链路，我们一会儿演示。</p>
<p><font color="darkblue"><strong>PyCodeObject *f_code</strong></font></p>
<p>栈帧对象是在 PyCodeObject 之上构建的，所以它内部一定有一个字段指向 PyCodeObject，而该字段就是 f_code。</p>
<pre><code class="language-Python">import inspect

def e():
    f()

def f():
    g()

def g():
    h()

def h():
    frame = inspect.currentframe()  # 获取栈帧
    func_names = []
    # 只要 frame 不为空，就一直循环，并将函数名添加到列表中
    while frame is not None:
        func_names.append(frame.f_code.co_name)
        frame = frame.f_back
    print(f&quot;函数调用链路：{' -&gt; '.join(func_names[:: -1])}&quot;)

f()
&quot;&quot;&quot;
函数调用链路：&lt;module&gt; -&gt; f -&gt; g -&gt; h
&quot;&quot;&quot;
</code></pre>
<p><code>模块 -&gt; f -&gt; g -&gt; h</code>，显然我们获取了整个调用链路，是不是很有趣呢？</p>
<p><font color="darkblue"><strong>PyObject *f_builtins、*f_gloabls、*f_locals</strong></font></p>
<p>这三者均表示名字空间，其中 f_gloabls 指向全局名字空间（一个字典），它是全局变量的容身之所。是的，Python 的全局变量是通过字典存储的，调用函数 globals 即可拿到该字典。</p>
<pre><code class="language-Python"># 等价于 name = &quot;古明地觉&quot;
globals()[&quot;name&quot;] = &quot;古明地觉&quot;

# 等价于 print(name)
print(globals()[&quot;name&quot;])  # 古明地觉

def foo():
    import inspect
    return inspect.currentframe()

frame = foo()
# frame.f_globals 同样会返回全局名字空间
print(frame.f_globals is globals())  # True
# 相当于创建了一个全局变量 age
frame.f_globals[&quot;age&quot;] = 18
print(age)  # 18
</code></pre>
<p>关于名字空间，我们后面会用专门的篇幅详细说明。</p>
<p>然后 f_locals 指向局部名字空间（一个字典），但和全局变量不同，局部变量不存在局部名字空间中，而是静态存储在数组中。该字段先有个印象，后续再详细说。</p>
<p>f_builtins 指向内置名字空间（一个字典），显然一些内置的变量都存在里面。</p>
<pre><code class="language-Python">def foo():
    import inspect
    return inspect.currentframe()

frame = foo()
print(frame.f_builtins[&quot;list&quot;](&quot;abcd&quot;))
&quot;&quot;&quot;
['a', 'b', 'c', 'd']
&quot;&quot;&quot;
</code></pre>
<p>和我们直接使用 list(&quot;abcd&quot;) 是等价的。</p>
<p><font color="darkblue"><strong>PyObject **f_valuestack</strong></font></p>
<p>指向运行时栈的栈底，关于什么是运行时栈，后续详细说明。</p>
<p><font color="darkblue"><strong>PyObject **f_stacktop</strong></font></p>
<p>指向运行时栈的栈顶。</p>
<p><font color="darkblue"><strong>PyObject *f_trace</strong></font></p>
<p>追踪函数，用于调试。</p>
<p><font color="darkblue"><strong>char f_trace_lines</strong></font></p>
<p>是否为每一行代码调用追踪函数，当设置为真（非零值）时，每当虚拟机执行到一个新的代码行时，都会调用追踪函数。这允许调试器在每行代码执行时进行干预，比如设置断点、检查变量等。</p>
<p><font color="darkblue"><strong>char f_trace_opcodes</strong></font></p>
<p>是否为每个字节码指令调用追踪函数，当设置为真时，虚拟机会在执行每个字节码指令之前调用追踪函数。这提供了更细粒度的控制，允许进行指令级别的调试。</p>
<p>所以不难发现，f_trace_lines 是行级追踪，对应源代码的每一行，通常用于普通的调试，如设置断点、单步执行等，并且开销相对较小。f_trace_opcodes 是指令级追踪，对应每个字节码指令，通常用于更深层次的调试，比如分析具体的字节码执行过程，并且开销较大。</p>
<pre><code class="language-Python">import sys

def trace_lines(frame, event, arg):
    print(f&quot;行号：{frame.f_lineno}，文件名：{frame.f_code.co_filename}&quot;)
    return trace_lines

sys.settrace(trace_lines)
</code></pre>
<p>设置追踪函数一般需要通过 sys.settrace，不过不常用，了解一下即可。</p>
<p><font color="darkblue"><strong>PyObject *f_gen</strong></font></p>
<p>是否是基于生成器的 PyCodeObject 构建的栈帧。</p>
<p><font color="darkblue"><strong>int f_lasti</strong></font></p>
<p>上一条已执行完毕的指令在指令序列中的偏移量。</p>
<p><font color="darkblue"><strong>int f_lineno</strong></font></p>
<p>获取该栈帧时的源代码行号。</p>
<pre><code class="language-Python">import inspect

def foo():
    return inspect.currentframe()

frame = foo()
print(frame.f_lineno)  # 4
</code></pre>
<p>我们是在第 4 行获取的栈帧，所以打印结果是 4。</p>
<p><font color="darkblue"><strong>int f_iblock</strong></font></p>
<p>用于跟踪 try / except / finally 代码块的层级深度。具体等介绍异常捕获的时候再说，总之 f_iblock 对于虚拟机的异常捕获来说非常重要，可以在异常处理时确定当前代码在哪个 try 语句块内，帮助确定应该执行哪个 except 或 finally 子句，保证异常处理和清理代码能按正确的嵌套顺序执行。</p>
<p><font color="darkblue"><strong>char f_executing</strong></font></p>
<p>当前栈帧是否仍在执行。</p>
<p><font color="darkblue"><strong>PyTryBlock f_blockstack[CO_MAXBLOCKS]</strong></font></p>
<p>一个栈，用于追踪代码块，比如代码块的进入和退出，以及管理代码块的上下文信息。那么都支持哪些代码块呢？</p>
<ul>
<li>SETUP_FINALLY：try / finally 块</li>
<li>SETUP_WITH：with 语句块</li>
<li>SETUP_ASYNC_WITH：async with 语句块</li>
</ul>
<p><font color="darkblue"><strong>PyObject *localsplus[1]</strong></font></p>
<p>一个柔性数组，负责维护 &quot;局部变量 + cell 变量 + free 变量 + 运行时栈&quot;，大小在运行时确定。</p>
<p>以上就是栈帧内部的字段，这些字段先有个印象，后续在剖析虚拟机的时候还会继续细说。</p>
<p>总之我们看到，PyCodeObject 并不是虚拟机的最终目标，虚拟机最终是在栈帧中执行的。每一个栈帧都会维护一个 PyCodeObject 对象，换句话说，每一个 PyCodeObject 对象都会隶属于一个栈帧。并且从 f_back 可以看出，虚拟机在实际执行时，会产生很多的栈帧对象，而这些对象会被链接起来，形成一条执行环境链表，或者说栈帧链表。</p>
<p>而这正是 x64 机器上栈帧之间关系的模拟，在 x64 机器上，栈帧之间通过 RSP 和 RBP 指针建立了联系，使得新栈帧在结束之后能够顺利地返回到旧栈帧中，而 Python 虚拟机则是利用 f_back 来完成这个动作。</p>
<p>当然，获取栈帧除了通过 inspect 模块之外，在捕获异常时，也可以获取栈帧。</p>
<pre><code class="language-python">def foo():
    try:
        1 / 0
    except ZeroDivisionError:
        import sys
        # exc_info 返回一个三元组
        # 分别是异常的类型、值、以及 traceback
        exc_type, exc_value, exc_tb = sys.exc_info()
        print(exc_type)  # &lt;class 'ZeroDivisionError'&gt;
        print(exc_value)  # division by zero
        print(exc_tb)  # &lt;traceback object at 0x00000135CEFDF6C0&gt;

        # 调用 exc_tb.tb_frame 即可拿到异常对应的栈帧
        # 另外这个 exc_tb 也可以通过下面这种方式获取
        # except ZeroDivisionError as e; e.__traceback__
        print(exc_tb.tb_frame.f_code.co_name)  # foo
        print(exc_tb.tb_frame.f_back.f_code.co_name)  # &lt;module&gt;
        # 显然 tb_frame 是当前函数 foo 的栈帧
        # 那么 tb_frame.f_back 就是整个模块对应的栈帧
        # 而 tb_frame.f_back.f_back 显然就是 None 了
        print(exc_tb.tb_frame.f_back.f_back)  # None

foo()
</code></pre>
<p>关于栈帧内部的字段的含义，我们就说完了。当然如果有些字段现在不是很理解，也没关系，随着不断地学习，你会豁然开朗。</p>
<h2 id="小结-41"><a class="header" href="#小结-41">小结</a></h2>
<p>因为很多动态信息无法静态地存储在 PyCodeObject 对象中，所以 PyCodeObject 对象在交给虚拟机之后，虚拟机会在其之上动态地构建出 PyFrameObject 对象，也就是栈帧。</p>
<p>因此虚拟机是在栈帧里面执行的字节码，它包含了虚拟机在执行字节码时依赖的全部信息。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-42"><a class="header" href="#楔子-42">楔子</a></h2>
<p>在介绍栈桢的时候，我们看到了 3 个独立的名字空间：f_locals、f_globals、f_builtins。名字空间对 Python 来说是一个非常重要的概念，虚拟机的运行机制和名字空间有着非常紧密的联系。并且在 Python 中，与名字空间这个概念紧密联系在一起的还有名字、作用域这些概念，下面我们就来剖析这些概念是如何体现的。</p>
<h2 id="变量只是一个名字"><a class="header" href="#变量只是一个名字">变量只是一个名字</a></h2>
<p>在这个系列的最开始我们就说过，从解释器的角度来看，变量只是一个泛型指针 <font color="blue">PyObject *</font>，而从 Python 的角度来看，变量只是一个名字、或者说符号，用于和对象进行绑定的。</p>
<pre><code class="language-Python">name = &quot;古明地觉&quot;
</code></pre>
<p>上面这个赋值语句其实就是将 <font color="blue">name</font> 和 <font color="blue">&quot;古明地觉&quot;</font> 绑定起来，让我们可以通过 name 这个符号找到对应的 PyUnicodeObject。因此定义一个变量，本质上就是建立名字和对象之间的映射关系。</p>
<p>另外我们说 Python 虽然一切皆对象，但拿到的都是指向对象的指针，因此创建函数和类，以及模块导入，同样是在完成名字和对象的绑定。</p>
<pre><code class="language-python">def foo(): pass

class A(): pass
</code></pre>
<p>创建一个函数也相当于定义一个变量，会先根据函数体创建一个函数对象，然后将<font color="blue">名字 foo</font> 和<font color="blue">函数对象</font>绑定起来。所以函数名和函数体之间是分离的，同理类也是如此。</p>
<pre><code class="language-Python">import os
</code></pre>
<p>导入一个模块，也是在定义一个变量。<font color="blue">import os</font> 相当于将<font color="blue">名字 os</font> 和<font color="blue">模块对象绑定</font>起来，通过 os 可以找到指定的模块对象。</p>
<blockquote>
<p>当我们导入一个模块的时候，解释器是这么做的。</p>
<p>import os 等价于 os = __import__(&quot;os&quot;)，可以看到本质上还是一个赋值语句。</p>
</blockquote>
<p><font color="blue">import numpy as np</font> 中的 as 语句同样是在定义变量，将名字 np 和对应的模块对象绑定起来，以后就可以通过 np 这个名字去获取指定的模块了。</p>
<p><strong>总结：无论是普通的赋值语句，还是定义函数和类，亦或是模块导入，它们本质上都是在完成变量和对象的绑定。</strong></p>
<pre><code class="language-python">name = &quot;古明地觉&quot;

def foo(): pass

class A(): pass

import os
import numpy as np
</code></pre>
<p>里面的 name、foo、A、os、np，都只是一个变量，或者说名字、符号，然后通过名字可以获取与之绑定的对象。</p>
<h2 id="作用域和名字空间"><a class="header" href="#作用域和名字空间">作用域和名字空间</a></h2>
<p>正如上面所说，赋值语句、函数定义、类定义、模块导入，本质上只是完成了变量和对象之间的绑定，或者说我们创建了变量到对象的映射，通过变量可以获取对应的对象，而它们的容身之所就是名字空间。</p>
<p>所以名字空间是通过 PyDictObject 对象实现的，这对于映射来说简直再适合不过了。而前面介绍字典的时候，我们说字典是被高度优化的，原因就是虚拟机本身也重度依赖字典，从这里的名字空间即可得到体现。</p>
<p>当然，在一个模块内部，变量还存在可见性的问题，比如：</p>
<pre><code class="language-Python">x = 1

def foo():
    x = 2
    print(x)  # 2

foo()
print(x)  # 1
</code></pre>
<p>我们看到同一个变量名，打印的确是不同的值，说明指向了不同的对象，换句话说这两个变量是在不同的名字空间中被创建的。</p>
<p>名字空间本质上是一个字典，如果两者在同一个名字空间，那么由于 key 的不重复性，当执行 x = 2 的时候，会把字典里面 key 为 &quot;x&quot; 的 value 给更新成 2。但是在外面还是打印 1，这说明两者所在的不是同一个名字空间，打印的也就自然不是同一个 x。因此对于一个模块而言，内部可以存在多个名字空间，每一个名字空间都与一个作用域相对应。作用域可以理解为一段程序的正文区域，在这个区域里面定义的变量是有意义的，然而一旦出了这个区域，就无效了。</p>
<p>关于作用域这个概念，我们要记住：它仅仅是由源代码的文本所决定。在 Python 中，一个变量在某个位置是否起作用，是由它的文本位置决定的。</p>
<p>因此 Python 具有静态作用域（词法作用域），而名字空间则是作用域的动态体现，一个由程序文本定义的作用域在运行时会转化为一个名字空间、即一个 PyDictObject 对象。比如进入一个函数，显然会进入一个新的作用域，因此函数在执行时，会创建一个名字空间。</p>
<blockquote>
<p>在介绍 PyCodeObject 的时候，我们说解释器在对源代码进行编译的时候，对于代码中的每一个 code block，都会创建一个 PyCodeObject 对象与之对应。而当进入一个新的名字空间、或者说作用域时，就算是进入一个新的 block 了。</p>
<p>而根据我们使用 Python 的经验，显然函数、类都是一个新的 block，解释器在执行的时候会为它们创建各自的名字空间。</p>
</blockquote>
<p>所以名字空间是名字、或者说变量的上下文环境，名字的含义取决于名字空间。更具体的说，一个变量绑定的对象是不确定的，需要由名字空间来决定。位于同一个作用域的代码可以直接访问作用域中出现的名字，即所谓的<font color="blue">直接访问</font>；但不同的作用域，则需要通过<font color="blue">访问修饰符 <strong>.</strong></font> 进行属性访问。</p>
<pre><code class="language-python">class A:
    x = 1
    
class B:
    y = 2
    print(A.x)  # 1
    print(y)  # 2
</code></pre>
<p>如果想在 B 里面访问 A 里面的内容，要通过 <font color="blue">A.属性</font>的方式，表示通过 A 来获取 A 里面的属性。但是访问 B 的内容就不需要了，因为都是在同一个作用域，所以直接访问即可。</p>
<p>访问名字这样的行为被称为<font color="blue">名字引用</font>，名字引用的规则决定了 Python 程序的行为。</p>
<pre><code class="language-python">x = 1

def foo():
    x = 2
    print(x)  # 2

foo()
print(x)  # 1
</code></pre>
<p>还是上面的代码，如果我们把函数里面的 x = 2 给删掉，意味着函数的作用域里面已经没有 x 这个变量了，那么再执行程序会有什么结果呢？从 Python 层面来看，显然是会寻找外部的 x。因此我们可以得到如下结论：</p>
<ul>
<li>作用域是层层嵌套的；</li>
<li>内层作用域可以访问外层作用域；</li>
<li>外层作用域无法访问内层作用域，如果是把外层的 x = 1 给去掉，那么最后面的 print(x) 铁定报错；</li>
<li>查找元素会依次从当前作用域向外查找，也就是查找元素时，对应的作用域是按照从小往大、从里往外的方向前进的；</li>
</ul>
<h2 id="global-名字空间"><a class="header" href="#global-名字空间">global 名字空间</a></h2>
<p>不光函数、类有自己的作用域，模块对应的源文件本身也有相应的作用域。比如：</p>
<pre><code class="language-python">name = &quot;古明地觉&quot;
age = 16

def foo():
    return 123

class A:
    pass
</code></pre>
<p>这个文件本身也有自己的作用域，并且是 global 作用域，所以解释器在运行这个文件的时候，也会为其创建一个名字空间，而这个名字空间就是 global 名字空间，即全局名字空间。它里面的变量是全局的，或者说是模块级别的，在当前文件的任意位置都可以直接访问。</p>
<p>而 Python 也提供了 globals 函数，用于获取 global 名字空间。</p>
<pre><code class="language-python">name = &quot;古明地觉&quot;

def foo():
    pass

print(globals())
&quot;&quot;&quot;
{..., 'name': '古明地觉', 'foo': &lt;function foo at 0x0000015255143E20&gt;}
&quot;&quot;&quot;
</code></pre>
<p>里面的 ... 表示省略了一部分输出，我们看到创建的全局变量就在里面。而且 foo 也是一个全局变量，它指向一个函数对象。</p>
<p>注意：我们说函数内部是一个独立的 block，因此它会对应一个 PyCodeObject。然后在解释到 <font color="blue">def foo</font> 的时候，会根据 PyCodeObject 对象创建一个 PyFunctionObject 对象，然后将 foo 和这个函数对象绑定起来。</p>
<p>当后续调用 foo 的时候，再根据 PyFunctionObject 对象创建 PyFrameObject 对象、然后执行，至于具体细节留到介绍函数的时候再细说。总之，我们看到 foo 也是一个全局变量，全局变量都在 global 名字空间中。并且 <font color="blue">global 名字空间全局唯一</font>，它是程序运行时的<font color="blue">全局变量</font>和<font color="blue">与之绑定的对象</font>的容身之所。你在任何一个位置都可以访问到 global 名字空间，正如你在任何一个位置都可以访问全局变量一样。</p>
<p>另外我们思考一下，global 名字空间是一个字典，全局变量和对象会以键值对的形式存在里面。那如果我手动地往 global 名字空间里面添加一个键值对，是不是也等价于定义一个全局变量呢？</p>
<pre><code class="language-Python">globals()[&quot;name&quot;] = &quot;古明地觉&quot;
print(name)  # 古明地觉

def foo1():
    def foo2():
        def foo3():
            globals()[&quot;age&quot;] = 16
        return foo3
    return foo2

foo1()()()
print(age)  # 16
</code></pre>
<p>我们看到确实如此，往 global 名字空间里面插入一个键值对完全等价于定义一个全局变量。并且 global 名字空间是唯一的，你在任何地方调用 globals() 得到的都是 global 名字空间，正如你在任何地方都可以访问到全局变量一样。</p>
<p>所以即使是在函数中给 global 名字空间添加一个键值对，也等价于定义一个全局变量。</p>
<p><img src="./images/151.png" alt="" /></p>
<p>问题来了，如果在函数里面，我们不获取 global 名字空间，怎么创建全局变量呢？</p>
<pre><code class="language-python">name = &quot;古明地觉&quot;

def foo():
    global name
    name = &quot;古明地恋&quot;

print(name)  # 古明地觉
foo()
print(name)  # 古明地恋
</code></pre>
<p>很简单，Python 为我们准备了 global 关键字，表示声明的变量是全局的。</p>
<h2 id="local-名字空间"><a class="header" href="#local-名字空间">local 名字空间</a></h2>
<p>像函数和类拥有的作用域，我们称之为 local 作用域，在运行时会对应 local 名字空间，即局部名字空间。由于不同的函数具有不同的作用域，所以局部名字空间可以有很多个，但全局名字空间只有一个。</p>
<p>对于 local 名字空间来说，它也对应一个字典，显然这个字典就不是全局唯一的了。而如果想获取局部名字空间，Python 也提供了 locals 函数。</p>
<pre><code class="language-python">def foo():
    name = &quot;古明地觉&quot;
    age = 17
    return locals()

def bar():
    name = &quot;雾雨魔理沙&quot;
    age = 18
    return locals()

print(locals() == globals())  # True
print(foo())  # {'name': '古明地觉', 'age': 17}
print(bar())  # {'name': '雾雨魔理沙', 'age': 18}
</code></pre>
<p>对于模块来讲，它的 local 名字空间和 global 名字空间是一样的，也就是说，模块对应的栈桢对象里面的 f_locals 和 f_globals 指向的是同一个 PyDictObject 对象。但对于函数而言，局部名字空间和全局名字空间就不一样了，调用 locals() 是获取自身的局部名字空间，而不同函数的局部名字空间是不同的。但是 globals() 函数的调用结果是一样的，获取的都是全局名字空间，这也符合<font color="blue">函数内不存在指定变量的时候会去找全局变量</font>这一结论。</p>
<blockquote>
<p>注：关于 local 名字空间，还有一个重要的细节，全局变量会存储在 global 名字空间中，但局部变量却并不存储在 local 名字空间中。函数有哪些局部变量在编译的时候就已经确定了，会被静态存储在数组中，关于这一点，后续会单独详细说明。</p>
</blockquote>
<h2 id="builtin-名字空间"><a class="header" href="#builtin-名字空间">builtin 名字空间</a></h2>
<p>Python 有一个所谓的 LGB 规则，指的是在查找一个变量时，会按照自身的 local 空间、外层的 global 空间、内置的 builtin 空间的顺序进行查找。</p>
<p>builtin 名字空间也是一个字典，当 local 名字空间、global 名字空间都查找不到指定变量的时候，会去 builtin 空间查找。而关于 builtin 空间的获取，Python 提供了一个模块。</p>
<pre><code class="language-Python"># 等价于 __builtins__
import builtins
print(builtins is __builtins__)  # True
print(builtins)  # &lt;module 'builtins' (built-in)&gt;
</code></pre>
<p>builtins 是一个模块，那么 builtins.__dict__ 便是 builtin 名字空间，也叫内置名字空间。</p>
<pre><code class="language-Python">import builtins

# builtins.list 表示从 builtin 名字空间中查找 list
# 它等价于 builtins.__dict__[&quot;list&quot;]
# 而如果只写 list，那么由于 local 空间、global 空间都没有
# 因此最终还是会从 builtin 空间中查找
# 但如果是 builtins.list，那么就不兜圈子了
# 表示：&quot;builtin 空间，就从你这里获取了&quot;
print(builtins.list is list)  # True


# 将 builtin 空间的 dict 改成 123
builtins.dict = 123
# 那么此时获取的 dict 就是 123
print(dict + 456)  # 579


# 如果是 str = 123，等价于创建全局变量 str = 123
str = 123
# 显然影响的是 global 空间
print(str)  # 123
# builtin 空间则不受影响
print(builtins.str)  # &lt;class 'str'&gt;
print(builtins.__dict__[&quot;str&quot;])  # &lt;class 'str'&gt;
</code></pre>
<p><strong>这里提一下在 Python2 中，while 1 比 while True 要快，为什么？</strong></p>
<p>因为 True 在 Python2 中不是关键字，所以它是可以作为变量名的。那么虚拟机在执行的时候就要先看 local 空间和 global 空间里有没有 True 这个变量，有的话使用我们定义的，没有的话再使用内置的 True。</p>
<p>而 1 是一个常量，直接加载就可以，所以 while True 多了符号查找这一过程。但是在 Python3 中两者就等价了，因为 True 在 Python3 中是一个关键字，也会直接作为一个常量来加载。</p>
<h2 id="exec-和-eval"><a class="header" href="#exec-和-eval">exec 和 eval</a></h2>
<p>记得之前介绍 exec 和 eval 的时候，我们说这两个函数里面还可以接收第二个参数和第三个参数，它们分别表示 global 名字空间、local 名字空间。</p>
<pre><code class="language-Python"># 如果不指定，默认是当前所在的名字空间
# 显然此时是全局名字空间
exec(&quot;name = '古明地觉'&quot;)
print(name)  # 古明地觉

# 但我们也可以指定某个名字空间
namespace = {}
# 比如将 namespace 作为全局名字空间
# 另外这里没有指定第三个参数，也就是局部名字空间
# 如果指定了第二个参数，但没有指定第三个参数
# 那么第三个参数默认和第二个参数保持一致
exec(&quot;name = 'satori'&quot;, namespace)
print(namespace[&quot;name&quot;])  # satori
</code></pre>
<p>至于 eval 也是同理：</p>
<pre><code class="language-Python">namespace = {&quot;seq&quot;: [1, 2, 3, 4, 5]}
try:
    print(eval(&quot;sum(seq)&quot;))
except NameError as e:
    print(e)  # name 'seq' is not defined
# 告诉我们 seq 没有被定义
# 如果将 namespace 作为名字空间
print(eval(&quot;sum(seq)&quot;, namespace))  # 15
</code></pre>
<p>所以名字空间本质上就是一个字典，所谓的变量不过是字典里面的一个 key。为了进一步加深印象，再举个模块的例子：</p>
<pre><code class="language-Python"># 我们自定义一个模块吧
# 首先模块也是一个对象，类型为 &lt;class 'module'&gt;
# 但底层没有将这个类暴露给我们，所以需要换一种方式获取
import sys
ModuleType = type(sys)

# 以上就拿到了模块的类型对象，调用即可得到模块对象
# 这里我们自定义一个类，继承 ModuleType
class MyModule(ModuleType):

    def __init__(self, module_name):
        self.module_name = module_name
        super().__init__(module_name)
        # 也可以定义一些其它的属性

    def __str__(self):
        return f&quot;&lt;module '{self.module_name}' from '虚无之境'&gt;&quot;

my_module = MyModule(&quot;自定义模块&quot;)
print(my_module)
&quot;&quot;&quot;
&lt;module '自定义模块' from '虚无之境'&gt;
&quot;&quot;&quot;

# 此时的 my_module 啥也没有，我们为其添砖加瓦
my_module.__dict__[&quot;name&quot;] = &quot;古明地觉&quot;
print(my_module.name)  # 古明地觉

# 给模块设置属性，本质上也是操作模块的属性字典，当然获取属性也是如此
# 如果再和 exec 结合的话
code_string = &quot;&quot;&quot;
age = 16
def foo():
    return &quot;我是函数 foo&quot;
    
from functools import reduce     
&quot;&quot;&quot;
# 将属性设置在模块的属性字典里面
exec(code_string, my_module.__dict__)
# 然后我们获取它
print(my_module.age)  # 16
print(my_module.foo())  # 我是函数 foo
print(my_module.reduce(int.__add__, range(101)))  # 5050

# 是不是很神奇呢？由于 my_module 是一个模块对象
# 我们还可以将它注入到 sys.modules 中，然后通过 import 获取
sys.modules[&quot;俺滴模块&quot;] = my_module
from 俺滴模块 import name, age, foo
print(name)  # 古明地觉
print(age)  # 16
print(foo())  # 我是函数 foo
</code></pre>
<p>怎么样，是不是很有意思呢？相信你对名字空间已经有了足够清晰的认识，它是变量和与之绑定的对象的容身之所。</p>
<h2 id="小结-42"><a class="header" href="#小结-42">小结</a></h2>
<p>名字空间是 Python 的灵魂，它规定了一个变量应该如何查找，关于变量查找，下一篇文章来详细介绍，到时你会对名字空间有更加透彻的理解。</p>
<p>然后是作用域，所谓名字空间其实就是作用域的动态体现。整个 py 文件是一个作用域，也是全局作用域；定义函数、定义类、定义方法，又会创建新的作用域，这些作用域层层嵌套。那么同理，运行时的名字空间也是层层嵌套的，形成一条名字空间链。内层的变量对外层是不可见的，但外层的变量对内层是可见的。</p>
<p>然后全局名字空间是一个字典，它是唯一的，操作里面的键值对等价于操作全局变量；至于局部名字空间则不唯一，每一个函数都有自己的局部名字空间，但我们要知道函数内部在访问局部变量的时候是静态访问的（相关细节后续聊）。</p>
<p>还有内置名字空间，可以通过 __builtins__ 获取，但拿到的是一个模块，再获取它的属性字典，那么就是内置名字空间了。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-43"><a class="header" href="#楔子-43">楔子</a></h2>
<p>上一篇文章我们介绍了名字空间，并且知道了全局变量都存在 global 名字空间中，往 global 空间添加一个键值对相当于定义一个全局变量。那么问题来了，如果往函数的 local 空间里面添加一个键值对，是不是也等价于创建了一个局部变量呢？</p>
<pre><code class="language-Python">def foo():
    locals()[&quot;name&quot;] = &quot;古明地觉&quot;
    try:
        print(name)
    except Exception as e:
        print(e)

foo()  # name 'name' is not defined
</code></pre>
<p>全局变量的创建是通过向字典添加键值对实现的，因为全局变量会一直变，需要使用字典来动态维护。</p>
<p>但对于函数来讲，内部的变量是通过静态方式存储和访问的，因为局部作用域中存在哪些变量在编译的时候就已经确定了，我们通过 PyCodeObject 的 co_varnames 即可获取内部都有哪些变量。</p>
<p>所以，虽然我们说变量查找遵循 LGB 规则，但函数内部的变量其实是静态访问的，不过完全可以按照 LGB 的方式理解。关于这方面的细节，后续还会细说。</p>
<blockquote>
<p>因此名字空间是 Python 的灵魂，它规定了变量的作用域，使得 Python 对变量的查找变得非常清晰。</p>
</blockquote>
<h2 id="legb-规则"><a class="header" href="#legb-规则">LEGB 规则</a></h2>
<p>LGB 是针对 Python2.2 之前的，而从 Python2.2 开始，由于引入了嵌套函数，所以内层函数在找不到某个变量时应该先去外层函数找，而不是直接就跑到 global 空间里面找，那么此时的规则就是 LEGB。</p>
<pre><code class="language-Python">x = 1

def foo():
    x = 2
    def bar():
        print(x)
    return bar

foo()()
&quot;&quot;&quot;
2
&quot;&quot;&quot;
</code></pre>
<p>调用了内层函数 bar，如果按照 LGB 的规则来查找的话，由于函数 bar 的作用域没有 a，那么应该到全局里面找，打印的结果是 1 才对。</p>
<p>但我们之前说了，作用域仅仅是由文本决定的，函数 bar 位于函数 foo 之内，所以函数 bar 定义的作用域内嵌于函数 foo 的作用域之内。换句话说，函数 foo 的作用域是函数 bar 的作用域的直接外围作用域。所以应该先从 foo 的作用域里面找，如果没有那么再去全局里面找，而作用域和名字空间是对应的，所以最终打印了 2。</p>
<p>另外在调用 foo() 的时候，会执行函数 foo 中的 <font color="blue">def bar():</font> 语句，这个时候解释器会将 a = 2 与函数 bar 捆绑在一起，然后返回，这个捆绑起来的整体就叫做闭包。</p>
<p><strong>所以：闭包 = 内层函数 + 引用的外层作用域。</strong></p>
<p>而这里显示的规则就是 LEGB，其中 E 表示 Enclosing，代表直接外围作用域。</p>
<h2 id="global-表达式"><a class="header" href="#global-表达式">global 表达式</a></h2>
<p>在初学 Python 时，估计很多人都会对下面的问题感到困惑。</p>
<pre><code class="language-Python">x = 1

def foo():
    print(x)

foo()
&quot;&quot;&quot;
1
&quot;&quot;&quot;
</code></pre>
<p>首先这段代码打印 1，这显然是没有问题的，不过下面问题来了。</p>
<pre><code class="language-Python">x = 1

def foo():
    print(x)
    x = 2

foo()
</code></pre>
<p>这段代码在执行 print(x) 的时候是会报错的，会抛出一个 UnboundLocalError: local variable 'x' referenced before assignment，意思是局部变量 x 在赋值之前就被使用了。</p>
<p>那么问题来了，在 print(x) 的下面加一个 x = 2，整体效果不应该是先打印全局变量 x，然后再创建一个局部变量 x 吗？为啥就报错了呢，相信肯定有人为此困惑。如果想弄明白这个错误的原因，需要深刻理解两点：</p>
<ul>
<li>函数中的变量是静态存储、静态访问的，内部有哪些变量在编译的时候就已经确定；</li>
<li>局部变量在整个作用域内都是可见的；</li>
</ul>
<p>在编译的时候，因为 <font color="blue">x = 2</font> 这条语句，所以知道函数中存在一个局部变量 x，那么查找的时候就会在当前局部作用域中查找，但还没来得及赋值，就 print(x) 了。换句话说，在打印 x 的时候，它还没有和某个具体的值进行绑定，所以报错：局部变量 x 在赋值之前就被使用了。</p>
<p>但如果没有 <font color="blue">x = 2</font> 这条语句则不会报错，因为知道局部作用域中不存在 x 这个变量，所以会找全局变量 x，从而打印 1。</p>
<p>更有趣的东西隐藏在字节码当中，我们可以通过反汇编来查看一下：</p>
<pre><code class="language-Python">import dis

x = 1

def foo():
    print(x)

dis.dis(foo)
&quot;&quot;&quot;
  6           0 LOAD_GLOBAL              0 (print)
              2 LOAD_GLOBAL              1 (x)
              4 CALL_FUNCTION            1
              6 POP_TOP
              8 LOAD_CONST               0 (None)
             10 RETURN_VALUE
&quot;&quot;&quot;

def bar():
    print(x)
    x = 2
    
dis.dis(bar)    
&quot;&quot;&quot;
 19           0 LOAD_GLOBAL              0 (print)
              2 LOAD_FAST                0 (x)
              4 CALL_FUNCTION            1
              6 POP_TOP

 20           8 LOAD_CONST               1 (2)
             10 STORE_FAST               0 (x)
             12 LOAD_CONST               0 (None)
             14 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>第二列的序号代表字节码指令的偏移量，我们看偏移量为 2 的指令，函数 foo 对应的指令是 LOAD_GLOBAL，意思是在 global 空间中查找 x。而函数 bar 的指令是 LOAD_FAST，表示在数组中静态查找 x，但遗憾的是，此时 x 还没有和某个值进行绑定。</p>
<p>因此结果说明 Python 采用了静态作用域策略，在编译的时候就已经知道变量藏身于何处。而且这个例子也表明，一旦函数内有了对某个变量的赋值操作，它会在整个作用域内可见，因为编译时就已经确定。换句话说，会遮蔽外层作用域中相同的名字。</p>
<p>我们看一下函数 foo 和函数 bar 的符号表。</p>
<pre><code class="language-python">x = 1

def foo():
    print(x)


def bar():
    print(x)
    x = 2

print(foo.__code__.co_varnames)  # ()
print(bar.__code__.co_varnames)  # ('x',)
</code></pre>
<p>在编译的时候，就知道函数 bar 里面存在局部变量 x。</p>
<p>如果想修复这个错误，可以用之前说的 global 关键字，将变量 x 声明为全局的。</p>
<pre><code class="language-Python">x = 1

def bar():
    global x  # 表示变量 x 是全局变量
    print(x)
    x = 2

bar()  # 1
print(x)  # 2
</code></pre>
<p>但这样的话，会导致外部的全局变量被修改，如果不想出现这种情况，那么可以考虑直接获取全局名字空间。</p>
<pre><code class="language-Python">x = 1

def bar():
    print(globals()[&quot;x&quot;])
    x = 2

bar()  # 1
print(x)  # 1
</code></pre>
<p>这样结果就没问题了，同样的，类似的问题也会出现在嵌套函数中。</p>
<pre><code class="language-Python">def foo():
    x = 1
    def bar():
        print(x)
        x = 2
    return bar

foo()()
</code></pre>
<p>执行内层函数 bar 的时候，print(x) 也会出现 UnboundLocalError，如果想让它不报错，而是打印外层函数中的 x，该怎么做呢？Python 同样为我们准备了一个关键字：nonlocal。</p>
<pre><code class="language-Python">def foo():
    x = 1
    def bar():
        # 使用 nonlocal 的时候，必须是在内层函数里面
        nonlocal x
        print(x)
        x = 2
    return bar

foo()()  # 1
</code></pre>
<p>如果 bar 里面是 global x，那么表示 x 是全局变量，当 foo()() 执行完毕之后，会创建一个全局变量 <font color="blue">x = 2</font>。但这里不是 global，而是 nonlocal，表示 x 是外部作用域中的变量，因此会打印 foo 里面的变量 x。</p>
<p>当然啦，既然声明为 nonlocal，那么 foo 里面的 x 肯定会受到影响。</p>
<pre><code class="language-Python">import inspect

frame = None  

def foo():
    globals()[&quot;frame&quot;] = inspect.currentframe()
    x = 1
    def bar():
        nonlocal x
        # print(x)
        x = 2
    return bar

bar = foo()
# 打印 foo 的局部变量，此时变量 x 的值为 1
print(frame.f_locals)
&quot;&quot;&quot;
{'bar': &lt;function foo.&lt;locals&gt;.bar at 0x7fbe3b8664c0&gt;, 'x': 1}
&quot;&quot;&quot;
# 调用内层函数 bar
bar()
# 此时 foo 的局部变量 x 的值变成了 2
print(frame.f_locals)
&quot;&quot;&quot;
{'bar': &lt;function foo.&lt;locals&gt;.bar at 0x7fbe3b8664c0&gt;, 'x': 2}
&quot;&quot;&quot;
</code></pre>
<p>不过由于 foo 是一个函数，调用内层函数 bar 的时候，外层函数 foo 已经结束了，所以不管怎么修改它里面的变量，都无所谓了。</p>
<p>另外上面的函数只嵌套了两层，即使嵌套很多层也是可以的。</p>
<pre><code class="language-python">import inspect

frame = None

def a():
    def b():
        globals()[&quot;frame&quot;] = inspect.currentframe()
        x = 123
        def c():
            def d():
                def e():
                    def f():
                        nonlocal x
                        print(x)
                        x = 456
                    return f
                return e
            return d
        return c
    return b

b = a()
c = b()
d = c()
e = d()
f = e()
print(frame.f_locals)
&quot;&quot;&quot;
{'c': &lt;function a.&lt;locals&gt;.b.&lt;locals&gt;.c at 0x7fbe3b82d670&gt;, 'x': 123}
&quot;&quot;&quot;
# 调用函数 f 的时候，打印的是函数 b 里面的变量 x
# 当然，最后也会修改它
f()
&quot;&quot;&quot;
123
&quot;&quot;&quot;
# 可以看到 x 变成了 456
print(frame.f_locals)
&quot;&quot;&quot;
{'c': &lt;function a.&lt;locals&gt;.b.&lt;locals&gt;.c at 0x7fbe3b82d670&gt;, 'x': 456}
&quot;&quot;&quot;
</code></pre>
<p>不难发现，在嵌套多层的情况下，会采用就近原则。如果函数 d 里面也定义了变量 x，那么函数 f 里面的 nonlocal x 表示的就是函数 d 里面的局部变量 x。 </p>
<h2 id="属性查找"><a class="header" href="#属性查找">属性查找</a></h2>
<p>当我们访问某个变量时，会按照 LEGB 的规则进行查找，而属性查找也是类似的，本质上都是到名字空间中查找一个名字所引用的对象。但由于属性查找限定了范围，所以要更简单，比如 a.xxx，就是到 a 里面去找属性 xxx，这个规则是不受 LEGB 作用域限制的，就是到 a 里面查找，有就是有，没有就是没有。</p>
<pre><code class="language-Python">import numpy as np

# 在 np 指向的对象（模块）中查找 array 属性
print(np.array([1, 2, 3]))
&quot;&quot;&quot;
[1 2 3]
&quot;&quot;&quot;
# 本质上就是去 np 的属性字典中查找 key = &quot;array&quot; 对应的 value
print(np.__dict__[&quot;array&quot;]([11, 22, 33]))
&quot;&quot;&quot;
[11 22 33]
&quot;&quot;&quot;


class Girl:

    name = &quot;古明地觉&quot;
    age = 16

print(Girl.name, Girl.age)
&quot;&quot;&quot;
古明地觉 16
&quot;&quot;&quot;
print(Girl.__dict__[&quot;name&quot;], Girl.__dict__[&quot;age&quot;])
&quot;&quot;&quot;
古明地觉 16
&quot;&quot;&quot;
</code></pre>
<p>需要补充一点，我们说属性查找会按照 LEGB 规则，但这必须限制在自身所在的模块内，如果是多个模块就不行了。举个例子，假设有两个 py 文件，内容如下：</p>
<pre><code class="language-Python"># girl.py
print(name)

# main.py
name = &quot;古明地觉&quot;
from girl import name
</code></pre>
<p>关于模块的导入我们后续会详细说，总之执行 main.py 的时候报错了，提示<font color="blue">变量 name 没有被定义</font>，但问题是 main.py 里面定义了变量 name，为啥报错呢？</p>
<p>很明显，因为 girl.py 里面没有定义变量 name，所以导入 girl 的时候报错了。因此结论很清晰了，变量查找虽然是 LEGB 规则，但不会越过自身所在的模块。print(name) 在 girl.py 里面，而变量 name 定义在 main.py 里面，在导入时不可能跨过 girl.py 的作用域去访问 main.py 里的 name，因此在执行 <font color="blue">from girl import name</font> 的时候会抛出 NameError。</p>
<p><strong>虽然每个模块内部的作用域规则有点复杂，因为要遵循 LEGB；但模块与模块的作用域之间则划分得很清晰，就是相互独立。</strong></p>
<p>关于模块，我们后续会详细说。总之通过属性操作符 <font color="blue"><strong>.</strong></font> 的方式，本质上都是去指定的名字空间中查找对应的属性。</p>
<h2 id="属性空间"><a class="header" href="#属性空间">属性空间</a></h2>
<p>自定义的类里面如果没有 __slots__，那么这个类的实例对象会有一个属性字典，和名字空间的概念是等价的。</p>
<pre><code class="language-Python">class Girl:
    def __init__(self):
        self.name = &quot;古明地觉&quot;
        self.age = 16

g = Girl()
print(g.__dict__)  # {'name': '古明地觉', 'age': 16}

# 对于查找属性而言, 也是去属性字典中查找
print(g.name, g.__dict__[&quot;name&quot;])  # 古明地觉 古明地觉

# 同理设置属性, 也是更改对应的属性字典
g.__dict__[&quot;gender&quot;] = &quot;female&quot;
print(g.gender)  # female
</code></pre>
<p>当然模块也有属性字典，本质上和类的实例对象是一致的，因为模块本身就是一个实例对象。</p>
<pre><code class="language-Python">print(__builtins__.str)  # &lt;class 'str'&gt;
print(__builtins__.__dict__[&quot;str&quot;])  # &lt;class 'str'&gt;
</code></pre>
<p>另外这个 __builtins__ 位于 global 名字空间里面，然后获取 global 名字空间的 globals 又是一个内置函数，于是一个神奇的事情就出现了。</p>
<pre><code class="language-Python">print(globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;].
      globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;].
      globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;]
      )  # &lt;module 'builtins' (built-in)&gt;

print(globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;].
      globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;].
      globals()[&quot;__builtins__&quot;].globals()[&quot;__builtins__&quot;].list(&quot;abc&quot;)
      )  # ['a', 'b', 'c']
</code></pre>
<p>global 名字空间和 builtin 名字空间，都保存了指向彼此的指针，所以不管套娃多少次，都是可以的。</p>
<h2 id="小结-43"><a class="header" href="#小结-43">小结</a></h2>
<p>整个内容很好理解，关键的地方就在于局部变量，它是静态存储的，编译期间就已经确定。而在访问局部变量时，也是基于数组实现的静态查找，而不是使用字典。</p>
<p>关于 local 空间，以及如何使用数组实现静态查找，我们后面还会详细说。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-44"><a class="header" href="#楔子-44">楔子</a></h2>
<p>当解释器启动后，首先会进行<font color="blue">运行时环境</font>的初始化，注意这里的运行时环境，它和之前说的<font color="blue">执行环境</font>有很大不同，运行时环境是一个全局的概念，而执行环境是一个栈帧。</p>
<p>关于运行时环境的初始化是一个很复杂的过程，涉及到 Python 进程、线程的创建，类型对象的完善等非常多的内容，我们暂时先不讨论。这里就假设初始化动作已经完成，我们已经站在了虚拟机的门槛外面，只需要轻轻推动第一张骨牌，整个执行过程就像多米诺骨牌一样，一环扣一环地展开。</p>
<p>在介绍字节码的时候我们说过，解释器可以看成是：编译器+虚拟机，编译器负责将源代码编译成 PyCodeObject 对象，而虚拟机则负责执行。所以我们的重点就是虚拟机是怎么执行 PyCodeObject 对象的？整个过程是什么，掌握了这些，你对虚拟机会有一个更深的理解。</p>
<h2 id="虚拟机的运行框架"><a class="header" href="#虚拟机的运行框架">虚拟机的运行框架</a></h2>
<p>在介绍栈帧的时候我们说过，Python 是一门动态语言，一个变量指向什么对象需要在运行时才能确定，这些信息不可能静态存储在 PyCodeObject 对象中。所以虚拟机在运行时会基于 PyCodeObject 对象动态创建出栈帧对象，然后在栈帧里面执行字节码。而创建栈帧，主要使用以下两个函数：</p>
<pre><code class="language-C">// Python/ceval.c

/* 基于 PyCodeObject、全局名字空间、局部名字空间，创建栈帧
 * 参数非常简单，所以它一般适用于模块这种参数不复杂的场景
 * 前面说了，模块也会对应一个栈帧，并且它位于栈帧链的最顶层 
 */
PyObject *
PyEval_EvalCode(PyObject *co, PyObject *globals, PyObject *locals)
{
    return PyEval_EvalCodeEx(co,
                      globals, locals,
                      (PyObject **)NULL, 0,
                      (PyObject **)NULL, 0,
                      (PyObject **)NULL, 0,
                      NULL, NULL);
}

/* 相比 PyEval_EvalCode 多了很多的参数
 * 比如里面有位置参数以及个数，关键字参数以及个数
 * 还有默认参数以及个数，闭包等等，显然它用于函数等复杂场景 
 */
PyObject *
PyEval_EvalCodeEx(PyObject *_co, PyObject *globals, PyObject *locals,
                  PyObject *const *args, int argcount,
                  PyObject *const *kws, int kwcount,
                  PyObject *const *defs, int defcount,
                  PyObject *kwdefs, PyObject *closure)
{
    return _PyEval_EvalCodeWithName(_co, globals, locals,
                                    args, argcount,
                                    kws, kws != NULL ? kws + 1 : NULL,
                                    kwcount, 2,
                                    defs, defcount,
                                    kwdefs, closure,
                                    NULL, NULL);
}
</code></pre>
<p>我们看到 PyEval_EvalCode 也是调用了 PyEval_EvalCodeEx，后者是通用逻辑，只不过为模块创建栈帧时，参数非常简单，所以又封装了  PyEval_EvalCode 函数。</p>
<p>当然啦，上面这两个函数最终都会调用 _PyEval_EvalCodeWithName 函数，创建并初始化栈帧对象，我们来看一下该函数内部的逻辑。</p>
<pre><code class="language-C">// Python/ceval.c

PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,
           PyObject *const *kwnames, PyObject *const *kwargs,
           Py_ssize_t kwcount, int kwstep,
           PyObject *const *defs, Py_ssize_t defcount,
           PyObject *kwdefs, PyObject *closure,
           PyObject *name, PyObject *qualname)
{
    PyCodeObject* co = (PyCodeObject*)_co;
    PyFrameObject *f;
    PyObject *retval = NULL;
    PyObject **fastlocals, **freevars;
    // ...

    // 调用 _PyFrame_New_NoTrack 函数创建栈帧
    f = _PyFrame_New_NoTrack(tstate, co, globals, locals);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f-&gt;f_localsplus;
    freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;

    // ...
    
    // 调用 PyEval_EvalFrameEx 在栈帧中执行字节码
    retval = PyEval_EvalFrameEx(f,0);

fail:
    assert(tstate != NULL);
    if (Py_REFCNT(f) &gt; 1) {
        Py_DECREF(f);
        _PyObject_GC_TRACK(f);
    }
    else {
        ++tstate-&gt;recursion_depth;
        Py_DECREF(f);
        --tstate-&gt;recursion_depth;
    }
    return retval;
}
</code></pre>
<p>这个函数的逻辑比较长，但做的事情很简单。</p>
<ul>
<li>调用 _PyFrame_New_NoTrack 函数创建栈帧，并初始化内部字段。</li>
<li>栈帧创建完毕之后，里面的字段都是初始值，所以还要基于当前的 PyCodeObject 对象、位置参数、关键字参数、参数个数等信息修改栈帧字段，而省略掉的大部分代码就是在负责相关逻辑。以上这两步组合起来，就是我们之前说的基于 PyCodeObject 对象构建栈帧对象。</li>
<li>栈帧字段设置完毕之后，调用 PyEval_EvalFrameEx 函数，在栈帧中执行字节码。</li>
</ul>
<p>当然，PyEval_EvalFrameEx 也不是整个流程的终点，它内部还调用了一个函数。</p>
<pre><code class="language-C">// Python/ceval.c

PyObject *
PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)
{
    // interp 表示进程状态对象，它的 eval_frame 字段被设置为 _PyEval_EvalFrameDefault
    // 这个 _PyEval_EvalFrameDefault 函数便是虚拟机运行的核心，是一个代码量超级多的函数
    PyInterpreterState *interp = _PyInterpreterState_GET_UNSAFE();
    return interp-&gt;eval_frame(f, throwflag);
}
</code></pre>
<p>所以整个流程很清晰了，我们画一张图。</p>
<p><img src="./images/152.png" alt="" /></p>
<p>所以 _PyEval_EvalFrameDefault 函数是虚拟机运行的核心，该函数较为复杂，我们会在下一篇文章中分析它的具体实现。至于本篇文章就先从宏观的角度来描述一下虚拟机执行字节码的流程，并对之前的内容做一个补充，将背后涉及的概念阐述一遍，这样后续看源码的时候也会事半功倍。</p>
<p>首先栈帧中有一个 f_code 字段，它指向 PyCodeObject 对象，该对象的 co_code 字段则保存着字节码指令序列。而虚拟机执行字节码就是从头到尾遍历整个 co_code，对指令逐条执行的过程。</p>
<p>另外也不要觉得字节码指令（简称指令）有多神秘，说白了它就是个 uint8 整数，而一个程序肯定会包含多条指令，它们整体便构成了指令集，或者说指令序列。那么显然，使用 bytes 对象来表示指令序列再合适不过了，如果站在 C 的角度，则就是一个普普通通的字符数组，一条指令就是一个字符、或者说一个整数。</p>
<p>当然指令序列里面包含的不仅仅是指令，还有指令参数，因为每个指令都会带一个参数。因此索引为 0 2 4 6 8 ··· 的整数表示指令，索引为 1 3 5 7 9 ··· 的整数表示指令参数。</p>
<p>我们用 Python 来演示一下：</p>
<pre><code class="language-Python">code_string = &quot;&quot;&quot;
a = 1
b = 2
c = a + b
&quot;&quot;&quot;

code_object = compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;)
# 查看常量池
print(code_object.co_consts)
&quot;&quot;&quot;
(1, 2, None)
&quot;&quot;&quot;
# 查看符号表
print(code_object.co_names)
&quot;&quot;&quot;
('a', 'b', 'c')
&quot;&quot;&quot;
</code></pre>
<p>这些都比较简单，再来看一下反编译的结果，直接 dis.dis(code_object) 即可。</p>
<pre><code class="language-C">/* 常量池：(1, 2, None)
 * 符号表：('a', 'b', 'c')
 */
 
// 第一列表示源代码行号
// 第二列表示指令的偏移量
// 第三列表示指令，在 C 中它们都是宏，对应一个整数
// 第四列表示指令参数
// 第五列是 dis 模块为了方便我们阅读而补充的提示信息


// 指令：LOAD_CONST，指令参数：0
// 表示从常量池中加载索引为 0 的常量，并压入运行时栈（关于运行时栈，一会儿详细说明）
// 索引为 0 的常量显然是 1，而括号里面的提示信息显示的也是 1
2           0 LOAD_CONST               0 (1)
// 指令：STORE_NAME，指令参数：0
// 表示从符号表中加载索引为 0 的符号，显然结果是 &quot;a&quot;
// 然后弹出运行时栈的栈顶元素，显然是上一条指令压入的 1
// 将 &quot;a&quot; 和 1 组成键值对，存储在当前的名字空间中
// 到此 a = 1 这条语句便完成了，或者说完成了变量和值的绑定  
            2 STORE_NAME               0 (a)

// 从常量池中加载索引为 1 的常量（结果是 2），并压入运行时栈  
3           4 LOAD_CONST               1 (2)
// 从符号表中加载索引为 1 的符号（结果是 &quot;b&quot;)
// 然后从栈顶弹出元素 2，将 &quot;b&quot; 和 2 绑定起来  
            6 STORE_NAME               1 (b)

// 加载符号表中索引为 0 的符号对应的值，并压入运行时栈  
4           8 LOAD_NAME                0 (a)
// 加载符号表中索引为 1 的符号对应的值，并压入运行时栈  
           10 LOAD_NAME                1 (b)
// 将运行时栈的两个元素弹出，并执行加法运算
// 运算之后，再将结果 a + b 压入运行时栈    
           12 BINARY_ADD
// 从符号表中加载索引为 2 的符号，结果是 &quot;c&quot;           
// 将运行时栈的栈顶元素弹出，这里是 a + b 的运算结果
// 然后进行绑定，完成 c = a + b 这条赋值语句         
           14 STORE_NAME               2 (c)
// 从常量池中加载索引为 2 的元素并返回，有一个隐式的 return None  
           16 LOAD_CONST               2 (None)
           18 RETURN_VALUE
</code></pre>
<p>这些指令的源码实现后续都会说，但是不难发现，程序的主干逻辑都体现在字节码中，而依赖的信息则由其它字段来维护。所谓执行源代码，其实就是虚拟机执行编译之后的字节码，通过遍历 co_code，对不同的指令执行不同的逻辑。</p>
<p>然后我们基于上面这些输出信息，看看能否将字节码指令集还原出来，当然在还原之前首先要知道这些指令代表的数值是多少。</p>
<p><img src="./images/153.png" alt="" /></p>
<p>下面我们来进行还原。</p>
<pre><code class="language-python">&quot;&quot;&quot;
 0 LOAD_CONST               0 (1)
 2 STORE_NAME               0 (a)

 4 LOAD_CONST               1 (2)
 6 STORE_NAME               1 (b)

 8 LOAD_NAME                0 (a)
10 LOAD_NAME                1 (b)
12 BINARY_ADD
14 STORE_NAME               2 (c)
16 LOAD_CONST               2 (None)
18 RETURN_VALUE
&quot;&quot;&quot;
BINARY_ADD = 23
RETURN_VALUE = 83
STORE_NAME = 90
LOAD_CONST = 100
LOAD_NAME = 101

codes = [
    # a = 1
    LOAD_CONST, 0,
    STORE_NAME, 0,

    # b = 2
    LOAD_CONST, 1,
    STORE_NAME, 1,

    # c = a + b
    LOAD_NAME, 0,  # 加载 a
    LOAD_NAME, 1,  # 加载 b
    BINARY_ADD, 0,  # 计算 a + b
    STORE_NAME, 2,  # 和变量 c 绑定

    # 所有代码块都隐式地包含了一个 return None
    LOAD_NAME, 2,
    RETURN_VALUE, 0
]
print(bytes(codes))
&quot;&quot;&quot;
b'd\x00Z\x00d\x01Z\x01e\x00e\x01\x17\x00Z\x02e\x02S\x00'
&quot;&quot;&quot;
</code></pre>
<p>那么字节码是不是我们还原的这个样子呢？来对比一下。</p>
<pre><code class="language-python">&gt;&gt;&gt; code_object.co_code
b'd\x00Z\x00d\x01Z\x01e\x00e\x01\x17\x00Z\x02d\x02S\x00'
</code></pre>
<p>结果是一样的，到此相信你对 Python 源代码的执行过程应该有更深的了解了，简单来讲，其实就是以下几个步骤。</p>
<ul>
<li>1）源代码被编译成 PyCodeObject 对象，该对象的 co_code 字段指向字节码指令序列，它包含了程序执行的主干逻辑，剩余字段则保存常量池、符号表等其它静态信息。</li>
<li>2）虚拟机在 PyCodeObject 对象的基础上构建栈桢对象。</li>
<li>3）虚拟机在栈桢对象内部执行字节码（帧评估），具体流程就是遍历指令集和，根据不同指令执行不同的处理逻辑，而这一过程便由 _PyEval_EvalFrameDefault 函数负责完成。</li>
</ul>
<h2 id="什么是运行时栈"><a class="header" href="#什么是运行时栈">什么是运行时栈</a></h2>
<p>之前一直提到一个概念，叫运行时栈，那什么是运行时栈呢？别急，我们先来回顾一下栈桢的基本结构。</p>
<p><img src="./images/154.png" alt="" /></p>
<p>大部分字段都很好理解，因为之前通过 Python 代码演示过。但有几个字段是虚拟机用于执行指令的，后续会遇到，所以这里再拿出来解释一下。</p>
<p><font color="darkblue"><strong>f_lasti</strong></font></p>
<p>上一条刚执行完的字节码指令的偏移量，因为每个指令要带一个参数，所以当虚拟机要执行偏移量为 n 的指令时，那么 f_lasti 就是 n - 2。当然，如果字节码还没有开始执行，那么 f_lasti 为 -1。</p>
<p><font color="darkblue"><strong>f_localsplus</strong></font></p>
<p>一个柔性数组，它的内存大小被分为 4 个部分。</p>
<p><img src="./images/155.png" alt="" /></p>
<p>注：f_localsplus 是一个数组，所以它是一段连续的内存，只不过按照用途被分成了 4 个部分。如果用新一团团长丁伟的说法：每个部分之间是鸡犬相闻，但又老死不相往来。</p>
<p>然后再着重强调一下运行时栈，虚拟机在执行字节码指令时高度依赖它，因为一个指令只能带一个参数，那么剩余的参数就必须通过运行时栈给出。比如 <font color="blue">a = 1</font> 会对应两条字节码：LOAD_CONST 和 STORE_NAME。</p>
<p>STORE_NAME 的作用是从符号表中获取符号，或者说变量名，然后和值绑定起来。而要加载符号，那么必须要知道它在符号表中的索引，显然这可以通过指令参数给出，但问题是与之绑定的值怎么获取？毫无疑问，要通过运行时栈。因此 LOAD_CONST 将值读取进来之后，还要压入运行时栈，然后 STORE_NAME 会将值从运行时栈中弹出，从而完成符号（变量）和值的绑定。</p>
<p>关于运行时栈，我们再看个复杂的例子：</p>
<p><img src="./images/156.png" alt="" /></p>
<p>偏移量为 6 的指令表示要构建一个字典，指令参数 2 表示构建的字典的长度为 2，但问题是字典的键值对在什么地方？显然它们已经被提前压入了运行时栈，执行 BUILD_CONST_KEY_MAP 的时候直接弹出即可。</p>
<p>所以这就是运行时栈的作用，如果某个指令需要 n 个参数，那么其中的 n - 1 个必须要提前压入运行时栈，然后在该指令执行的时候依次弹出，因为一个指令只能带一个参数。</p>
<p><font color="darkblue"><strong>f_stacktop</strong></font></p>
<p>一个指针，指向运行时栈的栈顶。由于运行时栈存储的都是 PyObject *，所以 f_stacktop 的类型是 PyObject **。当然在源码中没有直接操作 f_stacktop 字段，而是定义了一个变量 stack_pointer，它初始等于 f_stacktop。后续操作的都是 stack_pointer，当然操作完之后，还要重新赋值给 f_stacktop。</p>
<p>所以 stack_pointer 始终指向运行时栈的栈顶，而元素的入栈和出栈，显然都是通过操作 stack_pointer 完成的。</p>
<ul>
<li>执行 *stack_pointer++ = v，一个元素就入栈了。</li>
<li>执行 v = *--stack_pointer，一个元素就出栈了。</li>
</ul>
<p>而随着元素的入栈和出栈，运行时栈的栈顶、或者说 stack_pointer 也在不断变化，但无论如何，stack_pointer 始终指向运行时栈的栈顶。当然啦，由于栈顶发生变化，后续还要对 f_stacktop 进行更新。</p>
<p><font color="darkblue"><strong>f_valuestack</strong></font></p>
<p>一个指针，指向运行时栈的栈底。</p>
<p>另外我们说 f_localsplus 数组被分成了 4 份，最后一份给了运行时栈，因此虽然我们称之为栈，但它其实就是一个数组，而且还是数组的一部分。</p>
<p>而对于数组而言，内存地址从左往右是增大的。</p>
<p><img src="./images/157.png" alt="" /></p>
<p>这是 f_localsplus 的示意图，灰色区域表示运行时栈之前的部分，这里我们只看运行时栈，目前栈里面有两个元素，stack_pointer 指向栈顶。</p>
<p>这时如果要添加一个元素 3，那么直接 <font color="blue">*stack_pointer++ = 3</font> 即可。</p>
<p><img src="./images/158.png" alt="" /></p>
<p>如果要将栈顶元素弹出，那么执行 <font color="blue">v = *--stack_pointer</font> 即可。</p>
<p><img src="./images/159.png" alt="" /></p>
<p>还是比较清晰的，不过还没结束，我们还要继续探讨运行时栈。</p>
<h2 id="运行时栈的一些宏"><a class="header" href="#运行时栈的一些宏">运行时栈的一些宏</a></h2>
<p>相信你已经知道什么是运行时栈了，说白了它就是参数的容身之所，比如虚拟机在执行 a + b 的时候，通过指令和指令参数可以判断这是一个加法操作，但在执行加法的时候，加号两边的值要怎么获取呢？这时候就需要一个栈来专门保存相应的参数。在执行加法之前，先将 a 和 b 压入栈中，等执行加法的时候，再将 a 和 b 从栈里面弹出来即可，非常简单。</p>
<p>然后再来看看和运行时栈相关的一些宏，并加深对运行时栈的理解。</p>
<pre><code class="language-C">// Python/ceval.c

#define STACK_LEVEL()     ((int)(stack_pointer - f-&gt;f_valuestack))
#define EMPTY()           (STACK_LEVEL() == 0)
#define TOP()             (stack_pointer[-1])
#define SECOND()          (stack_pointer[-2])
#define THIRD()           (stack_pointer[-3])
#define FOURTH()          (stack_pointer[-4])
#define PEEK(n)           (stack_pointer[-(n)])
#define SET_TOP(v)        (stack_pointer[-1] = (v))
#define SET_SECOND(v)     (stack_pointer[-2] = (v))
#define SET_THIRD(v)      (stack_pointer[-3] = (v))
#define SET_FOURTH(v)     (stack_pointer[-4] = (v))
#define SET_VALUE(n, v)   (stack_pointer[-(n)] = (v))
#define BASIC_STACKADJ(n) (stack_pointer += n)
#define BASIC_PUSH(v)     (*stack_pointer++ = (v))
#define BASIC_POP()       (*--stack_pointer)

#define PUSH(v)                BASIC_PUSH(v)
#define POP()                  BASIC_POP()
#define STACK_GROW(n)          BASIC_STACKADJ(n)
#define STACK_SHRINK(n)        BASIC_STACKADJ(-n)
#define EXT_POP(STACK_POINTER) (*--(STACK_POINTER))
</code></pre>
<p>宏还是比较多的，我们来逐一介绍。假设目前运行时栈内部有三个元素，从栈底到栈顶分别是整数 1、2、3，那么运行时栈的结构就是下面这样。</p>
<p><img src="./images/160.png" alt="" /></p>
<p>f_localsplus 数组被分成 4 个区域，运行时栈占据最后一个，因此图中的灰色区域便是运行时栈之前的内存。由于我们是研究运行时栈，所以这部分区域后续就不再画了。</p>
<p>然后看一下这些和运行时栈相关的宏都是干嘛的。</p>
<p><font color="darkblue"><strong>STACK_LEVEL()</strong></font></p>
<p>返回运行时栈的元素个数，显然直接让栈顶指针和栈底指针相减就完事了。</p>
<pre><code class="language-C">#define STACK_LEVEL()     ((int)(stack_pointer - f-&gt;f_valuestack))
</code></pre>
<p>所以 STACK_LEVEL() 是会动态变化的，因为 stack_pointer 会动态变化。</p>
<p>记得之前在介绍 PyCodeObject 时，我们说它内部的 co_stacksize 字段表示执行代码块所需要的<font color="blue">栈空间</font>，而这个栈空间就是运行时栈的长度。当然也可以理解为要想执行这段代码块，后续创建栈桢时，应该给 f_localsplus 数组中表示运行时栈的区域分配能存储多少个元素的内存。</p>
<p>比如 co_stacksize 是 1，那么表示应该给运行时栈分配能存储 1 个元素的内存，即运行时栈的长度为 1。</p>
<blockquote>
<p>STACK_LEVEL() 表示当前运行时栈已存储的元素数量，而 co_stacksize 表示运行时栈的长度，即最多能存储多少个元素。</p>
</blockquote>
<p>我们通过反编译的方式，实际演示一下。</p>
<pre><code class="language-Python">import dis

def some_func():
    a = 1
    b = 2
    c = 3

# 这里只保留字节码指令
dis.dis(some_func)
&quot;&quot;&quot;
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0 
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1 
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0 
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1
RETURN_VALUE   # 将元素从栈顶弹出，栈里的元素个数为 0
&quot;&quot;&quot;

# 也就是说，运行时栈只要能容纳一个元素，即可执行这段代码
print(some_func.__code__.co_stacksize)  # 1
</code></pre>
<p>我们再来看个例子。</p>
<pre><code class="language-python">import dis

def some_func():
    a = 1
    b = 2
    c = 3
    lst = [a, b, c]

dis.dis(some_func)
&quot;&quot;&quot;
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1 
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0  
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1   
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0   
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1   
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0    

LOAD_FAST      # 将元素压入运行时栈，栈里的元素个数为 1
LOAD_FAST      # 将元素压入运行时栈，栈里的元素个数为 2   
LOAD_FAST      # 将元素压入运行时栈，栈里的元素个数为 3
BUILD_LIST     # 将栈里的三个元素弹出，构建列表并入栈（此时元素个数为 1）
STORE_FAST     # 将元素从栈顶弹出，栈里的元素个数为 0   
LOAD_CONST     # 将元素压入运行时栈，栈里的元素个数为 1
RETURN_VALUE   # 将元素从栈顶弹出，栈里的元素个数为 0
&quot;&quot;&quot;

# 不难看出，要想执行这段代码，运行时栈要能容纳 3 个元素
print(some_func.__code__.co_stacksize)  # 3
</code></pre>
<p>相信你现在应该理解 co_stacksize 的作用了，它表示运行时栈最多能容纳多少个元素，也就是运行时栈的长度。以上面代码为例，由于最多会压入 3 个元素，所以运行时栈的长度就是 3，即最多能容纳 3 个元素。并且这个长度在编译之后就已经确定了，因为可以通过遍历指令集静态计算出来。</p>
<p>我们画一张图描述一下上面的代码在执行时，运行时栈的变化过程。</p>
<p><img src="./images/161.png" alt="" /></p>
<p>整个过程应该很清晰，当然上面只是运行时栈的变化，f_localsplus 中存储局部变量的内存区域也在变化。另外如果代码块位于全局作用域，那么变化的就是全局名字空间，相关细节后续详细展开。</p>
<p><font color="darkblue"><strong>EMPTY()</strong></font></p>
<pre><code class="language-c">#define EMPTY()           (STACK_LEVEL() == 0)
</code></pre>
<p>判断运行时栈是否为空，显然只需判断运行时栈的元素个数是否为 0 即可。</p>
<p><font color="darkblue"><strong>TOP()</strong></font></p>
<pre><code class="language-C">#define TOP()             (stack_pointer[-1])
</code></pre>
<p>查看当前运行时栈的栈顶元素。</p>
<p><font color="darkblue"><strong>SECOND()</strong></font></p>
<pre><code class="language-C">#define SECOND()          (stack_pointer[-2])
</code></pre>
<p>查看从栈顶元素开始的第二个元素。</p>
<p><font color="darkblue"><strong>THIRD()</strong></font></p>
<pre><code class="language-C">#define THIRD()           (stack_pointer[-3])
</code></pre>
<p>查看从栈顶元素开始的第三个元素。</p>
<p><font color="darkblue"><strong>FOURTH()</strong></font></p>
<pre><code class="language-C">#define FOURTH()          (stack_pointer[-4])
</code></pre>
<p>查看从栈顶元素开始的第四个元素。</p>
<p><font color="darkblue"><strong>PEEK(n)</strong></font></p>
<pre><code class="language-C">#define PEEK(n)           (stack_pointer[-(n)])
</code></pre>
<p>查看从栈顶元素开始的第 n 个元素。</p>
<p><font color="darkblue"><strong>SET_TOP(v)</strong></font></p>
<pre><code class="language-C">#define SET_TOP(v)        (stack_pointer[-1] = (v))
</code></pre>
<p>将当前运行时栈的栈顶元素设置成 v。</p>
<p><font color="darkblue"><strong>SET_SECOND(v)</strong></font></p>
<pre><code class="language-c">#define SET_SECOND(v)     (stack_pointer[-2] = (v))
</code></pre>
<p>将从栈顶元素开始的第二个元素设置成 v。</p>
<p><font color="darkblue"><strong>SET_THIRD(v)</strong></font></p>
<pre><code class="language-c">#define SET_THIRD(v)      (stack_pointer[-3] = (v))
</code></pre>
<p>将从栈顶元素开始的第三个元素设置成 v。</p>
<p><font color="darkblue"><strong>SET_FOURTH(v)</strong></font></p>
<pre><code class="language-C">#define SET_FOURTH(v)     (stack_pointer[-4] = (v))
</code></pre>
<p>将从栈顶元素开始的第四个元素设置成 v。</p>
<p><font color="darkblue"><strong>SET_VALUE(n, v)</strong></font></p>
<pre><code class="language-C">#define SET_VALUE(n, v)   (stack_pointer[-(n)] = (v))
</code></pre>
<p>将从栈顶元素开始的第 n 个元素设置成 v。</p>
<p><font color="darkblue"><strong>PUSH(v)</strong></font></p>
<pre><code class="language-C">#define PUSH(v)           BASIC_PUSH(v)
#define BASIC_PUSH(v)     (*stack_pointer++ = (v))
</code></pre>
<p>往运行时栈中压入一个元素，并且压入之后，栈中已存储的元素个数一定不超过 co_stacksize。假设当前栈里有一个元素 1，然后添加一个元素 2。</p>
<p><img src="./images/162.png" alt="" /></p>
<p>Python 的变量都是一个指针，所以 stack_pointer 是一个二级指针，它永远指向栈顶位置，只不过栈顶位置会变。另外要注意：运行时栈的内存一开始就申请好了，初始状态下，里面的元素全部为 NULL。而往栈里面压入一个元素，其实就是修改 stack_pointer 指向的内存单元，然后执行 stack_pointer++。</p>
<p><font color="darkblue"><strong>POP()</strong></font></p>
<pre><code class="language-C">#define POP()             BASIC_POP()
#define BASIC_POP()       (*--stack_pointer)
</code></pre>
<p>弹出栈顶元素，注意它和 TOP 的区别，TOP 是返回栈顶元素，但不弹出。</p>
<p><img src="./images/163.png" alt="" /></p>
<p>stack_pointer 指向栈顶位置，所以它向栈底移动一个位置，就相当于元素被弹出了。</p>
<p>关于<font color="blue">弹出元素</font>需要做一个说明，所谓弹出元素本质上就是将 stack_pointer 向栈底移动一个位置。我们看一下上图，一开始栈里面有两个元素，分别是整数 1 和整数 2，当然准确来说应该是指向它们的指针，但为了描述方便，我们就用对象本身代替了。</p>
<p>然后执行 POP()，将整数 2 弹出，但我们发现 POP() 之后，整数 2 还在栈里面。关于这一点很好理解，因为 stack_pointer 始终指向栈顶位置，而它向栈底移动了一个位置，那么整数 2 就已经不是栈顶元素了。当下一个元素入栈时，会把整数 2 替换掉。因此虽然整数 2 还在运行时栈里面，但和不在没有任何区别，此时我们依旧认为整数 2 被弹出了。</p>
<p>不过在后续的文章中，在画运行时栈的时候，我们也会这么画。</p>
<p><img src="./images/164.png" alt="" /></p>
<p>为了阅读清晰，stack_pointer 之后的元素就不写了。另外还要注意一点，运行时栈的内存一开始就已经申请好了，是固定的，弹出元素只是改变栈顶指针 stack_pointer 的指向，而内存区域的大小是不变的。</p>
<p>当然这些内容都比较简单，但为了避免出现歧义，这里单独解释一下。</p>
<p><font color="darkblue"><strong>STACK_GROW(n)</strong></font></p>
<pre><code class="language-C">#define STACK_GROW(n)          BASIC_STACKADJ(n)
#define BASIC_STACKADJ(n)      (stack_pointer += n)
</code></pre>
<p>改变运行时栈的栈顶，注：运行时栈的大小是固定的，但栈顶是由 stack_pointer 决定的。</p>
<p><img src="./images/165.png" alt="" /></p>
<p>那么问题来了，假设要往运行时栈压入两个元素，分别是 2、3，该怎么做呢？首先肯定可以通过 PUSH 实现。</p>
<pre><code class="language-C">PUSH(2);
PUSH(3);
</code></pre>
<p>但如果不让你用 PUSH，该怎么做呢？</p>
<pre><code class="language-c">STACK_GROW(2);
// 设置元素
SET_VALUE(1, 3);  // stack_pointer[-1] = 3
SET_VALUE(2, 2);  // stack_pointer[-2] = 2
</code></pre>
<p>两种做法都是可以的。</p>
<p><font color="darkblue"><strong>STACK_SHRINK(n)</strong></font></p>
<pre><code class="language-c">#define STACK_SHRINK(n)        BASIC_STACKADJ(-n)
#define BASIC_STACKADJ(n)      (stack_pointer += n)
</code></pre>
<p>它的作用和 STACK_GROWN 正好相反。</p>
<p><img src="./images/166.png" alt="" /></p>
<p>注意：STACK_SHRINK(3) 之后，stack_pointer 和 f_valuestack 都指向了运行时栈的栈底，同时也是栈顶。还是之前说的，栈空间是固定的，但栈顶会随着元素的入栈和出栈而动态变化。</p>
<p>另外，对于当前示例来说，如果你不关注栈里的元素的话，那么执行 STACK_SHRINK(3) 和执行三次 POP() 是等价的。当然不管是哪种情况，最终栈里的元素都还是 1、2、3，因为弹出元素只是改变栈顶指针 stack_pointer 的指向，而不会修改栈里的元素。当然啦，既然栈顶是由 stack_pointer 决定的，而它目前指向了栈底位置，所以我们可以认为此时栈是空的。</p>
<p><img src="./images/167.png" alt="" /></p>
<p>这么画似乎更清晰一些，但我们要知道这背后的整个过程。另外还要再次强调，运行时栈只是数组 f_localsplus 的一部分，并且是最后一部分，所以它的内存空间事先就申请好了，里面的每个元素都是 NULL。所谓添加元素，就是修改 stack_pointer 指针指向的内存，然后 stack_pointer++。所谓弹出元素，就是 stack_pointer--，然后返回 stack_pointer 指向的内存。</p>
<p>以上就是运行时栈的一些宏，后续阅读源码的时候，会经常遇到。</p>
<h2 id="小结-44"><a class="header" href="#小结-44">小结</a></h2>
<p>本篇文章我们就从宏观的角度介绍了虚拟机执行字节码的流程，说白了虚拟机就是把自己当成一个 CPU，在栈桢中执行指令。通过遍历字节码指令集，对不同的指令执行不同的处理逻辑。</p>
<p>然后是运行时栈，因为一个指令只能带一个参数，那么剩余的参数就需要通过运行时栈给出。比如 LOAD_CONST 指令，它在加载完常量之后，会将常量压入运行时栈，然后 STORE_NAME 或 STORE_FAST 指令再将常量从运行时栈的顶部弹出，并和某个符号（变量）绑定起来。</p>
<blockquote>
<p>关于这些指令，我们后面会详细说。</p>
</blockquote>
<p>最后我们介绍了运行时栈的一些宏，因为执行指令的时候会反复操作运行时栈，所以底层封装了很多的宏。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-45"><a class="header" href="#楔子-45">楔子</a></h2>
<p>上一篇文章我们介绍了虚拟机是怎么执行字节码指令的，并且还介绍了运行时栈，以及操作运行时栈的一些宏。相信你对字节码执行的整个流程应该有了清晰的认识，那么接下来我们就深入到源码中，进一步考察执行过程。</p>
<h2 id="源码解析字节码指令的执行过程"><a class="header" href="#源码解析字节码指令的执行过程">源码解析字节码指令的执行过程</a></h2>
<p>之前说了，虚拟机就是把自己当成一个 CPU，在栈帧中执行字节码，面对不同的字节码指令，执行不同的处理逻辑。</p>
<p>具体实现由 Python/ceval.c 中的 _PyEval_EvalFrameDefault 函数负责，该函数超级长，并且里面还包含了大量的宏，这些宏完全可以定义在其它的文件中。像我们之前介绍的操作运行时栈的宏，也定义在 _PyEval_EvalFrameDefault 函数里面了。所以为了方便大家理解，我决定先介绍里面出现的宏，等宏说完了之后再看具体的逻辑。</p>
<pre><code class="language-C">#ifdef HAVE_COMPUTED_GOTOS
    #ifndef USE_COMPUTED_GOTOS
    #define USE_COMPUTED_GOTOS 1
    #endif
#else
    #if defined(USE_COMPUTED_GOTOS) &amp;&amp; USE_COMPUTED_GOTOS
    #error &quot;Computed gotos are not supported on this compiler.&quot;
    #endif
    #undef USE_COMPUTED_GOTOS
    #define USE_COMPUTED_GOTOS 0
#endif

// 如果使用 &quot;计算跳转&quot;，导入静态跳转表
#if USE_COMPUTED_GOTOS
/* Import the static jump table */
#include &quot;opcode_targets.h&quot;
</code></pre>
<p>里面出现了一个关键词：计算跳转，这是什么意思呢？</p>
<p>首先 _PyEval_EvalFrameDefault（后续简称为帧评估函数）的代码量虽然很大，但它的核心不难理解，就是循环遍历字节码指令集，处理每一条指令。而当一条指令执行完毕时，虚拟机会有以下三种动作之一：</p>
<ul>
<li>停止循环、退出帧评估函数，当执行的指令为 RETURN_VALUE、YIELD_VALUE 等。</li>
<li>执行指令的过程中出错了，比如执行 GET_ITER 指令，但对象不具备可迭代的性质。那么要进行异常处理（或者直接抛出异常），然后退出帧评估函数。</li>
<li>执行下一条指令。</li>
</ul>
<p>前面两种动作没啥好说的，关键是第三种，如何执行下一条指令。首先虚拟机内部有一个巨型的 switch 语句，伪代码如下：</p>
<pre><code class="language-c">int opcode;
int oparg;

for (;;) {
    // 循环遍历指令集，获取指令和指令参数
    opcode = ...;  // 指令
    oparg = ...;  // 指令参数
    // 执行对应的处理逻辑
    switch (opcode) {
        case LOAD_CONST:
            处理逻辑;
        case LOAD_FAST:
            处理逻辑;
        case LOAD_FAST:
            处理逻辑;
        case BUILD_LIST: 
            处理逻辑;
        case DICT_UPDATE: 
            处理逻辑;
        // ...
    }
}
</code></pre>
<p>一个 case 分支，对应一个字节码指令的实现，由于指令非常多，所以这个 switch 语句也非常庞大。然后遍历出的指令，会进入这个 switch 语句进行匹配，执行相应的处理逻辑。所以循环遍历 co_code 得到字节码指令，然后交给内部的 switch 语句、执行匹配到的 case 分支，如此周而复始，最终完成了对整个 Python 程序的执行。</p>
<p>其实到这里，你应该已经了解了帧评估函数的整体结构。说白了就是将自己当成一个 CPU，在栈帧中执行一条条指令，而执行过程中所依赖的常量、变量等，则由栈帧的其它字段来维护。因此在虚拟机的执行流程进入了那个巨大的 for 循环，并取出第一条字节码指令交给里面的 switch 语句之后，第一张多米诺骨牌就已经被推倒，命运不可阻挡的降临了。一条接一条的指令如同潮水般涌来，浩浩荡荡，横无际涯。</p>
<p>虽然在概念上很好理解，但很多细节被忽略掉了，本篇文章就将它们深挖出来。还是之前的问题，当一个指令执行完毕时，怎么执行下一条指令。</p>
<p>估计有人对这个问题感到奇怪，在 case 分支的内部加一行 continue 进行下一轮循环不就行了吗？没错，这种做法是行得通的，但存在性能问题。因为 continue 会跳转到 for 循环所在位置，所以遍历出下一条指令之后，会再次进入 switch 语句进行匹配。尽管逻辑上是正确的，但 switch 里面有数百个 case 分支，如果每来一个指令，都要顺序匹配一遍的话，那么效率必然不高。</p>
<p>而事实上整个字节码指令集是已知的，所以不管执行哪个指令，我们都可以提前得知它的下一个指令，只需将指针向后偏移两个字节即可。</p>
<p><img src="./images/168.png" alt="" /></p>
<p>那么问题来了，既然知道下一条要执行的指令是什么，那么在当前指令执行完毕时，可不可以直接跳转到下一条指令对应的 case 分支中呢？</p>
<p>答案是可以的，这个过程就叫做计算跳转，通过<font color="blue">标签作为值</font>即可实现。关于什么是<font color="blue">标签作为值</font>，我们用一段 C 代码解释一下。</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;

void label_as_value(int jump) {
    int num = 4;
    void *label;
    switch (num) {
        case 1:
            printf(&quot;%d\n&quot;, 1);
            break;
        // 在 case 2 分支里面定义了一个标签叫 two
        case 2: two: {
            printf(&quot;%d\n&quot;, 2);
            break;
        }
        // 在 case 3 分支里面定义了一个标签叫 three
        case 3: three: {
            printf(&quot;%d\n&quot;, 3);
            break;
        }
        case 4:
            printf(&quot;%d\n&quot;, 4);
            // 如果参数 jump 等于 2，保存 two 标签的地址
            // 如果参数 jump 等于 3，保存 three 标签的地址
            if (jump == 2) label = &amp;&amp;two;
            else if (jump == 3) label = &amp;&amp;three;
            // 跳转到指定标签
            goto *label;
        default:
            break;
    }
}

int main() {
    label_as_value(2);
    // 4
    // 2
    label_as_value(3);
    // 4
    // 3
}
</code></pre>
<p>由于变量 num 等于 4，所以会进入 case 4 分支，在里面有一个 <font color="blue">goto *label</font>。如果你对 C 不是特别熟悉的话，估计会有些奇怪，觉得不应该是  <font color="blue">goto label</font> 吗？如果是 goto label，那么需要显式地定义一个名为 label 的标签，但这里并没有。我们的目的是跳转到 two 标签或 three 标签，具体跳转到哪一个，则由参数控制。因此可以使用 &amp;&amp; 运算符，这是 GCC 的一个扩展特性，叫做<font color="blue">标签作为值</font>，它允许我们获取标签的地址作为一个值。</p>
<p>所以在开头声明了一个 <font color="red">void *label</font>，然后让 label 保存标签地址，再通过 <font color="blue">goto *label</font> 跳转到指定标签。由于 *label 代表哪个标签是在运行时经过计算才能知晓，因此称为<font color="blue">计算跳转（在运行时动态决定跳转目标）</font>。</p>
<blockquote>
<p>注意：<code>goto *&amp;&amp;标签名</code> 属于高级的、非标准的 C 语言用法。</p>
</blockquote>
<p>那么毫无疑问，解释器也一定为处理指令的 case 分支定义了相应的标签，并拿到了这些标签的地址。没错，这些标签地址位于 Python/opcode_targets.h 中，这个 opcode_targets.h 就是上面的帧评估函数导入的头文件。</p>
<p><img src="./images/169.png" alt="" /></p>
<p>每个指令的处理逻辑都会对应一个标签，这些标签的地址全部保存在了数组中，执行帧评估函数时导入进来即可。这里可能有人会问，导入数组时，它里面的标签都还没有定义吧。确实如此，不过没关系，对于 C 来说，标签只要定义了，那么它在函数的任何一个位置都可以使用。</p>
<p>假设要执行的下一条指令为 opcode，那么就会跳转到 <font color="blue">*opcode_targets[opcode]</font>，因此我们有理由相信，指令和 opcode_targets 数组的索引之间存在某种关联。而这种关联也很好想，opcode_targets[opcode] 指向的标签，其内部的逻辑就是用来处理 opcode 指令的，我们来验证一下。</p>
<pre><code class="language-C">#define LOAD_CONST              100
#define LOAD_NAME               101
</code></pre>
<p>比如 LOAD_CONST 的值为 100，那么 opcode_targets[100] 肯定会指向 TARGET_LOAD_CONST 标签；LOAD_NAME 的值为 101，那么 opcode_targets[101] 肯定会指向 TARGET_LOAD_NAME 标签。</p>
<p><img src="./images/170.png" alt="" /></p>
<p>结果没有问题，其它指令也是一样的，通过计算跳转，可以直接 goto 到指定的标签。</p>
<p>好，我们总结一下，首先帧评估函数内部有一个巨型的 switch，每一个指令的处理逻辑都对应一个 case 分支，由于指令有一百多个，所以 case 分支也有一百多个。而当指令进入 switch 后，显然会顺序匹配这一百多个 case 分支，找到符合条件的那一个。</p>
<p>整个过程的逻辑是没问题的，但效率上还可以更进一步优化，因为整个字节码指令集是已知的，既然都提前知道了下一条待处理的指令是什么，那完全可以直接跳转到对应的 case 分支中。所以每个 case 分支都会对应一个标签，我们看一下源码。</p>
<p><img src="./images/171.png" alt="" /></p>
<p>这个 TARGET 是一个宏，也定义在帧评估函数中。</p>
<pre><code class="language-C">#define TARGET(op) \
    op: \
    TARGET_##op

// 所以 case TARGET(LOAD_CONST): 展开之后就会变成
// case LOAD_CONST: TARGET_LOAD_CONST:
</code></pre>
<p>所以在指令的名称前加一个 TARGET_ 就是对应的标签，比如下一条要执行的指令是 YIELD_VALUE，它等于 86，那么 <code>opcode_targets[86]</code> 就等于 &amp;&amp;TARGET_YIELD_VALUE，指向的标签内部便是 YIELD_VALUE 的处理逻辑，至于其它指令也是同理。</p>
<p>因此读取完下一条指令之后，就不用跳转到开头重新走一遍 switch 了。而是将指令作为索引，从 opcode_targets 拿到标签地址直接跳转即可，并且跳转后的标签内部的逻辑就是用来处理该指令的。</p>
<p><strong>所以底层为每个指令的处理逻辑都定义了一个标签，而标签的地址在数组中的索引，和要处理的指令本身是相等的。</strong></p>
<p>不过要想实现计算跳转，需要 GCC 支持标签作为值这一特性，即 <font color="blue">goto *标签地址</font>，至于标签地址是哪一个标签的地址，则在运行时动态计算得出。比如 opcode_targets[opcode] 指向哪个标签无从得知，这取决于 opcode 的值。</p>
<blockquote>
<p><code>goto 标签</code>：静态跳转，标签需要显式地定义好，跳转位置在编译期间便已经固定。</p>
<p><code>goto *标签地址</code>：动态跳转（计算跳转），跳转位置不固定，可以是已有标签中的任意一个。至于具体是哪一个，需要在运行时经过计算才能确定。</p>
</blockquote>
<p>以上就是计算跳转，我们继续往下说。</p>
<pre><code class="language-C">// 如果使用了计算跳转
#define FAST_DISPATCH() \
    { \
        if (!_Py_TracingPossible(ceval) &amp;&amp; !PyDTrace_LINE_ENABLED()) { \
            f-&gt;f_lasti = INSTR_OFFSET();   /* 将当前指令的偏移量赋值给 f_lasti */ \
            NEXTOPARG();                   /* 获取下一条指令 */ \
            goto *opcode_targets[opcode];  /* 跳转到对应的标签中 */ \
        } \
        goto fast_next_opcode; \
    }

#define DISPATCH() \
    { \
        if (!_Py_atomic_load_relaxed(eval_breaker)) { \
            FAST_DISPATCH(); \
        } \
        continue; \
    }

#define TARGET(op) \
    op: \
    TARGET_##op

// 如果不使用计算跳转
#define TARGET(op) op
#define FAST_DISPATCH() goto fast_next_opcode
#define DISPATCH() continue
</code></pre>
<p>每条指令在执行的最后，都会调用 DISPATCH() 或 FAST_DISPATCH()，我们看一下源码。</p>
<p><img src="./images/172.png" alt="" /></p>
<p>如果不使用计算跳转，那么 DISPATCH() 就等价于 continue，直接进行下一轮 for 循环，然后进入 switch。而 FAST_DISPATCH() 会跳转到 fast_next_opcode 标签，该标签定义在 for 循环的里面，switch 的外面，所以它虽然不用从 for 循环的位置开始执行，但依然要走一遍完整的 switch。另外由于不使用计算跳转，那么 case 分支里的标签也就没意义了，所以 <font color="blue">case TARGET(op)</font> 就等价于 <font color="blue">case op</font>。</p>
<p>如果使用计算跳转，那么就是之前说的那样，在指令执行完之后（并且没有中断请求）会调用 NEXTOPARG() 获取下一条指令，然后通过 <font color="blue">goto *opcode_targets[opcode]</font> 实现计算跳转，直接跳到下一条指令对应的 case 分支中，从而省去了匹配的时间。</p>
<p>好，我们继续往下看。</p>
<pre><code class="language-C">// 获取元组 v 中索引为 i 的元素
#define GETITEM(v, i) PyTuple_GetItem((v), (i))

/* 在遍历字节码指令序列时，会用到以下两个变量
 * first_instr：永远指向字节码指令序列的第一条指令
 * next_instr：永远指向下一条待执行（或正在执行）的字节码指令
 * 另外由于每条字节码指令都会带有一个参数
 * 所以 first_instr 和 next_instr 的类型都是 _Py_CODEUNIT *，即 uint16_t *
 * 其中前 8 位表示指令，后 8 位表示指令参数
 */

// 在调用 NEXTOPARG() 之前，next_instr 指向正在执行的字节码指令
// 如果调用了 NEXTOPARG()，那么 next_instr 就会指向下一条待执行的字节码指令
// 该宏计算的显然就是它和第一条指令（或者说字节码指令序列的起始位置）之间的偏移量
#define INSTR_OFFSET()  \
    (sizeof(_Py_CODEUNIT) * (int)(next_instr - first_instr))

// 获取 next_instr 指向的 uint16 的前 8 位和后 8 位，也就是拿到指令和指令参数
// 然后执行 next_instr++
#define NEXTOPARG()  do { \
        _Py_CODEUNIT word = *next_instr; \
        opcode = _Py_OPCODE(word); \
        oparg = _Py_OPARG(word); \
        next_instr++; \
    } while (0)
</code></pre>
<p>通过 INSTR_OFFSET 和 NEXTOPARG，我们介绍了两个指针变量：first_instr 和 next_instr，虚拟机就是通过它们来完成遍历的。</p>
<pre><code class="language-C">#define JUMPTO(x)       (next_instr = first_instr + (x) / sizeof(_Py_CODEUNIT))
#define JUMPBY(x)       (next_instr += (x) / sizeof(_Py_CODEUNIT))
</code></pre>
<p>这两个指令等到介绍 if 控制流的时候再说，不过相信你也能猜到它是做什么的，if 控制流的某个分支如果不满足条件，就会跳到下一个分支。而这个跳转过程是怎么实现的呢？显然要借助于这里的 JUMPTO 和 JUMPBY。</p>
<pre><code class="language-C">// 指令预测
#if defined(DYNAMIC_EXECUTION_PROFILE) || USE_COMPUTED_GOTOS
#define PREDICT(op)             if (0) goto PRED_##op
#else
#define PREDICT(op) \
    do{ \
        _Py_CODEUNIT word = *next_instr; \
        opcode = _Py_OPCODE(word); \
        if (opcode == op){ \
            oparg = _Py_OPARG(word); \
            next_instr++; \
            goto PRED_##op; \
        } \
    } while(0)
#endif
#define PREDICTED(op)           PRED_##op:
</code></pre>
<p>PREDICT 宏和指令预测相关，后续介绍 if 控制流的时候再说。</p>
<p>关于宏就说到这里，至于剩下的一些宏，暂时就先不用看了，我们在后续的部分才会用到它们。</p>
<p>好，既然宏说完了，接下来我们可以看整个帧评估函数都做些什么了，代码有删减。</p>
<pre><code class="language-C">PyObject* _Py_HOT_FUNCTION
_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)
{
    // 初始化一些变量，它们的含义等赋值的时候再说
    PyObject **stack_pointer;
    const _Py_CODEUNIT *next_instr;
    int opcode;
    int oparg;
    PyObject **fastlocals, **freevars;
    PyObject *retval = NULL;
    _PyRuntimeState * const runtime = &amp;_PyRuntime;
    PyThreadState * const tstate = _PyRuntimeState_GetThreadState(runtime);
    struct _ceval_runtime_state * const ceval = &amp;runtime-&gt;ceval;
    _Py_atomic_int * const eval_breaker = &amp;ceval-&gt;eval_breaker;
    PyCodeObject *co;
    int instr_ub = -1, instr_lb = 0, instr_prev = -1;
    const _Py_CODEUNIT *first_instr;
    PyObject *names;
    PyObject *consts;
    _PyOpcache *co_opcache;
    
    // ...
    // 省略了一堆的宏定义，就是我们上面刚介绍的
    // ...
    
    // 检查是否超过递归深度限制
    if (Py_EnterRecursiveCall(&quot;&quot;))
        return NULL;
    // tstate-&gt;frame 保存当前正在执行的栈桢，所以将 f 赋值给 tstate-&gt;frame
    // 至于之前的 tstate-&gt;frame，则保存在 f.f_back 字段中（在创建栈桢 f 的时候就完成了）
    tstate-&gt;frame = f;
    
    // 如果启用追踪机制
    if (tstate-&gt;use_tracing) {
        // tstate-&gt;c_tracefunc 对应 Python 里的 sys.settrace
        // 如果不为空，那么进行调用
        // 该函数可以监控每行代码的执行，因此一般用于调试器
        if (tstate-&gt;c_tracefunc != NULL) {
            if (call_trace_protected(tstate-&gt;c_tracefunc,
                                     tstate-&gt;c_traceobj,
                                     tstate, f, PyTrace_CALL, Py_None)) {
                goto exit_eval_frame;
            }
        }
        // tstate-&gt;c_profilefunc 对应 Python 里的 sys.setprofile
        // 如果不为空，那么进行调用，该函数主要用于性能分析
        if (tstate-&gt;c_profilefunc != NULL) {
            if (call_trace_protected(tstate-&gt;c_profilefunc,
                                     tstate-&gt;c_profileobj,
                                     tstate, f, PyTrace_CALL, Py_None)) {
                goto exit_eval_frame;
            }
        }
    }
    // DTrace 是一个强大的动态追踪工具
    // 这里检测是否启用了 DTrace 的函数入口探针
    if (PyDTrace_FUNCTION_ENTRY_ENABLED())
        // 如果启用了 DTrace，则记录函数进入的事件
        dtrace_function_entry(f);
    
    // 获取栈桢内部的关键字段
    co = f-&gt;f_code;
    names = co-&gt;co_names;
    consts = co-&gt;co_consts;
    fastlocals = f-&gt;f_localsplus;    
    freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;
    assert(PyBytes_Check(co-&gt;co_code));
    assert(PyBytes_GET_SIZE(co-&gt;co_code) &lt;= INT_MAX);
    assert(PyBytes_GET_SIZE(co-&gt;co_code) % sizeof(_Py_CODEUNIT) == 0);
    assert(_Py_IS_ALIGNED(PyBytes_AS_STRING(co-&gt;co_code), sizeof(_Py_CODEUNIT)));
    // 注意这里的 first_instr，上面已经介绍了，它指向字节码指令序列的起始位置，或者说第一条指令
    first_instr = (_Py_CODEUNIT *) PyBytes_AS_STRING(co-&gt;co_code);
    assert(f-&gt;f_lasti &gt;= -1);
    // 初始状态下，next_instr 和 first_instr 相等
    next_instr = first_instr;
    if (f-&gt;f_lasti &gt;= 0) {
        assert(f-&gt;f_lasti % sizeof(_Py_CODEUNIT) == 0);
        next_instr += f-&gt;f_lasti / sizeof(_Py_CODEUNIT) + 1;
    }
    stack_pointer = f-&gt;f_stacktop;
    assert(stack_pointer != NULL);
    f-&gt;f_stacktop = NULL;
    f-&gt;f_executing = 1;
    
// 进入主循环，在这个 for 循环里面一会儿就会看到那个巨型的 switch    
main_loop:
    // 遍历字节码指令集，处理每一条指令
    for (;;) {
        // stack_pointer 是栈顶指针，f_valuestack 是栈底指针
        // 由于 Python 的运行时栈是基于数组实现的，所以从栈底到栈顶，地址是增大的
        // 因此 stack_pointer 一定大于等于 f_valuestack
        assert(stack_pointer &gt;= f-&gt;f_valuestack);
        // STACK_LEVEL() 一定小于等于运行时栈的长度，之前说过的
        assert(STACK_LEVEL() &lt;= co-&gt;co_stacksize);
        // 线程状态对象里面没有异常产生
        assert(!_PyErr_Occurred(tstate));
        
        // 检测是否有待处理的中断（比如信号、GIL 释放请求等）
        if (_Py_atomic_load_relaxed(eval_breaker)) {
            opcode = _Py_OPCODE(*next_instr);
            /* 如果指令是以下之一，那么忽略中断，直接跳到 fast_next_opcode 标签进行处理
             *     SETUP_FINALLY：try / finally 语句的开始
             *     SETUP_WITH：with 语句的开始
             *     BEFORE_ASYNC_WITH：async with 语句的开始
             *     YIELD_FROM：yield from 表达式
             */
            // 这种设计主要是为了确保在某些关键操作（如资源管理、异常处理、异步操作）的开始阶段不被中断信号打断
            // 从而保证这些操作的正确性和可靠性，进而保证 Python 程序的稳定性和可预测性
            if (opcode == SETUP_FINALLY ||
                opcode == SETUP_WITH ||
                opcode == BEFORE_ASYNC_WITH ||
                opcode == YIELD_FROM) {
                goto fast_next_opcode;
            }
            // 使用原子操作检查是否有待处理的信号
            // 如果有待处理的信号，那么调用 handle_signals 函数处理它们
            // 这个机制允许 Python 程序响应外部事件和系统信号，同时保证执行的正确性
            if (_Py_atomic_load_relaxed(&amp;ceval-&gt;signals_pending)) {
                if (handle_signals(runtime) != 0) {
                    goto error;
                }
            }
            // 通过原子操作检查是否有待处理的调用需要执行，calls_to_do 是一个计数器，表示待处理的调用的数量
            // 如果有待处理的调用，那么执行 make_pending_calls 函数
            // pending calls 主要用于垃圾回收（GC）、异步 IO 回调、定时器事件等
            // 这个机制是 Python 运行时系统的重要组成部分，允许虚拟机在主循环中处理各种异步任务和周期性任务
            // 确保各种后台任务能够得到及时处理，并且不需要使用额外的线程和复杂的调度机制
            if (_Py_atomic_load_relaxed(&amp;ceval-&gt;pending.calls_to_do)) {
                if (make_pending_calls(runtime) != 0) {
                    goto error;
                }
            }
            // 通过原子操作检查是否有释放 GIL 的请求，如果有，那么该线程就要释放 GIL
            if (_Py_atomic_load_relaxed(&amp;ceval-&gt;gil_drop_request)) {
                // 将当前线程状态设置为 NULL，因为要发生切换了（关于 GIL，后续会单独介绍）
                if (_PyThreadState_Swap(&amp;runtime-&gt;gilstate, NULL) != tstate) {
                    Py_FatalError(&quot;ceval: tstate mix-up&quot;);
                }
                // 释放 GIL，给其它线程一个机会，不能让某一个线程一直霸占着
                // 如果开启了多线程，那么当释放 GIL 的那一刻，就会被其它线程获取
                drop_gil(ceval, tstate);
                // GIL 释放之后，还要再次获取，但 GIL 已经被其它线程拿走了
                // 所以会触发操作系统内核的线程调度机制，进入阻塞状态，等待 GIL 再度回到自己手中
                // 因此不难发现，如果有 n 个线程，那么其中的 n - 1 个会陷入阻塞，等待获取 GIL
                // 而一旦持有 GIL 的线程执行了 drop_gil 函数，将 GIL 释放了
                // 那么这 n - 1 个线程当中就会有一个线程拿到 GIL 并解除阻塞，然后开始执行字节码
                // 至于释放 GIL 的线程，则会尝试再次获取 GIL，但会因为获取不到而陷入阻塞（已经被其它线程拿走了）
                take_gil(ceval, tstate);
                // 检查是否需要快速退出线程（比如在解释器关闭时）
                exit_thread_if_finalizing(runtime, tstate);
                // 到这里说明 take_gil 返回了（即阻塞状态解除），也意味着拿到了 GIL，那么要恢复线程状态
                if (_PyThreadState_Swap(&amp;runtime-&gt;gilstate, tstate) != NULL) {
                    Py_FatalError(&quot;ceval: orphan tstate&quot;);
                }
            }
            // 检测线程状态中是否存在异步的异常
            if (tstate-&gt;async_exc != NULL) {
                PyObject *exc = tstate-&gt;async_exc;
                tstate-&gt;async_exc = NULL;
                UNSIGNAL_ASYNC_EXC(ceval);
                _PyErr_SetNone(tstate, exc);
                Py_DECREF(exc);
                goto error;
            }
        }

    // 以上是一些中断检测逻辑，如果执行顺利，那么会走到这里
    fast_next_opcode:
        // 保存上一条已执行完毕的字节码的偏移量
        f-&gt;f_lasti = INSTR_OFFSET();
        // 如果启用了 DTrace 行追踪，那么记录行级别的执行信息
        if (PyDTrace_LINE_ENABLED())
            maybe_dtrace_line(f, &amp;instr_lb, &amp;instr_ub, &amp;instr_prev);
        // 检查是否需要执行行级追踪，如果追踪功能可用并且设置了追踪函数，那么执行
        // 这是 Python 调试和性能分析功能的核心部分，使得像 pdb 这样的调试器能够逐行执行代码
        if (_Py_TracingPossible(ceval) &amp;&amp;
            tstate-&gt;c_tracefunc != NULL &amp;&amp; !tstate-&gt;tracing) {
            int err;
            // 保存当前栈指针
            f-&gt;f_stacktop = stack_pointer;
            // 调用行追踪函数
            err = maybe_call_line_trace(tstate-&gt;c_tracefunc,
                                        tstate-&gt;c_traceobj,
                                        tstate, f,
                                        &amp;instr_lb, &amp;instr_ub, &amp;instr_prev);
            // 追踪函数可能改变帧的状态，需要重新加载，并更新栈指针
            JUMPTO(f-&gt;f_lasti);
            if (f-&gt;f_stacktop != NULL) {
                stack_pointer = f-&gt;f_stacktop;
                f-&gt;f_stacktop = NULL;
            }
            if (err)
                goto error;
        }
        // 这个宏前面介绍了，它会获取下一条待处理的指令和指令参数
        NEXTOPARG();
    
    // 进入 dispatch_opcode 标签
    dispatch_opcode:
    // 下面这些宏主要用于指令追踪和性能分析，简单了解一下就好
#ifdef DYNAMIC_EXECUTION_PROFILE        // 如果启用了动态执行性能分析
#ifdef DXPAIRS                          // 如果启用了指令对分析
        dxpairs[lastopcode][opcode]++;  // 记录相邻指令对的出现次数
        lastopcode = opcode;            // 更新上一个指令
#endif
        dxp[opcode]++;                  // 记录单个指令的执行次数
#endif

#ifdef LLTRACE                         
        // 如果启用了低级追踪，并且追踪开关打开，那么打印偏移量、指令、指令参数等信息
        if (lltrace) {
            if (HAS_ARG(opcode)) {
                printf(&quot;%d: %d, %d\n&quot;,
                       f-&gt;f_lasti, opcode, oparg);
            }
            else {                      
                printf(&quot;%d: %d\n&quot;,
                       f-&gt;f_lasti, opcode);
            }
        }
#endif
        
        // 好的，关键来了，我们终于来到了这个巨型的 switch
        // 一个指令对应一个 case 分支，里面包含了该指令的处理逻辑
        // 因为有一百多个 case 分支，所以这个 switch 语句的代码量高达 2300 多行
        // 当然啦，也仅仅只是代码量大，但逻辑很单纯，就是定义了一百多条指令的处理逻辑嘛     
        switch (opcode) {
        
        // NOP 指令的处理逻辑，另外还记得这个 TARGET 宏吗？如果开启了计算跳转，那么分支内部还会定义一个标签
        // 此时 case TARGET(NOP) 会展开成 case NOP: TARGET_NOP:
        case TARGET(NOP): { 
            FAST_DISPATCH();
        }
        // LOAD_FAST 指令的处理逻辑
        case TARGET(LOAD_FAST): {
            PyObject *value = GETLOCAL(oparg);
            if (value == NULL) {
                format_exc_check_arg(tstate, PyExc_UnboundLocalError,
                                     UNBOUNDLOCAL_ERROR_MSG,
                                     PyTuple_GetItem(co-&gt;co_varnames, oparg));
                goto error;
            }
            Py_INCREF(value);
            PUSH(value);
            FAST_DISPATCH();
        }
        // LOAD_CONST 指令的处理逻辑
        case TARGET(LOAD_CONST): {
            PREDICTED(LOAD_CONST);
            PyObject *value = GETITEM(consts, oparg);
            Py_INCREF(value);
            PUSH(value);
            FAST_DISPATCH();
        }
        // STORE_FAST 指令的处理逻辑
        case TARGET(STORE_FAST): {
            PREDICTED(STORE_FAST);
            PyObject *value = POP();
            SETLOCAL(oparg, value);
            FAST_DISPATCH();
        }
        // POP_TOP 指令的处理逻辑
        case TARGET(POP_TOP): {
            PyObject *value = POP();
            Py_DECREF(value);
            FAST_DISPATCH();
        }
               
                
        // ...
        // ...                
        // ...                
        
                
        // MAKE_FUNCTION 指令的处理逻辑
        case TARGET(MAKE_FUNCTION): {
            // ...
            PUSH((PyObject *)func);
            DISPATCH();
        }
        // BUILD_SLICE 指令的处理逻辑
        case TARGET(BUILD_SLICE): {
            // ...
            if (slice == NULL)
                goto error;
            DISPATCH();
        }
        // FORMAT_VALUE 指令的处理逻辑
        case TARGET(FORMAT_VALUE): {
            // ...
            DISPATCH();
        }
        // EXTENDED_ARG 指令的处理逻辑
        case TARGET(EXTENDED_ARG): {
            int oldoparg = oparg;
            NEXTOPARG();
            oparg |= oldoparg &lt;&lt; 8;
            goto dispatch_opcode;
        }
        /* 这些指令内部的具体逻辑，我们后续会聊 */

        // 如果执行到这里，说明上面的 case 分支都没有匹配到，意味着出现了一个未知的指令
        // 那么打印错误信息：unknown opcde，不过基本不会发生，除非你刻意构造一个不存在的指令
#if USE_COMPUTED_GOTOS
        _unknown_opcode:
#endif
        default:
            fprintf(stderr,
                &quot;XXX lineno: %d, opcode: %d\n&quot;,
                PyFrame_GetLineNumber(f),
                opcode);
            _PyErr_SetString(tstate, PyExc_SystemError, &quot;unknown opcode&quot;);
            goto error;

        } // 到这里，switch 语句块就结束了

        // 这个位置永远不可能到达，因为在每条指令的处理逻辑的最后，要么调用 DISPATCH()，要么 goto error
        // 调用 DISPATCH() 会去执行下一条指令，goto error 会跳转到下面的 error 标签
        // 当然这里的 Py_UNREACHABLE() 有没有都无所谓，但加上之后会让程序显得更加严谨
        Py_UNREACHABLE();

// 如果字节码指令在执行时出错了，那么会设置异常，然后跳转到 error 标签
error:
// 以下是错误处理的防御性代码，用于确保在发生错误时总是设置了适当的异常     
// 记得之前介绍过异常的本质，其实就是解释器内部在执行时发现逻辑出问题了（比如索引超出范围）
// 那么会将异常（比如 IndexError）设置在回溯栈中，并立即返回一个表示错误的哨兵值
// 当解释器将返回值传递给 Python 时，会发现返回值为 NULL，知道出异常了
// 于是会将回溯栈里的异常输出到 stderr 当中，就是我们在终端中看到的那一坨红色的东西，然后结束进程
// 但如果解释器发现回溯栈里面没有异常，那么会额外设置一个 SystemError: error return without exception set
// 意思就是：&quot;明明发生错误了，为什么回溯栈里面没有设置异常呢？&quot;，一般这个问题会在用 C 编写扩展模块的时候遇到        
#ifdef NDEBUG
        if (!_PyErr_Occurred(tstate)) {
            _PyErr_SetString(tstate, PyExc_SystemError,
                             &quot;error return without exception set&quot;);
        }
#else
        // 当然如果没有定义 NDEBUG 宏的话，那么就会展开成一个 assert 断言
        // 对于解释器本身来说，像这种 assert 断言都是成立的，否则底层源码写的就有问题
        assert(_PyErr_Occurred(tstate));
#endif

        // 报错时，要生成 traceback，即回溯栈，关于 traceback，等介绍异常捕获的时候再说
        PyTraceBack_Here(f);
        // 执行追踪函数，用于调试器捕获异常、追踪异常、以及异常处理的监控和分析等
        // 在使用 pdb 调试器时，这个机制允许调试器捕获和显示异常信息
        if (tstate-&gt;c_tracefunc != NULL)
            call_exc_trace(tstate-&gt;c_tracefunc, tstate-&gt;c_traceobj,
                           tstate, f);

// 这里和异常捕获相关，我们后续再聊        
exception_unwind:
        while (f-&gt;f_iblock &gt; 0) {
            // ...
        }
        break;
        
    }  // 到这里，外层的 for 循环就结束了，显然会有两种情况
       // 要么字节码都执行完毕了，要么出异常了，但不管是哪种，都意味着要退出栈桢了

    assert(retval == NULL);
    assert(_PyErr_Occurred(tstate));

// 到这里说明要退出栈桢了，如果运行时栈里面还有元素的话，那么要清空
exit_returning:
    while (!EMPTY()) {
        PyObject *o = POP();
        Py_XDECREF(o);
    }

// 生成器在 yield 时的追踪处理逻辑
// 另外像这些追踪函数可以不用太关注，都是用于调试和性能分析的
exit_yielding:
    if (tstate-&gt;use_tracing) {
        if (tstate-&gt;c_tracefunc) {
            if (call_trace_protected(tstate-&gt;c_tracefunc, tstate-&gt;c_traceobj,
                                     tstate, f, PyTrace_RETURN, retval)) {
                Py_CLEAR(retval);
            }
        }
        if (tstate-&gt;c_profilefunc) {
            if (call_trace_protected(tstate-&gt;c_profilefunc, tstate-&gt;c_profileobj,
                                     tstate, f, PyTrace_RETURN, retval)) {
                Py_CLEAR(retval);
            }
        }
    }

// 帧评估函数退出时的清理代码
exit_eval_frame:
    // 如果启用了 DTrace，记录函数返回事件
    if (PyDTrace_FUNCTION_RETURN_ENABLED())
        dtrace_function_return(f);
    // 退出递归调用，与之前的 Py_EnterRecursiveCall() 相对应
    Py_LeaveRecursiveCall();
    // 标记帧不再处于执行状态
    f-&gt;f_executing = 0;
    // 当调用一个函数时，会在当前帧的基础上创建新的帧，并将执行权交给新的帧
    // 当函数执行完毕时，会销毁栈桢，并将执行权还给上一级栈帧（即调用者的帧），这个过程叫做栈桢回退
    // 显然这里要将 f-&gt;back 赋值给 tstate-&gt;frame，即回退到上一级栈桢
    tstate-&gt;frame = f-&gt;f_back;
    
    // 检查返回值的有效性，确保返回值符合 Python 的调用约定
    return _Py_CheckFunctionResult(NULL, retval, &quot;PyEval_EvalFrameEx&quot;);    
}    
</code></pre>
<p>以上就是帧评估函数的源码逻辑，总的来说并不难理解，其核心就是通过 for 循环遍历字节码指令集，将遍历出的指令交给内部的 switch 语句，执行对应的 case 分支。当匹配到的 case 分支执行完毕时，会有以下三种情况：</p>
<ul>
<li>停止循环、退出帧评估函数，当执行的指令为 RETURN_VALUE、YIELD_VALUE 等。</li>
<li>执行指令的过程中出错了，跳转到 error 标签，然后进行异常处理（或者直接抛出异常）。</li>
<li>执行下一条指令，如果开启了计算跳转，那么会精确跳转到下一条指令的处理逻辑中，否则会跳转到 fast_next_opcode 标签的所在位置、或者 for 循环的所在位置。但不管如何，虚拟机接下来的动作就是获取下一条字节码指令和指令参数，完成对下一条指令的执行。</li>
</ul>
<p>所以通过 for 循环一条一条遍历 co_code 中的字节码指令，然后交给内部的 switch 语句、执行对应的 case 分支，如此周而复始，最终完成了对整个 Python 程序的执行。</p>
<p><font color="darkblue"><strong>相信到此刻你已经彻底了解了 Python 执行引擎的整体结构。说白了虚拟机就是将自己当成一个 CPU，在栈帧中一条条的执行指令，而执行过程中所依赖的常量、变量等，则由栈帧的其它字段来维护。</strong></font></p>
<h2 id="通过反编译查看字节码"><a class="header" href="#通过反编译查看字节码">通过反编译查看字节码</a></h2>
<p>光看源码还是有点枯燥的，下面我们来写一段简单的代码，然后反编译，并通过画图来演示虚拟机是如何执行字节码的。</p>
<pre><code class="language-Python">code = &quot;&quot;&quot;\
chinese = 89
math = 99
english = 91
avg = (chinese + math + english) / 3
&quot;&quot;&quot;

# 将上面的代码以模块的方式进行编译
co = compile(code, &quot;my_module&quot;, &quot;exec&quot;)
# 查看常量池
print(co.co_consts)  # (89, 99, 91, 3, None)
# 查看符号表
print(co.co_names)  # ('chinese', 'math', 'english', 'avg')
</code></pre>
<p>在编译的时候，常量和符号（变量）都会被静态收集起来。然后我们反编译一下看看字节码，直接通过 dis.dis(co) 即可，结果如下：</p>
<pre><code class="language-C">  1           0 LOAD_CONST               0 (89)
              2 STORE_NAME               0 (chinese)

  2           4 LOAD_CONST               1 (99)
              6 STORE_NAME               1 (math)

  3           8 LOAD_CONST               2 (91)
             10 STORE_NAME               2 (english)

  4          12 LOAD_NAME                0 (chinese)
             14 LOAD_NAME                1 (math)
             16 BINARY_ADD
             18 LOAD_NAME                2 (english)
             20 BINARY_ADD
             22 LOAD_CONST               3 (3)
             24 BINARY_TRUE_DIVIDE
             26 STORE_NAME               3 (avg)
             28 LOAD_CONST               4 (None)
             30 RETURN_VALUE
</code></pre>
<p>上面每一列的含义之前说过，这里再重复一下。</p>
<ul>
<li>第一列是源代码的行号；</li>
<li>第二列是指令的偏移量，或者说该指令在整个字节码指令序列中的索引。因为每条指令后面都跟着一个参数，所以偏移量是 0 2 4 6 8 ...；</li>
<li>第三列是字节码指令，简称指令，它们在宏定义中代表整数；</li>
<li>第四列是字节码指令参数，简称指令参数、或者参数，不同的指令参数的含义不同；</li>
<li>第五列是 dis 模块给我们额外提供的信息，一会儿说；</li>
</ul>
<p><strong>我们从上到下依次解释每条指令都干了什么？</strong></p>
<p><font color="blue">0 LOAD_CONST</font>：表示加载一个常量（指针），并压入运行时栈。后面的指令参数 0 表示从常量池中加载索引为 0 的常量，至于 89 则表示加载的常量是 89。所以最后面的括号里面的内容实际上起到的是一个提示作用，告诉你加载的对象是什么。</p>
<p><font color="blue">2 STORE_NAME</font>：表示将 LOAD_CONST 加载的常量用一个名字绑定起来，放在所在的名字空间中。后面的 0 (chinese) 则表示使用符号表中索引为 0 的名字（符号），且名字为 &quot;chinese&quot;。</p>
<p>所以像 chinese = 89 这种简单的赋值语句，会对应两条字节码指令。</p>
<p>然后 4 LOAD_CONST、6 STORE_NAME 和 8 LOAD_CONST、10 STORE_NAME 的作用显然和上面是一样的，都是加载一个常量，然后将某个符号和常量绑定起来，并放在名字空间中。</p>
<p><font color="blue">12 LOAD_NAME</font>：加载一个变量，并压入运行时栈，而后面的 0 (chinese) 表示加载符号表中索引为 0 的变量的值，然后这个变量叫 chinese。<font color="blue">14 LOAD_NAME</font> 也是同理，将符号表中索引为 1 的变量的值压入运行时栈，并且变量叫 math。此时栈里面有两个元素，从栈底到栈顶分别是 chinese 和 math。</p>
<p><font color="blue">16 BINARY_ADD</font>：将上面两个变量从运行时栈弹出，然后执行加法操作，并将结果压入运行时栈。</p>
<p><font color="blue">18 LOAD_NAME</font>：将符号表中索引为 2 的变量 english 的值压入运行时栈，此时栈里面有两个元素，从栈底到栈顶分别是 <font color="red">chinese + math 的返回结果</font>和 <font color="red">english</font>。</p>
<p><font color="blue">20 BINARY_ADD</font>：将运行时栈里的两个元素弹出，然后执行加法操作，并将结果压入运行时栈。此时栈里面有一个元素，就是 <font color="red">chinese + math + english</font> 的返回结果。</p>
<p><font color="blue">22 LOAD_CONST</font>：将常量 3 压入运行时栈，此时栈里面有两个元素；</p>
<p><font color="blue">24 BINARY_TRUE_DIVIDE</font>：将运行时栈里的两个元素弹出，然后执行除法操作，并将结果压入运行时栈，此时栈里面有一个元素；</p>
<p><font color="blue">26 STORE_NAME</font>：将元素从运行时栈里面弹出，并用符号表中索引为 3 的变量 avg 和它绑定起来，然后放在名字空间中。</p>
<p><font color="blue">28 LOAD_CONST</font>：将常量 None 压入运行时栈，然后通过 <font color="blue">30 RETURN_VALUE</font> 将其从栈中弹出、并返回。</p>
<p>所以 Python 虚拟机就是把自己想象成一个 CPU，在栈帧中一条条执行字节码指令，当指令执行完毕或执行出错时，停止执行。</p>
<p>我们通过几张图展示一下上面的过程，为了阅读方便，这里将相应的源代码再贴一份。</p>
<pre><code class="language-Python">chinese = 89
math = 99
english = 91
avg = (chinese + math + english) / 3
</code></pre>
<p>之前说了，模块也有自己的作用域，并且是全局作用域，所以虚拟机也会为它创建栈帧。而在代码还没有执行的时候，栈帧就已经创建好了，整个布局如下。</p>
<p><img src="./images/173.png" alt="" /></p>
<blockquote>
<p>f_localsplus 下面的箭头方向，代表运行时栈从栈底到栈顶的方向。</p>
</blockquote>
<p>这里再强调一下 f_localsplus 字段，它是一个柔性数组。虽然声明的时候写着长度为 1，但实际使用时，长度不受限制，和 Go 语言不同，C 数组的长度不属于类型的一部分。然后 f_localsplus 在逻辑上被分成了四份，分别用于局部变量、cell 变量、free 变量、运行时栈，由于当前示例中的代码是以模块的方式编译的，里面所有的变量都是全局变量，而且也不涉及闭包啥的，所以这里就把 f_localsplus 理解为运行时栈即可。</p>
<p>接下来就开始执行字节码了，next_instr 指向下一条待执行的字节码指令，显然初始状态下，下一条待执行的指令就是第一条指令。</p>
<p>于是虚拟机开始执行 <font color="blue">0 LOAD_CONST</font>，该指令表示将常量加载进运行时栈，而要加载的常量在常量池中的索引，由指令参数表示。</p>
<blockquote>
<p>在源码中，指令对应的变量是 opcode，指令参数对应的变量是 oparg。</p>
</blockquote>
<pre><code class="language-C">case TARGET(LOAD_CONST): {
    PREDICTED(LOAD_CONST);
    // 调用元组的 GETITEM 方法，从常量池中加载索引为 oparg 的对象
    // 当然啦，为了描述方便我们称之为对象，但其实是指向对象的指针
    PyObject *value = GETITEM(consts, oparg);
    // 增加引用计数
    Py_INCREF(value);
    // 压入运行时栈
    PUSH(value);
    FAST_DISPATCH();
}
</code></pre>
<p>该指令的参数为 0，所以会将常量池中索引为 0 的元素 89 压入运行时栈，执行完之后，栈帧的布局就变成了下面这样：</p>
<p><img src="./images/174.png" alt="" /></p>
<p>接着虚拟机执行 <font color="blue">2 STORE_NAME</font> 指令，从符号表中获取索引为 0 的符号、即 chinese。然后将栈顶元素 89 弹出，再将<font color="red">符号 chinese</font> 和<font color="red">整数对象 89</font> 绑定起来保存到 local 名字空间中。</p>
<pre><code class="language-C">case TARGET(STORE_NAME): {
    // 从符号表中加载索引为 oparg 的符号  
    // 符号本质上就是一个 PyUnicodeObject 对象
    // 这里就是字符串 &quot;chinese&quot;
    PyObject *name = GETITEM(names, oparg);
    // 从运行时栈的栈顶弹出元素
    // 显然是上一步压入的 89
    PyObject *v = POP();
    // 获取名字空间 namespace
    PyObject *ns = f-&gt;f_locals;
    int err;
    // 如果没有名字空间则报错，设置异常
    if (ns == NULL) {
        _PyErr_Format(tstate, PyExc_SystemError,
                      &quot;no locals found when storing %R&quot;, name);
        Py_DECREF(v);
        goto error;
    }
    // 将符号和对象绑定起来放在 ns 中
    // 名字空间是一个字典，PyDict_CheckExact 负责检测 ns 是否为字典，等价于 type(ns) is dict
    // 除此之外，还有 PyDict_Check(ns)，它等价于 isinstance(ns, dict)
    if (PyDict_CheckExact(ns))
        // 通过字典的特定类型 API 将键值对 &quot;chinese&quot;: 89 设置到字典中
        err = PyDict_SetItem(ns, name, v);
    else
        // 走到这里说明 type(ns) 不是 dict，那么它应该继承 dict
        // 通过泛型 API 设置元素
        err = PyObject_SetItem(ns, name, v);
    // 对象的引用计数减 1，因为从运行时栈中弹出了
    Py_DECREF(v);
     // 如果 err != 0，证明设置元素出错了，跳转至 error 标签
    if (err != 0)
        goto error;
    // 调用 DISPATCH() 执行下一条指令，如果没有开启计算跳转，那么它就相当于一个 continue
    DISPATCH();
}
</code></pre>
<p>执行完之后，栈帧的布局就变成了下面这样：</p>
<p><img src="./images/175.png" alt="" /></p>
<p>此时运行时栈为空，local 名字空间多了个键值对。</p>
<p>同理剩余的两个赋值语句也是类似的，只不过指令参数不同，比如 <font color="blue">6 STORE_NAME</font> 加载的是符号表中索引为 1 的符号，<font color="blue">10 STORE_NAME</font> 加载的是符号表中索引为 2 的符号，分别是 math 和 english。它们执行完之后，栈桢布局如下：</p>
<p><img src="./images/176.png" alt="" /></p>
<p>然后 <font color="blue">12 LOAD_NAME</font> 和 <font color="blue">14 LOAD_NAME</font> 负责将符号表中索引为 0 和 1 的变量的值压入运行时栈：</p>
<pre><code class="language-C">case TARGET(LOAD_NAME): {
    // 从符号表 co_names 中加载索引为 oparg 的变量（符号）
    // 但是注意：全局变量是通过字典存储的
    // 所以这里的 name 只是一个字符串罢了，比如 &quot;chinese&quot;
    // 然后还要再根据这个字符串从字典里面查找对应的 value
    PyObject *name = GETITEM(names, oparg);
    // 对于模块来说，f-&gt;f_locals 和 f-&gt;f_globals 指向同一个字典
    PyObject *locals = f-&gt;f_locals;
    PyObject *v;
    // local 名字空间一定不为 NULL
    if (locals == NULL) {
        _PyErr_Format(tstate, PyExc_SystemError,
                      &quot;no locals when loading %R&quot;, name);
        goto error;
    }
    // 如果 type(locals) is dict 为真
    if (PyDict_CheckExact(locals)) {
        // 根据 name 获取 value，所以 print(chinese) 本质上就是下面这样
        // print(locals[&quot;chinese&quot;])
        v = PyDict_GetItemWithError(locals, name);
        if (v != NULL) {
            Py_INCREF(v);
        }
        else if (_PyErr_Occurred(tstate)) {
            goto error;
        }
    }
    // 否则说明 type(locals) is dict 为假，但 isinstance(locals, dict) 为真
    else {
        // 通过泛型 API 获取元素
        v = PyObject_GetItem(locals, name);
        if (v == NULL) {
            if (!_PyErr_ExceptionMatches(tstate, PyExc_KeyError))
                goto error;
            _PyErr_Clear(tstate);
        }
    }
    // 如果 v 等于 NULL，说明 local 空间不存在
    if (v == NULL) {
        // 那么从全局名字空间（global 名字空间）获取
        v = PyDict_GetItemWithError(f-&gt;f_globals, name);
        // 如果 v 不等于 NULL，说明获取到了
        if (v != NULL) {
            Py_INCREF(v);
        }
        // 否则说明 global 空间也不存在指定的 key
        // 这里检测一下是否有异常产生，有的话跳转到 error 标签
        else if (_PyErr_Occurred(tstate)) {
            goto error;
        }
        // local 空间和 global 空间都没有，那么该去 builtin 空间查找了
        else {
            // 逻辑和上面是类似的，如果查找不到，跳转到 error 标签，否则增加引用计数
            if (PyDict_CheckExact(f-&gt;f_builtins)) {
                v = PyDict_GetItemWithError(f-&gt;f_builtins, name);
                if (v == NULL) {
                    if (!_PyErr_Occurred(tstate)) {
                        format_exc_check_arg(
                                tstate, PyExc_NameError,
                                NAME_ERROR_MSG, name);
                    }
                    goto error;
                }
                Py_INCREF(v);
            }
            else {
                v = PyObject_GetItem(f-&gt;f_builtins, name);
                if (v == NULL) {
                    if (_PyErr_ExceptionMatches(tstate, PyExc_KeyError)) {
                        format_exc_check_arg(
                                    tstate, PyExc_NameError,
                                    NAME_ERROR_MSG, name);
                    }
                    goto error;
                }
            }
        }
    }
    // 压入运行时栈
    PUSH(v);
    DISPATCH();
}
</code></pre>
<p>上面两条指令执行完之后，栈帧的布局就变成了下面这样：</p>
<p><img src="./images/177.png" alt="" /></p>
<p>接下来执行 <font color="blue">16 BINARY_ADD</font>，它会将栈里的两个元素弹出，然后执行加法操作，最后再将结果入栈。</p>
<blockquote>
<p>当然上面这种说法是为了方便理解，其实虚拟机真正执行的时候，只会弹出一个元素，而另一个元素只是使用 TOP() 进行查看，但不弹出。等结果计算完毕之后，再将栈顶元素替换掉。 </p>
<p>所以本质上，和弹出两个元素、再将计算结果入栈是一样的。</p>
</blockquote>
<pre><code class="language-C">case TARGET(BINARY_ADD): {
    // 从栈顶弹出元素，这里是 99（变量 math）
    PyObject *right = POP();
    // math 弹出之后，chinese 就成为了新的栈顶元素
    // 这里的 TOP() 则是获取栈顶元素 89（变量 chinese）
    PyObject *left = TOP();
    // 用于保存两者的和
    PyObject *sum;
    // 如果是字符串，执行专门的函数
    if (PyUnicode_CheckExact(left) &amp;&amp;
             PyUnicode_CheckExact(right)) {
        sum = unicode_concatenate(tstate, left, right, f, next_instr);
    }
     // 否则通过泛型 API 进行计算
    else {
        sum = PyNumber_Add(left, right);
        Py_DECREF(left);
    }
    // 减少元素的引用计数
    Py_DECREF(right);
    // 将栈顶元素替换成 sum
    SET_TOP(sum);
    if (sum == NULL)
        goto error;
    DISPATCH();
}
</code></pre>
<p>BINARY_ADD 指令执行完之后，栈帧的布局就变成了下面这样：</p>
<p><img src="./images/178.png" alt="" /></p>
<p>然后 <font color="blue">18 LOAD_NAME</font> 负责将符号表中索引为 2 的变量 english 的值压入运行时栈，而指令 <font color="blue">20 BINARY_ADD</font> 则是继续执行加法操作，并将结果设置在栈顶，然后 <font color="blue">22 LOAD_CONST</font> 将常量 3 再压入运行时栈。</p>
<p>这三条指令执行之后，运行时栈的变化如下：</p>
<p><img src="./images/179.png" alt="" /></p>
<p>接着是 <font color="blue">24 BINARY_TRUE_DIVIDE</font>，它的逻辑和 BINARY_ADD 类似，只不过一个执行除法，一个执行加法。</p>
<pre><code class="language-C">case TARGET(BINARY_TRUE_DIVIDE): {
    // 从栈顶弹出元素，显然是 3
    PyObject *divisor = POP();
    // 查看栈顶元素，此时栈顶元素变成了 279
    PyObject *dividend = TOP();
    // 调用 PyNumber_TrueDivide，执行 279 / 3
    PyObject *quotient = PyNumber_TrueDivide(dividend, divisor);
    // 减少引用计数
    Py_DECREF(dividend);
    Py_DECREF(divisor);
    // 将栈顶元素替换成 279 / 3 的计算结果
    SET_TOP(quotient);
    if (quotient == NULL)
        goto error;
    DISPATCH();
}
</code></pre>
<p>当 24 BINARY_TRUE_DIVIDE 执行完之后，运行时栈如下：</p>
<p><img src="./images/180.png" alt="" /></p>
<p>然后 <font color="blue">26 STORE_NAME</font> 将栈顶元素 93.0 弹出，并将符号表中索引为 3 的变量 avg 和它绑定起来，放到名字空间中。因此最终栈帧关系图如下：</p>
<p><img src="./images/181.png" alt="" /></p>
<p>以上就是虚拟机对这几行代码的执行流程，整个过程就像 CPU 执行指令一样。</p>
<p>我们再用 Python 代码描述一遍上面的逻辑：</p>
<pre><code class="language-python"># LOAD_CONST 将 89 压入栈中，STORE_NAME 将 89 从栈中弹出
# 并将符号 &quot;chinese&quot; 和 89 绑定起来，放在名字空间中
chinese = 89
print(
    {k: v for k, v in locals().items() if not k.startswith(&quot;__&quot;)}
)  # {'chinese': 89}

math = 99
print(
    {k: v for k, v in locals().items() if not k.startswith(&quot;__&quot;)}
)  # {'chinese': 89, 'math': 99}

english = 91
print(
    {k: v for k, v in locals().items() if not k.startswith(&quot;__&quot;)}
)  # {'chinese': 89, 'math': 99, 'english': 91}

avg = (chinese + math + english) / 3
print(
    {k: v for k, v in locals().items() if not k.startswith(&quot;__&quot;)}
)  # {'chinese': 89, 'math': 99, 'english': 91, 'avg': 93.0}
</code></pre>
<p>现在你是不是对虚拟机执行字节码有更深的了解了呢？当然字节码指令非常多，不止我们上面看到的那几个。你可以随便写一些代码，然后分析一下它的字节码指令是什么。</p>
<h2 id="小结-45"><a class="header" href="#小结-45">小结</a></h2>
<p>到此，我们就深入源码，考察了虚拟机执行字节码的流程，帧评估函数虽然很长，也有那么一些复杂，但是核心逻辑不难理解。就是把自己当成一个 CPU，在栈帧中执行字节码指令。</p>
<p>下一篇文章我们来介绍一下常见的几个指令，并探讨不同的变量赋值语句的背后原理。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-46"><a class="header" href="#楔子-46">楔子</a></h2>
<p>前面我们剖析了字节码的执行流程，本来应该接着介绍一些常见指令的，但因为有几个指令涉及到了局部变量，所以我们单独拿出来说。与此同时，我们还要再度考察一下 local 名字空间，它的背后还隐藏了很多内容。</p>
<p>我们知道函数的参数和函数内部定义的变量都属于局部变量，均是通过静态方式访问的。</p>
<pre><code class="language-Python">x = 123

def foo1():
    global x
    a = 1
    b = 2

# co_nlocals 会返回局部变量的个数
# a 和 b 是局部变量，x 是全局变量，因此是 2
print(foo1.__code__.co_nlocals)  # 2


def foo2(a, b):
    pass

print(foo2.__code__.co_nlocals)  # 2


def foo3(a, b):
    a = 1
    b = 2
    c = 3

print(foo3.__code__.co_nlocals)  # 3
</code></pre>
<p>无论是参数还是内部新创建的变量，本质上都是局部变量。</p>
<p>按照之前的理解，当访问一个全局变量时，会去访问 global 名字空间（也叫全局名字空间）。</p>
<p><img src="./images/182.png" alt="" /></p>
<p>那么问题来了，当操作函数的局部变量时，是不是也等价于操作其内部的 local 名字空间（局部名字空间）呢？我们往下看。</p>
<h2 id="如何访问创建一个局部变量"><a class="header" href="#如何访问创建一个局部变量">如何访问（创建）一个局部变量</a></h2>
<p>之前我们说过 Python 变量的访问是有规则的，会按照本地、闭包、全局、内置的顺序去查找，也就是 LEGB 规则，所以在查找变量时，local 名字空间应该是第一选择。</p>
<p>但不幸的是，虚拟机在为调用的函数创建栈帧对象时，这个至关重要的 local 名字空间并没有被创建。因为栈帧的 f_locals 字段和 f_globals 字段分别指向了局部名字空间和全局名字空间，而创建栈帧时 f_locals 被初始化成了 NULL，所以并没有创建局部名字空间。这里可能有人会有疑问，因为印象之中函数是有 local 空间的吧。</p>
<pre><code class="language-Python">import inspect

# 模块的栈帧
frame = inspect.currentframe()
# 对于模块而言，局部名字空间和全局名字空间是同一个字典
print(frame.f_locals is frame.f_globals)  # True
# 当然啦，局部名字空间和全局名字空间也可以通过内置函数获取
print(
    frame.f_locals is locals() is frame.f_globals is globals()
)  # True


# 但对于函数而言就不一样了
def foo():
    name = &quot;古明地觉&quot;
    return inspect.currentframe()

frame = foo()
# global 名字空间全局唯一
# 无论是获取栈帧的 f_globals，还是调用 globals()，得到的都是同一份字典
print(frame.f_globals is globals())  # True
# 但每个函数都有自己独立的局部名字空间
print(frame.f_locals)  # {'name': '古明地觉'}

# 咦，不是说局部名字空间被初始化为 NULL 吗？
# 那么在 Python 里面获取的话，结果应该是个 None 才对啊
# 关于这一点，我们稍后会解释
</code></pre>
<p>总之对于函数而言，在创建栈帧时，它的 f_locals 被初始化为 NULL。那么问题来了，局部变量到底存储在什么地方呢？当然，由于变量只是一个名字（符号），而局部变量的名字都存储在符号表中，所以更严谨的说法是，局部变量的值存储在什么地方？</p>
<p>在介绍虚拟机执行字节码的时候我们说过，当函数被调用时，虚拟机会为其创建一个栈帧。栈帧是虚拟机的执行环境，包含了执行时所依赖的上下文，而栈帧内部有一个字段叫 f_localsplus，它是一个数组。</p>
<p><img src="./images/183.png" alt="" /></p>
<p>这个数组虽然是一段连续内存，但在逻辑上被分成了 4 份，其中局部变量便存储在 f_localsplus 的第一份空间中。现在我们明白了，局部变量是静态存储在数组中的。</p>
<p>我们举个例子。</p>
<pre><code class="language-python">def foo(a, b):
    c = a + b
    print(c)
</code></pre>
<p>它的字节码如下：</p>
<pre><code class="language-C">            // 加载局部变量 a，压入运行时栈
2           0 LOAD_FAST                0 (a)
            // 加载局部变量 b，压入运行时栈
            2 LOAD_FAST                1 (b)
            // 将 a 和 b 从栈中弹出，然后做加法运算，再将结果压入栈中
            4 BINARY_ADD
            // 加载符号 c，弹出栈顶元素（a + b 的运算结果）
            // 然后将两者绑定起来，完成赋值语句 c = a + b
            6 STORE_FAST               2 (c)
            
            // 加载变量 print，优先从 global 空间中加载
            // 如果 global 空间里面没有，那么再从 builtin 空间中加载
3           8 LOAD_GLOBAL              0 (print)
            // 加载局部变量 c
           10 LOAD_FAST                2 (c)
            // 执行 print(c)，并将返回值压入栈中，print 的返回值是 None
           12 CALL_FUNCTION            1
            // 弹出栈顶的返回值，因为没有用变量保存，所以会直接丢弃
           14 POP_TOP
            // 隐式的 return None
           16 LOAD_CONST               0 (None)
           18 RETURN_VALUE
</code></pre>
<p>注意里面的 LOAD_FAST 和 STORE_FAST，这两个指令对应的逻辑如下。</p>
<pre><code class="language-C">case TARGET(LOAD_FAST): {
    // 通过宏 GETLOCAL 获取局部变量的值
    PyObject *value = GETLOCAL(oparg);
    // 如果值为 NULL，抛出 UnboundLocalError
    if (value == NULL) {
        format_exc_check_arg(tstate, PyExc_UnboundLocalError,
                             UNBOUNDLOCAL_ERROR_MSG,
                             PyTuple_GetItem(co-&gt;co_varnames, oparg));
        goto error;
    }
    // 增加引用计数并压入运行时栈
    Py_INCREF(value);
    PUSH(value);
    FAST_DISPATCH();
}


case TARGET(STORE_FAST): {
    PREDICTED(STORE_FAST);
    // 获取栈顶元素
    PyObject *value = POP();
    // 通过宏 SETLOCAL 创建局部变量
    SETLOCAL(oparg, value);
    FAST_DISPATCH();
}
</code></pre>
<p>所以 LOAD_FAST 和 STORE_FAST 分别负责加载和创建局部变量，而核心就是里面的两个宏：GETLOCAL、SETLOCAL，这两个宏也是定义在帧评估函数里面的。</p>
<pre><code class="language-C">// Python/ceval.c

// 在帧评估函数中，fastlocals 会被赋值为 f-&gt;f_localsplus
#define GETLOCAL(i)     (fastlocals[i])

#define SETLOCAL(i, value)      do { PyObject *tmp = GETLOCAL(i); \
                                     GETLOCAL(i) = value; \
                                     Py_XDECREF(tmp); } while (0)
/* 这里额外再补充一个关于 C 语言的知识点
 * 我们看到宏 SETLOCAL 展开之后的结果是 do {...} while (0) 
 * do while 循环会先执行 do 里面的循环体，然后再判断条件是否满足
 * 因此从效果上来说，执行 do {...} while (0) 和直接执行 ... 是等价的
 * 那么问题来了，既然效果等价，为啥还要再套一层 do while 呢
 * 其实原因很简单，如果宏在展开之后会生成多条语句，那么这些语句要成为一个整体
 * 另外由于 C 程序的语句要以分号结尾，所以在调用宏时，我们也会习惯性地在结尾加上分号
 * 因此我们希望有这样一种结构，能同时满足以下要求：
 *   1）可以将多条语句包裹起来，作为一个整体；
 *   2）程序的语义不能发生改变；
 *   3）在语法上，要以分号结尾；
 * 显然 do while 完美满足以上三个要求，只需将 while 里的条件设置为 0 即可
 * 并且当编译器看到 while (0) 时，也会进行优化，去掉不必要的循环控制结构
 * 因此以后看到 do {...} while (0) 时，不要觉得奇怪，这是宏的一个常用技巧
 */
</code></pre>
<p>我们看到操作局部变量，就是在基于索引操作数组 f_localsplus，显然这个过程比操作字典要快。尽管字典是经过高度优化的，但显然再怎么优化，也不可能快过数组的静态操作。</p>
<p>所以此时我们对局部变量的藏身之处已经了然于心，它们就存放在栈帧的 f_localsplus 字段中，而之所以没有使用 local 名字空间的原因也很简单。因为函数内部的局部变量在编译时就已经确定了，个数是不会变的，因此编译时也能确定局部变量占用的内存大小，以及访问局部变量的字节码指令应该如何访问内存。</p>
<pre><code class="language-Python">def foo(a, b):
    c = a + b
    print(c)

print(
    foo.__code__.co_varnames
)  # ('a', 'b', 'c')
</code></pre>
<p>比如变量 c 位于符号表中索引为 2 的位置，这在编译时就已确定。</p>
<ul>
<li>当创建变量 c 时，只需修改数组 f_localsplus 中索引为 2 的元素即可。</li>
<li>当访问变量 c 时，只需获取数组 f_localsplus 中索引为 2 的元素即可。</li>
</ul>
<p>这个过程是基于数组索引实现的静态查找，所以操作局部变量和操作全局变量有着异曲同工之妙。操作全局变量本质上是基于 key 操作字典的 value，其中 key 是变量的名称，value 是变量的值；而操作局部变量本质上是基于索引操作数组 f_localsplus 的元素，这个索引就是变量名在符号表中的索引，对应的数组元素就是变量的值。</p>
<blockquote>
<p>所以我们说 Python 的变量其实就是个名字，或者说符号，到这里是不是更加深刻地感受到了呢？</p>
</blockquote>
<p>但对于局部变量来说，如果想实现静态查找，显然要满足一个前提：变量名在符号表中的索引和与之绑定的值在 f_localsplus 中的索引必须是一致的。毫无疑问，两者肯定是一致的，并且索引是多少在编译阶段便已经确定，会作为指令参数保存在字节码指令序列中。</p>
<p>好，到此可以得出结论，虽然虚拟机为函数实现了 local 名字空间（初始为 NULL），但在操作局部变量时却没有使用它，原因就是为了更高的效率。当然还有所谓的 LEGB，都说变量查找会遵循这个规则，但我们心里清楚，局部变量其实是静态访问的，不过完全可以按照 LEGB 的方式来理解。</p>
<h2 id="解密-local-名字空间"><a class="header" href="#解密-local-名字空间">解密 local 名字空间</a></h2>
<p>先来看一下全局名字空间：</p>
<pre><code class="language-Python">x = 1

def foo():
    globals()[&quot;x&quot;] = 2
    
foo()
print(x)  # 2
</code></pre>
<p>global 空间全局唯一，在 Python 层面上就是一个字典，在任何地方操作该字典，都相当于操作全局变量，即使是在函数内部。因此在执行完 foo() 之后，全局变量 x 就被修改了。但 local 名字空间也是如此吗？我们尝试一下。</p>
<pre><code class="language-Python">def foo():
    x = 1
    locals()[&quot;x&quot;] = 2
    print(x)

foo()  # 1
</code></pre>
<p>我们按照相同的套路，却并没有成功，这是为什么？原因就是上面解释的那样，函数内部有哪些局部变量在编译时就已经确定了，查询的时候是从数组 f_localsplus 中静态查找的，而不是从 local 名字空间中查找。</p>
<p>然后我们打印一下 local 名字空间，看看里面都有哪些内容。</p>
<pre><code class="language-Python">def foo():
    name = &quot;satori&quot;
    print(locals())
    age = 17
    print(locals())
    gender = &quot;female&quot;
    print(locals())

foo()
&quot;&quot;&quot;
{'name': 'satori'}
{'name': 'satori', 'age': 17}
{'name': 'satori', 'age': 17, 'gender': 'female'}
&quot;&quot;&quot;
</code></pre>
<p>我们看到打印 locals() 居然也会显示内部的局部变量，相信聪明如你已经猜到 locals() 是怎么回事了。符号表里面存储了局部变量的符号（或者说名字），f_localsplus 里面存储了局部变量的值，当执行 locals() 的时候，会基于符号表和 f_localsplus 创建一个字典出来。</p>
<pre><code class="language-Python">def foo():
    name = &quot;satori&quot;
    age = 17
    gender = &quot;female&quot;
    print(locals())

# 符号表：保存了函数中创建的局部变量的名字
print(foo.__code__.co_varnames)
&quot;&quot;&quot;
('name', 'age', 'gender')
&quot;&quot;&quot;
# 调用函数时会创建栈帧，局部变量的值都保存在 f_localsplus 里面
# 并且符号表中变量名的顺序和 f_localsplus 中变量值的顺序是一致的
f_localsplus = [&quot;satori&quot;, 17, &quot;female&quot;]
# 这里就用一个列表来模拟了
</code></pre>
<p>我们来看一下变量的创建。</p>
<ul>
<li>由于符号 name 位于符号表中索引为 0 的位置，那么执行 <font color="blue">name = &quot;satori&quot;</font> 时，就会将 &quot;satori&quot; 放在 f_localsplus 中索引为 0 的位置。</li>
<li>由于符号 age 位于符号表中索引为 1 的位置，那么执行 <font color="blue">age = 17</font> 时，就会将 17 放在 f_localsplus 中索引为 1 的位置。</li>
<li>由于符号 gender 位于符号表中索引为 2 的位置，那么执行 <font color="blue">gender = &quot;female&quot;</font> 时，就会将 &quot;female&quot; 放在 f_localsplus 中索引为 2 的位置。</li>
</ul>
<p>后续在访问变量的时候，比如访问变量 age，由于它位于符号表中索引为 1 的位置，那么就会通过 f_localsplus[1] 获取它的值，这些符号对应的索引都是在编译阶段确定的。所以在运行时才能实现静态查找，指令 LOAD_FAST 和 STORE_FAST 都是基于索引来静态操作底层数组。</p>
<p>我们用一张图来描述这个过程：</p>
<p><img src="./images/184.png" alt="" /></p>
<p>符号表负责存储局部变量的名字，f_localsplus 负责存储局部变量的值（里面的元素初始为 NULL），而在给局部变量赋值的时候，本质上就是将值写在了 f_localsplus 中。并且变量名在符号表中的索引，和变量值在 f_localsplus 中的索引是一致的，因此操作局部变量本质上就是在操作 f_localsplus 数组。至于 locals() 或者说局部名字空间，它是基于符号表和 f_localsplus 动态创建的，为了方便我们获取已存在的局部变量，执行 locals() 会临时创建一个字典（只会创建一次）。</p>
<p>所以我们通过 locals() 获取局部名字空间之后，访问里面的局部变量是可以的，只不过此时将静态访问变成了动态访问。</p>
<pre><code class="language-Python">def foo():
    name = &quot;satori&quot;
    # 会从 f_localsplus 中静态查找
    print(name)
    # 先基于已有的变量和值创建一个字典
    # 然后通过字典实现变量的动态查找
    print(locals()[&quot;name&quot;])

foo()
&quot;&quot;&quot;
satori
satori
&quot;&quot;&quot;
</code></pre>
<p>两种方式都是可以的，但基于 locals() 来访问，在效率上明显会低一些。</p>
<p>另外基于 locals() 访问一个变量是可以的，但无法创建一个变量。</p>
<pre><code class="language-Python">def foo():
    name = &quot;satori&quot;
    locals()[&quot;age&quot;] = 17
    try:
        print(age)
    except NameError as e:
        print(e)

foo()
&quot;&quot;&quot;
name 'age' is not defined
&quot;&quot;&quot;
</code></pre>
<p>局部变量是静态存储在数组里的，locals() 只是做了一个拷贝而已。往局部名字空间里面添加一个键值对，不等于创建一个局部变量，因为局部变量不是从它这里查找的，因此代码中打印 age 报错了。但如果外部还有一个全局变量 age 的话，那么会打印全局变量 age。</p>
<p>然后再补充一点，我们说全局名字空间在任何地方都是唯一的，而对于函数而言，它的局部名字空间在整个函数内部也是唯一的。不管调用 locals 多少次，拿到的都是同一个字典。</p>
<pre><code class="language-python">def foo():
    name = &quot;satori&quot;
    # 执行 locals() 的时候，内部只有一个键值对
    d = locals()
    print(d)  # {'name': 'satori'}
    # 再次获取，此时有两个键值对
    print(locals())  # {'name': 'satori', 'd': {...}}
    
    # 但两者的 id 相同，因为一个函数只有一个局部名字空间
    # 不管调用多少次 locals()，拿到的都是同一个字典
    print(id(d) == id(locals()))  # True

foo()
</code></pre>
<p>所以 locals() 和 globals() 指向的名字空间都是唯一的，只不过 locals() 是在某个函数内部唯一，而 globals() 在所有地方都唯一。</p>
<p>因此局部名字空间初始为 NULL，但在第一次执行 locals() 时，会以符号表中的符号作为 key，f_localsplus 中的值作为 value，创建一个字典作为函数的局部名字空间。而后续再执行 locals() 的时候，由于名字空间已存在，就不会再次创建了，直接基于当前的局部变量对字典进行更新即可。</p>
<pre><code class="language-Python">def foo():
    # 创建一个字典，由于当前还没有定义局部变量，因此是空字典
    print(locals())  # {}

    # 往局部名字空间添加一个键值对
    locals()[&quot;a&quot;] = &quot;b&quot;
    print(locals())  # {'a': 'b'}

    # 定义一个局部变量
    name = &quot;satori&quot;
    # 由于局部名字空间已存在，因此不会再次创建
    # 直接将局部变量的名字作为 key、值作为 value，拷贝到字典中
    print(locals())  # {'a': 'b', 'name': 'satori'}

foo()
</code></pre>
<p>注意：虽然局部名字空间里面存在 &quot;a&quot; 这个 key，但 a 这个局部变量是不存在的。</p>
<h2 id="local-名字空间的创建过程"><a class="header" href="#local-名字空间的创建过程">local 名字空间的创建过程</a></h2>
<p>目前我们已经知道 local 名字空间是怎么创建的了，也熟悉了它的特性，下面通过源码来看一下它的构建过程。</p>
<pre><code class="language-C">// Python/bltinmodule.c

static PyObject *
builtin_locals_impl(PyObject *module)
{
    PyObject *d;
    // Python 内置函数的源码实现位于 bltinmodule.c 中
    // 这里又调用了 PyEval_GetLocals
    d = PyEval_GetLocals();
    Py_XINCREF(d);
    return d;
}

// Python/ceval.c
PyObject *
PyEval_GetLocals(void)
{
    // 获取线程状态对象
    PyThreadState *tstate = _PyThreadState_GET();
    // 拿到当前栈桢
    PyFrameObject *current_frame = _PyEval_GetFrame(tstate);
    if (current_frame == NULL) {
        _PyErr_SetString(tstate, PyExc_SystemError, &quot;frame does not exist&quot;);
        return NULL;
    }
    // 调用 PyFrame_FastToLocalsWithError 创建 local 名字空间
    // 并赋值给 current_frame-&gt;f_locals
    if (PyFrame_FastToLocalsWithError(current_frame) &lt; 0) {
        return NULL;
    }

    assert(current_frame-&gt;f_locals != NULL);
    // 返回 current_frame-&gt;f_locals
    return current_frame-&gt;f_locals;
}

// Objects/frameobject.c
int
PyFrame_FastToLocalsWithError(PyFrameObject *f)
{
    PyObject *locals, *map;
    PyObject **fast;
    PyCodeObject *co;
    Py_ssize_t j;
    Py_ssize_t ncells, nfreevars;
    
    // 栈桢不能为空
    if (f == NULL) {
        PyErr_BadInternalCall();
        return -1;
    }
    // 获取局部名字空间
    locals = f-&gt;f_locals;
    // 如果为 NULL，那么创建一个新字典，作为名字空间
    // 所以局部名字空间只会创建一次，后续不会再创建
    if (locals == NULL) {
        locals = f-&gt;f_locals = PyDict_New();
        if (locals == NULL)
            return -1;
    }
    // 获取 PyCodeObject 对象
    co = f-&gt;f_code;
    // 拿到内部的符号表（一个元组），里面保存了函数局部变量的名字
    map = co-&gt;co_varnames;
    if (!PyTuple_Check(map)) {
        PyErr_Format(PyExc_SystemError,
                     &quot;co_varnames must be a tuple, not %s&quot;,
                     Py_TYPE(map)-&gt;tp_name);
        return -1;
    }
    // 获取 f_localsplus，它里面保存了局部变量的值
    // 只不过除了局部变量的值之外，还保存了其它的
    fast = f-&gt;f_localsplus;
    // 那么 f_localsplus 里面到底有多少个局部变量的值呢？显然这要基于符号表来判断
    // co_varnames 里面保存了多少个符号，f_localsplus 里面就保存了多少个局部变量的值
    j = PyTuple_GET_SIZE(map);
    if (j &gt; co-&gt;co_nlocals)
        // 理论上符号表的长度和局部变量的个数（co_nlocals）是相等的
        // 但如果超过了 co_nlocals，那么让它等于 co_nlocals
        j = co-&gt;co_nlocals;
   
    // 如果 co_nlocals 大于 0，证明存在局部变量，那么调用 map_to_dict
    // 将 co_varnames 和 f_localsplus 里的元素组成键值对，添加到局部名字空间中
    if (co-&gt;co_nlocals) {
        // 相当于 locals.update(zip(co_varnames, f_localsplus))
        if (map_to_dict(map, j, locals, fast, 0) &lt; 0)
            return -1;
    }
    // 如果里面有 cell 变量和 free 变量的话，也会添加到局部名字空间中
    // 关于 cell 变量和 free 变量，由于它们和闭包相关，所以等介绍闭包的时候再说
    ncells = PyTuple_GET_SIZE(co-&gt;co_cellvars);
    nfreevars = PyTuple_GET_SIZE(co-&gt;co_freevars);
    if (ncells || nfreevars) {
        if (map_to_dict(co-&gt;co_cellvars, ncells,
                        locals, fast + co-&gt;co_nlocals, 1))
            return -1;
        if (co-&gt;co_flags &amp; CO_OPTIMIZED) {
            if (map_to_dict(co-&gt;co_freevars, nfreevars,
                            locals, fast + co-&gt;co_nlocals + ncells, 1) &lt; 0)
                return -1;
        }
    }
    return 0;
}
</code></pre>
<p>可以看到，源码的实现逻辑和我们之前分析的是一样的。</p>
<ul>
<li>变量 map 是符号表 co_varnames，保存了局部变量的名字；</li>
<li>变量 fast 是 f_localsplus，保存了局部变量的值；</li>
<li>变量 j 是局部变量的个数；</li>
<li>变量 locals 是局部名字空间；</li>
</ul>
<p>然后将它们作为参数，传递给 map_to_dict 函数，该函数内部会进行遍历，按照顺序将变量名和变量值依次添加到局部名字空间中。然后我们再来看一下 map_to_dict 函数，它内部有一处细节非常之关键。</p>
<pre><code class="language-C">// Objects/frameobject.c

static int
map_to_dict(PyObject *map, Py_ssize_t nmap, PyObject *dict, PyObject **values,
            int deref)
{
    Py_ssize_t j;
    assert(PyTuple_Check(map));
    assert(PyDict_Check(dict));
    assert(PyTuple_Size(map) &gt;= nmap);
    // nmap 表示局部变量的个数
    for (j=0; j &lt; nmap; j++) {
        // 从符号表中获取符号（变量名）
        PyObject *key = PyTuple_GET_ITEM(map, j);
        // values 就是 f_localsplus，然后获取变量的值
        PyObject *value = values[j];
        assert(PyUnicode_Check(key));
        // 闭包变量相关，等介绍闭包的时候再说，由于当前不存在闭包，所以先忽略掉
        if (deref &amp;&amp; value != NULL) {
            assert(PyCell_Check(value));
            value = PyCell_GET(value);
        }
        // 注意这一步：检测 value 是否等于 NULL，那么问题来了，什么时候 value 会等于 NULL 呢？
        // 之前说了，局部变量有哪些在编译的时候就确定了，保存在符号表中，局部变量的值保存在 f_localsplus 中
        // 在局部变量还没有赋值的时候，它在 f_localsplus 中对应的值就是 NULL
        // 而给一个局部变量赋值，本质上就是在修改 f_localsplus
        // 假设一个函数的符号表为 (&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)，在给变量 c 赋值之前调用了 locals()
        // 那么在获取变量 c 对应的值时，拿到的就是一个 NULL
        if (value == NULL) {
            // 如果某个符号对应的值为 NULL，则说明在获取名字空间时，该变量还没有被赋值
            // 那么当该符号在 local 空间中已存在时，还要将它删掉。这一步非常关键，它的作用我们稍后会说
            if (PyObject_DelItem(dict, key) != 0) {
                if (PyErr_ExceptionMatches(PyExc_KeyError))
                    PyErr_Clear();
                else
                    return -1;
            }
        }
        // 如果 value 不等于 NULL，说明变量已经完成了和某个值的绑定，于是将它们组成键值对拷贝到 local 空间中
        else {
            if (PyObject_SetItem(dict, key, value) != 0)
                return -1;
        }
    }
    return 0;
}
</code></pre>
<p>以上就是 local 名字空间的获取过程在源码层面的体现。</p>
<h2 id="local-名字空间与-exec-函数"><a class="header" href="#local-名字空间与-exec-函数">local 名字空间与 exec 函数</a></h2>
<p>我们再来搭配 exec 关键字，结果会更加明显。首先 exec 函数可以将一段字符串当成代码来执行，并将执行结果体现在当前的名字空间中。</p>
<pre><code class="language-Python">def foo():
    print(locals())  # {}
    exec(&quot;x = 1&quot;)
    print(locals())  # {'x': 1}
    try:
        print(x)
    except NameError as e:
        print(e)  # name 'x' is not defined
        
foo()
</code></pre>
<p>尽管 locals() 变了，但是依旧访问不到 x，因为虚拟机并不知道 <font color="blue">exec(&quot;x = 1&quot;)</font> 是创建一个局部变量，它只知道这是一个函数调用。</p>
<blockquote>
<p>事实上 exec 会作为一个独立的编译单元来执行，并且有自己的作用域。</p>
</blockquote>
<p>所以 exec(&quot;x = 1&quot;) 执行完之后，效果就是改变了局部名字空间，里面多了一个 <font color="blue">&quot;x&quot;: 1</font> 键值对。但关键的是，局部变量 x 不是从局部名字空间中查找的，exec 终究还是错付了人。而由于函数 foo 对应的 PyCodeObject 对象的符号表中并没有 x 这个符号，所以报错了。</p>
<blockquote>
<p>补充：exec 默认影响的是 local 名字空间，如果在执行时发现 local 名字空间为 NULL，那么会自动创建一个。所以调用 exec 也可以创建名字空间（当它为 NULL 时）。</p>
</blockquote>
<pre><code class="language-python">exec(&quot;x = 1&quot;)
print(x)  # 1
</code></pre>
<p>如果放在模块里面是可以的，因为模块的 local 名字空间和 global 名字空间指向同一个字典，所以 global 名字空间会多一个 key 为 &quot;x&quot; 的键值对。而全局变量是从 global 名字空间中查找的，所以这里没有问题。</p>
<pre><code class="language-python">def foo():
    # 此时 exec 影响的是 global 名字空间
    exec(&quot;x = 123&quot;, globals())
    # 所以这里不会报错, 但此时的 x 不是局部变量, 而是全局变量
    print(x)

foo()
print(x)
&quot;&quot;&quot;
123
123
&quot;&quot;&quot;
</code></pre>
<p>可以给 exec 指定要影响的名字空间，代码中 exec 影响的是全局名字空间，打印的 x 也是全局变量。</p>
<h2 id="变量名冲突的问题"><a class="header" href="#变量名冲突的问题">变量名冲突的问题</a></h2>
<p>我们说 exec 的执行效果会体现在 local 名字空间中，但是需要考虑变量名冲突的问题。举个例子：</p>
<pre><code class="language-Python">def foo():
    exec(&quot;x = 1&quot;)
    print(locals()[&quot;x&quot;])

foo()
&quot;&quot;&quot;
1
&quot;&quot;&quot;

def bar():
    exec(&quot;x = 1&quot;)
    print(locals()[&quot;x&quot;])
    x = 123

bar()
&quot;&quot;&quot;
Traceback (most recent call last):
  File .....
    bar()
  File .....
    print(locals()[&quot;x&quot;])
KeyError: 'x'
&quot;&quot;&quot;
</code></pre>
<p>这是什么情况？函数 bar 只是多了一行赋值语句，为啥就报错了呢？要想搞懂这个问题，首先要明确两点：</p>
<ul>
<li>1）函数的局部变量在编译的时候就已经确定，并存储在对应的 PyCodeObject 对象的符号表 (co_varnames) 中，这是由语法规则所决定的；</li>
<li>2）函数内的局部变量在其整个作用域范围内都是可见的；</li>
</ul>
<p>对于 foo 函数来说，exec 执行完之后相当于往 local 名字空间中添加一个键值对，这没有问题。对于 bar 函数而言也是如此，在执行完 <font color="blue">exec(&quot;x = 1&quot;)</font> 之后，local 名字空间中也会存在 <font color="blue">&quot;x&quot;: 1</font> 这个键值对，但下面执行 locals() 的时候又把字典更新了。因为局部变量可以在函数的任意位置创建，或者修改，所以每一次执行 locals() 的时候，都会遍历符号表和 f_localsplus，组成键值对将原来的字典更新一遍。</p>
<p>在 bar 函数里面有一行 x  = 123，所以知道函数里面存在局部变量 x，符号表里面也会有 &quot;x&quot; 这个符号，这是在编译时就确定的。但我们是在 <font color="blue">x = 123</font> 之前调用的 locals，所以此时符号 x 在 f_localsplus 中对应的值还是一个 NULL，没有指向一个合法的 PyObject。换句话说就是，知道里面存在局部变量 x，但是还没有来得及赋值。</p>
<p>然后在更新名字空间的时候，如果发现值是个 NULL，那么就把名字空间中该变量对应的键值对给删掉。</p>
<p>我们回顾一下 map_to_dict 函数：</p>
<p><img src="./images/185.png" alt="" /></p>
<p>所以 bar 函数执行 locals()[&quot;x&quot;] 的时候，会先获取名字空间，原本里面是有 <font color="blue">&quot;x&quot;: 1</font> 这个键值对的。但因为赋值语句 <font color="blue">x = 123</font> 的存在，导致符号表里面存在 &quot;x&quot; 这个符号，但执行 locals() 的时候又尚未完成赋值，所以值为 NULL，于是又把这个键值对给删掉了。所以执行 locals()[&quot;x&quot;] 的时候，出现了 KeyError。</p>
<p>因为局部名字空间体现的是局部变量的值，而调用 locals 的时候，局部变量 x 还没有被创建。所以 locals() 里面不应该存在 key 为 &quot;x&quot; 的键值对，于是会将它删除。</p>
<p>我们将名字空间打印一下：</p>
<pre><code class="language-Python">def foo():
    # 创建局部名字空间，并写入键值对 &quot;x&quot;: 1
    # 此时名字空间为 {&quot;x&quot;: 1}
    exec(&quot;x = 1&quot;)
    # 获取名字空间，会进行更新
    # 但当前不存在局部变量，所以名字空间仍是 {&quot;x&quot;: 1}
    print(locals())

def bar():
    # 创建局部名字空间，并写入键值对 &quot;x&quot;: 1
    # 此时名字空间为 {&quot;x&quot;: 1}
    exec(&quot;x = 1&quot;)
    # 获取名字空间，会进行更新
    # 由于里面存在局部变量 x，但尚未赋值
    # 于是将字典中 key 为 &quot;x&quot; 的键值对给删掉
    # 所以名字空间变成了 {}
    print(locals())
    x = 123


foo()  # {'x': 1}
bar()  # {}
</code></pre>
<p>上面代码中，局部变量的创建发生在 exec 之后，如果发生在 exec 之前也是相同的结果。</p>
<pre><code class="language-Python">def foo():
    exec(&quot;x = 2&quot;)
    print(locals())

foo()  # {'x': 2}


def bar():
    x = 1
    exec(&quot;x = 2&quot;)
    print(locals())

bar()  # {'x': 1}
</code></pre>
<p>在 exec(&quot;x = 2&quot;) 执行之后，名字空间也变成了 {&quot;x&quot;: 2}。但从源码中我们看到，每次调用 locals，都会遍历符号表和 f_localsplus，对字典进行更新，所以在 bar 函数里面获取名字空间的时候，又把 &quot;x&quot; 对应的 value 给更新回来了。</p>
<p>当然这是在变量冲突的情况下，会保存真实存在的局部变量的值。但如果不冲突，比如 bar 函数里面是 <font color="blue">exec(&quot;y = 2&quot;)</font>，那么 locals() 里面就会存在两个键值对。但只有 x 才是真正的局部变量，而 y 则不是。</p>
<blockquote>
<p>将 exec(&quot;x = 2&quot;) 换成 locals()[&quot;x&quot;] = 2 也是一样的效果，它们都是往局部名字空间中添加一个键值对，但不会创建一个局部变量。</p>
</blockquote>
<h2 id="薛定谔的猫"><a class="header" href="#薛定谔的猫">薛定谔的猫</a></h2>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzUyOTk2MTcwNg==&amp;mid=2247484227&amp;idx=1&amp;sn=f823e086fea6905175f0099c7991303b&amp;scene=21#wechat_redirect">当 Python 中混进一只薛定谔的猫……</a>，这是猫哥在 19 年更新的一篇文章，里面探讨的内容我们本文的主题是重叠的。猫哥在文章中举了几个疑惑重重的例子，看看用上面学到的内容能不能合理地解释。</p>
<pre><code class="language-Python"># 例 0
def foo():
    exec('y = 1 + 1')
    z = locals()['y']
    print(z)

foo()
# 输出：2


# 例 1
def foo():
    exec('y = 1 + 1')
    y = locals()['y']
    print(y)

foo()
# 报错：KeyError: 'y'
</code></pre>
<p>以上是猫哥文章中举的示例，首先例 0 很简单，因为 exec 影响了所在的局部名字空间，里面存在 <font color="blue">&quot;y&quot;: 2</font> 这个键值对。至于里面的变量 z 则不影响，因为我们获取的是 &quot;y&quot; 这个 key 对应的 value。</p>
<p>但例 1 则不同，因为 Python 在语法解析的时候发现了 <font color="blue">y = ...</font> 这样的赋值语句，那么它在编译的时候就知道函数里面存在 y 这个局部变量，并写入符号表中。既然符号表中存在，那么调用 locals 的时候就会对它进行更新。但是对 y 赋值是发生在调用 locals 之后，所以在调用 locals 的时候，y 的值还是一个 NULL，也就是变量还没有赋值。所以会将名字空间中的 <font color="blue">&quot;y&quot;: 2</font> 这个键值对给删掉，于是报出 KeyError 错误。</p>
<p><font color="darkblue"><strong>再来看看猫哥文章的例 2：</strong></font></p>
<pre><code class="language-python"># 例 2
def foo():
    y = 1 + 1
    y = locals()['y']
    print(y)

foo()
# 输出：2
</code></pre>
<p>locals() 是对真实存在的局部变量的一个拷贝，在调用 locals 之前 y 就已经创建好了。符号表里面有 &quot;y&quot;，f_localsplus 里面有一个数值 2，所以调用 locals() 的时候，会得到 <font color="blue">{&quot;y&quot;: 2}</font>，因此函数执行正常。</p>
<p><font color="darkblue"><strong>猫哥文章的例 3：</strong></font></p>
<pre><code class="language-Python"># 例3
def foo():
    exec('y = 1 + 1')
    boc = locals()
    y = boc['y']
    print(y)

foo()
# KeyError: 'y'
</code></pre>
<p>这个例3 和例1 是一样的，只不过用变量 boc 将局部名字空间保存起来了。执行 exec 的时候，会创建局部名字空间，写入键值对 <font color="blue">&quot;y&quot;: 2</font>。但调用 locals 的时候，发现函数内部存在局部变量 y 并且还尚未赋值，于是又会将 <font color="blue">&quot;y&quot;: 2</font> 这个键值对给删掉，因此 boc 变成了一个空字典。</p>
<p>所以在执行 y = boc[&quot;y&quot;] 的时候会出现 KeyError。</p>
<p><font color="darkblue"><strong>猫哥文章的例 4：</strong></font></p>
<pre><code class="language-Python"># 例4
def foo():
    boc = locals()
    exec('y = 1 + 1')
    y = boc['y']
    print(y)

foo()
# 输出：2
</code></pre>
<p>显然在调用 locals 的时候，会返回一个空字典，因为此时的局部变量都还没有赋值。但需要注意的是：boc 已经指向了局部名字空间（字典），而局部名字空间在一个函数里面也是唯一的。所以 <font color="blue">exec(&quot;y = 1 + 1&quot;)</font> 执行之后，会往局部名字空间里面写入一个键值对，而变量 boc 指向的字典也会发生改变，因为是同一个字典，所以程序正常执行。</p>
<p><font color="darkblue"><strong>猫哥文章的例 5：</strong></font></p>
<pre><code class="language-python"># 例5
def foo():
    boc = locals()
    exec('y = 1 + 1')
    print(locals())
    y = boc['y']
    print(y)

foo()
# {'boc': {...}} 
# KeyError: 'y'
</code></pre>
<p>首先在执行 boc = locals() 之后，boc 会指向一个空字典，然后 exec 函数执行之后会往字典里面写入一个键值对 <font color="blue">&quot;y&quot;: 2</font>。如果在 exec 执行之后，直接执行 <font color="blue">y = boc[&quot;y&quot;]</font>，那么代码是没有问题的，但问题是执行之前插入了一个 print(locals())。</p>
<p>我们说过，当调用 locals 的时候，会对名字空间进行更新，然后返回更新之后的名字空间。由于函数内部存在 <font color="blue">y = ...</font> 这样的赋值语句，所以符号表中就存在 &quot;y&quot; 这个符号，于是会进行更新。但更新的时候，发现 y 还没有被赋值，于是又将字典中的键值对 <font color="blue">&quot;y&quot;: 2</font> 给删掉了。</p>
<p>由于局部名字空间只有一份，所以 boc 指向的字典也会发生改变，换句话说在 print(locals()) 之后，boc 就指向了一个空字典，因此执行 <font color="blue">y = boc[&quot;y&quot;]</font> 时会出现 KeyError。</p>
<h2 id="小结-46"><a class="header" href="#小结-46">小结</a></h2>
<p>以上我们就探讨了 local 名字空间相关的内容，它是一个字典，是对真实存在的局部变量的一个拷贝，每当我们调用 locals，都会拷贝一次（但字典只会存在一份）。</p>
<p>然后函数的局部变量都是静态存储的，编译时就已经确定，无法在运行时动态添加。我们往局部名字空间里面添加键值对，并不等价于创建局部变量。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-47"><a class="header" href="#楔子-47">楔子</a></h2>
<p>前面我们考察了虚拟机执行字节码指令的原理，那么本篇文章就来看看这些指令对应的逻辑是怎样的，每个指令都做了哪些事情。当然啦，由于字节码指令有一两百个，我们没办法逐一分析，这里会介绍一些常见的。至于其它的指令，会随着学习的深入，慢慢揭晓。</p>
<p>介绍完常见指令之后，我们会探讨 Python 赋值语句的背后原理，并分析它们的差异。</p>
<h2 id="常用指令"><a class="header" href="#常用指令">常用指令</a></h2>
<p>有一部分指令出现的频率极高，非常常用，我们来看一下。</p>
<ul>
<li>LOAD_CONST：加载一个常量；</li>
<li>LOAD_FAST：在局部作用域中加载一个局部变量；</li>
<li>LOAD_GLOBAL：在局部作用域中加载一个全局变量或内置变量；</li>
<li>LOAD_NAME：在全局作用域中加载一个全局变量或内置变量；</li>
<li>STORE_FAST：在局部作用域中定义一个局部变量，来建立和某个对象之间的映射关系；</li>
<li>STORE_GLOBAL：在局部作用域中定义一个使用 global 关键字声明的全局变量，来建立和某个对象之间的映射关系；</li>
<li>STORE_NAME：在全局作用域中定义一个全局变量，来建议和某个对象之间的映射关系；</li>
</ul>
<p>我们举例说明：</p>
<pre><code class="language-Python">import dis

name = &quot;古明地觉&quot;

def foo():
    age = 16
    print(age)
    global name
    print(name)
    name = &quot;古明地恋&quot;

dis.dis(foo)
&quot;&quot;&quot;
  6           0 LOAD_CONST               1 (16)
              2 STORE_FAST               0 (age)

  7           4 LOAD_GLOBAL              0 (print)
              6 LOAD_FAST                0 (age)
              8 CALL_FUNCTION            1
             10 POP_TOP

  9          12 LOAD_GLOBAL              0 (print)
             14 LOAD_GLOBAL              1 (name)
             16 CALL_FUNCTION            1
             18 POP_TOP

 10          20 LOAD_CONST               2 ('古明地恋')
             22 STORE_GLOBAL             1 (name)
             24 LOAD_CONST               0 (None)
             26 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p><font color="darkblue"><strong>我们看到 age = 16 对应两条字节码指令。</strong></font></p>
<ul>
<li>LOAD_CONST：加载一个常量，这里是 16；</li>
<li>STORE_FAST：在局部作用域中创建一个局部变量，这里是 age；</li>
</ul>
<p><font color="darkblue"><strong>print(age) 对应四条字节码指令。</strong></font></p>
<ul>
<li>LOAD_GLOBAL：在局部作用域中加载一个全局变量或内置变量，这里是 print；</li>
<li>LOAD_FAST：在局部作用域中加载一个局部变量，这里是 age；</li>
<li>CALL_FUNCTION：函数调用；</li>
<li>POP_TOP：从栈顶弹出返回值；</li>
</ul>
<p><font color="darkblue"><strong>print(name) 对应四条字节码指令。</strong></font></p>
<ul>
<li>LOAD_GLOBAL：在局部作用域中加载一个全局变量或内置变量，这里是 print；</li>
<li>LOAD_GLOBAL：在局部作用域中加载一个全局变量或内置变量，这里是 name；</li>
<li>CALL_FUNCTION：函数调用；</li>
<li>POP_TOP：从栈顶弹出返回值；</li>
</ul>
<p><font color="darkblue"><strong>name = &quot;古明地恋&quot; 对应两条字节码指令。</strong></font></p>
<ul>
<li>LOAD_CONST：加载一个常量，这里是 &quot;古明地恋&quot;；</li>
<li>STORE_GLOBAL：在局部作用域中创建一个 global 关键字声明的全局变量，这里是 name；</li>
</ul>
<p>这些指令非常常见，因为它们和常量、变量的加载，以及变量的定义密切相关，你写的任何代码在反编译之后都少不了它们的身影。</p>
<blockquote>
<p>注：不管加载的是常量、还是变量，得到的永远是指向对象的指针。</p>
</blockquote>
<h2 id="变量赋值的具体细节"><a class="header" href="#变量赋值的具体细节">变量赋值的具体细节</a></h2>
<p>这里再通过变量赋值感受一下字节码的执行过程，首先关于变量赋值，你平时是怎么做的呢？</p>
<p><img src="./images/186.png" alt="" /></p>
<p>这些赋值语句背后的原理是什么呢？我们通过字节码来逐一回答。</p>
<p><font color="darkblue"><strong>1）a, b = b, a 的背后原理是什么？</strong></font></p>
<p>想要知道背后的原理，查看它的字节码是我们最好的选择。</p>
<pre><code class="language-C">  1           0 LOAD_NAME                0 (b)
              2 LOAD_NAME                1 (a)
              4 ROT_TWO
              6 STORE_NAME               1 (a)
              8 STORE_NAME               0 (b)
             10 LOAD_CONST               0 (None)
             12 RETURN_VALUE
</code></pre>
<p>里面关键的就是 ROT_TWO 指令，虽然我们还没看这个指令，但也能猜出来它负责交换栈里面的两个元素。假设 a 和 b 的值分别为 22、33，看一下运行时栈的变化过程。</p>
<p><img src="./images/187.png" alt="" /></p>
<p>示意图还是很好理解的，关键就在于 ROT_TWO 指令，它是怎么交换元素的呢？</p>
<pre><code class="language-C">case TARGET(ROT_TWO): {
    // 获取栈顶元素
    PyObject *top = TOP();
    // 获取从栈顶开始的第二个元素（栈底元素）
    PyObject *second = SECOND();
    // 将栈顶元素设置为 second，将栈的第二个元素设置为 top
    // 完成两个元素之间的交换
    SET_TOP(second);
    SET_SECOND(top);
    FAST_DISPATCH();
}
</code></pre>
<p>执行 ROT_TWO 指令之前，栈里有两个元素，栈顶元素是 a，栈底元素是 b。执行 ROT_TWO 指令之后，栈顶元素是 b，栈底元素是 a。然后后面的两个 STORE_NAME 会将栈里面的元素 b、a 依次弹出，赋值给 a、b，从而完成变量交换。</p>
<p><font color="darkblue"><strong>2）a, b, c = c, b, a 的背后原理是什么？</strong></font></p>
<p>老规矩，还是查看字节码，因为一切真相都隐藏在字节码当中。</p>
<pre><code class="language-C">  1           0 LOAD_NAME                0 (c)
              2 LOAD_NAME                1 (b)
              4 LOAD_NAME                2 (a)
              6 ROT_THREE
              8 ROT_TWO
             10 STORE_NAME               2 (a)
             12 STORE_NAME               1 (b)
             14 STORE_NAME               0 (c)
             16 LOAD_CONST               0 (None)
             18 RETURN_VALUE
</code></pre>
<p>整个过程和 a, b = b, a 是相似的，首先 LOAD_NAME 将变量 c、b、a 依次压入栈中。由于栈先入后出的特性，此时栈的三个元素按照顺序（从栈顶到栈底）分别是 a、b、c。然后是 ROT_THREE 和 ROT_TWO，毫无疑问，这两个指令执行完之后，会将栈的三个元素调换顺序，也就是将 a、b、c 变成 c、b、a。最后 STORE_NAME 将栈的三个元素 c、b、a 依次弹出，分别赋值给 a、b、c，从而完成变量的交换。</p>
<p>因此核心就在 ROT_THREE 和 ROT_TWO 上面，由于后者上面已经说过了，所以我们看一下 ROT_THREE。</p>
<pre><code class="language-C">case TARGET(ROT_THREE): {
    PyObject *top = TOP();
    PyObject *second = SECOND();
    PyObject *third = THIRD();
    SET_TOP(second);
    SET_SECOND(third);
    SET_THIRD(top);
    FAST_DISPATCH();
}
</code></pre>
<p>栈顶元素是 top、栈的第二个元素是 second、栈的第三个元素是 third，然后将栈顶元素设置为 second、栈的第二个元素设置为 third、栈的第三个元素设置为 top。所以栈里面的 a、b、c 在经过 ROT_THREE 之后就变成了 b、c、a，显然这还不是正确的结果。于是继续执行 ROT_TWO，将栈的前两个元素进行交换，执行完之后就变成了 c、b、a。</p>
<p>假设 a、b、c 的值分别为 &quot;a&quot;、&quot;b&quot;、&quot;c&quot;，整个过程如下：</p>
<p><img src="./images/188.png" alt="" /></p>
<p>对于多元赋值来说，解释器的做法是固定的，首先按照从左往右的顺序，将等号右边的变量依次压入栈中，然后在栈里面对元素做处理，最后再将栈里的元素弹出，仍旧按照从左往右的顺序，依次赋值给等号左边的变量。</p>
<p>另外这里为了交换栈里的三个元素，使用了两个指令，但其实一个指令就够了，只需将栈顶元素和栈底元素进行交换即可，因为中间的元素是不需要动的。而在之后的版本中，官方优化了这个逻辑。</p>
<p><font color="darkblue"><strong>3）a, b, c, d = d, c, b, a 的背后原理是什么？它和上面提到的 1）和 2）有什么区别呢？</strong></font></p>
<p>我们还是看一下字节码。</p>
<pre><code class="language-C">  1           0 LOAD_NAME                0 (d)
              2 LOAD_NAME                1 (c)
              4 LOAD_NAME                2 (b)
              6 LOAD_NAME                3 (a)
              8 BUILD_TUPLE              4
             10 UNPACK_SEQUENCE          4
             12 STORE_NAME               3 (a)
             14 STORE_NAME               2 (b)
             16 STORE_NAME               1 (c)
             18 STORE_NAME               0 (d)
             20 LOAD_CONST               0 (None)
             22 RETURN_VALUE
</code></pre>
<p>将等号右边的变量，按照从左往右的顺序，依次压入栈中，但此时没有直接将栈里面的元素做交换，而是构建一个元组。因为往栈里面压入了四个元素，所以 BUILD_TUPLE 后面的 oparg 是 4，表示构建长度为 4 的元组。</p>
<pre><code class="language-C">case TARGET(BUILD_TUPLE): {
    // 元素从栈顶到栈底依次是 a、b、c、d
    PyObject *tup = PyTuple_New(oparg);
    if (tup == NULL)
        goto error;
    // 将元素依次弹出，弹出的顺序也是 a、b、c、d
    // 但是注意循环，元素是从后往前设置的
    // 所以 item[3], item[2], item[1], item[0] = a, b, c, d
    while (--oparg &gt;= 0) {
        PyObject *item = POP();
        PyTuple_SET_ITEM(tup, oparg, item);
    }
    // 将元组 item 压入栈中，元组为 (d, c, b, a)
    PUSH(tup);
    DISPATCH();
}
</code></pre>
<p>此时栈里面只有一个元素，指向一个元组。接下来是 UNPACK_SEQUENCE，负责对序列进行解包，它的指令参数也是 4，表示要解包的序列的长度为 4，我们来看看它的逻辑。</p>
<pre><code class="language-C">case TARGET(UNPACK_SEQUENCE): {
    PREDICTED(UNPACK_SEQUENCE);
    // seq：从栈里面弹出的元组 (d, c, b, a)
    // item：用于遍历元素
    // items：指向一个 PyObject * 类型的数组
    PyObject *seq = POP(), *item, **items;
    if (PyTuple_CheckExact(seq) &amp;&amp;
        PyTuple_GET_SIZE(seq) == oparg) {
        // 获取元组内部的 ob_item 字段，元素就存储在它指向的数组中
        items = ((PyTupleObject *)seq)-&gt;ob_item;
        // 遍历内部的每一个元素，并依次压入栈中
        // 由于是从后往前遍历的，所以遍历的元素依次是 a b c d
        // 但在压入栈中之后，元素从栈顶到栈底就变成了 d c b a
        while (oparg--) {
            item = items[oparg];
            Py_INCREF(item);
            PUSH(item);
        }
    } else if (PyList_CheckExact(seq) &amp;&amp;
               PyList_GET_SIZE(seq) == oparg) {
        // 该指令同样适用于列表，逻辑一样（一会儿会看到）
        items = ((PyListObject *)seq)-&gt;ob_item;
        while (oparg--) {
            item = items[oparg];
            Py_INCREF(item);
            PUSH(item);
        }
    } 
    // ...
    Py_DECREF(seq);
    DISPATCH();
}
</code></pre>
<p>最后 STORE_NAME 将 d c b a 依次弹出，赋值给变量 a b c d，从而完成变量交换。所以当交换的变量多了之后，不会直接在运行时栈里面操作，而是将栈里面的元素挨个弹出，构建元组；然后再按照指定顺序，将元组里面的元素重新压到栈里面。</p>
<p>假设变量 a b c d 的值分别为 1 2 3 4，我们画图来描述一下整个过程。</p>
<p><img src="./images/189.png" alt="" /></p>
<p>不管是哪一种做法，Python 在进行变量交换时所做的事情是不变的，核心分为三步走。首先将等号右边的变量，按照从左往右的顺序，依次压入栈中；然后对运行时栈里面元素的顺序进行调整；最后再将运行时栈里面的元素挨个弹出，还是按照从左往右的顺序，再依次赋值给等号左边的变量。</p>
<p>只不过当变量不多时，调整元素位置会直接基于栈进行操作；而当达到四个时，则需要额外借助于元组。</p>
<p>然后多元赋值也是同理，比如 a, b, c = 1, 2, 3，看一下它的字节码。</p>
<pre><code class="language-C">  1           0 LOAD_CONST               0 ((1, 2, 3))
              2 UNPACK_SEQUENCE          3
              4 STORE_NAME               0 (a)
              6 STORE_NAME               1 (b)
              8 STORE_NAME               2 (c)
             10 LOAD_CONST               1 (None)
             12 RETURN_VALUE
</code></pre>
<p>元组直接作为一个常量被加载进来了，然后解包，再依次赋值。</p>
<p><font color="darkblue"><strong>4）a, b, c, d = d, c, b, a 和 a, b, c, d = [d, c, b, a] 有区别吗？</strong></font></p>
<p>答案是没有区别，两者在反编译之后对应的字节码指令只有一处不同。</p>
<pre><code class="language-C">  1           0 LOAD_NAME                0 (d)
              2 LOAD_NAME                1 (c)
              4 LOAD_NAME                2 (b)
              6 LOAD_NAME                3 (a)
              8 BUILD_LIST               4
             10 UNPACK_SEQUENCE          4
             12 STORE_NAME               3 (a)
             14 STORE_NAME               2 (b)
             16 STORE_NAME               1 (c)
             18 STORE_NAME               0 (d)
             20 LOAD_CONST               0 (None)
             22 RETURN_VALUE
</code></pre>
<p>前者是 BUILD_TUPLE，现在变成了 BUILD_LIST，其它部分一模一样，并且解包用的依旧是 UNPACK_SEQUENCE 指令，所以两者的效果是相同的。当然啦，由于元组的构建比列表快一些，因此还是推荐第一种写法。</p>
<p><font color="darkblue"><strong>5）a = b = c = 123 背后的原理是什么？</strong></font></p>
<p>如果变量 a、b、c 指向的值相同，比如都是 123，那么便可以通过这种方式进行链式赋值。那么它背后是怎么做的呢？</p>
<pre><code class="language-C">  1           0 LOAD_CONST               0 (123)
              2 DUP_TOP
              4 STORE_NAME               0 (a)
              6 DUP_TOP
              8 STORE_NAME               1 (b)
             10 STORE_NAME               2 (c)
             12 LOAD_CONST               1 (None)
             14 RETURN_VALUE
</code></pre>
<p>出现了一个新的字节码指令 DUP_TOP，只要搞清楚它的作用，事情就简单了。</p>
<pre><code class="language-C">case TARGET(DUP_TOP): {
    // 获取栈顶元素，注意是获取、不是弹出
    // TOP：查看元素，POP：弹出元素
    PyObject *top = TOP();
    // 增加指向对象的引用计数
    Py_INCREF(top);
    // 压入栈中
    PUSH(top);
    FAST_DISPATCH();
}
</code></pre>
<p>所以 DUP_TOP 干的事情就是将栈顶元素拷贝一份，再重新压到栈里面。另外不管链式赋值语句中有多少个变量，模式都是一样的。</p>
<p>我们以 a = b = c = d = e = 123 为例：</p>
<pre><code class="language-C">  1           0 LOAD_CONST               0 (123)
              2 DUP_TOP
              4 STORE_NAME               0 (a)
              6 DUP_TOP
              8 STORE_NAME               1 (b)
             10 DUP_TOP
             12 STORE_NAME               2 (c)
             14 DUP_TOP
             16 STORE_NAME               3 (d)
             18 STORE_NAME               4 (e)
             20 LOAD_CONST               1 (None)
             22 RETURN_VALUE
</code></pre>
<p>将常量压入运行时栈，然后拷贝一份，赋值给 a；再拷贝一份，赋值给 b；再拷贝一份，赋值给 c；再拷贝一份，赋值给 d；最后自身赋值给 e。</p>
<blockquote>
<p>当然啦，虽然 Python 一切皆对象，但拿到的都是指向对象的指针，所以这里拷贝的是指针。</p>
</blockquote>
<p>以上就是链式赋值的秘密，其实没有什么好神奇的，就是将栈顶元素进行拷贝，再依次赋值。但是这背后有一个坑，就是给变量赋的值不能是可变对象，否则容易造成 BUG。</p>
<pre><code class="language-Python">a = b = c = {}

a[&quot;ping&quot;] = &quot;pong&quot;
print(a)  # {'ping': 'pong'}
print(b)  # {'ping': 'pong'}
print(c)  # {'ping': 'pong'}
</code></pre>
<p>虽然 Python 一切皆对象，但对象都是通过指针来间接操作的。所以 DUP_TOP 是将字典的地址拷贝一份，而字典只有一个，因此最终 a、b、c 会指向同一个字典。</p>
<p><font color="darkblue"><strong>6）a is b 和 a == b 的区别是什么？</strong></font></p>
<p>is 用于判断两个变量是不是引用同一个对象，也就是保存的对象的地址是否相等；而 == 则是判断两个变量引用的对象是否相等，等价于 a.__eq__(b) 。</p>
<blockquote>
<p>Python 的变量在 C 看来只是一个指针，因此两个变量是否指向同一个对象，等价于 C 中的两个指针存储的地址是否相等；</p>
<p>而 Python 的 ==，则需要调用 PyObject_RichCompare，来比较它们指向的对象所维护的值是否相等。</p>
</blockquote>
<p>这两个语句的字节码指令是一样的，唯一的区别就是指令 COMPARE_OP 的参数不同。</p>
<pre><code class="language-C">              // a is b
  1           0 LOAD_NAME                0 (a)
              2 LOAD_NAME                1 (b)
              4 COMPARE_OP               8 (is)
              6 POP_TOP
              8 LOAD_CONST               0 (None)
             10 RETURN_VALUE
  
              // a == b
  1           0 LOAD_NAME                0 (a)
              2 LOAD_NAME                1 (b)
              4 COMPARE_OP               2 (==)
              6 POP_TOP
              8 LOAD_CONST               0 (None)
             10 RETURN_VALUE      
</code></pre>
<p>我们看到指令参数一个是 8、一个是 2，然后是 COMPARE_OP 指令的背后逻辑：</p>
<pre><code class="language-C">case TARGET(COMPARE_OP): {
    // 弹出栈顶元素，这里是 b
    PyObject *right = POP();
    // 显然 left 就是 a，因为 b 被弹出之后，a 就成为了新的栈顶元素
    PyObject *left = TOP();
    // 进行比较，比较结果为 res
    PyObject *res = cmp_outcome(tstate, oparg, left, right);
    // 减少 left 和 right 引用计数
    Py_DECREF(left);
    Py_DECREF(right);
    // 将栈顶元素替换为 res
    SET_TOP(res);
    if (res == NULL)
        goto error;
    // 指令预测，暂时不用管，等介绍 if 控制流的时候再说
    PREDICT(POP_JUMP_IF_FALSE);
    PREDICT(POP_JUMP_IF_TRUE);
    DISPATCH();
}
</code></pre>
<p>所以逻辑很简单，核心就在 cmp_outcome 函数中。</p>
<pre><code class="language-C">// Python/ceval.c
static PyObject *
cmp_outcome(PyThreadState *tstate, int op, PyObject *v, PyObject *w)
{
    int res = 0;
    // op 就是 COMPARE_OP 指令的参数
    switch (op) {
    // PyCmp_IS 是一个枚举变量，等于 8，定义在 Include/opcode.h 中
    // 而 is 关键字，在 C 的层面就是一个 == 判断
    case PyCmp_IS:
        res = (v == w);
        break;
    // is not 则对应 !=
    case PyCmp_IS_NOT:
        res = (v != w);
        break;
    // in 关键字
    case PyCmp_IN:
        res = PySequence_Contains(w, v);
        if (res &lt; 0)
            return NULL;
        break;
    // not in 关键字
    case PyCmp_NOT_IN:
        res = PySequence_Contains(w, v);
        if (res &lt; 0)
            return NULL;
        res = !res;
        break;
    // except 关键字
    case PyCmp_EXC_MATCH:
        if (PyTuple_Check(w)) {
            Py_ssize_t i, length;
            length = PyTuple_Size(w);
            for (i = 0; i &lt; length; i += 1) {
                PyObject *exc = PyTuple_GET_ITEM(w, i);
                if (!PyExceptionClass_Check(exc)) {
                    _PyErr_SetString(tstate, PyExc_TypeError,
                                     CANNOT_CATCH_MSG);
                    return NULL;
                }
            }
        }
        else {
            if (!PyExceptionClass_Check(w)) {
                _PyErr_SetString(tstate, PyExc_TypeError,
                                 CANNOT_CATCH_MSG);
                return NULL;
            }
        }
        res = PyErr_GivenExceptionMatches(v, w);
        break;
    default:
        // 剩下的走 PyObject_RichCompare 逻辑
        // 这是一个函数调用，比较对象维护的值是否相等
        return PyObject_RichCompare(v, w, op);
    }
    v = res ? Py_True : Py_False;
    Py_INCREF(v);
    return v;
}
</code></pre>
<p>我们实际举个栗子：</p>
<pre><code class="language-Python">a = 3.14
b = float(&quot;3.14&quot;)
print(a is b)  # False
print(a == b)  # True
</code></pre>
<p>a 和 b 都是 3.14，两者是相等的，但不是同一个对象。</p>
<p>反过来也是如此，如果 a is b 成立，那么 a == b 也不一定成立。可能有人好奇，a is b 成立说明 a 和 b 指向的是同一个对象，那么 a == b 表示该对象和自己进行比较，结果应该始终是相等的呀，为啥也不一定成立呢？以下面两种情况为例：</p>
<pre><code class="language-Python">class Girl:

    def __eq__(self, other):
        return False

g = Girl()
print(g is g)  # True
print(g == g)  # False
</code></pre>
<p>__eq__ 返回 False，此时虽然是同一个对象，但是两者不相等。</p>
<pre><code class="language-Python">import math
import numpy as np

a = float(&quot;nan&quot;)
b = math.nan
c = np.nan
print(a is a, a == a)  # True False
print(b is b, b == b)  # True False
print(c is c, c == c)  # True False
</code></pre>
<p>nan 是一个特殊的浮点数，意思是 not a number（不是一个数字），用于表示空值。而 nan 和所有数字的比较结果均为 False，即使是和它自身比较。</p>
<p>但需要注意的是，在使用 == 进行比较的时候虽然是不相等的，但如果放到容器里面就不一定了。举个例子：</p>
<pre><code class="language-Python">import numpy as np

lst = [np.nan, np.nan, np.nan]
print(lst[0] == np.nan)  # False
print(lst[1] == np.nan)  # False
print(lst[2] == np.nan)  # False
# lst 里面的三个元素和 np.nan 均不相等

# 但是 np.nan 位于列表中，并且数量是 3
print(np.nan in lst)  # True
print(lst.count(np.nan))  # 3
</code></pre>
<p>出现以上结果的原因就在于，元素被放到了容器里，而容器的一些 API 在比较元素时会先判定它们存储的对象的地址是否相同，即：是否指向了同一个对象。如果是，直接认为相等；否则，再去比较对象维护的值是否相等。可以理解为先进行 is 判断，如果结果为 True，直接判定两者相等；如果 is 操作的结果不为 True，再去进行 == 判断。</p>
<p>因此 np.nan in lst 的结果为 True，lst.count(np.nan) 的结果是 3，因为它们会先比较对象的地址。地址相同，则直接认为对象相等。</p>
<blockquote>
<p>在用 pandas 做数据处理的时候，nan 是一个非常容易坑的地方。</p>
</blockquote>
<p>提到 is 和 ==，那么问题来了，在和 True、False、None 比较时，是用 is 还是用 == 呢？由于 True、False、None 它们不仅是关键字，而且也被看做是一个常量，最重要的是它们都是单例的，所以我们应该用 is 判断。</p>
<p>另外 is 在底层只需要一个 == 即可完成，但 Python 的 ==，在底层则需要调用 PyObject_RichCompare 函数。因此 is 在速度上也更有优势，== 操作肯定比函数调用要快。</p>
<blockquote>
<p>补充：判断对象是否相等，底层有两个常用的函数，分别是 PyObject_RichCompare 和 PyObject_RichCompareBool。</p>
<p>PyObject_RichCompare 是直接比较对象的值是否相等。而 PyObject_RichCompareBool 会先比较地址是否相等（即是否是同一个对象），如果是同一个对象，那么直接认为相等，否则再调用 PyObject_RichCompare 判断值是否相等。</p>
<p>对于容器的一些 API，在比较对象是否相等时，调用的都是 PyObject_RichCompareBool。</p>
</blockquote>
<h2 id="小结-47"><a class="header" href="#小结-47">小结</a></h2>
<p>以上我们就分析了常见的几个指令，以及变量赋值的底层逻辑，怎么样，是不是对 Python 有更深的理解了呢。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-48"><a class="header" href="#楔子-48">楔子</a></h2>
<p>前面我们分析了虚拟机执行字节码的原理，并且也介绍了不少指令，但这些指令都是从上往下顺序执行的，不涉及任何的跳转。而像流程控制语句，比如 if、for、while、try 等等，它们在执行时会发生跳转，因此 Python 底层一定还存在相应的跳转指令。</p>
<p>那么从现在开始，就来分析一下这些流程控制语句的实现原理，本文先来介绍 if 语句。</p>
<h2 id="if-字节码"><a class="header" href="#if-字节码">if 字节码</a></h2>
<p>if 语句应该是最简单也是最常用的流程控制语句，那么它的字节码是怎么样的呢？当然这里的 if 语句指的是 <font color="blue">if elif else</font> 整体，里面的某个条件叫做该 if 语句的分支。</p>
<p>我们看一下 if 语句的字节码长什么样子。</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
score = 90

if score &gt;= 85:
    print(&quot;Good&quot;)
    
elif score &gt;= 60:
    print(&quot;Normal&quot;)

else:
    print(&quot;Bad&quot;)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>反编译得到的字节码指令比较多，我们来慢慢分析。另外为了阅读方便，源代码行号就不显示了。</p>
<pre><code class="language-C">      // 加载常量 90 并压入运行时栈
      0 LOAD_CONST               0 (90)
      // 加载符号表中索引为 0 的符号 &quot;score&quot;，弹出运行时栈的栈顶元素 90
      // 然后将两者绑定起来，存放在当前的名字空间中
      2 STORE_NAME               0 (score)
      // 加载变量 score
      4 LOAD_NAME                0 (score)
      // 加载常量 85
      6 LOAD_CONST               1 (85)
      // 进行比较，操作符是 &gt;=，这个指令之前介绍过的
      8 COMPARE_OP               5 (&gt;=)
      // 如果比较结果为 False，就进行跳转，从名字也能看出指令的含义
      // 那么跳转到什么地方呢？指令参数 22 表示跳转到偏移量为 22 的指令
      // 很明显，就是当前分支的下一个分支。关于具体是怎么跳转的，一会儿说
     10 POP_JUMP_IF_FALSE       22
      // 如果走到这里说明没有跳转，当前分支的条件为真，那么开始执行该分支内部的逻辑
      // 以下 4 条指令对应 print(&quot;Good&quot;)
     12 LOAD_NAME                1 (print)
     14 LOAD_CONST               2 ('Good')
     16 CALL_FUNCTION            1
     18 POP_TOP
      // if 语句只有一个分支会被执行，如果执行了某个分支，那么整个 if 语句就结束了
      // 于是向前跳转 26 个偏移量，来到偏移量为 48 的指令
     20 JUMP_FORWARD            26 (to 48)
     
      // 对应 score &gt;= 60
&gt;&gt;   22 LOAD_NAME                0 (score)
     24 LOAD_CONST               3 (60)
     26 COMPARE_OP               5 (&gt;=)
      // 如果比较结果为假，跳转到偏移量为 40 的指令
     28 POP_JUMP_IF_FALSE       40
      // 以下 4 条指令对应 print(&quot;Normal&quot;)
     30 LOAD_NAME                1 (print)
     32 LOAD_CONST               4 ('Normal')
     34 CALL_FUNCTION            1
     36 POP_TOP
      // 向前跳转 8 个偏移量，来到偏移量为 48 的指令
     38 JUMP_FORWARD             8 (to 48)
      
      // 最后一个是 else 分支，而 else 分支没有判断条件
&gt;&gt;   40 LOAD_NAME                1 (print)
     42 LOAD_CONST               5 ('Bad')
     44 CALL_FUNCTION            1
     46 POP_TOP
      
      // 到这里说明 if 语句结束了，而下面也没有代码了，于是返回
      // 每个代码块对应的指令的最后都有一个 return
&gt;&gt;   48 LOAD_CONST               6 (None)
     50 RETURN_VALUE
</code></pre>
<p>我们看到字节码偏移量之前有几个 <font color="blue">&gt;&gt;</font> 这样的符号，显然这是 if 语句中的每一个分支开始的地方。</p>
<p>经过分析，整个 if 语句的字节码指令还是很简单的。就是从上到下依次判断每一个分支，如果某个分支条件成立，就执行该分支的代码，执行完毕后结束整个 if 语句；否则跳转到下一个分支。</p>
<p>显然核心就在于 POP_JUMP_IF_FALSE 指令，我们看一下它的逻辑。</p>
<h2 id="pop_jump_if_false"><a class="header" href="#pop_jump_if_false">POP_JUMP_IF_FALSE</a></h2>
<p>COMPARE_OP 执行完之后会将比较的结果压入运行时栈，而 POP_JUMP_IF_FALSE 指令则是将结果从栈顶弹出并判断真假。如果为假，那么跳到下一个分支，否则执行此分支的代码。</p>
<pre><code class="language-c">case TARGET(POP_JUMP_IF_FALSE): {
    PREDICTED(POP_JUMP_IF_FALSE);
    // 从栈顶弹出比较结果
    PyObject *cond = POP();
    int err;
    // 如果 cond is True，说明当前分支的条件成立，那么执行下一条指令
    if (cond == Py_True) {
        Py_DECREF(cond);
        FAST_DISPATCH();
    }
    // 如果 cond is False，那么通过 JUMPTO 跳转到 if 语句的下一个分支
    // 关于 JUMPTO 一会儿介绍
    if (cond == Py_False) {
        Py_DECREF(cond);
        JUMPTO(oparg);
        FAST_DISPATCH();
    }
    // 到这里说明 cond 不是布尔值，那么调用 PyObject_IsTrue 并判断结果是否为真
    // PyObject_IsTrue(cond)：等价于 Python 的 bool(cond) is True
    err = PyObject_IsTrue(cond);
    Py_DECREF(cond);
    // 如果 cond 的布尔值为真，那么返回 1，此时什么也不做
    // 最后会调用 DISPATCH()，去执行下一条指令
    if (err &gt; 0)
        ;
    // 如果 cond 的布尔值为假，那么返回 0，跳转到下一个 if 分支
    else if (err == 0)
        JUMPTO(oparg);
    else
        goto error;
    DISPATCH();
}
</code></pre>
<p>逻辑不难理解，但是里面出现了判断对象布尔值的函数，我们补充一下。</p>
<pre><code class="language-C">// Objects/object.c

// 等价于 Python 的 bool(v) is True
int
PyObject_IsTrue(PyObject *v)
{
    Py_ssize_t res;
    // 如果 v 本身就是布尔值 True，返回 1
    if (v == Py_True)
        return 1;
    // 如果 v 本身就是布尔值 False，返回 0
    if (v == Py_False)
        return 0;
    // 如果 v 是 None，返回 0
    if (v == Py_None)
        return 0;
    // 如果 v 是数值型对象，并且实现了 nb_bool（对应 __bool__）
    // 那么调用，如果结果不为 0，返回 1，否则返回 0
    else if (v-&gt;ob_type-&gt;tp_as_number != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_number-&gt;nb_bool != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_number-&gt;nb_bool)(v);
    // 如果 v 是映射型对象，并且实现了 mp_length（对应 __len__)
    // 那么调用，返回对象的长度
    else if (v-&gt;ob_type-&gt;tp_as_mapping != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_mapping-&gt;mp_length != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_mapping-&gt;mp_length)(v);
    // 如果 v 是序列型对象，并且实现了 sq_length（对应 __len__)
    // 那么调用，返回对象的长度
    else if (v-&gt;ob_type-&gt;tp_as_sequence != NULL &amp;&amp;
             v-&gt;ob_type-&gt;tp_as_sequence-&gt;sq_length != NULL)
        res = (*v-&gt;ob_type-&gt;tp_as_sequence-&gt;sq_length)(v);
    // 如果以上条件都不满足，直接返回 1，比如自定义类的实例对象（默认为真）
    else
        return 1;
    // 如果 res &gt; 0 返回 1，否则返回 0
    return (res &gt; 0) ? 1 : Py_SAFE_DOWNCAST(res, Py_ssize_t, int);
}

// not 底层也调用了 PyObject_IsTrue
int
PyObject_Not(PyObject *v)
{
    int res;
    // 如果 v 是真，res == 1，那么 res == 0 结果是 0
    // 如果 v 是假，res == 0，那么 res == 0 结果是 1
    // 相当于取反
    res = PyObject_IsTrue(v);
    if (res &lt; 0)
        return res;
    return res == 0;
}

// Objects/boolobject.c
static PyObject *
bool_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
{
    // &lt;class 'bool'&gt; 是一个 Python 类，这里的 bool_new 便是它的构造函数
    PyObject *x = Py_False;
    long ok;
    // 不接收关键字参数
    if (!_PyArg_NoKeywords(&quot;bool&quot;, kwds))
        return NULL;
    // 只接收 0 ~ 1 个参数，如果不传，那么默认返回 False
    if (!PyArg_UnpackTuple(args, &quot;bool&quot;, 0, 1, &amp;x))
        return NULL;
    // 调用 PyObject_IsTrue，所以我们说 if v 和 if bool(v) 是等价的
    // 因为当 v 不是布尔值时，if v 对应的指令内部会调用 PyObject_IsTrue
    // 而 bool(v) 也会调用 PyObject_IsTrue，所以两者是等价的
    ok = PyObject_IsTrue(x);
    if (ok &lt; 0)
        return NULL;
    // 调用 PyBool_FromLong 创建布尔值，ok 为 1 返回 True，为 0 返回 False
    return PyBool_FromLong(ok);
}

PyObject *PyBool_FromLong(long ok)
{
    PyObject *result;

    if (ok)
        result = Py_True;
    else
        result = Py_False;
    Py_INCREF(result);
    return result;
}
</code></pre>
<p>相信你现在明白了为什么 if 后面不跟布尔值也是可以的，因为有一个 C 函数 PyObject_IsTrue，可以判断任意对象的真假。如果 if 后面跟着的不是布尔值，那么会自动调用该函数。另外由于 bool(v) 也会调用该函数，所以 <font color="blue">if v</font> 和 <font color="blue">if bool(v)</font> 是等价的。</p>
<blockquote>
<p>注：没有 PyObject_IsFalse。</p>
</blockquote>
<p>说完了 POP_JUMP_IF_FALSE 指令，再补充一个和它相似的指令叫 POP_JUMP_IF_TRUE，它表示当比较结果为真时，跳到下一个分支，否则执行当前分支的代码。可能有人觉得，这不对吧，比较结果为真，难道不应该执行当前分支的逻辑吗？所以 POP_JUMP_IF_TRUE 指令似乎本身就是矛盾的。</p>
<p><img src="./images/190.png" alt="" /></p>
<p>仔细想想你应该能够猜到原因，答案就是使用了 not。</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
if 2 &gt; 1:
    print(&quot;古明地觉&quot;)
&quot;&quot;&quot;
# 只打印部分字节码
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
&quot;&quot;&quot;
    0 LOAD_CONST               0 (2)
    2 LOAD_CONST               1 (1)
    4 COMPARE_OP               4 (&gt;)
    6 POP_JUMP_IF_FALSE       16
&quot;&quot;&quot;

code_string = &quot;&quot;&quot;
if not 2 &gt; 1:
    print(&quot;古明地觉&quot;)
&quot;&quot;&quot;
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
&quot;&quot;&quot;
    0 LOAD_CONST               0 (2)
    2 LOAD_CONST               1 (1)
    4 COMPARE_OP               4 (&gt;)
    6 POP_JUMP_IF_TRUE        16
&quot;&quot;&quot;
</code></pre>
<p>正常情况下如果比较结果为 False，则跳转到 if 语句的下一个分支，所以 POP_JUMP_IF_FALSE 指令是合理的。至于 POP_JUMP_IF_TRUE 指令从逻辑上似乎就不该存在，因为它和 if 语句本身是相矛盾的。但现在我们明白了，该指令其实是为 not 关键字准备的。如果比较结果为真，那么 not 取反就是假，于是跳转到 if 语句的下一个分支，所以整个逻辑依旧是正确的。</p>
<p>当然这里只有一个 not，即使有很多个 not 也是可以的，尽管这没太大意义。</p>
<pre><code class="language-python">import dis

# 这里有 4 个 not，因为是偶数个，两两相互抵消
# 所以结果等价于 if 2 &gt; 1
code_string = &quot;&quot;&quot;
if not not not not 2 &gt; 1:
    print(&quot;古明地觉&quot;)
&quot;&quot;&quot;
# 只打印部分字节码
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
&quot;&quot;&quot;
    0 LOAD_CONST               0 (2)
    2 LOAD_CONST               1 (1)
    4 COMPARE_OP               4 (&gt;)
    6 POP_JUMP_IF_FALSE       16
&quot;&quot;&quot;

# 这里有 5 个 not，因为是奇数个，两两相互抵消之后还剩下一个
# 所以结果等价于 if not 2 &gt; 1
code_string = &quot;&quot;&quot;
if not not not not not 2 &gt; 1:
    print(&quot;古明地觉&quot;)
&quot;&quot;&quot;
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
&quot;&quot;&quot;
    0 LOAD_CONST               0 (2)
    2 LOAD_CONST               1 (1)
    4 COMPARE_OP               4 (&gt;)
    6 POP_JUMP_IF_TRUE        16
&quot;&quot;&quot;
</code></pre>
<p>然后再看一下 POP_JUMP_IF_TRUE 指令的内部逻辑，显然它和 POP_JUMP_IF_FALSE 是类似的。</p>
<pre><code class="language-C">case TARGET(POP_JUMP_IF_TRUE): {
    PREDICTED(POP_JUMP_IF_TRUE);
    // 弹出栈顶元素
    PyObject *cond = POP();
    int err;
    // 如果 cond is False，那么 not 之后就是 True
    // 所以当前 if 分支成立，于是执行下一条指令
    if (cond == Py_False) {
        Py_DECREF(cond);
        FAST_DISPATCH();
    }
    // 如果 cond is True，那么 not 之后就是 False
    // 因此跳转到下一个分支
    if (cond == Py_True) {
        Py_DECREF(cond);
        JUMPTO(oparg);
        FAST_DISPATCH();
    }
    // 说明 cond 不是布尔值，那么通过 PyObject_IsTrue 判断是否为真
    // 为真返回 1，为假返回 0，出现错误的话返回 -1（基本不会发生）
    err = PyObject_IsTrue(cond);
    Py_DECREF(cond);
    // 如果 err &gt; 0，说明布尔值为真，但还要进行 not 取反，因此最终整体为假
    // 所以会跳转到下一个分支
    if (err &gt; 0) {
        JUMPTO(oparg);
    }
    // 如果 err == 0，说明布尔值为假，那么 not 取反之后整体为真
    // 因此会执行当前分支内的逻辑，所以此处什么也不用做，直接 DISPATCH() 到下一条指令即可
    else if (err == 0)
        ;
    else
        goto error;
    DISPATCH();
}
</code></pre>
<p>以上就是 POP_JUMP_IF_FALSE 和 POP_JUMP_IF_TRUE 的内部逻辑，可以说非常简单。</p>
<h2 id="jumpto"><a class="header" href="#jumpto">JUMPTO</a></h2>
<p>指令跳转是由 JUMPTO 实现的，它内部的逻辑长啥样呢？并且跳转除了 JUMPTO 之外，还有一个 JUMPBY，这两者有啥区别呢？</p>
<pre><code class="language-C">// Python/ceval.c

#define JUMPTO(x)       (next_instr = first_instr + (x) / sizeof(_Py_CODEUNIT))
#define JUMPBY(x)       (next_instr += (x) / sizeof(_Py_CODEUNIT))
</code></pre>
<p>字节码指令的遍历是通过 next_instr 实现的，如果将指令执行的方向代表前进的方向。</p>
<ul>
<li>JUMPTO(x)：表示从头开始向前跳转 x 个偏移量。</li>
<li>JUMPBY(x)：表示从当前指令所在的位置向前跳转 x 个偏移量。</li>
</ul>
<p>所以 JUMPTO 表示绝对跳转，JUMPBY 表示相对跳转。不难发现，JUMPTO 既可以向前跳转（偏移量增大），也可以向后跳转（偏移量减小）；而 JUMPBY 只能向前跳转。</p>
<p>假设参数为 n，当前指令的偏移量为 m。对于 JUMPTO 而言，跳转之后的偏移量始终为 2n，如果 <font color="blue">m &lt; 2n</font> 就是向前跳转，<font color="blue">m &gt; 2n</font> 就是向后跳转。但对于 JUMPBY 而言，由于它是从当前待执行的指令开始跳转的，所以只能向前跳转（偏移量增大）。</p>
<p>另外在看字节码指令的时候，我们还看到了一个 JUMP_FORWARD 指令，当某个分支执行完毕之后，会直接跳转到 if 语句结束的下一条指令。并且不同分支对应的 JUMP_FORWARD 指令的参数是不同的，所以它内部一定使用了相对跳转。</p>
<pre><code class="language-C">case TARGET(JUMP_FORWARD): {
    JUMPBY(oparg);
    FAST_DISPATCH();
}
</code></pre>
<p>我们分析的没错，它内部就是调用了一个 JUMPBY，因为终点相同、但跳转的偏移量不同，所以只能是相对跳转。</p>
<h2 id="指令预测"><a class="header" href="#指令预测">指令预测</a></h2>
<p>通过引入计算跳转，可以避免不必要的匹配。因为整个指令集合是已知的，这就说明某条指令在执行时，便可知道它的下一条指令是什么。所以当前指令处理完后，可以直接跳转到下一条指令对应的处理逻辑中，这就是计算跳转。但如果不使用计算跳转，那么每次读取到指令后，都要进入 switch，顺序匹配一百多个 case 分支，找到匹配成功的那一个。</p>
<p>因此使用计算跳转可以避免不必要的匹配，既然提前知道下一条指令是啥了，那么直接精确跳转就行，无需多走一遍 switch。不过要想实现计算跳转，需要 GCC 支持<font color="blue">标签作为值</font>，即 <font color="blue">goto *label_addr</font> 用法，由于 label_addr 是一个标签地址，那么解引用之后就是标签了。至于具体会跳转到哪一个标签，取决于 label_addr 保存了哪一个标签的地址，因此这种跳转是动态的，在运行时决定跳转目标。</p>
<blockquote>
<p><code>goto 标签</code>：静态跳转，标签需要显式地定义好，跳转位置在编译期间便已经固定。</p>
<p><code>goto *标签地址</code>：动态跳转（计算跳转），跳转位置不固定，可以是已有标签中的任意一个。至于具体是哪一个，需要在运行时经过计算才能确定。</p>
</blockquote>
<p>虚拟机为每个指令的处理逻辑都定义了一个标签，对于计算跳转来说，goto 的结果是 <font color="blue">*标签地址</font>，这个地址是运行时计算得出的。我们举个例子，随便看一段字节码指令集。</p>
<p><img src="./images/191.png" alt="" /></p>
<p>比如当前正在执行 LOAD_FAST 指令，那么下一条指令可以是 STORE_FAST、LOAD_FAST 以及 BUILD_LIST 等。当开启计算跳转时：</p>
<ul>
<li>如果下一条指令是 STORE_FAST，那么之后就会跳转到 STORE_FAST 对应的标签；</li>
<li>如果下一条指令是 LOAD_FAST，那么之后就会跳转到 LOAD_FAST 对应的标签；</li>
<li>如果下一条指令是 BUILD_LIST，那么之后就会跳转到 BUILD_LIST 对应的标签；</li>
</ul>
<p>所以在运行时判断指令的值，获取对应的标签，从而实现精确跳转，这就是计算跳转。当然这些内容在剖析虚拟机执行字节码时已经说过了，这里再回顾一下。</p>
<p>接下来说一说指令预测，不难发现，如果是计算跳转，那么指令预测功能貌似没啥用，因为总是能精确跳转到下一条指令对应的标签中。没错，指令预测只有在不使用计算跳转的情况下有用，那什么是指令预测呢？</p>
<p>在不使用计算跳转时，goto 后面必须是一个静态的标签，跳转位置在编译阶段便已经固定，换句话说一个指令执行完毕后要跳转到哪一个标签是写死的，不能保证跳转后的标签正好对应下一条指令的处理逻辑。比如 LOAD_FAST 的下一条指令可以是 STORE_FAST 和 BUILD_LIST，那么应该跳转到哪一个指令对应的标签中呢？</p>
<p>正因为这种不确定性，绝大部分指令在执行完毕后都会直接跳转到 fast_next_opcode 标签，然后顺序匹配 case 分支。</p>
<p>但也有那么几个指令，由于彼此的关联性很强，很多时候都是成对出现的，面对这样的指令，虚拟机会进行预测。比如 A 和 B 两个指令的关联性很强，尽管 A 的下一条指令除了是 B 之外，也有可能是其它指令，但 B 出现的概率是最大的，因此虚拟机会预测下一条指令是 B 指令。于是在执行完 A 指令之后，会验证自己的预测是否正确，即检测下一条指令是否是 B 指令。如果预测对了，可以实现精确跳转，如果预测错了，就只能回到 switch 语句逐一匹配 case 分支了。</p>
<p><strong>总结一下：指令在执行时，它的下一条指令是已知的，但是不固定，有多种可能。如果不使用计算跳转，由于 goto 后面必须是一个写死的标签，而下一条指令却不固定，那么只能选择进入 switch、顺序匹配 case 分支。但也有那么几对指令，关联性很强，虽然不能保证百分百，但值得做一次尝试，这便是指令预测。</strong></p>
<p><strong>当然啦，如果使用计算跳转，情况则不一样了，此时压根用不到指令预测。因为 goto 后面是 *标签地址，而地址是可以动态获取的。由于所有标签的地址都保存在了一个数组中，不管接下来要处理哪一条指令，都可以获取到对应的标签地址，实现精确跳转。</strong></p>
<p>好，关于指令预测我们已经知道是啥了，那么在源码层面又是如何体现的呢？在 POP_JUMP_IF_FALSE 指令中，我们看到有这么一行逻辑。</p>
<p><img src="./images/192.png" alt="" /></p>
<p>里面有一个宏 PREDICTED。</p>
<pre><code class="language-C">// Python/ceval.c
#define PREDICTED(op)           PRED_##op:
</code></pre>
<p>这个宏展开之后又是一个标签，由于调用时结尾加了分号，所以这还是一个空标签。整体效果如下：</p>
<p><img src="./images/193.png" alt="" /></p>
<p>那么展开成一个标签有什么用呢？首先肯定是为了跳转，至于具体过程我们再看一下 COMPARE_OP 指令就明白了。</p>
<p><img src="./images/194.png" alt="" /></p>
<p>COMPARE_OP  指令上面已经介绍了，它会对两个对象进行比较，并将比较结果压入运行时栈。之后它做了指令预测，并且还预测了两次，因为虚拟机认为 COMPARE_OP 执行完之后大概率会执行 POP_JUMP_IF_FALSE 或 POP_JUMP_IF_TRUE，所以做了一个预测。而相关逻辑位于 PREDICT 中，看一下它长什么样子。</p>
<pre><code class="language-C">// Python/ceval.c

// 如果开启计算跳转，那么指令预测不生效，因为本身就知道该跳转到哪个指令对应的标签
#if defined(DYNAMIC_EXECUTION_PROFILE) || USE_COMPUTED_GOTOS
#define PREDICT(op)             if (0) goto PRED_##op
#else
// 如果不开启计算跳转，那么会比较预测的指令和实际的指令是否相等
// 所以 COMPARE_OP 指令处理逻辑里面的 PREDICT(POP_JUMP_IF_FALSE)
// 就是在判断下一条指令是不是自己预测的 POP_JUMP_IF_FALSE
// 如果是，说明预测成功，那么 goto PRED_POP_JUMP_IF_FALSE
// 否则说明预测失败，那么会执行 DISPATCH()，然后 goto 到 switch 语句所在位置
#define PREDICT(op) \
    do{ \
        _Py_CODEUNIT word = *next_instr; \
        opcode = _Py_OPCODE(word); \
        if (opcode == op){ \
            oparg = _Py_OPARG(word); \
            next_instr++; \
            goto PRED_##op; \
        } \
    } while(0)
#endif
</code></pre>
<p>以上便是指令预测，说白了就是如果指令 A 和指令 B 具有极高的关联性（甚至百分百），那么执行完 A 指令后会判断下一条指令是不是 B。如果是，那么直接跳转即可，就省去了匹配 case 分支的时间，如果不是，那就只能挨个匹配了。</p>
<p>因为是静态跳转，goto 后面的标签是写死的，编译阶段就确定了，所以只有那种关联度极高的指令才会开启预测功能，因为预测成功的概率比较高。但如果指令 A 的下一条指令有多种可能（假设有 6 种），并且每种指令出现的概率还差不多，那么这时不管预测哪一个，成功的概率都只有 1/6。显然这就不叫预测了，这是在掷骰子，因此对于这样的指令，虚拟机不会为它开启预测功能。</p>
<p><img src="./images/195.png" alt="" /></p>
<p>比如 LOAD_FAST 的下一个指令可以是 STORE_FAST、LOAD_FAST、BUILD_LIST 等等，不管预测哪一种，成功的概率都不是特别高，因此它没有进行指令预测。</p>
<p>所以就一句话：只有 A 和 B 两个指令的关联度极高的时候，执行 A 之后才会预测下一条指令是否是 B。预测成功直接跳转，预测失败执行 DISPATCH()，跳转到 fast_next_opcode 标签，进入 switch 语句。</p>
<p>但如果使用了计算跳转，情况就不一样了，此时不会开启指令预测，或者说指令预测里的逻辑会变得无效。</p>
<p><img src="./images/196.png" alt="" /></p>
<p>很明显，使用计算跳转后，PREDICT(op) 不会产生任何效果，因此也可以理解为没有开启指令预测。而之所以不用预测，是因为执行 DISPATCH() 的时候，本身就可以精确跳转到指定位置。</p>
<h2 id="小结-48"><a class="header" href="#小结-48">小结</a></h2>
<p>本篇文章我们就分析了 if 语句的实现原理，总的来说不难理解。依旧是在栈桢中执行字节码，只是多了一个指令跳转罢了，至于怎么跳转、跳转到什么地方，全部都体现在字节码中。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-49"><a class="header" href="#楔子-49">楔子</a></h2>
<p>在介绍 if 语句的时候，我们看到了最基本的控制流，其核心就是跳转。但是 if 只能向前跳转，而接下来介绍的 for、while 循环，指令是可以回退的，也就是向后跳转。</p>
<h2 id="for-控制流"><a class="header" href="#for-控制流">for 控制流</a></h2>
<p>我们看一个简单的 for 循环的字节码。</p>
<pre><code class="language-Python">import dis

code_string = &quot;&quot;&quot;
lst = [1, 2]
for item in lst:
    print(item)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>反编译之后，字节码指令如下。</p>
<pre><code class="language-C">      // 加载常量 1，压入运行时栈
      0 LOAD_CONST               0 (1)
      // 加载常量 2，压入运行时栈
      2 LOAD_CONST               1 (2)
      // 将运行时栈的元素弹出，构建长度为 2 的列表，并压入栈中
      4 BUILD_LIST               2
      // 将上一步构建的列表从栈顶弹出，并用符号 lst 与之绑定
      // 到此 lst = [1, 2] 便完成了
      6 STORE_NAME               0 (lst)
      
      // 从全局名字空间中加载 lst
      8 LOAD_NAME                0 (lst)
      // 获取对应的迭代器，即 iter(lst)
     10 GET_ITER
      // 开始 for 循环，将里面的元素依次迭代出来
      // 如果迭代结束，向前跳转 12 个偏移量，来到偏移量为 26 的指令
&gt;&gt;   12 FOR_ITER                12 (to 26)
      // 到这里说明上一步迭代出元素了
      // 用符号 item 和迭代出的元素进行绑定
     14 STORE_NAME               1 (item)
      
      // 对应 print(item)
     16 LOAD_NAME                2 (print)
     18 LOAD_NAME                1 (item)
     20 CALL_FUNCTION            1
     22 POP_TOP
      // 到此，一次遍历就完成了，那么跳转到偏移量为 12 的指令，进行下一轮循环
      // 注意：上面的 FOR_ITER 指令和这里的 JUMP_ABSOLUTE 指令的参数都是 12
      // 但它们有着不同，FOR_ITER 指令的参数 12 表示从当前位置向前跳转 12 个偏移量
      // 而 JUMP_ABSOLUTE 指令的参数 12 表示跳转到偏移量为 12 个位置（或者说从开头跳转 12 个偏移量）
     24 JUMP_ABSOLUTE           12
&gt;&gt;   26 LOAD_CONST               2 (None)
     28 RETURN_VALUE
</code></pre>
<p>我们直接从 10 GET_ITER 开始看起，首先 for 循环遍历的对象必须是可迭代对象，然后会调用它的 __iter__ 方法，得到迭代器。再不断地调用迭代器的 __next__ 方法，一步一步将里面的值全部迭代出来，当出现 StopIteration 异常时，for 循环捕捉，最后退出。</p>
<p>另外，我们说 Python 里面是先有值，后有变量，for 循环也不例外。循环的时候，先将迭代器中的元素迭代出来，然后再让变量 item 指向。因此包含 10 个元素的迭代器，需要迭代 11 次才能结束。因为 for 循环事先是不知道迭代 10 次就能结束的，它需要再迭代一次，发现没有元素可以迭代、并捕获抛出的 StopIteration 之后，才能结束。</p>
<blockquote>
<p>for 循环遍历可迭代对象时，会先拿到对应的迭代器，那如果遍历的就是一个迭代器呢？答案是依旧调用 __iter__，只不过由于本身就是一个迭代器，所以返回的还是其本身。</p>
</blockquote>
<p>将元素迭代出来之后，就开始执行 for 循环体的逻辑了。</p>
<p>执行完一轮循环之后，通过 JUMP_ABSOLUTE 跳转到字节码偏移量为 12、也就是 FOR_ITER 的位置开始下一次循环。这里我们发现它没有跳到 GET_ITER 那里，所以可以得出结论，for 循环在遍历的时候只会创建一次迭代器。</p>
<p>下面来看指令对应的具体逻辑：</p>
<pre><code class="language-C">case TARGET(GET_ITER): {
    // 获取栈顶元素，即上一步压入的列表指针
    PyObject *iterable = TOP();
    // 调用 PyObject_GetIter，获取对应的迭代器
    // 这个函数在介绍迭代器的时候已经说过了
    // 等价于 iter = type(iterable).__iter__(iterable)
    PyObject *iter = PyObject_GetIter(iterable);
    Py_DECREF(iterable);
    // 将迭代器 iter 设置为栈顶元素
    SET_TOP(iter);
    if (iter == NULL)
        goto error;
    // 指令预测，解释器认为下一条指令大概率是 FOR_ITER 或 CALL_FUNCTION
    PREDICT(FOR_ITER);
    PREDICT(CALL_FUNCTION);
    DISPATCH();
}
</code></pre>
<p>当创建完迭代器之后，就正式进入 for 循环了。所以从 FOR_ITER 开始，进入了虚拟机层面上的 for 循环。</p>
<blockquote>
<p>源代码中的 for 循环，在虚拟机层面也一定对应着一个相应的循环控制结构。因为无论进行怎样的变换，都不可能在虚拟机层面利用顺序结构来实现源码层面上的循环结构，这也可以看作是程序的拓扑不变性。</p>
<p>因此源代码是宏观的，虚拟机执行字节码是微观的，尽管两者的层级不同，但本质上等价的，是程序从一种形式到另一种形式的等价转换。</p>
</blockquote>
<p>我们来看一下 FOR_ITER 指令对应的具体实现：</p>
<pre><code class="language-C">case TARGET(FOR_ITER): {
    PREDICTED(FOR_ITER);
    // 从栈顶获取迭代器对象（指针）
    PyObject *iter = TOP();
    // 调用迭代器类型对象的 tp_iternext，将迭代器内的元素迭代出来
    PyObject *next = (*iter-&gt;ob_type-&gt;tp_iternext)(iter);
    // 如果 next != NULL，说明迭代到元素了，那么压入运行时栈
    if (next != NULL) {
        PUSH(next);
        PREDICT(STORE_FAST);
        PREDICT(UNPACK_SEQUENCE);
        DISPATCH();
    }
    // 否则说明迭代出现异常
    if (_PyErr_Occurred(tstate)) {
        // 如果异常还不是 StopIteration，那么跳转到 error 标签
        if (!_PyErr_ExceptionMatches(tstate, PyExc_StopIteration)) {
            goto error;
        }
        else if (tstate-&gt;c_tracefunc != NULL) {
            call_exc_trace(tstate-&gt;c_tracefunc, tstate-&gt;c_traceobj, tstate, f);
        }
        // 否则说明是 StopIteration，那么证明迭代完毕，将异常清空
        _PyErr_Clear(tstate);
    }
    // 迭代结束了，但运行时栈里面还有一个迭代器对象
    // 那么要将它弹出，因此这里执行了 STACK_SHRINK(1)
    STACK_SHRINK(1);
    Py_DECREF(iter);
    // 跳转到 for 循环结束后的下一条指令
    // 当前的指令为：12 FOR_ITER  12 (to 26)
    // 所以会通过 JUMPBY 实现一个相对跳转
    // 从当前位置向前跳转 12 个偏移量，来到偏移量为 26 的指令
    JUMPBY(oparg);
    PREDICT(POP_BLOCK);
    DISPATCH();
}
</code></pre>
<p>在执行 FOR_ITER 的时候，如果迭代器没有耗尽，那么会迭代出元素，压入运行时栈，然后调用 DISPATCH() 去执行下一条指令。当一轮循环结束后，还要进行指令回退，从字节码中也看到了，for 循环遍历一次之后，会再次跳转到 FOR_ITER，而跳转所使用的指令就是 JUMP_ABSOLUTE，从名字也能看出这个指令会使用绝对跳转。</p>
<pre><code class="language-C">case TARGET(JUMP_ABSOLUTE): {
    PREDICTED(JUMP_ABSOLUTE);
    // 跳转到偏移量为 oparg 的指令
    JUMPTO(oparg);
#if FAST_LOOPS
    FAST_DISPATCH();
#else
    DISPATCH();
#endif
}
</code></pre>
<p>之前介绍过 JUMPTO 和 JUMPBY 两个宏，</p>
<pre><code class="language-C">#define JUMPTO(x)       (next_instr = first_instr + (x) / sizeof(_Py_CODEUNIT))
#define JUMPBY(x)       (next_instr += (x) / sizeof(_Py_CODEUNIT))
</code></pre>
<p>这两个宏都表示跳转 x 个偏移量，但 JUMPTO 是从头开始跳转，所以只要 x 固定，那么跳转位置就始终是固定的。而 JUMPBY 表示从当前位置开始跳转，所以位置不同，跳转的结果也不同。</p>
<p>然后天下没有不散的宴席，随着迭代的进行，for 循环总有退出的那一刻，而这个退出的动作只能落在 FOR_ITER 的身上。在 FOR_ITER 指令执行的过程中，如果遇到了 StopIteration，就意味着迭代结束了。这个结果将导致虚拟机会将迭代器从运行时栈中弹出，同时执行一个 JUMPBY 动作，向前跳跃，在字节码的层面是向下，也就是偏移量增大的方向。</p>
<h2 id="while-控制流"><a class="header" href="#while-控制流">while 控制流</a></h2>
<p>看完了 for，再来看看 while，并且我们还要分析两个关键字：break、continue。</p>
<pre><code class="language-Python">import dis

code_string = &quot;&quot;&quot;
a = 0
while a &lt; 10:
    a += 1
    if a == 5:
        continue
    if a == 7:
        break
    print(a)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>看一下它的指令：</p>
<pre><code class="language-c">      // a = 0
      0 LOAD_CONST               0 (0)
      2 STORE_NAME               0 (a)
      
      // 比较 a &lt; 10
&gt;&gt;    4 LOAD_NAME                0 (a)
      6 LOAD_CONST               1 (10)
      8 COMPARE_OP               0 (&lt;)
      // 如果 a &lt; 10 为假，说明循环结束
      // 跳转到偏移量为 50 的指令，内部会使用绝对跳转
     10 POP_JUMP_IF_FALSE       50
      // 到这里说明 while 条件成立，进入循环体
      // 执行 a += 1
     12 LOAD_NAME                0 (a)
     14 LOAD_CONST               2 (1)
     16 INPLACE_ADD
     18 STORE_NAME               0 (a)
        
      // 比较 a == 5        
     20 LOAD_NAME                0 (a)
     22 LOAD_CONST               3 (5)
     24 COMPARE_OP               2 (==)
      // 如果 a == 5 为假，跳转到偏移量为 30 的指令
     26 POP_JUMP_IF_FALSE       30
      // 否则说明 a == 5 为真，执行 continue
      // 由于 continue 是立即进入下一轮循环
      // 所以直接跳转到偏移量为 4 的指令，即 while 循环的开始位置
      // 所以在虚拟机的层面，continue 就是一个跳转指令
     28 JUMP_ABSOLUTE            4
        
      // 比较 a == 7
&gt;&gt;   30 LOAD_NAME                0 (a)
     32 LOAD_CONST               4 (7)
     34 COMPARE_OP               2 (==)
      // 如果 a == 7 为假，跳转到偏移量为 40 的指令
     36 POP_JUMP_IF_FALSE       40
      // 否则说明 a == 7 为真，执行 break
      // 因此直接跳转到偏移量为 50 的位置，即 while 循环结束后的下一条指令
     38 JUMP_ABSOLUTE           50
        
      // print(a)
&gt;&gt;   40 LOAD_NAME                1 (print)
     42 LOAD_NAME                0 (a)
     44 CALL_FUNCTION            1
     46 POP_TOP
      // 到这里说明一轮循环结束了，那么跳转到偏移量为 4 的位置，即 while 循环的开始位置
     48 JUMP_ABSOLUTE            4
        
      // 隐式的 return None
&gt;&gt;   50 LOAD_CONST               5 (None)
     52 RETURN_VALUE
</code></pre>
<p>有了 for 循环，再看 while 循环就简单多了，整体逻辑和 for 高度相似，当然里面还结合了 if。</p>
<p>刚才说了，尽管源代码和字节码的层级不同，但本质上是等价的，是程序从一种形式到另一种形式的等价转换。在源码中能看到的，在字节码当中也能看到。比如源代码中的 continue 会跳转到循环所在位置，那么在字节码中自然也会对应一个跳转指令。</p>
<h2 id="小结-49"><a class="header" href="#小结-49">小结</a></h2>
<p>以上我们就探讨了 Python 的两种循环，总的来说没什么难度，本质上还是跳转。只不过有时会通过 JUMPTO 进行绝对跳转，有时会通过 JUMPBY 进行相对跳转。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-50"><a class="header" href="#楔子-50">楔子</a></h2>
<p>程序在运行的过程中，总是会不可避免地产生异常，此时为了让程序不中断，必须要将异常捕获掉。如果能提前得知可能会发生哪些异常，建议使用精确捕获，如果不知道会发生哪些异常，则使用 Exception 兜底。</p>
<p>另外异常也可以用来传递信息，比如生成器。</p>
<pre><code class="language-Python">def gen():
    yield 1
    yield 2
    return &quot;result&quot;

g = gen()
next(g)
next(g)
try:
    next(g)
except StopIteration as e:
    print(f&quot;返回值: {e.value}&quot;)   # 返回值: result
</code></pre>
<p>如果想要拿到生成器的返回值，我们需要让它抛出 StopIteration，然后进行捕获，再通过 value 属性拿到返回值。所以，Python 是将生成器的返回值封装到了异常里面。</p>
<p>之所以举这个例子，目的是想说明，异常并非是让人嗤之以鼻的东西，它也可以作为信息传递的载体。特别是在 Java 语言中，引入了 checked exception，方法的所有者还可以声明自己会抛出什么异常，然后调用者对异常进行处理。在 Java 程序启动时，抛出大量异常都是司空见惯的事情，并在相应的调用堆栈中将信息完整地记录下来。至此，Java 的异常不再是异常，而是一种很普遍的结构，从良性到灾难性都有所使用，异常的严重性由调用者来决定。</p>
<p>虽然在 Python 里面，异常还没有达到像 Java 异常那么高的地位，但使用频率也是很高的，下面我们就来剖析一下异常是怎么实现的？</p>
<h2 id="异常的本质是什么"><a class="header" href="#异常的本质是什么">异常的本质是什么？</a></h2>
<p><font color="blue">Python 解释器 = Python 编译器 + Python 虚拟机</font>，所以异常可以由编译器抛出，也可以由虚拟机剖出。如果是编译器抛出的异常，那么基本上都是 SyntaxError，即语法错误。</p>
<pre><code class="language-python">try:
    &gt;&gt;&gt;
except Exception as e:
    print(e)
</code></pre>
<p>比如上面这段代码，你会发现异常捕获根本没用，因为这是编译阶段就发生的错误，而异常捕获是在运行时进行的。当然语法不对属于低级错误，所以不会留到运行时。</p>
<p>然后是运行时产生的异常：</p>
<pre><code class="language-Python">try:
    1 / 0
except ZeroDivisionError:
    print(&quot;Division by zero&quot;)
</code></pre>
<p>像这种语法正确，但程序执行时因逻辑出现问题而导致的异常，是可以被捕获的。对于我们来说，关注的显然是运行时产生的异常，比如 TypeError、IndexError 等等。</p>
<p>那么问题来了，异常本质上是什么呢？我们以列表为例，看看 IndexError 是怎么产生的。</p>
<pre><code class="language-Python">lst = [1, 2, 3]
print(lst[3])
&quot;&quot;&quot;
IndexError: list index out of range
&quot;&quot;&quot;
</code></pre>
<p>列表的最大索引是 2，但我们访问了索引为 3 的元素，虚拟机就知道不能再执行下去了，否则会访问非法内存。因此虚拟机的做法是：输出异常信息，结束进程。我们通过源码来验证一下：</p>
<p><img src="./images/197.png" alt="" /></p>
<p>在获取列表元素时发现索引不合法，就知道要抛出 IndexError 了，于是将异常写入到回溯栈中，并返回 NULL。正常情况下，返回值应该指向一个合法的对象，如果为 NULL，证明出现异常了。</p>
<p>此时虚拟机会将回溯栈里的异常抛出来（就是我们在控制台看到的那一抹鲜红），然后结束进程，这就是异常的本质。当然异常也是一个 Python 对象，虚拟机在退出前，会写入到 stderr 中。</p>
<h2 id="异常写入的一些-c-api"><a class="header" href="#异常写入的一些-c-api">异常写入的一些 C API</a></h2>
<p>当我们用 C 编写 Python 扩展时，如果想设置异常的话，该怎么做呢？首先设置异常之前，我们要知道有哪些异常。在 pyerrors.h 中，虚拟机内置了大量的异常，另外 Python 一切皆对象，因此异常也是一个对象。</p>
<p><img src="./images/198.png" alt="" /></p>
<p>有了异常之后，怎么写入呢？关于异常写入，底层也提供了相应的 C API。</p>
<ul>
<li>PyErr_SetNone：设置异常，不包含提示信息。</li>
<li>PyErr_SetObject：设置异常，包含提示信息（Python 字符串）。</li>
<li>PyErr_SetString：设置异常，包含提示信息（C 字符串）。</li>
<li>PyErr_Occurred：检测回溯栈中是否有异常产生。</li>
<li>PyErr_Clear：将回溯栈中的异常清空，相当于 Python 的异常捕获。</li>
<li>PyErr_Fetch：将回溯栈中的异常清空，同时拿到它的 exc_type、exc_value、exc_tb。</li>
<li>PyErr_Restore：基于 exc_type、exc_value、exc_tb 设置异常。</li>
</ul>
<p>我们以 PyErr_Restore 为例，看看异常的具体设置过程。</p>
<pre><code class="language-C">// Python/errors.c

// PyErr_SetObject、PyErr_SetString 等等，最终都会调用 PyErr_Restore
void
PyErr_Restore(PyObject *type, PyObject *value, PyObject *traceback)
{
    // 获取线程状态对象
    PyThreadState *tstate = _PyThreadState_GET();
    _PyErr_Restore(tstate, type, value, traceback);
}

// 将异常设置在线程状态对象中
void
_PyErr_Restore(PyThreadState *tstate, PyObject *type, PyObject *value,
               PyObject *traceback)
{
    PyObject *oldtype, *oldvalue, *oldtraceback;

    if (traceback != NULL &amp;&amp; !PyTraceBack_Check(traceback)) {
        Py_DECREF(traceback);
        traceback = NULL;
    }
    // 获取线程状态对象中已存在的异常（可能为空）
    oldtype = tstate-&gt;curexc_type;
    oldvalue = tstate-&gt;curexc_value;
    oldtraceback = tstate-&gt;curexc_traceback;

    // 将新异常设置在线程状态对象中
    tstate-&gt;curexc_type = type;
    tstate-&gt;curexc_value = value;
    tstate-&gt;curexc_traceback = traceback;
    
    // 减少旧异常的引用计数
    Py_XDECREF(oldtype);
    Py_XDECREF(oldvalue);
    Py_XDECREF(oldtraceback);
}
</code></pre>
<p>注意这里的 PyThreadState 对象，它是与线程相关的，但它只是线程信息的一个抽象描述，而真实的线程及状态肯定是由操作系统来维护和管理的。</p>
<p>但虚拟机在运行的时候总需要另外一些与线程相关的状态和信息，比如是否发生了异常等等，而这些信息显然操作系统是没办法提供的。而 PyThreadState 对象正是 Python 为线程准备的、在虚拟机层面保存线程状态信息的对象（后面简称线程状态对象、或者线程对象）。</p>
<p>当前活动线程（OS 原生线程）对应的 PyThreadState 对象可以通过 PyThreadState_GET 获得，在得到了线程状态对象之后，就将异常信息存放在里面。</p>
<blockquote>
<p>关于线程相关的内容，后续会详细说。</p>
</blockquote>
<h2 id="traceback-是什么"><a class="header" href="#traceback-是什么">traceback 是什么？</a></h2>
<p>帧评估函数里面有一个巨型的 switch，负责执行字节码指令，如果执行出错，那么跳转到 error 标签。</p>
<p><img src="./images/199.png" alt="" /></p>
<p>如果在执行指令的时候出现了异常，那么会跳转到 error 这里，否则会跳转到其它地方。另外当出现异常时，会在线程状态对象中将异常信息记录下来，包括异常类型、异常值、回溯栈（traceback），这个 traceback 就是在 error 标签中调用 PyTraceBack_Here 创建的。</p>
<p>另外可能有人不清楚 traceback 是做什么的，我们举个 Python 的例子。</p>
<pre><code class="language-python">def h():
    1 / 0

def g():
    h()

def f():
    g()

f()
&quot;&quot;&quot;
Traceback (most recent call last):
  File &quot;/Users/.../main.py&quot;, line 10, in &lt;module&gt;
    f()
  File &quot;/Users/.../main.py&quot;, line 8, in f
    g()
  File &quot;/Users/.../main.py&quot;, line 5, in g
    h()
  File &quot;/Users/.../main.py&quot;, line 2, in h
    1 / 0
ZeroDivisionError: division by zero
&quot;&quot;&quot;
</code></pre>
<p>这是脚本运行时产生的错误输出，我们看到了函数调用的信息：比如在源代码的哪一行调用了哪一个函数，那么这些信息是从何而来的呢？没错，显然是 traceback 对象。虚拟机在处理异常的时候，会创建 traceback 对象，在该对象中记录栈帧的信息。虚拟机利用该对象来将栈帧链表中每一个栈帧的状态进行可视化，可视化的结果就是上面输出的异常信息。</p>
<p>而且我们发现输出的信息也是一个链状的结构，因为每一个栈帧都会对应一个 traceback 对象，这些 traceback 对象之间也会组成一个链表。</p>
<p>所以当虚拟机开始处理异常的时候，它首先的动作就是创建 traceback 对象，用于记录异常发生时活动栈帧的状态。创建方式是通过 PyTraceBack_Here 函数，它接收一个栈帧作为参数。</p>
<pre><code class="language-C">// Python/traceback.c
int
PyTraceBack_Here(PyFrameObject *frame)
{
    // 获取当前的异常对象，拿到它的 exc_type、exc_val、exc_tb
    PyObject *exc, *val, *tb, *newtb;
    PyErr_Fetch(&amp;exc, &amp;val, &amp;tb);
    // 创建新的 traceback 对象，并和旧的 traceback 对象组成链表
    newtb = _PyTraceBack_FromFrame(tb, frame);
    if (newtb == NULL) {
        _PyErr_ChainExceptions(exc, val, tb);
        return -1;
    }
    // 将异常设置在线程状态对象中
    // 并且异常的 exc_type 和 exc_val 保持不变，但 traceback 是新的 traceback
    PyErr_Restore(exc, val, newtb);
    Py_XDECREF(tb);
    return 0;
}
</code></pre>
<p>那么这个 traceback 对象究竟长什么样呢？</p>
<pre><code class="language-C">// Include/cpython/traceback.h
typedef struct _traceback {
    PyObject_HEAD
    struct _traceback *tb_next;
    struct _frame *tb_frame;
    int tb_lasti;
    int tb_lineno;
} PyTracebackObject;
</code></pre>
<p>里面有一个 tb_next，所以很容易想到 traceback 也是一个链表结构。其实 traceback 对象的链表结构跟栈帧对象的链表结构是同构的、或者说一一对应的，即一个栈帧对象对应一个 traceback 对象。</p>
<h2 id="traceback-创建"><a class="header" href="#traceback-创建">traceback 创建</a></h2>
<p>在 PyTraceBack_Here 函数中我们看到，traceback 对象是通过 _PyTraceBack_FromFrame 创建的，那么秘密就隐藏在这个函数中。</p>
<pre><code class="language-C">// Python/traceback.c
_PyTraceBack_FromFrame(PyObject *tb_next, PyFrameObject *frame)
{
    assert(tb_next == NULL || PyTraceBack_Check(tb_next));
    assert(frame != NULL);

    return tb_create_raw((PyTracebackObject *)tb_next, frame, frame-&gt;f_lasti,
                         PyFrame_GetLineNumber(frame));
}

static PyObject *
tb_create_raw(PyTracebackObject *next, PyFrameObject *frame, int lasti,
              int lineno)
{
    PyTracebackObject *tb;
    if ((next != NULL &amp;&amp; !PyTraceBack_Check(next)) ||
                    frame == NULL || !PyFrame_Check(frame)) {
        PyErr_BadInternalCall();
        return NULL;
    }
    // 为 traceback 对象申请内存
    tb = PyObject_GC_New(PyTracebackObject, &amp;PyTraceBack_Type);
    if (tb != NULL) {
        // 设置属性
        Py_XINCREF(next);
        tb-&gt;tb_next = next;
        Py_XINCREF(frame);
        tb-&gt;tb_frame = frame;
        tb-&gt;tb_lasti = lasti;
        tb-&gt;tb_lineno = lineno;
        PyObject_GC_Track(tb);
    }
    return (PyObject *)tb;
}
</code></pre>
<p>tb_next 将两个 traceback 连接了起来，不过这个和栈帧的 f_back 正好相反，f_back 指向的是上一个栈帧，而 tb_next 指向的是下一个 traceback。</p>
<p>另外在 traceback 中，还通过 tb_frame 字段和对应的 PyFrameObject 对象建立了联系，当然还有最后执行完毕时的字节码偏移量、以及在源代码中对应的行号。</p>
<h2 id="栈帧展开"><a class="header" href="#栈帧展开">栈帧展开</a></h2>
<p>traceback 的创建我们知道了，那么它和栈帧对象是怎么联系起来的呢？我们还以之前的代码为例，来解释一下。</p>
<pre><code class="language-python">def h():
    1 / 0

def g():
    h()

def f():
    g()

f()
</code></pre>
<p>当执行到函数 h 的 1 / 0 这行代码时，底层会执行 BINARY_TRUE_DIVIDE 指令。</p>
<pre><code class="language-C">case TARGET(BINARY_TRUE_DIVIDE): {
    PyObject *divisor = POP();
    PyObject *dividend = TOP();
    // 调用了数值型对象的泛型 API
    PyObject *quotient = PyNumber_TrueDivide(dividend, divisor);
    Py_DECREF(dividend);
    Py_DECREF(divisor);
    SET_TOP(quotient);
    if (quotient == NULL)
        goto error;
    DISPATCH();
}

// Objects/abctract.c
PyObject *
PyNumber_TrueDivide(PyObject *v, PyObject *w)
{
    return binary_op(v, w, NB_SLOT(nb_true_divide), &quot;/&quot;);
}

#define NB_SLOT(x) offsetof(PyNumberMethods, x)
// 最终会执行 (&amp;PyLong_Type) -&gt; tp_as_methods -&gt; nb_true_divide
// 即 long_true_divice 函数，看一下它的逻辑

// Objects/longobject.c
static PyObject *
long_true_divide(PyObject *v, PyObject *w)
{
    // ...
    a_size = Py_ABS(Py_SIZE(a));
    b_size = Py_ABS(Py_SIZE(b));
    negate = (Py_SIZE(a) &lt; 0) ^ (Py_SIZE(b) &lt; 0);
    // 如果除数为 0，设置 ZeroDivisionError
    if (b_size == 0) {
        PyErr_SetString(PyExc_ZeroDivisionError,
                        &quot;division by zero&quot;);
        goto error;
    }
    // ...
    error:
        return NULL;
}
</code></pre>
<p>由于除数为 0，因此会通过 PyErr_SetString 设置一个异常进去，最终将异常类型、异常值、以及 traceback 保存到线程状态对象中。然后跳转到 error 标签，注意：当前是 long_true_divide 的 error 标签，然后会返回 NULL。</p>
<p><img src="./images/200.png" alt="" /></p>
<p>当 long_true_divide 返回 NULL 时，那么变量 quotient 拿到的就是 NULL，由于没有指向一个合法的 PyObject，虚拟机就意识到发生异常了，这时候会跳转到 error 标签。注意：这个 error 标签是帧评估函数里的 error 标签。</p>
<p><img src="./images/201.png" alt="" /></p>
<p>在里面会先取出线程状态对象中已有的 traceback 对象，然后以函数 h 的栈帧为参数，创建一个新的 traceback 对象，将两者通过 tb_next 关联起来。最后，再替换掉线程状态对象里面的 traceback 对象。</p>
<p>在虚拟机意识到有异常抛出，并创建了 traceback 之后，它会在当前栈帧中寻找 try except 语句，来执行开发人员指定的异常捕捉动作。如果没有找到，那么虚拟机将退出当前的活动栈帧，并沿着栈帧链回退到上一个栈帧（这里是函数 g 的栈帧），在上一个栈帧中寻找 try except 语句。</p>
<p>就像我们之前说的，函数调用会创建栈帧，当函数执行完毕或者出现异常时，会回退到上一级栈帧。一层一层创建、一层一层返回。至于回退的这个动作，则是在 _PyEval_EvalFrameDefault 的最后完成。</p>
<p><img src="./images/202.png" alt="" /></p>
<p>当出现异常时，虚拟机会进入 exception_unwind 标签寻找异常捕获逻辑，相关细节下一篇文章再说，这里就让它抛出去。然后来到 exit_returning 标签，将运行时栈清空。最后进入 exit_eval_frame 标签，将当前线程状态对象中的活跃栈帧设置为上一级栈帧，从而完成栈帧回退的动作。</p>
<p>当栈帧回退时，会进入函数 g 的栈帧，由于返回值为 NULL，所以知道自己调用的函数 h 的内部发生异常了（否则返回值一定会指向一个合法的 PyObject），那么继续寻找异常捕获语句。对于当前这个例子来说，显然是找不到的，于是会从线程状态对象中取出已有的 traceback 对象（函数 h 的栈帧对应的 traceback），然后以函数 g 的栈帧为参数，创建新的 traceback 对象，再将两者通过 tb_next 关联起来，并重新设置到线程状态对象中。</p>
<p>异常会沿着栈帧链进行反向传播，函数 h 出现的异常被传播到了函数 g 中，显然接下来函数 g 要将异常传播到函数 f 中。因为函数 g 在无法捕获异常时，那么返回值也是 NULL，而函数 f 看到返回值为 NULL 时，同样会去寻找异常捕获语句。但是找不到，于是会从线程状态对象中取出已有的 traceback 对象（此时是函数 g 的栈帧对应的 traceback），然后以函数 f 的栈帧为参数，创建新的 traceback 对象，再将两者通过 tb_next 关联起来，并重新设置到线程状态对象中。</p>
<p>最后再传播到模块对应的栈帧中，如果还无法捕获发生的异常，那么虚拟机就要将异常抛出来了。</p>
<p><strong>这个沿着栈帧链不断回退的过程我们称之为<font color="blue">栈帧展开</font>，在栈帧展开的过程中，虚拟机不断地创建与各个栈帧对应的 traceback，并将其链接成链表。</strong></p>
<p><img src="./images/203.png" alt="" /></p>
<p>由于没有异常捕获，那么接下来会调用 PyErr_Print。然后在 PyErr_Print 中，虚拟机取出维护的 traceback 链表，并进行遍历，将里面的信息逐个输出到 stderr 当中，最终就是我们在 Python 中看到的异常信息。</p>
<p>并且打印顺序是：.py文件、函数f、函数g、函数h。因为每一个栈帧对应一个 traceback，而栈帧又是往后退的，因此显然会从 .py文件对应的 traceback 开始打印，然后通过 tb_next 找到函数 f 对应的 traceback，依次下去。当异常信息全部输出完毕之后，解释器就结束运行了。</p>
<p>因此从链路的开始位置到结束位置，将整个调用过程都输出出来，可以很方便地定位问题出现在哪里。</p>
<p><img src="./images/204.png" alt="" /></p>
<p>另外，虽然 traceback 一直在更新（因为要对整个调用链路进行追踪），但是<font color="blue">异常类型</font>和<font color="blue">异常值</font>始终是不变的，就是函数 h 中抛出的 <font color="blue">ZeroDivisionError: division by zero</font>。</p>
<h2 id="小结-50"><a class="header" href="#小结-50">小结</a></h2>
<p>以上就是虚拟机抛异常的过程，异常在 Python 里面也是一个对象，和其它的实例对象并无本质区别。</p>
<pre><code class="language-Python">exc = StopIteration(&quot;迭代结束了&quot;)
print(exc.value)  # 迭代结束了
print(exc.args)  # ('迭代结束了',)

exc = IndexError(&quot;索引越界了&quot;)
print(exc.args)  # ('索引越界了',)

exc = Exception(&quot;不知道是啥异常，总之出问题了&quot;)
print(exc.args)  # ('不知道是啥异常，总之出问题了',)

# 异常都有一个 args 属性，以元组的形式保存传递的参数
</code></pre>
<p>所谓抛出异常，就是将错误信息输出到 stderr 中，然后停止进程。并且除了虚拟机内部会抛出异常之外，我们还可以使用 raise 关键字手动引发一个异常。</p>
<pre><code class="language-Python">def judge_score(score: int):
    if score &gt; 100 or score &lt; 0:
        raise ValueError(&quot;Score must be between 0 and 100&quot;)
</code></pre>
<p>站在虚拟机的角度，score 取任何值都是合理的，但对于我们来说，希望 score 位于 0 ~ 100。那么当 score 不满足 0 ~ 100 时，就可以手动 raise 一个异常。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-51"><a class="header" href="#楔子-51">楔子</a></h2>
<p>上一篇文章我们介绍了 Python 的异常是怎么实现的，抛出异常这个动作在虚拟机层面上是怎样的一个行为，以及虚拟机在处理异常时的栈帧展开行为。</p>
<p>既然虚拟机内建的异常处理动作我们已经了解了，那么接下来就看看异常捕获是如何实现的，还有它又是如何影响虚拟机的异常处理流程的。毕竟在大部分情况下，我们都不会将异常抛出去，而是将它捕获起来。</p>
<h2 id="异常捕获语句"><a class="header" href="#异常捕获语句">异常捕获语句</a></h2>
<p>这里先来回顾一下异常捕获语句，首先一个完整的异常捕获语句如下。</p>
<pre><code class="language-python">try:
    pass
except IndexError as e:
    pass
except Exception as e:
    pass
else:
    pass
finally:
    pass 
</code></pre>
<p>情况可以分为以下几种：</p>
<p><font color="darkblue"><strong>1）如果 try 里面的代码在执行时没有出现异常，那么会执行 else ，然后执行 finally。</strong></font></p>
<pre><code class="language-python">try:
    print(&quot;我是 try&quot;)
except Exception as e:
    print(&quot;我是 except&quot;)
else:
    print(&quot;我是 else&quot;)
finally:
    print(&quot;我是 finally&quot;)
&quot;&quot;&quot;
我是 try
我是 else
我是 finally
&quot;&quot;&quot;    
</code></pre>
<p><font color="darkblue"><strong>2）如果 try 里面的代码在执行时出现异常了（异常会被设置在线程状态对象中），那么会依次判断 except（可以有多个）能否匹配发生的异常。如果某个 except 将异常捕获了，那么会将异常给清空，然后执行 finally。</strong></font></p>
<pre><code class="language-python">try:
    raise IndexError(&quot;IndexError Occurred&quot;)
except ValueError as e:
    print(&quot;ValueError 匹配上了异常&quot;)
except IndexError as e:
    print(&quot;IndexError 匹配上了异常&quot;)
except Exception as e:
    print(&quot;Exception 匹配上了异常&quot;)
else:
    print(&quot;我是 else&quot;)
finally:
    print(&quot;我是 finally&quot;)
&quot;&quot;&quot;
IndexError 匹配上了异常
我是 finally
&quot;&quot;&quot;   
</code></pre>
<p>except 子句可以有很多个，发生异常时会从上往下依次匹配。但是注意：多个 except 子句最多只有一个被执行，比如当前的 IndexError 和 Exception 都能匹配发生的异常，但只会执行匹配上的第一个 except 子句。</p>
<p>另外只要发生异常了，else 就不会执行了。不管 except 有没有将异常捕获到，都不会执行 else，因为 else 只有在 try 里面没有发生异常的时候才会执行。</p>
<p><font color="darkblue"><strong>3）如果 try 里面的代码在执行时出现异常了，但 except 没有将异常捕获掉，那么异常仍然被保存在线程状态对象中，然后执行 finally。如果 finally 子句中没有出现 return、break、continue 等关键字，再将异常抛出来。</strong></font></p>
<pre><code class="language-python">try:
    raise IndexError(&quot;IndexError Occurred&quot;)
except ValueError:
    print(&quot;ValueError 匹配上了异常&quot;)
finally:
    print(&quot;我是 finally&quot;)
&quot;&quot;&quot;
我是 finally
Traceback (most recent call last):
  File &quot;......&quot;, line 2, in &lt;module&gt;
    raise IndexError(&quot;IndexError Occurred&quot;)
IndexError: IndexError Occurred
&quot;&quot;&quot;
</code></pre>
<p>except 没有将异常捕获掉，所以执行完 finally 之后，异常又被抛出来了。但如果 finally 里面出现了 return、break、continue 等关键字，也不会抛出异常，而是将异常丢弃掉。</p>
<pre><code class="language-python">def f():
    try:
        raise IndexError(&quot;IndexError Occurred&quot;)
    except ValueError:
        print(&quot;ValueError 匹配上了异常&quot;)
    finally:
        print(&quot;我是 finally&quot;)
        return

f()
&quot;&quot;&quot;
我是 finally
&quot;&quot;&quot;

def g():
    for i in range(3):
        try:
            raise IndexError(&quot;IndexError Occurred&quot;)
        except ValueError:
            print(&quot;ValueError 匹配上了异常&quot;)
        finally:
            print(f&quot;我是 finally，i = {i}&quot;)
            continue

g()
&quot;&quot;&quot;
我是 finally，i = 0
我是 finally，i = 1
我是 finally，i = 2
&quot;&quot;&quot;
</code></pre>
<p>由于 finally 里面出现了 return 和 continue，所以异常并没有发生，而是被丢弃掉了。这个特性相信有很多小伙伴之前还是没有发现的。</p>
<p>然后 try、except、else、finally 这几个关键字不需要同时出现，可以有以下几种组合。</p>
<pre><code class="language-python">try ... except

try ... finally

try ... except ... else

try ... except ... else ... finally
</code></pre>
<p>注意里面的 except，可以出现多次，但其它关键字在一个 try 语句内只能出现一次。</p>
<h2 id="返回值问题"><a class="header" href="#返回值问题">返回值问题</a></h2>
<p>如果这几个关键字对应的代码块都指定了返回值，那么听谁的呢？下面解释一下。</p>
<pre><code class="language-python">def retval():
    try:
        return 123
    except Exception:
        return 456

print(retval())  # 123
</code></pre>
<p>由于没有发生异常，所以返回了 try 指定的返回值。</p>
<pre><code class="language-python">def retval():
    try:
        return 123
    except Exception:
        return 456
    else:
        return 789

print(retval())  # 123
</code></pre>
<p>虽然指定了 else，但是 try 里面已经执行 return 了，所以打印的仍是 try 的返回值。</p>
<pre><code class="language-python">def retval():
    try:
        1 / 0
        return 123
    except Exception:
        return 456

print(retval())  # 456
</code></pre>
<p>由于发生异常，所以返回了 except 指定的返回值。</p>
<pre><code class="language-python">def retval():
    try:
        1 / 0
        return 123
    except Exception:
        return 456
    else:
        return 789

print(retval())  # 456
</code></pre>
<p>一旦发生异常，else 就不可能执行，所以此时仍然返回 456。</p>
<pre><code class="language-python">def retval():
    try:
        return 123
    except Exception:
        return 456
    finally:
        pass

print(retval())  # 123
</code></pre>
<p>finally 永远会执行，但它没有指定返回值，所以此时返回的是 123。</p>
<pre><code class="language-python">def retval():
    try:
        return 123
    except Exception:
        return 456
    finally:
        return

print(retval())  # None
</code></pre>
<p>一旦 finally 中出现了 return，那么返回的都是 finally 指定的返回值。并且此时即便出现了没有捕获的异常，也不会报错，因为会将异常丢弃掉。</p>
<pre><code class="language-python">def retval():
    try:
        return 123
    except Exception:
        return 456
    finally:
        pass
    return 789

print(retval())  # 123
</code></pre>
<p>函数一旦 return，就表示要返回了，但如果这个 return 是位于出现了 finally 的异常捕获语句中，那么会先执行 finally，然后再返回。所以最后的 return 789 是不会执行的，因为已经出现 return 了，finally 执行完毕之后就直接返回了。</p>
<pre><code class="language-python">def retval():
    try:
        pass
    except Exception:
        return 456
    finally:
        pass
    return 789

print(retval())  # 789
</code></pre>
<p>没有异常，所以 except 里的 return 不会执行，而 try 和 finally 里面也没有 return，因此返回 789。</p>
<blockquote>
<p>一个简单的异常捕获，总结起来还稍微有点绕呢。</p>
</blockquote>
<p>从 Python 的层面理解完异常捕获之后，再来看看虚拟机是如何实现这一机制的？想要搞清楚这一点，还是得从字节码入手。</p>
<h2 id="异常捕获对应的字节码"><a class="header" href="#异常捕获对应的字节码">异常捕获对应的字节码</a></h2>
<p>随便写一段代码，然后反编译一下。</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
try:
    raise Exception(&quot;抛出一个异常&quot;)
except Exception as e:
    print(e)
finally:
    print(&quot;我一定会被执行的&quot;)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;exception&quot;, &quot;exec&quot;))
</code></pre>
<p>抛异常有两种方式，一种是虚拟机执行的时候出现错误而抛出异常，另一种是使用 raise 关键字手动抛出异常。这里我们就用第二种方式，来看一下反编译的结果（为了清晰，省略掉了源代码行号）。</p>
<pre><code class="language-C">      0 SETUP_FINALLY           60 (to 62)
      2 SETUP_FINALLY           12 (to 16)

      4 LOAD_NAME                1 (Exception)
      6 LOAD_CONST               1 ('抛出一个异常')
      8 CALL_FUNCTION            1
     10 RAISE_VARARGS            1
     12 POP_BLOCK
     14 JUMP_FORWARD            42 (to 58)

&gt;&gt;   16 DUP_TOP
     18 LOAD_NAME                1 (Exception)
     20 COMPARE_OP              10 (exception match)
     22 POP_JUMP_IF_FALSE       56
     24 POP_TOP
     26 STORE_NAME               2 (e)
     28 POP_TOP
     30 SETUP_FINALLY           12 (to 44)

     32 LOAD_NAME                0 (print)
     34 LOAD_NAME                2 (e)
     36 CALL_FUNCTION            1
     38 POP_TOP
     40 POP_BLOCK
     42 BEGIN_FINALLY
&gt;&gt;   44 LOAD_CONST               2 (None)
     46 STORE_NAME               2 (e)
     48 DELETE_NAME              2 (e)
     50 END_FINALLY
     52 POP_EXCEPT
     54 JUMP_FORWARD             2 (to 58)
&gt;&gt;   56 END_FINALLY
&gt;&gt;   58 POP_BLOCK
     60 BEGIN_FINALLY

&gt;&gt;   62 LOAD_NAME                0 (print)
     64 LOAD_CONST               0 ('我一定会被执行的')
     66 CALL_FUNCTION            1
     68 POP_TOP
     70 END_FINALLY
     72 LOAD_CONST               2 (None)
     74 RETURN_VALUE
</code></pre>
<p>指令集还是有点复杂的，因为要分好几种情况。</p>
<ul>
<li>try 里面没有出现异常。</li>
<li>try 里面出现了异常，但是 except 没有捕获到。</li>
<li>try 里面出现了异常，except 捕获到了。</li>
</ul>
<p>但我们知道无论是哪种情况，都要执行 finally，所以开头有两个 SETUP_FINALLY 指令，但为什么会有两个呢？因为在 Python 的异常处理机制中，<font color="blue">try-except-finally</font> 结构会被编译成两个嵌套的异常处理块：</p>
<ul>
<li>第一个 SETUP_FINALLY 是为了处理 finally 块，会把 finally 块的地址压入栈中，它确保无论 try 块中是否发生异常，finally 块中的代码都会被执行；</li>
<li>第二个 SETUP_FINALLY 实际上是在处理 except 块，在 Python 的字节码层面，except 块也是通过 SETUP_FINALLY 实现的；</li>
</ul>
<p>我们来看一下 SETUP_FINALLY 指令都干了什么。</p>
<pre><code class="language-C">case TARGET(SETUP_FINALLY): {
    PyFrame_BlockSetup(f, SETUP_FINALLY, INSTR_OFFSET() + oparg,
                       STACK_LEVEL());
    DISPATCH();
}
</code></pre>
<p>该指令内部仅仅是调用了 PyFrame_BlockSetup 函数，但是参数我们需要解释一下。</p>
<ul>
<li>f：当前的栈帧对象。</li>
<li>SETUP_FINALLY：指令本身，一个整数，值为 122。</li>
<li>INSTR_OFFSET()：一个宏，下一条待执行指令的偏移量，如果再加上 oparg，那么会对应 finally 子句（或 except 子句）。</li>
<li>STACK_LEVEL()：返回运行时栈的元素个数。</li>
</ul>
<p>下面看看 PyFrame_BlockSetup 函数的本体。</p>
<pre><code class="language-C">// Objects/frameobject.c

void
PyFrame_BlockSetup(PyFrameObject *f, int type, int handler, int level)
{
    // 关于 PyTryBlock 我们稍后再聊，总之 except 和 finally 都会对应 SETUP_FINALLY 指令
    // 虚拟机都会为它们创建 PyTryBlock
    PyTryBlock *b;
    // 一会儿解释
    if (f-&gt;f_iblock &gt;= CO_MAXBLOCKS)
        Py_FatalError(&quot;XXX block stack overflow&quot;);
    // 栈帧有一个 f_blockstack 字段，它是 PyTryBlock 类型的数组
    // 当栈帧创建完毕后，f_blockstack 的内存就已经申请好了
    // 因此当需要创建 PyTryBlock 实例时，只需从 f_blockstack 里面获取即可
    b = &amp;f-&gt;f_blockstack[f-&gt;f_iblock++];
    // 设置 PyTryBlock 实例的字段，这个结构体一会儿说
    b-&gt;b_type = type;
    b-&gt;b_level = level;
    b-&gt;b_handler = handler;
}
</code></pre>
<p>当解释器发现 except 和 finally 时，在进入 try 语句块之前会先执行 SETUP_FINALLY 指令，通过索引 f_iblock 从 f_blockstack 数组中获取 PyTryBlock。</p>
<ul>
<li>每获取一个 PyTryBlock，f_iblock 会自增 1；</li>
<li>当 except 或 finally 执行完毕时，要交还对应的 PyTryBlock，所以 f_iblock 会自减 1。</li>
</ul>
<p>然后注意一下上面代码中的 if 条件，CO_MAXBLOCKS 是一个宏，值为 20，所以 f_iblock 的值必须小于 20。这也意味着，try 语句不能嵌套太深。我们举例说明：</p>
<p><img src="./images/205.png" alt="" /></p>
<p>每个 try 都对应一个 except，因为屏幕不够，这里只截取了一半。每次进入 try 之前，会提前执行 SETUP_FINALLY，获取 PyTryBlock。由于每获取一个，f_iblock 自增 1，而这里嵌套了 20 层，导致 f_iblock 达到了 20，所以报错了，这是一个在编译阶段就能检测出的错误。</p>
<p>如果我们去掉一层呢？看看报不报错。</p>
<p><img src="./images/206.png" alt="" /></p>
<p>结果没有问题，当然啦，如果不是恶意代码，我个人认为不会存在嵌套层级如此之深的异常捕获。</p>
<p>然后再来看看里面的 f_iblock，它表示对应的 PyTryBlock 在 f_blockstack 数组中的索引。栈帧刚创建时，f_iblock 的值为 0，每当执行 SETUP_FINALLY 指令时，就会从 f_blockstack 数组中获取一个 PyTryBlock，然后 f_iblock 自增 1。那么 PyTryBlock 长什么样子呢？</p>
<pre><code class="language-C">// Include/frameobject.h
typedef struct {
    int b_type;
    int b_handler;
    int b_level;
} PyTryBlock;
</code></pre>
<p>b_type 表示 block 的种类，因为存在多种用途的 PyTryBlock 对象，除了 SETUP_FINALLY 之外还有 SETUP_WITH 等。然后在 PyFrame_BlockSetup 中我们看到它被设置成了参数 type，而参数 type 接收的就是当前虚拟机正在执行的字节码指令。因此 PyTryBlock 具有多种用途，具体用于哪种则基于字节码指令进行判断。</p>
<p>b_handler 表示处理程序的字节码偏移量，即跳转目标，比如当前的 try 语句块，当 try 执行完了或者执行出错后，要跳转到什么位置呢？在 SETUP_FINALLY 指令中我们看到它被设置成了 <font color="blue">INSTR_OFFSET() + oparg</font>，所以它会跳转到 finally 或 except 所在的位置。</p>
<p>b_level 表示进入 try 语句块时的 STACK_LEVEL()，即运行时栈的深度，或者说当前运行时栈的元素个数，因为当发生异常时，要把运行时栈恢复到进入 try 语句块时的状态。</p>
<pre><code class="language-python"># 假设此时运行时栈的深度是 n
try:                          # SETUP_FINALLY 执行时 b_level = n
    ...                       # 执行内部逻辑
    raise Exception(&quot;error&quot;)  # 在这里不幸发生异常，那么要将栈恢复到 b_level 记录的深度 n
except Exception:
    pass
</code></pre>
<p>所以 b_level 相当于一个检查点，通过 b_level，可以在发生异常时将运行时栈恢复到进入 try 时的状态。这种检查点机制确保了异常处理的可靠性，因为无论 try 块中发生什么，我们总能回到一个已知的、正确的栈状态。</p>
<p>然后我们再回头看开头的两个指令：</p>
<pre><code class="language-C">      0 SETUP_FINALLY           60 (to 62)
      2 SETUP_FINALLY           12 (to 16)
</code></pre>
<p>执行之后，f_blockstack 数组的布局如下：</p>
<p><img src="./images/207.png" alt="" /></p>
<p>取出两块 PyTryBlock，第一块对应 finally，会无条件执行，第二块对应 except，异常捕获的时候用。至于具体怎么做的稍后再说，我们先回到抛异常的地方看看。</p>
<pre><code class="language-C">      // 加载 &lt;class 'Exception'&gt;
      4 LOAD_NAME                1 (Exception)
      // 加载字符串
      6 LOAD_CONST               1 ('抛出一个异常')
      // 尽管 Exception 是一个类，但调用的指令也同样是 CALL_FUNCTION
      // 至于这个指令的具体细节后面会介绍
      // 这里只需要知道一个异常对象已经被创建出来了，并被压入了运行时栈
      8 CALL_FUNCTION            1
      // 从运行时栈中弹出异常对象，然后抛出
     10 RAISE_VARARGS            1
</code></pre>
<p>下面我们来看一下 RAISE_VARARGS 指令。</p>
<pre><code class="language-C">case TARGET(RAISE_VARARGS): {
    PyObject *cause = NULL, *exc = NULL;
    // raise 一个异常有三种方式
    // 1）重新抛出当前异常，只写一个 raise 即可，此时 oparg = 0
    // 2）抛出指定异常：raise exc，此时 oparg = 1
    // 3）抛出指定异常并指定原因：raise exc from cause，此时 oparg = 2
    // 所以当前的 oparg = 1
    switch (oparg) {
    case 2:
        cause = POP(); /* cause */
        /* fall through */
    case 1:
        exc = POP(); /* exc */
        /* fall through */
    case 0:
        // 调用 do_raise 函数，将异常设置在线程状态对象中
        if (do_raise(tstate, exc, cause)) {
            goto exception_unwind;
        }
        break;
    default:
        _PyErr_SetString(tstate, PyExc_SystemError,
                         &quot;bad RAISE_VARARGS oparg&quot;);
        break;
    }
    goto error;
}
</code></pre>
<p>当异常设置完毕后，我们看到它跳转到了帧评估函数的 exception_unwind 标签，执行异常捕获。</p>
<pre><code class="language-C">exception_unwind:
    // 虚拟机在进入 try 代码块之前，会为 except 和 finally 块创建 PyTryBlock
    // 对于当前来说，由于同时指定了 except 和 finally，因此会存在两个 PyTryBlock
    // 所以 f-&gt;f_iblock 的值为 2
    while (f-&gt;f_iblock &gt; 0) {
        // 弹出 PyTryBlock，因为 except 在后面，所以要从后往前获取
        PyTryBlock *b = &amp;f-&gt;f_blockstack[--f-&gt;f_iblock];
        
        // EXCEPT_HANDLER 定义在 opcode.h 中，值为 257，用于异常处理
        // 但比较特殊的是，它不是一个指令，至于相关细节后续会看到
        if (b-&gt;b_type == EXCEPT_HANDLER) {  // 如果两者相等的话
            // 这是一个宏，所做的事情如下
            // 从线程状态对象中拿到 exc_info，这个和 python 里的 sys.exc_info() 等价
            // 然后从栈顶弹出 exc_type、exc_value、exc_traceback，并设置在 exc_info 中
            UNWIND_EXCEPT_HANDLER(b);
            continue;
        }
        // UNWIND_BLOCK 是一个宏，所做的事情如下
        /*
            // 如果当前栈深度大于进入 try 块时记录的深度
            // 不断从栈顶弹出对象，并减少引用计数
            #define UNWIND_BLOCK(b) \
                while (STACK_LEVEL() &gt; (b)-&gt;b_level) { \
                    PyObject *v = POP(); \
                    Py_XDECREF(v); \
                }
        */
        // 这个 b_level 我们上面说过的，它保存了进入 try 块时的运行时栈的深度
        // 因此这个宏就是用来倒掉多余的栈内容，把栈恢复到之前保存的检查点状态
        UNWIND_BLOCK(b);
        // 对于当前的代码而言，第一次弹出的 PyTryBlock 用于 except
        // 它的 b_type = SETUP_FINALLY，b_handler = 16
        if (b-&gt;b_type == SETUP_FINALLY) {
            // 异常类型、异常值、回溯栈
            PyObject *exc, *val, *tb;
            // 拿到 b_handler，一会要跳转的目标位置，也就是 except 所在位置
            int handler = b-&gt;b_handler;
            // 从线程状态对象中拿到 exc_info，这个 exc_info 保存的还是旧异常的 exc_info
            // 然后 exc_info 有三个字段，假设抛出的异常是 ValueError(&quot;值错了&quot;)
            // exc_info-&gt;exc_type 就是 &lt;class 'ValueError'&gt;
            // exc_info-&gt;exc_value 就是抛出的异常对象本身
            // exc_info-&gt;exc_traceback 就是回溯栈
            // exc_info-&gt;previous_item 指向上一个 _PyErr_StackItem 实例
            _PyErr_StackItem *exc_info = tstate-&gt;exc_info;
            // 将当前 PyTryBlock 的 b_type 设置为 EXCEPT_HANDLER
            PyFrame_BlockSetup(f, EXCEPT_HANDLER, -1, STACK_LEVEL());
            // 将旧异常的 exc_type、exc_value、exc_traceback 压入运行时栈
            PUSH(exc_info-&gt;exc_traceback);
            PUSH(exc_info-&gt;exc_value);
            if (exc_info-&gt;exc_type != NULL) {
                PUSH(exc_info-&gt;exc_type);
            }
            else {
                Py_INCREF(Py_None);
                PUSH(Py_None);
            }
            // 在 RAISE_VARARGS 指令中调用了 do_raise，设置了新异常
            // 这里是拿到新异常的 exc_type、exc_value、exc_traceback
            _PyErr_Fetch(tstate, &amp;exc, &amp;val, &amp;tb);
            // 对异常规范化处理，不用关注
            _PyErr_NormalizeException(tstate, &amp;exc, &amp;val, &amp;tb);
            if (tb != NULL)
                PyException_SetTraceback(val, tb);
            else
                PyException_SetTraceback(val, Py_None);
            // 用新异常的 exc_type、exc_value、exc_traceback 更新 exc_info
            Py_INCREF(exc);
            exc_info-&gt;exc_type = exc;
            Py_INCREF(val);
            exc_info-&gt;exc_value = val;
            exc_info-&gt;exc_traceback = tb;
            if (tb == NULL)
                tb = Py_None;
            Py_INCREF(tb);
            // 将新异常的 exc_type、exc_value、exc_traceback 也压入运行时栈
            PUSH(tb);
            PUSH(val);
            PUSH(exc);
            // 绝对跳转，跳转到偏移量为 handler 的指令
            JUMPTO(handler);
            /* Resume normal execution */
            goto main_loop;
        }
    } /* unwind stack */

    /* End the loop as we still have an error */
    break;
} /* main loop */

assert(retval == NULL);
assert(_PyErr_Occurred(tstate));
</code></pre>
<p>我们看到虚拟机调用 PUSH 将旧异常和新异常的 exc_traceback、exc_value、exc_type 分别压入运行时栈中，并且知道此时开发者已经为异常处理做好了准备，所以接下来的异常处理工作，则需要交给开发者指定的代码来解决。于是内部调用了 <code>JUMPTO(b-&gt;b_handler)</code>，将虚拟机要执行的下一条指令设置为异常处理代码编译后所得到的第一条字节码指令。</p>
<p>因为第一个弹出的 PyTryBlock 的 b_handler 为 16，那么虚拟机将要执行的下一条指令就是偏移量为 16 的指令，而这条指令就是 DUP_TOP。</p>
<pre><code class="language-C">     // 在上面的 exception_unwind 标签中调用了 6 个 PUSH
     // 按照从栈顶到栈底顺序，目前运行时栈的元素如下
     /* 新异常的 exc_type
      * 新异常的 exc_value
      * 新异常的 exc_traceback
      * 旧异常的 exc_type
      * 旧异常的 exc_value
      * 旧异常的 exc_traceback
      */
     // DUP_TOP 指令之前介绍过，它会将栈顶元素拷贝一份，然后重新压入运行时栈
     // 显然这里就是新异常的 exc_type，即 &lt;class 'Exception'&gt;
&gt;&gt;   16 DUP_TOP
     // 因为是 except Excepion as e，所以将 &lt;class 'Exception'&gt; 压入运行时栈
     18 LOAD_NAME                1 (Exception)
     // 将前两个元素从运行时栈中弹出，分别是 except 后面指定的异常类型、新异常的 exc_type
     // 然后比较产生的异常的类型是否是 except 指定的异常类型的子类
     20 COMPARE_OP              10 (exception match)
     // 因为 raise 了一个 Exception 对象，所以 exc_type 就是 Exception
     // 而 except 子句后面指定的也是 Exception，所以是匹配的
     // 如果不匹配，那么跳转到偏移量为 56 的指令，去执行 finally
     22 POP_JUMP_IF_FALSE       56
     // 这个指令内部负责弹出栈顶元素，减少引用计数，直接丢弃
     // 目前栈里面有 6 个元素，栈顶元素是新异常的 exc_type
     // 所以 POP_TOP 之后，栈顶元素就变成了新异常的 exc_value
     24 POP_TOP
     // 弹出栈顶的 exc_value，赋值给变量 e，到此 except Exception as e 完成
     // 我们看到这个过程其实也是一个变量赋值，字节码为 STORE_NAME
     26 STORE_NAME               2 (e)
     // 继续弹出栈顶元素，此时是新异常的 exc_traceback
     28 POP_TOP
     // 这里为啥又出现一个 SETUP_FINALLY 指令？很简单
     /*
      try:
          pass
      except Exception as e:
          pass
      
      上面这段代码，在内部会变成下面这样
      
      try:
          pass
      except Exception as e:
          try:
              pass
          finally:
              del e
      */
     // 所以这里会多出一个 SETUP_FINALLY，因为内部又嵌套了一个 try ... finally
     // 至于这么做的原因，我们稍后解释
     30 SETUP_FINALLY           12 (to 44)
     // 以下四条指令对应 except 子句内的 print(e)
     32 LOAD_NAME                0 (print)
     34 LOAD_NAME                2 (e)
     36 CALL_FUNCTION            1
     38 POP_TOP
     // except 子句里的代码执行完毕，调用 POP_BLOCK
     // 该指令内部会交还 PyTryBlock，然后 f_iblock--
     // 注意：这一步交还的 PyTryBlock，是 except 内部的 finally 对应的 PyTryBlock
     40 POP_BLOCK
     // BEGIN_FINALLY 会往栈顶 PUSH 一个 NULL 进去，标识 finally 的开始
     // 注意：这个 finally 是 except 子句内部的 finally，是解释器自动生成的
     42 BEGIN_FINALLY
     // 将 e 赋值为 None，然后将 e 删除掉
&gt;&gt;   44 LOAD_CONST               2 (None)
     46 STORE_NAME               2 (e)
     48 DELETE_NAME              2 (e)
     50 END_FINALLY
     // 到此整个 except 执行完毕，然后执行 POP_EXCEPT，交还对应的 PyTryBlock
     // 然后在该指令内部还会恢复之前保存的异常状态，我们上面看到，解释器往运行时栈里面推了 6 个元素
     // 前 3 个已经被弹出了，还剩下旧异常的 exc_type、exc_value、exc_traceback
     // 那么将它们继续弹出，赋值给 exc_info 里面的字段，相当于恢复成之前的异常状态
     52 POP_EXCEPT
     // 跳转到第 58 条指令
     54 JUMP_FORWARD             2 (to 58)    
</code></pre>
<p>上面的内容有点多，我们再单独解释一下，首先在 exception_unwind 标签内部获取 <code>tstate-&gt;exc_info</code> 的三个字段，它们是旧异常的 exc_type、exc_value、exc_traceback，然后压入运行时栈。再通过 _PyErr_Fetch 获取 tstate 里面的新异常的 exc_type、exc_value、exc_traceback，用它们更新 <code>tstate-&gt;exc_info</code>，然后再压入运行时栈。</p>
<p>所以此时运行时栈里面有 6 个元素。</p>
<p><img src="./images/208.png" alt="" /></p>
<p>然后使用 JUMPTO 跳转到偏移量为 <code>b-&gt;b_handler</code> 的指令，对于当前来说就是 except 子句对应的指令，然后执行。</p>
<ul>
<li>通过 DUP_TOP 将栈顶元素拷贝一份并入栈。</li>
<li>通过 LOAD_NAME 将 except 子句指定的异常类型入栈。</li>
<li>通过 COMPARE_OP 将栈顶的两个元素弹出，进行比较，将比较结果入栈。</li>
<li>再通过 POP_JUMP_IF_FALSE 将比较结果弹出，进行判断，由于新异常的 exc_type 和 except 子句指定的异常类型都是 Exception，所以结果为 True。</li>
</ul>
<p>我们画张图，展示一下运行时栈的变化过程。</p>
<p><img src="./images/209.png" alt="" /></p>
<p>然后是 30 SETUP_FINALLY，至于为什么会多出这条指令，原因我们也解释了。</p>
<pre><code class="language-Python">e = 2.71

try:
    raise Exception(&quot;Some Error&quot;)
except Exception as e:
    # 一些逻辑
    ...

print(e)
&quot;&quot;&quot;
NameError: name 'e' is not defined
&quot;&quot;&quot;
# 打印 print(e) 的时候居然 NameError 了
# 因为上面的代码会被转成下面这个样子
try:
    raise Exception(&quot;Some Error&quot;)
except Exception as e:
    try:
        # 一些逻辑
        ...
    finally:
        del e
</code></pre>
<p>所以又产生了一个 SETUP_FINALLY 指令，至于解释器这么做的动机我们稍后解释。</p>
<p>然后偏移量为 32、34、36、38 的指令就无需解释了，这几条指令执行完毕后，except 语句块里的代码就执行完了。然后执行 40 POP_BLOCK，它会交还当前 except 内部的 finally 语句块对应的 PyTryBlock，然后将 f_iblock 自减 1。</p>
<pre><code class="language-C">case TARGET(POP_BLOCK): {
    PREDICTED(POP_BLOCK);
    PyFrame_BlockPop(f);
    DISPATCH();
}

// Objects/frameobject.c
PyTryBlock *
PyFrame_BlockPop(PyFrameObject *f)
{
    PyTryBlock *b;
    if (f-&gt;f_iblock &lt;= 0)
        Py_FatalError(&quot;XXX block stack underflow&quot;);
    b = &amp;f-&gt;f_blockstack[--f-&gt;f_iblock];
    return b;
}
</code></pre>
<p>接着将变量 e 赋值为 None，然后删除变量 e，完事之后再执行 52 POP_EXCEPT。</p>
<pre><code class="language-C">case TARGET(POP_EXCEPT): {
    PyObject *type, *value, *traceback;
    _PyErr_StackItem *exc_info;
    // 同样调用 PyFrame_BlockPop，拿到 except 对应的 PyTryBlock
    PyTryBlock *b = PyFrame_BlockPop(f);
    // 在 exception_unwind 标签中，将 b_type 设置成了 EXCEPT_HANDLER
    // 所以这里一定等于 EXCEPT_HANDLER，否则不应该执行 POP_EXCEPT 指令
    if (b-&gt;b_type != EXCEPT_HANDLER) {
        _PyErr_SetString(tstate, PyExc_SystemError,
                         &quot;popped block is not an except handler&quot;);
        goto error;
    }
    assert(STACK_LEVEL() &gt;= (b)-&gt;b_level + 3 &amp;&amp;
           STACK_LEVEL() &lt;= (b)-&gt;b_level + 4);
    // 此时 exc_info 里面保存的是新异常的 exc_info、exc_type、exc_value
    // 但是新异常被捕获了
    exc_info = tstate-&gt;exc_info;
    type = exc_info-&gt;exc_type;
    value = exc_info-&gt;exc_value;
    traceback = exc_info-&gt;exc_traceback;
    // 那么应该将 exc_info 的字段改成之前的旧异常的 exc_info、exc_type、exc_value
    exc_info-&gt;exc_type = POP();
    exc_info-&gt;exc_value = POP();
    exc_info-&gt;exc_traceback = POP();
    // 减少引用计数
    Py_XDECREF(type);
    Py_XDECREF(value);
    Py_XDECREF(traceback);
    DISPATCH();
}
</code></pre>
<p>到此整个 except 语句块我们就分析完了，接下来是 finally 语句块。</p>
<pre><code class="language-C">     // 交还 finally 语句块对应的 PyTryBlock，将 f_iblock 自减 1
&gt;&gt;   58 POP_BLOCK
     // finally 语句块的开始
     60 BEGIN_FINALLY
     // 内部的代码逻辑
&gt;&gt;   62 LOAD_NAME                0 (print)
     64 LOAD_CONST               0 ('我一定会被执行的')
     66 CALL_FUNCTION            1
     68 POP_TOP
     // 如果异常未被捕获掉，那么向上传播，让外层的异常处理程序去处理它
     70 END_FINALLY
     72 LOAD_CONST               2 (None)
     74 RETURN_VALUE
</code></pre>
<p>因此在异常机制的实现中，最重要的就是线程状态以及栈帧对象的 f_blockstack 字段里面存放的 PyTryBlock 对象。首先根据线程状态可以判断当前是否发生了异常，而 PyTryBlock 对象则告诉虚拟机，开发者是否为异常设置了 except 和 finally，虚拟机异常处理的流程就是在线程所处的状态和 PyTryBlock 的共同作用下完成的。</p>
<p>当然啦，我们这里分析的是异常能捕获的情况，如果不能捕获呢？具体细节可以自己写段代码测试一下，这里我们直接画张图总结一下。</p>
<p><img src="./images/210.png" alt="" /></p>
<p>另外这张图只适用于一个 except 子句的情况，如果有多个 except 子句，那么当第一个不匹配时，应该要顺序匹配下一个。</p>
<p>总之 Python 中一旦出现异常了，那么会将异常类型、异常值、异常回溯栈设置在线程状态对象中，然后栈帧一步一步地回退，寻找异常捕获代码（从内向外）。如果退到了模块级别还没有发现异常捕获，那么从外向内打印 traceback 中的信息，当走到最内层的时候再将线程中设置的异常类型和异常值打印出来。</p>
<pre><code class="language-Python">def h():
    1 / 0

def g():
    h()

def f():
    g()

f()

# traceback 回溯栈
Traceback (most recent call last):
  # 打印模块的 traceback
  # 并提示：发生错误是因为在第 10 行调用了 f()
  File &quot;/Users/.../main.py&quot;, line 10, in &lt;module&gt;
    f()

  # 打印函数 f 的 traceback
  # 并提示：发生错误是因为在第 8 行调用了 g()
  File &quot;/Users/.../main.py&quot;, line 8, in f
    g()

  # 打印函数 g 的 traceback
  # 并提示：发生错误是因为在第 5 行调用了 h()
  File &quot;/Users/.../main.py&quot;, line 5, in g
    h()

  # 打印函数 h 的 traceback
  # 并提示：发生错误是因为在第 2 行执行了 1 / 0
  File &quot;/Users/.../main.py&quot;, line 2, in h
    1 / 0

# 函数 h 的 traceback-&gt;tb_next 为 None，证明错误是发生在函数 h 中
# 而在模块中调用函数 f 相当于导火索，然后一层一层输出，最终定位到函数 h
# 最后再将之前设置在线程状态对象中的异常类型和异常值打印出来即可
ZeroDivisionError: division by zero
</code></pre>
<p>模块中调用了函数 f，函数 f 调用了函数 g，函数 g 调用了函数 h。然后在函数 h 中执行出错了，但又没有异常捕获，那么会将执行权交给函数 g 对应的栈帧，但是函数 g 也没有异常捕获，那么再将执行权交给函数 f 对应的栈帧。所以调用的时候，栈帧一层层创建，当执行完毕或者出现异常时，栈帧再一层层回退。</p>
<p><img src="./images/211.png" alt="" /></p>
<p>因此栈帧的遍历顺序是<font color="blue">从函数 h 到模块</font>，traceback 的遍历顺序是<font color="blue">从模块到函数 h</font>。</p>
<h2 id="为什么要执行-del"><a class="header" href="#为什么要执行-del">为什么要执行 del</a></h2>
<p>前面说了，在 except 语句块内，如果将异常赋给了某个变量，那么 except 结束时会将变量删掉。</p>
<pre><code class="language-python">e = 2.71

def get_e():
    return e

try:
    raise Exception(&quot;我要引发异常了&quot;)
except Exception as e:
    # 因为 except Exception as e 位于全局作用域
    # 所以执行完之后，全局变量 e 就被修改了
    print(get_e())  # 我要引发异常了
    # 但是在最后还会隐式地执行 del e，那为什么要这么做呢？
    # 因为 except 子句结束后，变量 e 指向的异常对象就没用了
    # 而如果不 del e 的话，那么异常对象不会被销毁
    # 此外还有一个原因，通过 __traceback__ 可以拿到当前的回溯栈，即 traceback 对象
    print(e.__traceback__)  # &lt;traceback object at 0x104a98b80&gt;
    # 而 traceback 对象保存了当前的栈帧，然后栈帧又保存了包含变量 e 的名字空间
    print(e.__traceback__.tb_frame.f_locals[&quot;e&quot;] is e)  # True
    # 相信你能猜到这会带来什么后果，没错，就是循环引用
    # 因此在 except 结束时会隐式地 del e

# 显然当 except 结束后，全局变量 e 就无法访问了
print(e)
&quot;&quot;&quot;
NameError: name 'e' is not defined
&quot;&quot;&quot;
</code></pre>
<p>所以在附加了回溯信息的情况下，它们会形成堆栈帧的循环引用，在下一次垃圾回收执行之前，会使所有变量都保持存活。</p>
<h2 id="小结-51"><a class="header" href="#小结-51">小结</a></h2>
<p>本篇文章我们就分析了异常捕获的实现原理，总的来说并不难。另外在更高的版本中，所有的信息会静态保存在一张异常跳转表中，速度会更快。当然啦，在没有报错时，异常捕获对程序性能没有任何影响，所以放心使用。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-52"><a class="header" href="#楔子-52">楔子</a></h2>
<p>函数是任何一门编程语言都具备的基本元素，它可以将多个动作组合起来，一个函数代表了一系列的动作。而且在调用函数时会干什么来着，没错，要创建栈帧，用于函数的执行。</p>
<p>那么下面就来看看函数在 C 中是如何实现的，生得一副什么模样。</p>
<h2 id="pyfunctionobject"><a class="header" href="#pyfunctionobject">PyFunctionObject</a></h2>
<p>Python 一切皆对象，函数也不例外，函数这种抽象机制在底层是通过 PyFunctionObject 结构体实现的。</p>
<pre><code class="language-C">// Include/funcobject.h

typedef struct {
    PyObject_HEAD
    PyObject *func_code;
    PyObject *func_globals;
    PyObject *func_defaults;
    PyObject *func_kwdefaults;
    PyObject *func_closure;
    PyObject *func_doc;
    PyObject *func_name;
    PyObject *func_dict;
    PyObject *func_weakreflist;
    PyObject *func_module;
    PyObject *func_annotations;
    PyObject *func_qualname;
    vectorcallfunc vectorcall;
} PyFunctionObject;
</code></pre>
<p>我们来解释一下这些字段，并实际获取一下，看看它们在 Python 中是如何表现的。</p>
<p><font color="darkblue"><strong>func_code：函数对应的 PyCodeObject 对象</strong></font></p>
<pre><code class="language-python">def foo(a, b, c):
    pass

code = foo.__code__
print(code)  # &lt;code object foo at ......&gt;
print(code.co_varnames)  # ('a', 'b', 'c')
</code></pre>
<p>函数便是基于 PyCodeObject 构建的。</p>
<p><font color="darkblue"><strong>func_globals：global 名字空间</strong></font></p>
<pre><code class="language-python">def foo(a, b, c):
    pass

name = &quot;古明地觉&quot;
print(foo.__globals__)  # {..., 'name': '古明地觉'}
# 拿到的其实就是外部的 global 名字空间
print(foo.__globals__ is globals())  # True
</code></pre>
<p>函数内部之所以可以访问全局变量，就是因为它保存了全局名字空间。</p>
<p><font color="darkblue"><strong>func_defaults：函数参数的默认值</strong></font></p>
<pre><code class="language-python">def foo(name=&quot;古明地觉&quot;, age=16):
    pass
# 打印的是默认值
print(foo.__defaults__)  # ('古明地觉', 16)

def bar():
    pass
# 没有默认值的话，__defaults__ 为 None
print(bar.__defaults__)  # None
</code></pre>
<p>注：默认值只会创建一次，所以默认值不应该是可变对象。</p>
<p><font color="darkblue"><strong>func_kwdefaults：只能通过关键字参数传递的 &quot;参数&quot; 和 &quot;该参数的默认值&quot; 组成的字典</strong></font></p>
<pre><code class="language-python">def foo(name=&quot;古明地觉&quot;, age=16):
    pass
# 打印为 None，这是因为虽然有默认值
# 但并不要求必须通过关键字参数的方式传递
print(foo.__kwdefaults__)  # None

def bar(name=&quot;古明地觉&quot;, *, age=16):
    pass
print(bar.__kwdefaults__)  # {'age': 16}
</code></pre>
<p>加上一个 * 表示后面的参数必须通过关键字的方式传递。</p>
<p><font color="darkblue"><strong>func_closure：一个元组，包含了内层函数使用的外层作用域的变量，即 cell 变量。</strong></font></p>
<pre><code class="language-python">def foo():
    name = &quot;古明地觉&quot;
    age = 17

    def bar():
        print(name, age)

    return bar


# 内层函数 bar 使用了外层作用域中的 name、age 变量
print(foo().__closure__)
&quot;&quot;&quot;
(&lt;cell at 0x7f3f4398ac70: int object at 0x7f3f442413c0&gt;, 
 &lt;cell at 0x7f3f439e38b0: str object at 0x7f3f43b0ded0&gt;)
&quot;&quot;&quot;

print(foo().__closure__[0].cell_contents)  # 17
print(foo().__closure__[1].cell_contents)  # 古明地觉
</code></pre>
<p>注意：查看闭包属性使用的是内层函数。</p>
<p><font color="darkblue"><strong>func_doc：函数的 docstring</strong></font></p>
<pre><code class="language-python">def foo():
    &quot;&quot;&quot;
    hi，欢迎来到我的小屋
    遇见你真好
    &quot;&quot;&quot;
    pass

print(foo.__doc__)
&quot;&quot;&quot;
    hi，欢迎来到我的小屋
    遇见你真好
&quot;&quot;&quot;
</code></pre>
<p>当我们在写 Python 扩展的时候，由于编译之后是一个 pyd，那么就会通过 docstring 来描述函数的相关信息。</p>
<p><font color="darkblue"><strong>func_name：函数的名字</strong></font></p>
<pre><code class="language-python">def foo(name, age):
    pass

print(foo.__name__)  # foo
</code></pre>
<p>当然不光是函数，还有方法、类、模块等都有自己的名字。</p>
<pre><code class="language-python">import numpy as np

print(np.__name__)  # numpy
print(np.ndarray.__name__)  # ndarray
print(np.array([1, 2, 3]).transpose.__name__)  # transpose
</code></pre>
<p>除了 func_name 之外，函数还有一个 func_qualname 字段，表示全限定名。</p>
<pre><code class="language-python">print(str.join.__name__)  # join
print(str.join.__qualname__)  # str.join
</code></pre>
<p>函数如果定义在类里面，那么它就叫类的成员函数，当然它本质上依旧是个函数，和普通函数并无区别。只是在获取全限定名的时候，会带上类名。</p>
<p><font color="darkblue"><strong>func_dict：函数的属性字典</strong></font></p>
<pre><code class="language-python">def foo(name, age):
    pass

print(foo.__dict__)  # {}
</code></pre>
<p>函数在底层也是由一个类实例化得到的，所以它也可以有自己的属性字典，只不过这个字典一般为空。</p>
<p><font color="darkblue"><strong>func_weakreflist：弱引用列表</strong></font></p>
<p>这里不做讨论。</p>
<p><font color="darkblue"><strong>func_module：函数所在的模块</strong></font></p>
<pre><code class="language-python">import numpy as np

print(np.array.__module__)  # numpy
</code></pre>
<p>除了函数之外，类、方法、协程也有 __module__ 属性。</p>
<p><font color="darkblue"><strong>func_annotations：函数的类型注解</strong></font></p>
<pre><code class="language-python">def foo(name: str, age: int):
    pass

# Python3.5 新增的语法，但只能用于函数参数
# 而在 3.6 的时候，声明变量也可以使用这种方式
# 特别是当 IDE 无法得知返回值类型时，便可通过类型注解的方式告知 IDE
# 这样就又能使用 IDE 的智能提示了
print(
    foo.__annotations__
)  # {'name': &lt;class 'str'&gt;, 'age': &lt;class 'int'&gt;}  
</code></pre>
<p>像 FastAPI、Pydantic 等框架，都大量应用了类型注解。</p>
<p><font color="darkblue"><strong>vectorcall：矢量调用协议</strong></font></p>
<p>函数本质上也是一个实例对象，在调用时会执行类型对象的 tp_call，对应 Python 里的 __call__。但 tp_call 属于通用逻辑，而通用往往也意味着平庸，tp_call 在执行时需要创建临时元组和临时字典来存储位置参数、关键字参数，这些临时对象增加了内存分配和垃圾回收的开销。</p>
<p>如果只是一般的实例对象倒也没什么，但函数不同，它作为实例对象注定是要被调用的。所以底层对它进行了优化，引入了速度更快的 vectorcall，即矢量调用。而一个实例对象如果支持矢量调用，那么它也必须支持普通调用，并且两者的结果是一致的，如果对象不支持矢量调用，那么会退化成普通调用。</p>
<h2 id="小结-52"><a class="header" href="#小结-52">小结</a></h2>
<p>以上就是函数的底层结构，在 Python 里面是由 &lt;class 'function'&gt; 实例化得到的。</p>
<pre><code class="language-python">def foo(name, age):
    pass

# &lt;class 'function'&gt; 就是 C 里面的 PyFunction_Type
print(foo.__class__)  # &lt;class 'function'&gt;
</code></pre>
<p>但这个类底层没有暴露给我们，所以不能直接用，因为函数通过 def 创建即可，不需要通过类型对象来创建。</p>
<p>后续会介绍更多关于函数相关的知识。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-53"><a class="header" href="#楔子-53">楔子</a></h2>
<p>前面我们介绍了函数的基本结构，它在底层由 PyFunctionObject 结构体表示，那么本篇文章来看看函数的创建过程。</p>
<h2 id="函数是何时创建的"><a class="header" href="#函数是何时创建的">函数是何时创建的</a></h2>
<p>介绍函数结构时，我们看到内部有一个 func_code 字段，指向一个 PyCodeObject 对象，而函数就是根据 PyCodeObject 对象创建的。</p>
<p>因为一个 PyCodeObject 是对一段代码的静态表示，Python 编译器将源代码编译之后，针对里面的每一个代码块（code block）都会生成相应的 PyCodeObject 对象，该对象包含了这个代码块的一些静态信息，也就是可以从源代码中看到的信息。</p>
<p>比如某个函数对应的代码块里面有一个 <font color="blue">a = 1</font> 这样的表达式，那么<font color="blue">符号 a</font> 和<font color="blue">整数 1</font>、以及它们之间的联系就是静态信息。这些信息会被静态存储起来，符号 a 被存在符号表 co_varnames 中，整数 1 被存在常量池 co_consts 中。然后 a = 1 是一条赋值语句，因此会有两条指令 LOAD_CONST 和 STORE_FAST 存在字节码指令序列 co_code 中。</p>
<p>这些信息是在编译的时候就可以得到的，因此 PyCodeObject 对象是编译之后的结果。</p>
<p>但 PyFunctionObject 对象是何时产生的呢？显然它是 Python 代码在运行时动态产生的，更准确的说，是在执行一个 def 语句的时候创建的。当虚拟机发现了 def 语句，那么就代表发现了新的 PyCodeObject 对象，因为它们是可以层层嵌套的。</p>
<p>然后虚拟机会根据这个 PyCodeObject 对象创建对应的 PyFunctionObject 对象，并将变量名和 PyFunctionObject 对象（函数体）组成键值对放在当前的 local 空间中。而在 PyFunctionObject 对象中，也需要拿到相关的静态信息，因此会有一个 func_code 字段指向 PyCodeObject。</p>
<p>除此之外，PyFunctionObject 对象还包含了一些函数在执行时所必需的动态信息，即上下文信息。比如 func_globals，就是函数在执行时关联的 global 名字空间，如果没有这个空间的话，函数就无法访问全局变量了。</p>
<p>由于 global 作用域中的符号和值必须在运行时才能确定，所以这部分必须在运行时动态创建，无法静态存储在 PyCodeObject 中。因此要基于 PyCodeObject 对象和 global 名字空间来创建 PyFunctionObject 对象，相当于一个封装。总之一切的目的，都是为了更好地执行字节码。</p>
<p>我们举个例子：</p>
<pre><code class="language-python"># 首先虚拟机从上到下执行字节码
name = &quot;古明地觉&quot;
age = 17

# 啪，很快啊，出现了一个 def
def foo():
    pass

# 出现了 def，虚拟机就知道源代码进入了一个新的作用域了
# 也就是遇到一个新的 PyCodeObject 对象了
# 而通过 def 关键字知道这是一个函数，于是会进行封装
# 将 PyCodeObject 封装成 PyFunctionObject，同时包含了全局名字空间
# 所以当执行完 def 语句之后，一个函数就被创建了
# 然后将变量名 foo 和函数体（PyFunctionObject）组成键值对存放在当前的 local 空间中
# 当然对于模块而言，local 空间也是 global 空间
print({k: v for k, v in locals().items() if k == &quot;foo&quot;})
&quot;&quot;&quot;
{'foo': &lt;function foo at 0x7f3f43b135e0&gt;}
&quot;&quot;&quot;

# 函数内部也保存了 global 空间
print(foo.__globals__ is globals() is locals())
&quot;&quot;&quot;
True
&quot;&quot;&quot;
print(foo.__globals__[&quot;foo&quot;] is foo is locals()[&quot;foo&quot;])
&quot;&quot;&quot;
True
&quot;&quot;&quot;
</code></pre>
<p>调用的时候，会从 local 空间中取出符号 foo 对应的 PyFunctionObject 对象（函数对象）。然后根据函数对象创建栈帧对象，也就是为函数创建一个栈帧，随后将执行权交给新创建的栈帧，并在新创建的栈帧中执行字节码。</p>
<h2 id="函数是怎么创建的"><a class="header" href="#函数是怎么创建的">函数是怎么创建的</a></h2>
<p>经过分析我们知道，当执行到 def 语句时会创建函数，并保存在 local 空间中。而通过<font color="blue">函数名()</font> 进行调用时，会从 local 空间取出和函数名绑定的函数对象，然后执行。</p>
<p>那么问题来了，函数（对象）是怎么创建的呢？或者说虚拟机是如何完成 PyCodeObject 对象到 PyFunctionObject 对象之间的转变呢？显然想了解这其中的奥秘，就必须从字节码入手。</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
name = &quot;satori&quot;

def foo(a, b):
    print(a, b)

foo(1, 2)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;func&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>源代码很简单，定义一个变量 name 和一个函数 foo，然后调用函数。显然这里面会产生两个 PyCodeObject，我们来看一下。</p>
<pre><code class="language-C">     // name = &quot;satori&quot;
   0 LOAD_CONST               0 ('satori')
   2 STORE_NAME               0 (name)
     
     // 我们看到 PyCodeObject 也会作为常量被静态收集
     // 这里是将常量池中索引为 1 的 PyCodeObject 压入运行时栈
   4 LOAD_CONST               1 (&lt;code object foo at 0x7f3f43b12c90...&gt;)
     // 加载字符串常量 &quot;foo&quot;，也就是函数名
   6 LOAD_CONST               2 ('foo')
     // 从栈中弹出函数名和 PyCodeObject，构建函数对象
     // 然后将函数对象（的指针）再压入运行时栈
   8 MAKE_FUNCTION            0
     // 从栈中弹出函数对象，并用符号 foo 绑定起来，到此函数就创建完毕了
  10 STORE_NAME               1 (foo)
    
     // 以下是 foo(1, 2) 对应的字节码
     // 加载全局变量 foo 并入栈
  12 LOAD_NAME                1 (foo)
     // 加载常量 1 和 2 并入栈
  14 LOAD_CONST               3 (1)
  16 LOAD_CONST               4 (2)
     // 从栈中弹出函数和参数，然后调用，并将调用结果、即函数的返回值压入栈中
  18 CALL_FUNCTION            2
     // 从栈顶弹出返回值，因为我们没有使用变量保存，所以会直接丢弃
     // 如果使用变量保存了，比如 res = foo(1, 2)，那么这里的字节码就是 STORE_NAME
  20 POP_TOP
  22 LOAD_CONST               5 (None)
  24 RETURN_VALUE
     
     // 以上是模块对应的字节码指令，下面是函数对应的字节码指令
Disassembly of &lt;code object foo at 0x7f3f43b12c90, file &quot;&lt;func&gt;&quot;, line 4&gt;:
     // 比较简单，就是 print(a, b) 对应的字节码
   0 LOAD_GLOBAL              0 (print)
   2 LOAD_FAST                0 (a)
   4 LOAD_FAST                1 (b)
   6 CALL_FUNCTION            2
   8 POP_TOP
  10 LOAD_CONST               0 (None)
  12 RETURN_VALUE
</code></pre>
<p>通过字节码我们看到，def 关键字实际上还是在定义变量，正所谓<font color="blue">函数即变量</font>，我们可以把函数当成普通的变量来处理。函数名就是变量名，它位于模块对应的 PyCodeObject 的符号表中。函数体就是变量指向的值，它是基于一个独立的 PyCodeObject 构建的。</p>
<p>至此，函数的结构就已经非常清晰了。</p>
<p><img src="./images/212.png" alt="" /></p>
<p>分析完结构之后，重点就要落在 MAKE_FUNCTION 指令上了，我们说当遇到 def 关键字的时候，就知道要创建函数了。在语法上这是函数的声明语句，但从虚拟机的角度来看，这其实是函数对象的创建语句。</p>
<p>所以函数是怎么创建的，就是执行 MAKE_FUNCTION 指令创建的，该指令执行完毕后，一个函数对象就被压入了运行时栈。等到 STORE_NAME 执行时，再将它从栈中弹出，然后和变量（函数名）绑定起来。</p>
<h2 id="make_function-指令"><a class="header" href="#make_function-指令">MAKE_FUNCTION 指令</a></h2>
<p>下面我们就来分析一下 MAKE_FUNCTION 指令，看看它是怎么将一个 PyCodeObject 对象变成一个 PyFunctionObject 对象的。</p>
<pre><code class="language-c">case TARGET(MAKE_FUNCTION): {
    // 弹出函数的全限定名
    PyObject *qualname = POP();
    // 弹出 PyCodeObject 对象
    PyObject *codeobj = POP();
    // 创建 PyFunctionObject 对象，接收三个参数
    // 分别是 PyCodeObject 对象、global 名字空间、函数的全限定名
    PyFunctionObject *func = (PyFunctionObject *)
        PyFunction_NewWithQualName(codeobj, f-&gt;f_globals, qualname);
    
    Py_DECREF(codeobj);
    Py_DECREF(qualname);
    // 如果函数创建失败会返回 NULL，那么跳转至 error 标签
    if (func == NULL) {
        goto error;
    }
  
    // 编译时，解释器能够静态检测出函数有没有闭包变量、类型注解等属性，并体现在 oparg 中
    // 构建函数时，通过 oparg 和一系列标志位做按位与，来判断函数是否包含指定属性
    // 由于 oparg 是指令参数，所以这些属性是否存在、以及如何访问，在编译阶段就已经确定了
    if (oparg &amp; 0x08) {
        assert(PyTuple_CheckExact(TOP()));
        func -&gt;func_closure = POP();
    }
    if (oparg &amp; 0x04) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_annotations = POP();
    }
    if (oparg &amp; 0x02) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_kwdefaults = POP();
    }
    if (oparg &amp; 0x01) {
        assert(PyTuple_CheckExact(TOP()));
        func-&gt;func_defaults = POP();
    }
    // 函数创建之后，压入运行时栈
    PUSH((PyObject *)func);
    DISPATCH();
}
</code></pre>
<p>整个步骤很好理解，先通过 LOAD_CONST 将 PyCodeObject 对象和符号 foo 压入栈中。然后执行 MAKE_FUNCTION，将两者从栈中弹出，再加上当前栈帧对象中维护的 global 名字空间，三者作为参数传入 PyFunction_NewWithQualName 函数中，从而构建出相应的 PyFunctionObject 对象。</p>
<p>下面来看看 PyFunction_NewWithQualName 是如何构造出一个 Python 函数的。</p>
<pre><code class="language-C">// Objects/funcobject.c

PyObject *
PyFunction_NewWithQualName(PyObject *code, PyObject *globals, PyObject *qualname)
{
    // 要返回的 PyFunctionObject 对象的指针 
    PyFunctionObject *op;
    // 函数的 doc、常量池、函数所在的模块
    PyObject *doc, *consts, *module;
    static PyObject *__name__ = NULL;
    // 将变量 __name__ 赋值为 &quot;__main__&quot;
    // 另外由于 __name__ 是静态变量，所以只会初始化一次
    if (__name__ == NULL) {
        __name__ = PyUnicode_InternFromString(&quot;__name__&quot;);
        if (__name__ == NULL)
            return NULL;
    }
    // 从 global 空间中获取 __name__ 的值
    // 如果创建 Python 函数时所在的文件是被导入的，那么它的值就是对应的模块名
    // 如果创建 Python 函数时所在的文件是直接执行的，那么它的值就是 __main__
    module = PyDict_GetItemWithError(globals, __name__);
    if (module) {
        Py_INCREF(module);
    }
    else if (PyErr_Occurred()) {
        return NULL;
    }
    // 通过 PyObject_GC_New 为函数对象申请空间，这里我们看到了 gc
    // 因为函数是可以发生循环引用的，因此需要被 GC 跟踪
    // 而想被 GC 跟踪，则需要有一个 PyGC_Head
    // 所以此处使用 PyObject_GC_New，同时也会为 PyGC_Head 申请内存
    op = PyObject_GC_New(PyFunctionObject, &amp;PyFunction_Type);
    if (op == NULL) {
        Py_XDECREF(module);
        return NULL;
    }
    // 下面就是设置 PyFunctionObject 对象的字段属性了
    op-&gt;func_weakreflist = NULL;
    Py_INCREF(code);
    op-&gt;func_code = code;
    Py_INCREF(globals);
    op-&gt;func_globals = globals;
    op-&gt;func_name = ((PyCodeObject *)code)-&gt;co_name;
    Py_INCREF(op-&gt;func_name);
    op-&gt;func_defaults = NULL;
    op-&gt;func_kwdefaults = NULL;
    op-&gt;func_closure = NULL;
    // 以后会通过 _PyFunction_Vectorcall 来实现函数的调用
    op-&gt;vectorcall = _PyFunction_Vectorcall;
    op-&gt;func_module = module;
    // 通过 PyCodeObject 对象获取常量池
    consts = ((PyCodeObject *)code)-&gt;co_consts;
    // 函数的 docstring 其实就是一个字符串，显然它也是常量池的一个常量，并且是常量池的第一个常量
    // 如果函数没有 docstring，那么常量池里的第一个元素会是 None，而不是字符串
    if (PyTuple_Size(consts) &gt;= 1) {
        // 所以如果 consts 的长度 &gt;=1，并且第一个元素是字符串，那么它就是函数的 docstring
        doc = PyTuple_GetItem(consts, 0);
        if (!PyUnicode_Check(doc))
            doc = Py_None;
    }
    else
        doc = Py_None;
    Py_INCREF(doc);
    // 下面也是设置 PyFunctionObject 对象的字段
    op-&gt;func_doc = doc;
    op-&gt;func_dict = NULL;
    op-&gt;func_annotations = NULL;
    if (qualname)
        op-&gt;func_qualname = qualname;
    else
        op-&gt;func_qualname = op-&gt;func_name;
    Py_INCREF(op-&gt;func_qualname);
    // 让函数对象被 GC 跟踪
    _PyObject_GC_TRACK(op);
    // 返回其泛型指针
    return (PyObject *)op;
}
</code></pre>
<p>以上就是函数对象的创建过程，说白了就是对 PyCodeObject 进行了一个封装。等函数对象创建完毕后会回到 MAKE_FUNCTION，然后设置闭包、注解等属性，并将函数对象压入栈中。接着执行 STORE_NAME 从符号表中加载符号（函数名），并从栈顶弹出函数对象，然后将两者组成键值对存储在当前栈帧的 local 名字空间中，整体还是比较简单的。</p>
<p>但如果再加上类型注解、以及默认值，会有什么效果呢？</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
name = &quot;satori&quot;
def foo(a: int = 1, b: int = 2):
    print(a, b)
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;func&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>我们看看加上了类型注解和默认值之后，它的字节码指令会有什么变化？</p>
<pre><code class="language-C"> 0 LOAD_CONST               0 ('satori')
 2 STORE_NAME               0 (name)

 4 LOAD_CONST               7 ((1, 2))
 6 LOAD_NAME                1 (int)
 8 LOAD_NAME                1 (int)
10 LOAD_CONST               3 (('a', 'b'))
12 BUILD_CONST_KEY_MAP      2
14 LOAD_CONST               4 (&lt;code object foo at 0x7f3f4...&gt;)
16 LOAD_CONST               5 ('foo')
18 MAKE_FUNCTION            5 (defaults, annotations)
20 STORE_NAME               2 (foo)
// ......
</code></pre>
<p>不难发现，在构建函数时会先将默认值以元组的形式压入运行时栈；然后再将使用了类型注解的<font color="blue">参数</font>和<font color="blue">类型</font>也组成一个元组，并压入运行时栈。后续创建函数的时候，会将默认值保存在 func_defaults 字段中，类型注解对应的字典会保存在 func_annotations 字段中。</p>
<p><img src="./images/213.png" alt="" /></p>
<p>验证一下：</p>
<pre><code class="language-python">def foo(a: int = 1, b: int = 2):
    print(a, b)

print(foo.__defaults__)
&quot;&quot;&quot;
(1, 2)
&quot;&quot;&quot;
print(foo.__annotations__)
&quot;&quot;&quot;
{'a': &lt;class 'int'&gt;, 'b': &lt;class 'int'&gt;}
&quot;&quot;&quot;
</code></pre>
<p>基于类型注解，我们便可以额外施加一些手段，让 Python 像静态语言一样，实现函数参数的类型约束。</p>
<h2 id="聊一聊函数名"><a class="header" href="#聊一聊函数名">聊一聊函数名</a></h2>
<p>这里再说一下函数名，举个例子。</p>
<pre><code class="language-python">def foo():
    pass

print(foo.__name__)  # foo

bar = foo
print(bar.__name__)  # foo
</code></pre>
<p>我们定义了一个函数 foo，那么函数名就是 foo，这是没问题的，但怎么理解 bar 呢？</p>
<p>所以严格意义上讲，代码中的 foo 应该是一个变量。之前说过，定义函数、类、导入模块，其实都是创建了一个变量。所以代码中的 foo 也是一个变量，它指向了函数对象，而函数的名字是保存在函数对象里面的。</p>
<pre><code class="language-python">code_string = &quot;&quot;&quot;
def foo():
    pass
&quot;&quot;&quot;

code_obj = compile(code_string, &quot;&lt;func&gt;&quot;, &quot;exec&quot;)
# 我们是以模块的形式编译的，它里面只有一个变量 foo
# 所以符号表就是 ('foo',)
print(code_obj.co_names)  # ('foo',)

# 然后常量池里面存在一个 PyCodeObject
# 这个 PyCodeObject 便是函数对应的 PyCodeObject
print(code_obj.co_consts[0])  # &lt;code object foo ...&gt;
print(code_obj.co_consts[0].co_name)  # foo

# 构建函数时，PyCodeObject 的 co_name 会被赋值给函数的 func_name
# 所以严格意义上讲，def foo() 中的 foo 只能算做是变量名
# 而真正的函数名是函数对象的 func_name，它来自于 co_name
# 只不过在编译成 PyCodeObject 对象时，会进行词法分析
# 因为 def 后面是 foo，所以编译之后的 PyCodeObject 的 co_name 也是 foo

# 当然其它对象也是如此
class A:
    pass

# 这里的 A 指向了类型对象，但类型对象的名称是保存在类型对象里面的
print(A.__name__)  # A
# A.__name__ 才是类名，class 后面的 A 只是一个变量名

# 这里同样创建了一个类
B = type(&quot;B1&quot;, (object,), {})
print(B.__name__)  # B1
# 但是我们看到类名不是 B，而是 B1
# 所以我们需要明白，不管是变量赋值、还是定义函数、类、方法，导入模块
# 我们得到的只是一个变量，这个变量指向了具体的对象（它们是字典中的一个键值对）
# 而对象的名称、类型等信息，都保存在对象里面，和变量无关
# 因为变量只是一个符号，或者理解为代号，每个对象都可以有不同的代号

def foo():
    pass

# 名称也可以自由更改
foo.__name__ = &quot;foo1&quot;
# 在更改过后，函数的名字就变成了 foo1
print(foo.__name__)  # foo1

# bar = foo 之后，这个函数对象就有了两个代号，你通过 foo 和 bar 都可以找到它
# 但函数对象的名字是不变的，还是 foo1，因为它的 __name__ 属性的值是 foo1
bar = foo
print(bar.__name__)  # foo1
</code></pre>
<p>我们之前说变量只是一个和对象绑定的符号，或者说代号，运行时会和某个对象（的地址）组成键值对保存在字典中。虚拟机通过变量可以找到它代表的对象，本质上就是将变量名作为 key，去字典中检索 value。至于获取到的对象叫什么名字，是保存在对象里面的。</p>
<p>如果变量指向的是整数、字符串等，那么该对象就没有名字。如果指向的是函数、类、模块，那么对象的 __name__ 就是对象的名字。只不过在默认情况下，定义函数（以及类）时，变量名默认和函数名是一样的，所以我们会把指向函数对象的变量的名称也叫做函数名。</p>
<p>关于这一点，大家一定要清晰。</p>
<pre><code class="language-python">name = &quot;古明地觉&quot;

def foo():
    pass

class A:
    pass

import os

print(&quot;name&quot; in locals())  # True
print(&quot;foo&quot; in locals())  # True
print(&quot;A&quot; in locals())  # True
print(&quot;os&quot; in locals())  # True
</code></pre>
<p>这里的 name、foo、A、os 都是变量，站在虚拟机的角度，它们没有任何的不同，只不过指向的对象不同罢了。而站在 Python 的角度，它们也是一样的，其名称都是字典里的一个 key，只不过关联的 value 不同罢了。</p>
<p><img src="./images/214.png" alt="" /></p>
<p>比如 name 指向的是字符串对象，foo 指向的是函数对象，A 指向的是类对象，os 指向的是模块对象。但我们也可以改变指向，比如让 foo 指向类对象，A 指向字符串对像等等，都是可以的。</p>
<p>总结：变量只是一个指针，可以保存任意对象的地址，也就是可以指向任意的对象。而对象的名字、类型等一切信息，都保存在对象中，和变量无关。</p>
<p>当然这些都是之前说过的内容，再来回顾一下，总之一定要了解 Python 变量的本质。</p>
<h2 id="函数的一些骚操作"><a class="header" href="#函数的一些骚操作">函数的一些骚操作</a></h2>
<p>我们通过一些骚操作，来更好地理解一下函数。之前说 &lt;class 'function'&gt; 是函数的类型对象，而这个类底层没有暴露给我们，但我们依旧可以通过曲线救国的方式进行获取。</p>
<pre><code class="language-python">def foo():
    pass

print(type(foo))  # &lt;class 'function'&gt;
# lambda 匿名函数的类型也是 function
print(type(lambda: None))  # &lt;class 'function'&gt;
</code></pre>
<p>那么下面就来创建函数：</p>
<pre><code class="language-python">gender = &quot;female&quot;

def foo(name, age):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

# 得到 PyCodeObject 对象
code = foo.__code__
# 根据 class function 创建函数对象
# 接收三个参数：PyCodeObject 对象、global 名字空间、函数名
new_foo = type(foo)(code, globals(), &quot;根据 foo 创建的 new_foo&quot;)

# 打印函数名
print(new_foo.__name__)
&quot;&quot;&quot;
根据 foo 创建的 new_foo
&quot;&quot;&quot;

# 调用函数
print(new_foo(&quot;古明地觉&quot;, 17))
&quot;&quot;&quot;
name: 古明地觉, age: 17, gender: female
&quot;&quot;&quot;
</code></pre>
<p>是不是很神奇呢？另外函数之所以能访问全局变量，是因为在创建函数的时候将 global 名字空间传进去了，如果我们不传递呢？</p>
<pre><code class="language-python">gender = &quot;female&quot;

def foo(name, age):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

code = foo.__code__
# 第二个参数必须是一个字典，不能传 None
new_foo = type(foo)(code, {}, &quot;根据 foo 创建的 new_foo&quot;)

try:
    print(new_foo(&quot;古明地觉&quot;, 17))
except NameError as e:
    print(e)  # name 'gender' is not defined
</code></pre>
<p>因此现在我们又从 Python 的角度理解了一遍，为什么在函数内部能够访问全局变量。原因就在于构建函数的时候，将 global 名字空间交给了函数，使得函数可以在 global 空间中进行变量查找，所以它才能够找到全局变量。而我们这里给了一个空字典，那么显然就找不到 gender 这个变量了。</p>
<pre><code class="language-python">gender = &quot;female&quot;

def foo(name, age):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

code = foo.__code__
new_foo = type(foo)(code, {&quot;gender&quot;: &quot;萌妹子&quot;}, &quot;根据 foo 创建的 new_foo&quot;)

# 我们可以手动传递一个字典进去
# 此时传递的字典对于函数来说就是 global 名字空间
print(new_foo(&quot;古明地觉&quot;, 17))
&quot;&quot;&quot;
name: 古明地觉, age: 17, gender: 萌妹子
&quot;&quot;&quot;
# 所以此时的 gender 不再是外部的 &quot;female&quot;, 而是我们指定的 &quot;萌妹子&quot;
</code></pre>
<p>此外也可以为函数指定默认值：</p>
<pre><code class="language-python">def foo(name, age, gender):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

# 必须接收一个 PyTupleObject 对象
foo.__defaults__ = (&quot;古明地觉&quot;, 17, &quot;female&quot;)
print(foo())
&quot;&quot;&quot;
name: 古明地觉, age: 17, gender: female
&quot;&quot;&quot;
</code></pre>
<p>我们看到函数 foo 明明接收三个参数，但是调用时不传递居然也不会报错，原因就在于我们指定了默认值。而默认值可以在定义函数的时候指定，也可以通过 __defaults__ 指定，但很明显我们应该通过前者来指定。</p>
<p>如果你使用的是 PyCharm，那么会在 foo() 这个位置给你加波浪线，提示你参数没有传递。但我们知道，由于通过 __defaults__ 设置了默认值，所以这里是不会报错的。只不过 PyCharm 没有检测到，当然基本上所有的 IDE 都无法做到这一点，毕竟动态语言。</p>
<p>另外如果 __defaults__ 接收的元组里面的元素个数和参数个数不匹配怎么办？</p>
<pre><code class="language-python">def foo(name, age, gender):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

foo.__defaults__ = (15, &quot;female&quot;)
print(foo(&quot;古明地恋&quot;))
&quot;&quot;&quot;
name: 古明地恋, age: 15, gender: female
&quot;&quot;&quot;
</code></pre>
<p>由于元组里面只有两个元素，意味着我们在调用时需要至少传递一个参数，而这个参数会赋值给 name。原因就是在设置默认值的时候是从后往前设置的，也就是 &quot;female&quot; 会赋值给 gender，15 会赋值给 age。而 name 没有得到默认值，那么它就需要调用者显式传递了。</p>
<p>如果返回值从前往后设置的话，会出现什么后果？显然 15 会赋值给 name，&quot;female&quot; 会赋值给 age，此时函数就等价于如下：</p>
<pre><code class="language-python">def foo(name=15, age=&quot;female&quot;, gender):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;
</code></pre>
<p>这样的函数显然无法通过编译，因为默认参数必须在非默认参数的后面。所以 Python 的这个做法是完全正确的，必须要从后往前进行设置。</p>
<p>另外我们知道默认值的个数是小于等于参数个数的，如果大于会怎么样呢？</p>
<pre><code class="language-python">def foo(name, age, gender):
    return f&quot;name: {name}, age: {age}, gender: {gender}&quot;

foo.__defaults__ = (&quot;古明地觉&quot;, &quot;古明地恋&quot;, 15, &quot;female&quot;)
print(foo())
&quot;&quot;&quot;
name: 古明地恋, age: 15, gender: female
&quot;&quot;&quot;
</code></pre>
<p>依旧是从后往前进行设置，当所有参数都有默认值时，就结束了，多余的默认值会丢弃。当然，如果不使用 __defaults__，是不可能出现默认值个数大于参数个数的。可要是 __defaults__ 指向的元组先结束，那么没有得到默认值的参数就必须由调用者显式传递了。</p>
<p>最后，再来说一下如何深拷贝一个函数。首先如果是你的话，你会怎么拷贝一个函数呢？不出意外的话，你应该会使用 copy 模块。</p>
<pre><code class="language-python">import copy

def foo(a, b):
    return [a, b]

# 但是问题来了，这样能否实现深度拷贝呢？
new_foo = copy.deepcopy(foo)
# 修改 foo 的默认值
foo.__defaults__ = (2, 3)
# 但是 new_foo 也会受到影响
print(new_foo())  # [2, 3]
</code></pre>
<p>打印结果提示我们并没有实现函数的深度拷贝，事实上 copy 模块无法对函数、方法、回溯栈、栈帧、模块、文件、套接字等类型的数据实现深度拷贝。那我们应该怎么做呢？</p>
<pre><code class="language-python">from types import FunctionType

def foo(a, b):
    return &quot;result&quot;

# FunctionType 就是函数的类型对象，它也是通过 type 得到的
new_foo = FunctionType(foo.__code__,
                       foo.__globals__,
                       foo.__name__,
                       foo.__defaults__,
                       foo.__closure__)
# 显然 function 还可以接收第四个参数和第五个参数
# 分别是函数的默认值和闭包

# 然后别忘记将属性字典也拷贝一份
new_foo.__dict__ = {**foo.__dict__}

foo.__defaults__ = (2, 3)
print(foo.__defaults__)  # (2, 3)
print(new_foo.__defaults__)  # None
</code></pre>
<p>此时修改 foo 不会影响 new_foo，当然在拷贝的时候也可以自定义属性。</p>
<p>其实上面实现的深拷贝，本质上就是定义了一个新的函数。由于是两个不同的函数，那么自然就没有联系了。</p>
<h2 id="判断函数都有哪些参数"><a class="header" href="#判断函数都有哪些参数">判断函数都有哪些参数</a></h2>
<p>最后再来看看如何检测一个函数有哪些参数，首先函数的局部变量（包括参数）在编译时就已经确定，会存在符号表 co_varnames 中。</p>
<pre><code class="language-python">def foo(a, b, /, c, d, *args, e, f, **kwargs):
    g = 1
    h = 2

print(foo.__code__.co_varnames)
&quot;&quot;&quot;
('a', 'b', 'c', 'd', 'e', 'f', 'args', 'kwargs', 'g', 'h')
&quot;&quot;&quot;
</code></pre>
<p>在定义函数的时候，* 和 ** 最多只能出现一次。然后这里的 a 和 b 必须通过位置参数传递，c 和 d 可以通过位置参数或者关键字参数传递，e 和 f 必须通过关键字参数传递。</p>
<p>而从打印的符号表来看，里面的符号是有顺序的。参数永远在函数内部定义的局部变量的前面，比如 g 和 h 就是函数内部定义的局部变量，所以它在所有参数的后面。而对于参数，* 和 ** 会位于最后面，其它参数位置不变。所以除了 g 和 h，最后面的就是 args 和 kwargs。</p>
<p>有了这些信息，我们就可以进行检测了。</p>
<pre><code class="language-python">def foo(a, b, /, c, d, *args, e, f, **kwargs):
    g = 1
    h = 2

varnames = foo.__code__.co_varnames
# 1. 寻找必须通过位置参数传递的参数
posonlyargcount = foo.__code__.co_posonlyargcount
print(posonlyargcount)  # 2
print(varnames[: posonlyargcount])  # ('a', 'b')

# 2. 寻找可以通过位置参数（或关键字参数）传递的参数
argcount = foo.__code__.co_argcount
# 注：co_argcount 里面包含了 co_posonlyargcount
print(argcount)  # 4
print(varnames[: argcount])  # ('a', 'b', 'c', 'd')
print(varnames[posonlyargcount: argcount])  # ('c', 'd')

# 3. 寻找必须通过关键字参数传递的参数
kwonlyargcount = foo.__code__.co_kwonlyargcount
print(kwonlyargcount)  # 2
print(varnames[argcount: argcount + kwonlyargcount])  # ('e', 'f')

# 4. 寻找 *args 和 **kwargs
flags = foo.__code__.co_flags
# 在介绍 PyCodeObject 的时候，我们说里面有一个 co_flags 字段
# 它是函数的标识，可以对函数类型和参数进行检测
# 如果 co_flags 和 4 按位与的结果为真，那么就代表有 *args，否则没有
# 如果 co_flags 和 8 按位与的结果为真，那么就代表有 **kwargs，否则没有
step = argcount + kwonlyargcount
if flags &amp; 0x04:
    print(varnames[step])  # args
    step += 1

if flags &amp; 0x08:
    print(varnames[step])  # kwargs
</code></pre>
<p>以上我们就检测出了函数都有哪些参数，你也可以自己试一试。另外还要注意一点，如果定义的时候，指定的不是 *args，而只是一个 *，那么它就不是参数了。</p>
<pre><code class="language-python">def f(a, b, *, c):
    pass


# 符号表里面只有 a、b、c
print(f.__code__.co_varnames)  # ('a', 'b', 'c')

# 显然此时也都为假
print(f.__code__.co_flags &amp; 0x04)  # 0
print(f.__code__.co_flags &amp; 0x08)  # 0
</code></pre>
<p>单独的一个 * 只是为了强制要求后面的参数必须通过关键字参数的方式传递。</p>
<h2 id="小结-53"><a class="header" href="#小结-53">小结</a></h2>
<p>这一次我们简单地分析了一下函数是如何创建的，并且还在 Python 的层面上做了一些小 trick。最后我们也分析了如何通过 PyCodeObject 对象来检索函数的参数，以及相关种类，标准库中的 inspect 模块也是这么做的。准确的说，是我们模仿人家的思路做的。</p>
<p>现在你是不是对函数有了一个更深刻的认识了呢？当然目前介绍的只是函数的一部分内容，还有更多内容等待我们挖掘，比如：</p>
<ul>
<li>函数如何调用。</li>
<li>位置参数和关键字参数如何解析。</li>
<li>对于有默认值的参数，如何在不传参的时候使用默认值、在传参的时候使用我们传递的值。</li>
<li>*args 和 **kwargs 如何解析。</li>
<li>闭包怎么实现。</li>
<li>装饰器怎么实现</li>
<li>......</li>
</ul>
<p>这些内容我们接下来慢慢说。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-54"><a class="header" href="#楔子-54">楔子</a></h2>
<p>上一篇文章我们说了 Python 函数的底层实现，并且还演示了如何通过函数的类型对象自定义一个函数，以及如何获取函数的参数。虽然这在工作中没有太大意义，但是可以让我们深刻理解函数的行为。</p>
<p>那么接下来看看函数是如何调用的。</p>
<h2 id="pycfunctionobject"><a class="header" href="#pycfunctionobject">PyCFunctionObject</a></h2>
<p>在介绍调用之前，我们需要补充一个知识点。</p>
<pre><code class="language-Python">def foo():
    pass

class A:

    def foo(self):
        pass

print(type(foo))  # &lt;class 'function'&gt;
print(type(A().foo))  # &lt;class 'method'&gt;
print(type(sum))  # &lt;class 'builtin_function_or_method'&gt;
print(type(&quot;&quot;.join))  # &lt;class 'builtin_function_or_method'&gt;
</code></pre>
<p>如果采用 Python 实现，那么函数的类型是 function，方法的类型是 method。而如果采用原生的 C 实现，那么函数和方法的类型都是 builtin_function_or_method。</p>
<p>关于方法，等我们介绍类的时候再说，先来看看函数。</p>
<p><img src="./images/215.png" alt="" /></p>
<p>所以函数分为两种：</p>
<ul>
<li>Python 实现的函数，在底层由 PyFunctionObject 结构体实例表示，其类型对象 <font color="blue">&lt;class 'function'&gt;</font> 在底层由 PyFunction_Type 表示。</li>
<li>C 实现的函数（还有方法），在底层由 PyCFunctionObject 结构体实例表示，其类型对象 <font color="blue">&lt;class 'builtin_function_or_method'&gt;</font> 在底层由 PyCFunction_Type 表示。</li>
</ul>
<p>像我们使用 def 关键字定义的就是 Python 实现的函数，而内置函数则是 C 实现的函数，它们在底层对应不同的结构，因为 C 实现的函数可以有更快的执行方式。</p>
<h2 id="函数的调用"><a class="header" href="#函数的调用">函数的调用</a></h2>
<p>我们来调用一个函数，看看它的字节码是怎样的。</p>
<pre><code class="language-python">import dis 

code_string = &quot;&quot;&quot;
def foo(a, b):
    return a + b

foo(1, 2)
&quot;&quot;&quot;
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>字节码指令如下：</p>
<pre><code class="language-C">  // 加载 PyCodeObject 对象，压入运行时栈
  0 LOAD_CONST               0 (&lt;code object foo at 0x7f69...&gt;)
  // 加载函数名 foo，压入运行时栈
  2 LOAD_CONST               1 ('foo')
  // 从栈顶弹出函数名和 PyCodeObject 对象，构建函数
  4 MAKE_FUNCTION            0
  // 将符号 foo 和函数对象绑定起来，存储在名字空间中
  6 STORE_NAME               0 (foo)
  // 加载全局变量 foo，压入运行时栈
  8 LOAD_NAME                0 (foo)
  // 加载常量 1，压入运行时栈
 10 LOAD_CONST               2 (1)
  // 加载常量 2，压入运行时栈
 12 LOAD_CONST               3 (2)
  // 弹出 foo 和参数，进行调用，指令参数 2，表示给调用的函数传递了两个参数
  // 函数调用结束后，将返回值压入栈中
 14 CALL_FUNCTION            2
  // 因为没有用变量保存，所以从栈顶弹出返回值并丢弃
 16 POP_TOP
  // 隐式的 return None
 18 LOAD_CONST               4 (None)
 20 RETURN_VALUE
  
  // 函数内部逻辑对应的字节码，比较简单，就不说了
Disassembly of &lt;code object foo at 0x7f69...&gt;:
  0 LOAD_FAST                0 (a)
  2 LOAD_FAST                1 (b)
  4 BINARY_ADD
  6 RETURN_VALUE
</code></pre>
<p>我们看到函数调用使用的是 CALL_FUNCTION 指令，那么这个指令都做了哪些事情呢？</p>
<pre><code class="language-C">case TARGET(CALL_FUNCTION): {
    PREDICTED(CALL_FUNCTION);
    PyObject **sp, *res;
    // 指向运行时栈的栈顶
    sp = stack_pointer;
    // 调用函数，将返回值赋值给 res
    // tstate 表示线程状态对象，&amp;sp 是一个三级指针，oparg 表示指令参数
    res = call_function(tstate, &amp;sp, oparg, NULL);
    // 函数执行完毕之后，sp 会指向运行时栈的栈顶
    // 所以再将修改之后的 sp 赋值给 stack_pointer
    stack_pointer = sp;
    // 将 res 压入栈中：*stack_pointer++ = res
    PUSH(res);
    if (res == NULL) {
        goto error;
    }
    DISPATCH();
}
</code></pre>
<p>所以函数调用会执行 CALL_FUNCTION 指令，但是函数的核心执行流程是在 call_function 里面，它位于 ceval.c 中，我们来看一下。</p>
<pre><code class="language-C">Py_LOCAL_INLINE(PyObject *) _Py_HOT_FUNCTION
call_function(PyThreadState *tstate, PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)
{
    // pp_stack 参数是在 CALL_FUNCTION 指令中传入的栈顶指针的指针
    // 由于栈里面的元素都是 PyObject *，所以栈顶指针 stack_pointer 是 PyObject **
    // 而 pp_stack 是栈顶指针的指针，所以它的类型是 PyObject ***
    // 对于当前运行时栈来说，从栈底到栈顶的元素依次是：函数、参数1、参数2、...、参数n
    // 而 *pp_stack 指向栈顶元素，所以通过 (*pp_stack) - oparg - 1 即可拿到函数指针
    PyObject **pfunc = (*pp_stack) - oparg - 1;
    // 我们在 Python 中定义的 foo 就对应这里的 func 
    // 可能有人好奇，为什么要搞一个三级指针出来，直接传 stack_pointer 不好吗
    // 原因很简单，因为函数执行完毕之后，运行时栈的元素会发生改变
    // 这也意味着 stack_pointer 会发生改变，因为必须把它的指针传进去
    PyObject *func = *pfunc;
    // 两个 PyObject *
    PyObject *x, *w;
    // 通过关键字参数传递的参数个数，对于当前函数来说是 0
    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);
    // 通过位置参数参数传递的参数个数，对于当前函数来说是 2
    Py_ssize_t nargs = oparg - nkwargs;
    // 移动栈指针，这里相当于 stack_pointer - oparg
    // 所以在移动之后，stack 会指向第一个参数
    PyObject **stack = (*pp_stack) - nargs - nkwargs;
    
    // 到此函数和参数都已经获取完毕，那么开始调用了，通过调用 C 函数来实现 Python 函数的调用
    // 如果通过 threading.settrace 或 sys.settrace 绑定了追踪函数，那么调用 trace_call_function
    if (tstate-&gt;use_tracing) {
        x = trace_call_function(tstate, func, stack, nargs, kwnames);
    }
    // 而我们这里没有绑定追踪函数，所以会调用 _PyObject_Vectorcall
    // 当然啦，trace_call_function 只是一个包装器，它内部依旧调用了 _PyObject_Vectorcall
    // 所谓的追踪函数只是为了在执行时收集一些堆栈信息，用于调试和性能分析
    else {
        x = _PyObject_Vectorcall(func, stack, nargs | PY_VECTORCALL_ARGUMENTS_OFFSET, kwnames);
    }
    // 执行完毕之后，将返回值赋值给 x，而在 CALL_FUNCTION 指令中，有下面一行代码：
    // res = call_function(tstate, &amp;sp, oparg, NULL);
    // 里面的 res 就是这里返回的 x，后续会将 res 压入运行时栈
    // 如果没有接收返回值，那么再执行 POP_TOP 将其从栈顶弹出、丢弃
    // 如果接收了返回值，那么执行 STORE_FAST 将其保存起来
    assert((x != NULL) ^ (_PyErr_Occurred(tstate) != NULL));

    // 在后续将返回值 res 压入运行时栈之前，要先将栈里的函数参数清空
    while ((*pp_stack) &gt; pfunc) {
        w = EXT_POP(*pp_stack);
        Py_DECREF(w);
    }
    // 循环结束之后，栈顶也发生了改变，因此在 CALL_FUNCTION 指令中，还要将 *pp_stack 赋值给 stack_pointer
    // 所以会有一行 stack_pointer = sp，而 sp 就是这里的 *pp_stack
    // 相信你明白在调用 call_function 时为什么要传递三级指针了，因为需要在调用完毕后，外部的 sp 能够被影响
    // 所以必须传递 &amp;sp，即三级指针，当 *pp_stack 在变化时，外部的 sp 也在变化
    // 而 call_function 执行完毕后，sp 会指向新的栈顶，因此再将它赋值给 stack_pointer
    // 然后执行 PUSH(res)，也就是 *stack_pointer++ = res，将返回值压入运行时栈
    return x;
}
</code></pre>
<p>因此接下来重点就在 _PyObject_Vectorcall 函数上面，它都做了哪些事情呢？</p>
<pre><code class="language-C">// Include/cpython/abstract.h

static inline PyObject *
_PyObject_Vectorcall(PyObject *callable, PyObject *const *args,
                     size_t nargsf, PyObject *kwnames)
{
    PyObject *res;
    vectorcallfunc func;
    assert(kwnames == NULL || PyTuple_Check(kwnames));
    assert(args != NULL || PyVectorcall_NARGS(nargsf) == 0);
    // 获取对象的 vectorcallfunc
    func = _PyVectorcall_Function(callable);
    // 如果 func 为空，说明对象不支持矢量调用
    if (func == NULL) {
        // 那么执行 tp_call，也就是退化为常规调用
        Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
        return _PyObject_MakeTpCall(callable, args, nargs, kwnames);
    }
    // 否则执行矢量调用函数
    res = func(callable, args, nargsf, kwnames);
    // 检查返回值的有效性，是否符合 Python 协议
    return _Py_CheckFunctionResult(callable, res, NULL);
}

// 获取对象内部的矢量调用函数
static inline vectorcallfunc
_PyVectorcall_Function(PyObject *callable)
{
    // 获取对象的类型对象
    PyTypeObject *tp = Py_TYPE(callable);
    // 类型对象的 tp_vectorcall_offset
    // 它记录了对象的矢量调用函数相对于对象首地址的偏移量
    Py_ssize_t offset = tp-&gt;tp_vectorcall_offset;
    vectorcallfunc ptr;
    // 先判断对象是否支持矢量调用，如果类型对象没有设置 _Py_TPFLAGS_HAVE_VECTORCALL 标志位
    // 即 tp-&gt;tp_flags &amp; _Py_TPFLAGS_HAVE_VECTORCALL == 0
    // 说明变量 callable 指向的对象不支持矢量调用，因此返回 NULL，然后退化为常规调用
    if (!PyType_HasFeature(tp, _Py_TPFLAGS_HAVE_VECTORCALL)) {
        return NULL;
    }
    assert(PyCallable_Check(callable));
    assert(offset &gt; 0);
    // 否则说明对象支持矢量调用，从对象的首地址向后偏移 offset 个字节，会得到一个函数指针
    // 这个函数指针符合矢量调用协议，由于我们调用的是 Python 函数，所以它肯定是支持的
    memcpy(&amp;ptr, (char *) callable + offset, sizeof(ptr));
    return ptr;
}
</code></pre>
<p>Python 函数在底层对应的结构体是 PyFunctionObject，所以它内部一定有一个字段指向了符合矢量调用协议的函数，该字段便是 vectorcall。在介绍 Python 函数的创建时，我们看到它被赋值为 _PyFunction_Vectorcall。</p>
<pre><code class="language-C">// Objects/funcobject.c

PyTypeObject PyFunction_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;function&quot;,                                 /* tp_name */
    sizeof(PyFunctionObject),                   /* tp_basicsize */
    0,                                          /* tp_itemsize */
    (destructor)func_dealloc,                   /* tp_dealloc */
    // PyFunctionObject 内部的 vectorcall 字段便是矢量函数指针
    // 而在类型对象 PyFunction_Type 中记录了它相对于 PyFunctionObject 的偏移量
    offsetof(PyFunctionObject, vectorcall),     /* tp_vectorcall_offset */
    0,                                          /* tp_getattr */
    // ...
}

PyObject *
PyFunction_NewWithQualName(PyObject *code, PyObject *globals, PyObject *qualname)
{
    PyFunctionObject *op;
    PyObject *doc, *consts, *module;
    static PyObject *__name__ = NULL;
    // ...
    // 被赋值为 _PyFunction_Vectorcall
    op-&gt;vectorcall = _PyFunction_Vectorcall;
    // ...
    _PyObject_GC_TRACK(op);
    return (PyObject *)op;
}
</code></pre>
<p>所以最终 _PyObject_Vectorcall 内部会通过 _PyFunction_Vectorcall 来执行 Python 函数，显然执行的关键就落在了 _PyFunction_Vectorcall 上面，看一下它的逻辑。</p>
<pre><code class="language-C">// Objects/call.c

PyObject *
_PyFunction_Vectorcall(PyObject *func, PyObject* const* stack,
                       size_t nargsf, PyObject *kwnames)
{
    // 获取函数的 PyCodeObject 对象
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    // 获取函数的 global 名字空间
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    // 获取函数的默认值参数
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *kwdefs, *closure, *name, *qualname;
    PyObject **d;
    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);
    Py_ssize_t nd;

    assert(PyFunction_Check(func));
    // 获取实际的参数个数
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
    assert(nargs &gt;= 0);
    assert(kwnames == NULL || PyTuple_CheckExact(kwnames));
    assert((nargs == 0 &amp;&amp; nkwargs == 0) || stack != NULL);
    
    // 如果没有仅限位置参数、没有关键字参数、没有闭包，那么走快速通道
    if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp;
        (co-&gt;co_flags &amp; ~PyCF_MASK) == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE))
    {   
        // 如果参数没有默认值，co_argcount 和传递的位置参数相等
        // 那么执行 function_code_fastcall
        if (argdefs == NULL &amp;&amp; co-&gt;co_argcount == nargs) {
            return function_code_fastcall(co, stack, nargs, globals);
        }
        // 如果参数有默认值，但当参数和个数和默认值个数相等时（此时外界一个参数都不传）
        // 那么也会执行 function_code_fastcall
        else if (nargs == 0 &amp;&amp; argdefs != NULL
                 &amp;&amp; co-&gt;co_argcount == PyTuple_GET_SIZE(argdefs)) {
            stack = _PyTuple_ITEMS(argdefs);
            return function_code_fastcall(co, stack, PyTuple_GET_SIZE(argdefs),
                                          globals);
        }
        // 所以 function_code_fastcall 对应的便是快速通道，既然是快速通道，那么自然是要求的
        // 首先定义函数时，不可以出现 / 和 *，比如像 def foo(a, b, /, c, *, d) 这种
        // 也就是要这么定义：def foo(a, b, c, d)，不能有任何多余的东西
        // 然后传参的时候，也必须都通过位置参数传递，比如 foo(1, 2, 3, 4)，这种情况下会走快速通道
        // 第二种走快速通道的方式是，所有参数都有默认值，比如 def foo(a=1, b=2, c=3, d=4)
        // 然后调用时不额外传值，也就是让所有参数都使用默认值
        
        // 以上两种情况都会执行快速通道，而在 function_code_fastcall
    }
    
    // 否则执行通用逻辑
    // 获取仅限默认值参数、闭包、函数名等
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
    closure = PyFunction_GET_CLOSURE(func);
    name = ((PyFunctionObject *)func) -&gt; func_name;
    qualname = ((PyFunctionObject *)func) -&gt; func_qualname;

    if (argdefs != NULL) {
        d = _PyTuple_ITEMS(argdefs);
        nd = PyTuple_GET_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
    // 执行通用逻辑 _PyEval_EvalCodeWithName
    return _PyEval_EvalCodeWithName((PyObject*)co, globals, (PyObject *)NULL,
                                    stack, nargs,
                                    nkwargs ? _PyTuple_ITEMS(kwnames) : NULL,
                                    stack + nargs,
                                    nkwargs, 1,
                                    d, (int)nd, kwdefs,
                                    closure, name, qualname);
}
</code></pre>
<p>无论是快速通道 function_code_fastcall，还是通用通道 _PyEval_EvalCodeWithName，它们内部做的事情都是一样的。</p>
<ul>
<li>调用 _PyFrame_New_NoTrack 函数创建栈帧，并初始化内部字段。</li>
<li>栈帧创建完毕之后，里面的字段都是初始值，所以还要基于函数的参数信息修改栈帧字段（主要是修改 f_localsplus）。</li>
<li>栈帧字段设置完毕之后，调用 PyEval_EvalFrameEx 函数，在栈帧中执行字节码。</li>
</ul>
<p>而这两者的区别就在于第二步，如果走快速通道，那么它的参数处理会非常简单，我们看一下 function_code_fastcall 的逻辑。</p>
<pre><code class="language-C">// Objects/call.c

static PyObject* _Py_HOT_FUNCTION
function_code_fastcall(PyCodeObject *co, PyObject *const *args, Py_ssize_t nargs,
                       PyObject *globals)
{
    PyFrameObject *f;
    PyThreadState *tstate = _PyThreadState_GET();
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;

    assert(globals != NULL);
    assert(tstate != NULL);
    // 基于 PyCodeObject 对象、全局名字空间创建栈桢
    f = _PyFrame_New_NoTrack(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    // 获取 f_localsplus，它用于局部变量、cell 变量、free 变量、运行时栈
    // 不过这里不会存在 cell 变量和 free 变量，否则无法进入快速通道
    fastlocals = f-&gt;f_localsplus;
    // 将传递的位置参数拷贝到 f_localsplus 的第一段内存（局部变量）
    for (i = 0; i &lt; nargs; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    // 调用 PyEval_EvalFrameEx，然后执行帧评估函数 _PyEval_EvalFrameDefault
    result = PyEval_EvalFrameEx(f,0);

    if (Py_REFCNT(f) &gt; 1) {
        Py_DECREF(f);
        _PyObject_GC_TRACK(f);
    }
    else {
        ++tstate-&gt;recursion_depth;
        Py_DECREF(f);
        --tstate-&gt;recursion_depth;
    }
    return result;
}
</code></pre>
<p>所以快速通道的整个过程非常简单，如果是走通用通道 _PyEval_EvalCodeWithName，它的逻辑也是一样的，只是在处理参数处理方面要复杂很多。比如要考虑位置参数、关键字参数、*args、**kwargs、哪些参数使用默认值、哪些参数不使用默认值等等。但快速通道和通用通道做的事情是一样的，都是先为调用的函数创建栈桢、然后设置栈桢字段、最后调用帧评估函数。</p>
<p>所以当调用一个 Python 函数时，底层 C 函数的调用链路就很清晰了。</p>
<p><img src="./images/216.png" alt="" /></p>
<p>因此我们看到，总共有两条途径，这两条途径的区别就在于一个参数复杂、一个参数不复杂。但最终两者是殊途同归的，都会走到 PyEval_EvalFrameEx 那里，然后在新的栈帧中执行字节码。</p>
<h2 id="小结-54"><a class="header" href="#小结-54">小结</a></h2>
<p>以上就是整个函数的调用逻辑，还是非常清晰的，至于这两条执行途径的具体细节，以及参数是如何解析的，我们下一篇文章再说。</p>
<p>另外再补充一点，我们说 PyFrameObject 是根据 PyCodeObject 创建的，而 PyFunctionObject 也是根据 PyCodeObject 创建的，那么 PyFrameObject 和 PyFunctionObject 之间有啥关系呢？</p>
<p>很简单，如果把 PyCodeObject 比喻成妹子的话，那么 PyFunctionObject 就是妹子的备胎，PyFrameObject 就是妹子的心上人。其实在栈帧中执行指令的时候，PyFunctionObject 的影响就已经消失了。</p>
<p>也就是说，最终是 PyFrameObject 和 PyCodeObject 两者如胶似漆，跟 PyFunctionObject 没有关系。所以 PyFunctionObject 辛苦一场，实际上是为别人做了嫁衣，PyFunctionObject 主要是对 PyCodeObject 和 global 名字空间的一种打包和运输方式。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-55"><a class="header" href="#楔子-55">楔子</a></h2>
<p>函数最大的特点就是可以接收参数，如果只是单纯的封装，未免太无趣了。对于函数来说，参数会传什么，事先是不知道的，函数体内部只是利用参数做一些事情，比如调用参数的 get 方法。但是到底能不能调用 get 方法，就取决于给参数传的值是什么了。</p>
<p>因此可以把参数看成是一个占位符，调用的时候，将值传进去赋给相应的参数，然后将函数内部的逻辑走一遍即可。</p>
<h2 id="参数的类别"><a class="header" href="#参数的类别">参数的类别</a></h2>
<p>调用函数时传递的参数，根据形式的不同可以分为四种类别：</p>
<ul>
<li>位置参数（positional argument）；</li>
<li>关键字参数（keyword argument）；</li>
<li>扩展位置参数（excess positional argument）；</li>
<li>扩展关键字参数（excess keyword argument）；</li>
</ul>
<blockquote>
<p>参数分为形参和实参，在英文中形参叫做 parameter，实参叫做 argument。但在中文里区分的不是那么明显，我们一般统一称为参数。</p>
</blockquote>
<p>然后我们看一下 call_function。</p>
<pre><code class="language-C">Py_LOCAL_INLINE(PyObject *) _Py_HOT_FUNCTION
call_function(PyThreadState *tstate, PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)
{
    PyObject **pfunc = (*pp_stack) - oparg - 1;
    PyObject *func = *pfunc;
    PyObject *x, *w;
    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);
    Py_ssize_t nargs = oparg - nkwargs;
    PyObject **stack = (*pp_stack) - nargs - nkwargs;
    // ...
}
</code></pre>
<p>CALL_FUNCTION 指令的 oparg 记录了函数的参数个数，包括位置参数和关键字参数。虽然扩展位置参数和扩展关键字参数是更高级的用法，但本质上也是由多个位置参数、多个关键字参数组成的。这就意味着，虽然函数中存在四种参数，但是只要记录位置参数和关键字参数的个数，就能知道一共有多少个参数，进而知道一共需要多大的内存来维护。</p>
<p>因此 call_function 里面的 nkwargs 就是调用函数时传递的关键字参数的个数，nargs 就是传递的位置参数的个数，两者加起来等于 oparg。然后是函数内部的局部变量的个数，可以通过 co_nlocals 来获取。</p>
<p>注意：局部变量包括了参数，因为函数参数也是局部变量，它们在内存中是连续放置的，局部变量的名称都存储在符号表 co_varnames 中。当虚拟机为函数申请局部变量的内存空间时，就需要通过 co_nlocals 知道局部变量的总数。</p>
<blockquote>
<p>可能会有人将 co_nlocals 和 co_argcount 搞混，前者表示局部变量的个数，后者表示可以通过位置参数或关键字参数传递的参数个数。</p>
</blockquote>
<pre><code class="language-python">def foo(a, b, c, d=1):
    pass

print(foo.__code__.co_argcount)  # 4
print(foo.__code__.co_nlocals)  # 4


def foo(a, b, c, d=1):
    a = 1
    b = 1

print(foo.__code__.co_argcount)  # 4
print(foo.__code__.co_nlocals)  # 4


def foo(a, b, c, d=1):
    e = 1

print(foo.__code__.co_argcount)  # 4
print(foo.__code__.co_nlocals)  # 5
</code></pre>
<p>co_nlocals 等于参数的个数加上函数体中新创建的局部变量的个数，注意：函数参数也是局部变量，比如有一个参数 a，但函数体里面新建了一个变量也叫 a，这是重新赋值，因此还是相当于一个参数。</p>
<p>但是 co_argcount 只记录参数的个数，因此一个很明显的结论：对于任意一个函数，co_nlocals 一定大于等于 co_argcount。</p>
<pre><code class="language-python">def foo(a, b, c, d=1, *args, **kwargs):
    pass

print(foo.__code__.co_argcount)  # 4
print(foo.__code__.co_nlocals)  # 6
</code></pre>
<p>我们看到，对于扩展位置参数和扩展关键字参数来说，co_argcount 是不算在内的，因为完全可以不传递，所以直接当成 0 来算。但我们在函数体内部肯定能拿到 args 和 kwargs，这也是两个局部变量，因此 co_argcount 是 4，co_nlocals 是 6。</p>
<blockquote>
<p>所有的扩展位置参数都存储在一个 PyTupleObject 对象中，所有的扩展关键字参数都存储在一个 PyDictObject 对象中。</p>
</blockquote>
<p>co_argcount 和 co_nlocals 的值在编译的时候就已经确定。</p>
<h2 id="位置参数的传递"><a class="header" href="#位置参数的传递">位置参数的传递</a></h2>
<p>下面来看看位置参数是如何传递的：</p>
<pre><code class="language-python">import dis

code = &quot;&quot;&quot;
def foo(name, age):
    gender = &quot;female&quot;
    print(name, age)
    
foo(&quot;satori&quot;, 17)    
&quot;&quot;&quot;

dis.dis(compile(code, &quot;&lt;func&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>相信对于现在的我们来说，下面的字节码已经没有任何难度了。</p>
<pre><code class="language-C">  0 LOAD_CONST               0 (&lt;code object foo at 0x7f3&gt;)
  2 LOAD_CONST               1 ('foo')
  4 MAKE_FUNCTION            0
  6 STORE_NAME               0 (foo)

  8 LOAD_NAME                0 (foo)
 10 LOAD_CONST               2 ('satori')
 12 LOAD_CONST               3 (17)
 14 CALL_FUNCTION            2
 16 POP_TOP
 18 LOAD_CONST               4 (None)
 20 RETURN_VALUE

Disassembly of &lt;code object foo at 0x7f3...&gt;:
  0 LOAD_CONST               1 ('female')
  2 STORE_FAST               2 (gender)

  4 LOAD_GLOBAL              0 (print)
  6 LOAD_FAST                0 (name)
  8 LOAD_FAST                1 (age)
 10 CALL_FUNCTION            2
 12 POP_TOP
 14 LOAD_CONST               0 (None)
 16 RETURN_VALUE
</code></pre>
<p>这里我们先看 <font color="blue">foo(&quot;satori&quot;, 17) </font>的字节码：</p>
<pre><code class="language-C">  8 LOAD_NAME                0 (foo)
 10 LOAD_CONST               2 ('satori')
 12 LOAD_CONST               3 (17)
 14 CALL_FUNCTION            2
 16 POP_TOP
</code></pre>
<p>首先将函数以及相关参数压入运行时栈：</p>
<p><img src="./images/217.png" alt="" /></p>
<p>然后执行 CALL_FUNCTION 指令，由于在调用时全部都是位置参数，那么根据之前介绍的函数调用链路，我们知道它最终会执行 function_code_fastcall，即快速通道。这个函数之前介绍过了，这里再拿出来解释一遍。</p>
<pre><code class="language-C">static PyObject* _Py_HOT_FUNCTION
function_code_fastcall(PyCodeObject *co, PyObject *const *args, Py_ssize_t nargs,
                       PyObject *globals)
{
    // 栈帧对象
    PyFrameObject *f;
    // 线程状态对象
    PyThreadState *tstate = _PyThreadState_GET();
    // f-&gt;localsplus
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;

    assert(globals != NULL);
    assert(tstate != NULL);
    // 为调用的函数创建 PyFrameObject，参数是 PyCodeObject 和 global 空间
    // 因此最后执行的时候其实没有 PyFunctionObject 什么事，它只是起到一个打包和输送的作用
    f = _PyFrame_New_NoTrack(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    // 获取函数栈帧的 f_localsplus
    fastlocals = f-&gt;f_localsplus;
    // 调用函数时传递的参数会被提前压入运行时栈，注意：此时的运行时栈是模块的运行时栈
    // 因为加载参数入栈时，函数还没调用呢。所以对于当前来说，参数被压入了模块的运行时栈
    // 其中 nargs 表示参数个数，args 指向运行时栈的第一个参数
    // 然后将运行时栈中的参数拷贝到局部变量对应的内存中
    for (i = 0; i &lt; nargs; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    // 调用 PyEval_EvalFrameEx、进而调用 _PyEval_EvalFrameDefault
    // 以新创建的栈帧为执行环境，执行内部的字节码，执行完毕后将返回值赋给 result
    result = PyEval_EvalFrameEx(f,0);
    
    // 如果 f 的引用计数大于 1，说明栈帧被保存起来了
    // 引用计数减一之后，由于不会被销毁，所以还要被 GC 跟踪
    if (Py_REFCNT(f) &gt; 1) {
        Py_DECREF(f);
        _PyObject_GC_TRACK(f);
    }
    else {
        ++tstate-&gt;recursion_depth;
        Py_DECREF(f);
        --tstate-&gt;recursion_depth;
    }
    // 返回 result
    return result;
}
</code></pre>
<p>从源码中可以看到，虚拟机首先通过 _PyFrame_New_NoTrack 创建了函数 foo 对应的栈帧对象。随后将参数逐个拷贝到新创建的栈帧对象的 f_localsplus 中，f_localsplus 是一个数组，在概念上被分成了四部分，而源码中的索引是从 0 开始的，所以运行时栈中的参数被拷贝到了<font color="blue">局部变量对应的内存</font>中。</p>
<p>再次强调：上面说的运行时栈指的是<font color="blue">模块栈帧的运行时栈</font>，因为加载参数的时候还没有涉及函数的调用。</p>
<pre><code class="language-c">  // 函数、以及参数都位于模块栈帧的运行时栈里面
  8 LOAD_NAME                0 (foo)
 10 LOAD_CONST               2 ('satori')
 12 LOAD_CONST               3 (17)
  // 加载完毕之后，在模块的栈帧中调用函数
 14 CALL_FUNCTION            2
 16 POP_TOP
</code></pre>
<p>调用函数 foo 时，为其创建新的栈帧，并将参数从<font color="blue">模块栈帧的运行时栈</font>拷贝到<font color="blue">函数栈帧的 f_localsplus（局部变量对应的内存）</font>里面。而在拷贝之后，函数 foo 栈帧的 f_localsplus 布局如下：</p>
<p><img src="./images/218.png" alt="" /></p>
<p>栈帧 f_localsplus 的第一段内存用于存储局部变量，不管是函数参数，还是函数内部新创建的局部变量，它们都是局部变量，都保存在 f_localsplus 的第一段内存中。其中 name 和 age 是参数，它们在创建栈帧之后、执行帧评估函数之前，就已经被设置在函数栈帧的 f_localsplus 中了。</p>
<p>至于图中的第三个位置，显然它用于存储局部变量 gender 的值，只不过 gender 是函数内部创建的局部变量，它需要等到函数执行时才会设置。当执行到 <code>gender = &quot;female&quot;</code> 时，通过 <code>f-&gt;f_localsplus[2] = &quot;female&quot;</code> 进行设置。</p>
<p><strong>总结：在调用函数时，要提前确定参数，而参数会被压入运行时栈，由于此时函数还没有调用，所以这里的运行时栈是模块栈帧的 f_localsplus 的运行时栈。当参数确定完毕后，开始执行 CALL_FUNCTION 指令，经过一系列操作之后，最终会为调用的函数创建一个新的栈帧。</strong></p>
<p><strong>然后是参数拷贝，因为参数还位于模块栈帧的 f_localsplus 的运行时栈里面，所以要将它们拷贝到函数栈帧的 f_localsplus 的局部变量对应的内存里面。这样的话，函数在执行时就可以通过 f_localsplus[0] 和  f_localsplus[1] 获取变量 name 和 age 的值了，我们看一下函数对应的字节码。</strong></p>
<pre><code class="language-C">  // 此时开启了函数 foo 内部代码的执行
  // 将字符串常量压入运行时栈
  0 LOAD_CONST               1 ('female')
  // 将元素从栈顶弹出，并和变量 gender 进行绑定
  // 由于 &quot;gender&quot; 位于符号表中索引为 2 的位置
  // 所以执行 f_localsplus[2] = &quot;female&quot;
  2 STORE_FAST               2 (gender)

  4 LOAD_GLOBAL              0 (print)
  // 将局部变量 name 和 age 压入运行时栈
  // 或者说将 f_localsplus[0] 和 f_localsplus[1] 压入运行时栈
  // 那么问题来了，这两个变量是什么时候创建的呢？
  // 很明显，在执行帧评估函数之前，name 和 age 的值就已经被设置在函数栈帧的 f_localsplus 中了
  6 LOAD_FAST                0 (name)
  8 LOAD_FAST                1 (age)
 10 CALL_FUNCTION            2
 12 POP_TOP
 14 LOAD_CONST               0 (None)
 16 RETURN_VALUE
</code></pre>
<p><strong>所以函数的参数在执行帧评估函数之前就确定了，它们的值位于函数栈帧的 f_localsplus 里面。</strong></p>
<h2 id="位置参数的访问"><a class="header" href="#位置参数的访问">位置参数的访问</a></h2>
<p>当参数拷贝的动作完成之后，就会进入 PyEval_EvalFrameEx，然后进入 _PyEval_EvalFrameDefault 真正开始 foo 的调用动作。会抽出栈帧里的 f_code，对指令逐条执行，而这个过程会涉及参数的访问。当然这就很简单了，我们之前介绍过局部变量是如何创建和访问的，而参数也是局部变量，这里我们再来复习一下。</p>
<pre><code class="language-C">case TARGET(LOAD_FAST): {
    // oparg 表示变量名在符号表中的索引
    // 同时也是变量值在 f_localsplus 中的索引，这两者是对应的
    // 所以这行代码等价于 PyObject *value = f_localsplus[oparg]
    PyObject *value = GETLOCAL(oparg);
    // f_localsplus 里面的元素初始为 NULL，当创建局部变量时，会修改 f_localsplus
    // 所以如果获取到的 value 为 NULL，这就说明在访问变量时，它还没有完成赋值
    // 此时会抛出 UnboundLocalError
    if (value == NULL) {
        format_exc_check_arg(tstate, PyExc_UnboundLocalError,
                             UNBOUNDLOCAL_ERROR_MSG,
                             PyTuple_GetItem(co-&gt;co_varnames, oparg));
        goto error;
    }
    Py_INCREF(value);
    // 将局部变量的值压入运行时栈
    PUSH(value);
    FAST_DISPATCH();
}

case TARGET(STORE_FAST): {
    PREDICTED(STORE_FAST);
    // STORE_FAST 用于变量赋值，但在赋值之前，它的值一定已经被压入了运行时栈
    // 所以要将值从栈顶弹出
    PyObject *value = POP();
    // oparg 表示变量名在符号表中的索引，那么它也是变量值在 f_localsplus 中的索引
    // 所以这行代码等价于 f_localsplus[oparg] = value
    SETLOCAL(oparg, value);
    FAST_DISPATCH();
}

// 然后我们看一下 GETLOCAL 和 SETLOCAL 这两个宏
// 在帧评估函数中，会创建变量 fastlocals，并将其赋值为 f-&gt;f_localsplus
#define GETLOCAL(i)     (fastlocals[i])
#define SETLOCAL(i, value)      do { PyObject *tmp = GETLOCAL(i); \
                                     GETLOCAL(i) = value; \
                                     Py_XDECREF(tmp); } while (0)
</code></pre>
<p>非常简单，都是之前说过的内容。我们再总结一下变量的创建和访问：</p>
<ul>
<li>全局变量是通过字典存储的，这个字典也叫 global 名字空间，变量名就是里面的 key，变量值就是里面的 value。创建一个全局变量，本质上就是往 global 空间中添加一个键值对；访问一个全局变量，本质上就是将变量名作为 key、从 global 空间中查询 value。</li>
<li>局部变量是通过数组静态存储的，函数内部的局部变量有哪些在编译时就确定了，变量的名称都保存在符号表中，变量的值都保存在 f_localsplus 中，并且变量名在符号表中的索引，和变量值在 f_localsplus 中的索引是一致的。创建一个局部变量，本质上就是基于变量名在符号表中的索引去修改 f_localsplus；访问一个局部变量，本质上就是基于变量名在符号表中的索引去查询 f_localsplus，如果查询到的结果为 NULL，说明该局部变量在赋值之前就被访问了，于是会抛出 UnboundLocalError。</li>
</ul>
<p>前面说了，函数参数和函数内部新创建的变量都属于局部变量，它们的访问逻辑是完全一致的，没有任何区别。只是创建的时候，函数参数在执行帧评估函数之前就已经创建了，被设置在了 f_localsplus 中，执行的时候直接访问即可。</p>
<h2 id="小结-55"><a class="header" href="#小结-55">小结</a></h2>
<p>关于位置参数在函数调用时是如何传递的、在函数执行时又是如何被访问的，现在已经真相大白了。</p>
<p>在调用函数时，虚拟机将函数和参数依次压入<font color="blue">调用者栈帧</font>的运行时栈中，而在 function_code_fastcall 里面会为函数创建新的栈帧，也就是<font color="blue">被调用者栈帧</font>。然后将<font color="blue">调用者栈帧</font>的运行时栈中的参数依次拷贝到<font color="blue">被调用者栈帧</font>的 f_localsplus 中。</p>
<p>所以在访问函数参数时（或者说局部变量），虚拟机并没有按照通常访问符号的做法，去查什么名字空间，而是根据索引访问 f_localsplus 中和符号绑定的值（指针）。而这种基于索引（偏移位置）来访问参数的方式也正是位置参数的由来，并且这种访问方式的速度也是最快的。</p>
<blockquote>
<p>调用函数 foo 时会创建新的栈帧，而等函数 foo 执行完之后，也会回退到模块的栈帧中，并拿到函数 foo 的返回值。然后再将运行时栈里的函数参数清空，回到 CALL_FUNCTION 指令，通过 PUSH(res) 将函数的返回值入栈，接着在模块栈帧中继续执行下一条指令。</p>
</blockquote>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-56"><a class="header" href="#楔子-56">楔子</a></h2>
<p>上一篇文章介绍了位置参数，下面来看一看关键字参数。另外函数还支持默认值，我们就放在一起介绍吧。</p>
<h2 id="函数的默认值"><a class="header" href="#函数的默认值">函数的默认值</a></h2>
<p>简单看一个函数：</p>
<pre><code class="language-python">import dis

code = &quot;&quot;&quot;
def foo(a=1, b=2):
    print(a + b)
    
foo()    
&quot;&quot;&quot;

dis.dis(compile(code, &quot;&lt;func&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>字节码指令如下：</p>
<pre><code class="language-C">  // 构造函数的时候，默认值会被提前压入运行时栈
  0 LOAD_CONST               5 ((1, 2))
  2 LOAD_CONST               2 (&lt;code object foo at 0x7f3...&gt;)
  4 LOAD_CONST               3 ('foo')
  6 MAKE_FUNCTION            1 (defaults)
  8 STORE_NAME               0 (foo)
  // ...
</code></pre>
<p>相比无默认值的函数，有默认值的函数在加载 PyCodeObject 和函数名之前，会先将默认值以元组的形式给加载进来。</p>
<p>然后再来观察一下构建函数用的 MAKE_FUNCTION 指令，我们发现指令参数是 1，而之前都是 0，那么这个 1 代表什么呢？根据提示，我们看到了一个 defaults，它和函数的 func_defaults 有什么关系吗？带着这些疑问，我们再来回顾一下这个指令：</p>
<pre><code class="language-C">case TARGET(MAKE_FUNCTION): {
    // 对于当前例子来说，栈里面有三个元素
    // 从栈顶到栈底分别是：函数名、PyCodeObject、默认值
    PyObject *qualname = POP();  // 弹出函数名
    PyObject *codeobj = POP();  // 弹出 PyCodeObject
  
    // ...
    if (oparg &amp; 0x08) {
        assert(PyTuple_CheckExact(TOP()));
        func -&gt;func_closure = POP();
    }
    if (oparg &amp; 0x04) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_annotations = POP();
    }
    if (oparg &amp; 0x02) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_kwdefaults = POP();
    }
    // 当前 oparg 是 1，和 0x01 按位与的结果为真，所以知道函数有默认值
    // 于是将其从栈顶弹出，保存在函数的 func_defaults 字段中
    if (oparg &amp; 0x01) {
        assert(PyTuple_CheckExact(TOP()));
        func-&gt;func_defaults = POP();
    }

    PUSH((PyObject *)func);
    DISPATCH();
}
</code></pre>
<p>通过以上命令可以很容易看出，该指令创建函数对象时，还会处理参数的默认值、以及类型注解等。另外当前 MAKE_FUNCTION 的指令参数只能表示要构建的函数存在默认值，但具体有多少个是看不到的，因为所有的默认值会按照顺序塞到一个 PyTupleObject 对象里面。</p>
<p>然后将默认值组成的元组用 func_defaults 字段保存，在 Python 层面可以通过 __defaults__ 访问。如此一来，默认值也成为了 PyFunctionObject 对象的一部分，它和 PyCodeObject 对象、global 名字空间一样，也被塞进了 PyFunctionObject 这个大包袱。</p>
<blockquote>
<p>所以说 PyFunctionObject 这个嫁衣做的是很彻底的，工具人 PyFunctionObject，给个赞。</p>
</blockquote>
<pre><code class="language-python">def foo(a=1, b=2):
    print(a + b)
</code></pre>
<p>然后我们还是以这个 foo 函数为例，看看不同的调用方式对应的底层实现。</p>
<h2 id="执行-foo"><a class="header" href="#执行-foo">执行 foo()</a></h2>
<p>由于函数参数都有默认值，此时可以不传参，看看这种方式在底层是如何处理的？</p>
<pre><code class="language-C">// Objects/call.c

PyObject *
_PyFunction_Vectorcall(PyObject *func, PyObject* const* stack,
                       size_t nargsf, PyObject *kwnames)
{
    // ...
    
    // 判断能否进入快速通道，首先要满足函数定义时，参数不可以出现 / 和 *，并且内部不能出现闭包变量
    // 然后调用时不能使用关键字参数
    if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp;
        (co-&gt;co_flags &amp; ~PyCF_MASK) == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE))
    {
        // 上面的 if 虽然满足了，但是还不够，还要保证函数参数不能有默认值
        if (argdefs == NULL &amp;&amp; co-&gt;co_argcount == nargs) {
            return function_code_fastcall(co, stack, nargs, globals);
        }
        // 但很明显上面的要求有点苛刻了，毕竟参数哪能没有默认值呢？
        // 所以底层还提供了另外一种进入快速通道的方式
        // 如果所有的参数都有默认值，然后调用的时候不传参，让参数都使用默认值，此时也会进入快速通道
        else if (nargs == 0 &amp;&amp; argdefs != NULL
                 &amp;&amp; co-&gt;co_argcount == PyTuple_GET_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            stack = _PyTuple_ITEMS(argdefs);
            return function_code_fastcall(co, stack, PyTuple_GET_SIZE(argdefs),
                                          globals);
        }
        // 总的来说，以上两个条件都挺苛刻的
    }

    // ...
    // 否则进入通用通道
    return _PyEval_EvalCodeWithName((PyObject*)co, globals, (PyObject *)NULL,
                                    stack, nargs,
                                    nkwargs ? _PyTuple_ITEMS(kwnames) : NULL,
                                    stack + nargs,
                                    nkwargs, 1,
                                    d, (int)nd, kwdefs,
                                    closure, name, qualname);
}
</code></pre>
<p>对于当前执行的 foo() 来说，由于参数都有默认值，并且此时也没有传参，因此会进入快速通道。而快速通道之前已经介绍过了，这里就不再说了，总之想要进入快速通道，条件还是蛮苛刻的。</p>
<h2 id="执行-foo1"><a class="header" href="#执行-foo1">执行 foo(1)</a></h2>
<p>显然此时就走不了快速通道了，会进入通用通道。此时重点就落在了 _PyEval_EvalCodeWithName 函数中，我们看一下它的逻辑。注意：该函数的逻辑较为复杂，理解起来会比较累，可能需要多读几遍。</p>
<pre><code class="language-C">// Python/ceval.c

PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,
           PyObject *const *kwnames, PyObject *const *kwargs,
           Py_ssize_t kwcount, int kwstep,
           PyObject *const *defs, Py_ssize_t defcount,
           PyObject *kwdefs, PyObject *closure,
           PyObject *name, PyObject *qualname)
{    
    // PyCodeObject 对象
    PyCodeObject* co = (PyCodeObject*)_co;
    // 栈桢对象
    PyFrameObject *f;
    // 函数的返回值
    PyObject *retval = NULL;
    // 和闭包相关，暂时不做讨论
    PyObject **fastlocals, **freevars;
    PyObject *x, *u;
    // co-&gt;co_argcount：可以通过位置参数（或关键字参数）传递的参数个数
    // co-&gt;co_kwonlyargcount：只能通过关键字参数传递的参数个数
    // 两者相加便是参数总个数
    const Py_ssize_t total_args = co-&gt;co_argcount + co-&gt;co_kwonlyargcount;
    Py_ssize_t i, j, n;
    PyObject *kwdict;
    // 线程状态对象
    PyThreadState *tstate = _PyThreadState_GET();
    assert(tstate != NULL);
    // global 名字空间不能为 NULL
    if (globals == NULL) {
        _PyErr_SetString(tstate, PyExc_SystemError,
                         &quot;PyEval_EvalCodeEx: NULL globals&quot;);
        return NULL;
    }

    // 为调用的函数创建栈桢对象
    f = _PyFrame_New_NoTrack(tstate, co, globals, locals);
    if (f == NULL) {
        return NULL;
    }
    // 获取 f_localsplus
    fastlocals = f-&gt;f_localsplus;
    // 闭包相关，后续再聊
    freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;

    // 还记得这个 co_flags 吗? 
    // 如果它和 0x08 按位与的结果为真，说明参数定义了 **kwargs
    // 如果它和 0x04 按位与的结果为真，说明参数定义了 *args
    if (co-&gt;co_flags &amp; CO_VARKEYWORDS) {
        // 申请字典，用于 kwargs
        kwdict = PyDict_New();
        if (kwdict == NULL)
            goto fail;
        i = total_args;
        // 参数是有顺序的，*args 和 **kwargs 在最后面
        // 如果不存在 *args，那么将 fastlocals[total_args] 设置为 kwdict
        // 如果存在 *args，那么将 fastlocals[total_args + 1] 设置为 kwdict
        if (co-&gt;co_flags &amp; CO_VARARGS) {
            i++;
        }
        // 所以如果 co-&gt;co_flags &amp; CO_VARARGS 为真，那么 i++
        // 然后将 kwdict 设置在 fastlocals 中索引为 i 的位置
        SETLOCAL(i, kwdict);
    }
    else {
        kwdict = NULL;
    }

    // argcount 是实际传递的位置参数的个数，co-&gt;co_argcount 是可以通过位置参数传递的参数个数
    // 如果 argcount &gt; co-&gt;co_argcount，证明有扩展位置参数，即 *args，否则没有 
    if (argcount &gt; co-&gt;co_argcount) {
        // 如果有 *args，那么让 n 等于 co-&gt;co_argcount
        n = co-&gt;co_argcount;
    }
    else {
        // 没有 *args, 那么调用者通过位置参数的方式传了几个参数，n 就是几
        n = argcount;
    }
    // 然后我们仔细看一下这个 n，假设有一个函数 def bar(a, b, c=1, d=2, *args)
    // 如果 argcount &gt; co-&gt;co_argcount，说明传递的位置参数的个数超过了 4，于是 n 为 4
    // 但如果我们只传递了两个，比如 bar('a', 'b')，那么 n 显然为 2

    // 下面就是将已经传递的参数的值依次设置到 f_localsplus 里面去
    for (j = 0; j &lt; n; j++) {
        x = args[j];
        Py_INCREF(x);
        SETLOCAL(j, x);
    }

    // 如果有 *args
    if (co-&gt;co_flags &amp; CO_VARARGS) {
        u = _PyTuple_FromArray(args + n, argcount - n);
        if (u == NULL) {
            goto fail;
        }
        // 设置在索引为 total_args 的位置，也就是 **kwargs 的前面
        SETLOCAL(total_args, u);
    }

    // 关键字参数，后面说
    kwcount *= kwstep;
    for (i = 0; i &lt; kwcount; i += kwstep) {
        // ...
    }

    // 条件判断：如果 argcount &gt; co-&gt;co_argcount，并且还没有定义 *args
    // 说明我们传递了超过指定数量的位置参数
    if ((argcount &gt; co-&gt;co_argcount) &amp;&amp; !(co-&gt;co_flags &amp; CO_VARARGS)) {
        // 那么会直接报错：takes m positional arguments but n were given
        too_many_positional(tstate, co, argcount, defcount, fastlocals);
        goto fail;
    }

    // 如果 argcount &lt; co-&gt;co_argcount，说明传递的参数不够，那么证明有默认值
    if (argcount &lt; co-&gt;co_argcount) {
        // defcount 表示设置了默认值的参数个数，显然 m 就是需要传递的没有默认值的参数的个数
        // 比如一个函数接收 6 个参数，但是有两个参数有默认值
        // 这就意味着调用者通过位置参数的方式传递的话，需要至少传递 4 个，那么 m 就是 4
        Py_ssize_t m = co-&gt;co_argcount - defcount;
        Py_ssize_t missing = 0;
        // i = argcount 是我们调用函数时传递的位置参数的总个数
        // 很明显如果参数足够，那么 i &lt; m 是不会满足的
        for (i = argcount; i &lt; m; i++) {
            // 但如果传递的参数不足，那么 GETLOCAL 从 f_localsplus 中就获取不到值
            // 而一旦找不到，missing++，缺少的参数个数加一
            if (GETLOCAL(i) == NULL) {
                missing++;
            }
        }
        // 如果 missing 不为 0，表示缺少参数，直接抛出异常
        if (missing) {
            // {func} missing {n} required positional arguments:
            missing_arguments(tstate, co, missing, defcount, fastlocals);
            goto fail;
        }
        // 下面可能有点难理解，m 是调用者使用位置参数的方式至少需要传递的参数个数
        // 而 n 是使用位置参数的方式实际传递的参数个数，比如：
        /*
        def bar(a, b, c, d=1, e=2, f=3):
            pass

        函数有 6 个参数，其中 3 个有默认值，显然 m 是 3，因为使用位置参数的方式至少要传递 3 个参数
        实际上函数定义好了，m 就是一个不变的值了，就是没有默认值的参数个数
        但我们调用时可以是 bar(1,2,3)，也就是只传递 3 个，那么这里的 n 就是 3
        也可以是 bar(1, 2, 3, 4, 5)，那么显然 n = 5，而 m 依旧是 3
        */         
        if (n &gt; m)
            // 因此现在这里的逻辑就很好理解了，假设调用的是 bar(1, 2, 3, 4, 5)
            // 由于其中 3 个参数有默认值，那么调用时只传递 6 - 3 = 3 个就可以了，但这里传递了 5 个
            // 说明有两个参数我们不想使用默认值，想重新传递，而使用默认值的只有最后一个参数
            // 因此这个 i 就是明明可以使用默认值、但却没有使用的参数的个数            
            i = n - m;
        else
            // 如果按照位置参数传递能走到这一步，说明已经不存在少传的情况了
            // 因此这个 n 至少是 &gt;= m 的，如果 n == m 的话，那么 i 就是 0
            i = 0;
        for (; i &lt; defcount; i++) {
            // 默认参数的值一开始就已经被压入栈中，整体作为一个元组，赋值给了 func_defaults 字段
            // 但对于函数的参数来讲，肯定还要设置到 f_localsplus 里面
            // 并且要在后面，因为默认参数的顺序在非默认参数之后       
            // 所以要从索引 i 开始，将 func_defaults 内部的元素，拷贝到 f_localsplus 中
            if (GETLOCAL(m+i) == NULL) {
                // 还是之前的例子，假设函数接收 6 个参数，其中三个有默认值，但是我们传了 5 个
                // 说明 n = 5，m = 3，那么 i 就等于 n - m = 2，因此有两个参数可以使用默认值，但我们没有使用
                // 所以只需从索引 i 开始，将 func_defaults 里的元素拷贝到 f_localsplus 即可，显然此时只会拷贝最后一个
                // 那么问题来了，如果我们传递了 3 个位置参数呢？显然此时 i 是 0，因为 n == m
                // 这就意味着参数都使用默认值，既然这样，那就从头开始拷
                // 同理如果传了 4 个参数，证明第一个参数的默认值是不需要的，只把后面两个拷贝过去就可以了
                // 显然要从索引为 1 的位置开始拷贝，而此时 n - m、也就是 i，正好为 1
                // 所以 n - m 就是&quot;默认值组成的元组中需要拷贝到 f_localsplus 的第一个值的索引&quot;
                // 然后 i &lt; defcount; i++，一直拷贝到结尾    
                PyObject *def = defs[i];
                Py_INCREF(def);
                // 将值设置到 f_localsplus 里面，因为已经传了 n 个参数
                // 所以要从 f_localsplus[n] 开始设置，而 n 初始正好是 m + i，然后不断执行 i++
                // 因此当前这个 for 循环做的事情就是将 func_defaults[i] 赋值给 f_localsplus[m + i]
                SETLOCAL(m+i, def);
            }
        }
    }

    // 关键字参数，稍后说
    if (co-&gt;co_kwonlyargcount &gt; 0) {
        // ...
    }
    // 闭包相关，后续再聊
    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_cellvars); ++i) {
        // ...
    }
    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_freevars); ++i) {
        // ...
    }

    // 生成器、协程、异步生成器相关，后续再聊
    if (co-&gt;co_flags &amp; (CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR)) {
        // ...
    }
    
    // 到此函数参数就已经设置完毕，拷贝到了栈桢的 f_localsplus 中
    // 然后执行帧评估函数，之后会在 CALL_FUNCTION 指令中拿到返回值，压入运行时栈
    retval = PyEval_EvalFrameEx(f,0);
fail:
    assert(tstate != NULL);
    if (Py_REFCNT(f) &gt; 1) {
        Py_DECREF(f);
        _PyObject_GC_TRACK(f);
    }
    else {
        ++tstate-&gt;recursion_depth;
        Py_DECREF(f);
        --tstate-&gt;recursion_depth;
    }
    return retval;
}
</code></pre>
<p>以上我们就知道了位置参数的默认值是怎么一回事了，还是那句话，逻辑理解起来不是很容易。主要是因为涉及到默认值的处理，但核心就是先将调用者传递的参数拷贝到 f_localsplus 中，然后判断传递的参数个数和默认值个数之间的关系，再将默认值从 func_defaults 拷贝到 f_localsplus 中。</p>
<p>所以快速通道和通用通道做的事情是一样的，都是创建栈桢、修改栈桢字段（主要是修改 f_localsplus）、执行帧评估函数，但通用通道在处理函数参数方面要复杂很多，因为要考虑多种情况。</p>
<h2 id="执行-foob2"><a class="header" href="#执行-foob2">执行 foo(b=2)</a></h2>
<p>这里我们传递了一个关键字参数，此时也会走通用通道。并且在调用函数之前，会先将<font color="blue">符号 b</font> 和<font color="blue">对象 3</font> 压入运行时栈。</p>
<pre><code class="language-C">PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,
           PyObject *const *kwnames, PyObject *const *kwargs,
           Py_ssize_t kwcount, int kwstep,
           PyObject *const *defs, Py_ssize_t defcount,
           PyObject *kwdefs, PyObject *closure,
           PyObject *name, PyObject *qualname)
{
    PyCodeObject* co = (PyCodeObject*)_co;
    PyFrameObject *f;
    // ...
    f = _PyFrame_New_NoTrack(tstate, co, globals, locals);
    // ...
    // 遍历关键字参数
    kwcount *= kwstep;
    for (i = 0; i &lt; kwcount; i += kwstep) {
        PyObject **co_varnames;  // 符号表
        PyObject *keyword = kwnames[i];  // 参数名
        PyObject *value = kwargs[i];     // 参数值
        Py_ssize_t j;
        
        // 函数参数必须是字符串，比如你可以这么做: {**{1: &quot;a&quot;, 2: &quot;b&quot;}}
        // 但不可以这么做: dict(**{1: &quot;a&quot;, 2: &quot;b&quot;})
        if (keyword == NULL || !PyUnicode_Check(keyword)) {
            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() keywords must be strings&quot;,
                          co-&gt;co_name);
            goto fail;
        }
        co_varnames = ((PyTupleObject *)(co-&gt;co_varnames))-&gt;ob_item;
        // 遍历符号表，看看符号表中是否存在和关键字参数相同的符号
        // 注意：这里的 j 不是从 0 开始的, 而是从 posonlyargcount 开始
        // 因为在 Python3.8 中引入了 /, 在 / 前面的参数只能通过位置参数传递
        for (j = co-&gt;co_posonlyargcount; j &lt; total_args; j++) {
            // 比如传递了 b=3，那么要保证符号表中存在 &quot;b&quot; 这个符号
            // 如果有，那么该参数就是合法的关键字参数，如果没有，再看是否存在 **kwargs
            // 要是没有 **kwargs，报错：got an unexpected keyword argument
            PyObject *name = co_varnames[j];
            if (name == keyword) {
                // 找到了，跳转到 kw_found 标签
                goto kw_found;
            }
        }

        /* Slow fallback, just in case */
        // 逻辑和上面一样，只是比较符号时用的是 PyObject_RichCompareBool
        for (j = co-&gt;co_posonlyargcount; j &lt; total_args; j++) {
            PyObject *name = co_varnames[j];
            int cmp = PyObject_RichCompareBool( keyword, name, Py_EQ);
            if (cmp &gt; 0) {
                goto kw_found;
            }
            else if (cmp &lt; 0) {
                goto fail;
            }
        }

        assert(j &gt;= total_args);
        // 到这里说明符号表中不存在指定的符号
        if (kwdict == NULL) {  // 没有定义 **kwargs
            // 说明指定了一个不存在的关键字参数
            if (co-&gt;co_posonlyargcount
                &amp;&amp; positional_only_passed_as_keyword(tstate, co,
                                                     kwcount, kwnames))
            {
                goto fail;
            }

            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() got an unexpected keyword argument '%S'&quot;,
                          co-&gt;co_name, keyword);
            goto fail;
        }
        // 到这里说明虽然符号表中不存在指定的符号，但函数定义了 **kwargs
        // 那么将参数名和参数值设置到字典 kwargs 中
        if (PyDict_SetItem(kwdict, keyword, value) == -1) {
            goto fail;
        }
        continue;

      kw_found:
        // 索引 j 就是该参数在 f_localsplus 中的索引
        // 但如果 GETLOCAL(j) != NULL，说明已经通过位置参数指定了
        if (GETLOCAL(j) != NULL) {
            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() got multiple values for argument '%S'&quot;,
                          co-&gt;co_name, keyword);
            goto fail;
        }
        // 否则增加引用计数，设置在 f_localsplus 中
        Py_INCREF(value);
        SETLOCAL(j, value);
    }

    // 判断函数是否定义了仅限关键字参数
    // 而仅限关键字参数的默认值是不包含在 func_defaults 里面的，它位于 func_kwdefaults 里面
    if (co-&gt;co_kwonlyargcount &gt; 0) {
        Py_ssize_t missing = 0;
        // 同样是遍历符号表，获取默认值，如果有，设置在 f_localsplus 中
        for (i = co-&gt;co_argcount; i &lt; total_args; i++) {
            PyObject *name;
            if (GETLOCAL(i) != NULL)
                continue;
            name = PyTuple_GET_ITEM(co-&gt;co_varnames, i);
            if (kwdefs != NULL) {
                PyObject *def = PyDict_GetItemWithError(kwdefs, name);
                if (def) {
                    Py_INCREF(def);
                    SETLOCAL(i, def);
                    continue;
                }
                else if (_PyErr_Occurred(tstate)) {
                    goto fail;
                }
            }
            missing++;
        }
        if (missing) {
            missing_arguments(tstate, co, missing, -1, fastlocals);
            goto fail;
        }
    }
    
    // ...
    return retval;
}
</code></pre>
<p>总结一下，虚拟机会将函数中出现的符号都记录在符号表（co_varnames）里面。对于 foo(b=2) 来说，虚拟机在执行 CALL_FUNCTION 指令之前会将关键字参数的名字都压入到运行时栈，那么在执行 _PyEval_EvalCodeWithName 时就能利用运行时栈中保存的关键字参数的名字在 co_varnames 里面进行查找。</p>
<p>最妙的是，变量名在 co_varnames 中的索引，和变量值在 f_localsplus 中的索引是一致的。所以在 co_varnames 中搜索到关键字参数的名字时，就可以根据对应的索引直接修改 f_localsplus，这就为默认参数设置了函数调用者希望的值。</p>
<p><strong>为了理解清晰，我们再举个简单例子，总结一下。</strong></p>
<pre><code class="language-Python">def foo(a, b, c, d=1, e=2, f=3):
    pass
</code></pre>
<p>对于上面这个函数，首先虚拟机知道调用者至少要给 a、b、c 传递参数。如果是 foo(1)，那么 1 会传递给 a，但是 b 和 c 是没有接收到值的，所以报错。</p>
<p>如果是 foo(1, e=11, c=22, b=33)，还是老规矩先将 1 传递给 a，发现依旧不够，这时就会把希望寄托在关键字参数上。并且由于 f_localsplus 中变量值的顺序，和 co_varnames 中变量名的顺序是一致的，所以关键字参数是不讲究顺序的。当找到了 e=11，那么虚拟机通过符号表，就知道把 e 的值设置在 f_localsplus 中索引为 4 的地方。为什么索引是 4 呢？因为符号 e 在符号表中的索引是 4。而 c=22，显然设置在索引为 2 的地方，b=3，设置在索引为 1 的地方。等位置参数和关键字参数都设置完毕之后，虚拟机会再检测需要传递的参数、也就是没有默认值的参数，调用者有没有全部传递。</p>
<h2 id="小结-56"><a class="header" href="#小结-56">小结</a></h2>
<p>这一篇的内容稍微有点枯燥，因为从 Python 的角度来看的话，就是一个传参罢了。</p>
<p>参数的传递可以使用位置参数、也可以使用关键字参数；如果带有默认值，我们也可以只给一部分参数传值，然后没收到值的参数使用默认值，收到值的参数使用我们传递的值。而我们这里所做的事情，就是在看这些参数解析具体是怎么实现的。</p>
<p>最后再给出两个思考题：</p>
<ul>
<li>1）经过分析我们知道，关键字参数具体设置在 f_localsplus 中的哪一个地方，是通过将参数名代入到 co_varnames 里面查找所得到的。但如果这个关键字参数的参数名不在 co_varnames 里面，怎么办？</li>
<li>2）如果传递的位置参数的个数比 co_argcount 还要多，怎么办？</li>
</ul>
<p>这里直接给出答案，首先是问题一，如果出现这种情况，说明指定了不存在的关键字参数，会报错，如果不想报错，意味着函数要定义 **kwargs。然后是问题二，说明位置参数传多了，显然也会报错，如果不想报错，意味着函数要定义 *args。</p>
<p>关于 *args 和 **kwargs，我们下一篇文章介绍。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>本篇文章再来补充一下扩展位置参数和扩展关键字参数，即 *args 和 **kwargs。</p>
<pre><code class="language-python">def foo(a, b, *args, **kwargs):
    pass

print(foo.__code__.co_nlocals)  # 4
print(foo.__code__.co_argcount)  # 2
</code></pre>
<p>对于 co_nlocals 来说，它统计的是所有局部变量的个数，而当前的 foo 函数内部存在 4 个局部变量：a、b、args、kwargs，所以结果是 4。但对于 co_argcount 来说，统计的结果不包括 args 和 kwargs，因此结果是 2。</p>
<p>然后 *args 可以接收多个位置参数，这些位置参数会放在一个由 args 指向的元组中；**kwargs 则可以接收多个关键字参数，而这些关键字参数（名字和值）会放在一个由 kwargs 指向的字典中。当然这些即使不从源码的角度来分析，从 Python 的实际使用中我们也能得出这个结论。</p>
<pre><code class="language-Python">def foo(*args, **kwargs):
    print(args)
    print(kwargs)


foo(1, 2, 3, a=1, b=2, c=3)
&quot;&quot;&quot;
(1, 2, 3)
{'a': 1, 'b': 2, 'c': 3}
&quot;&quot;&quot;

foo(*(1, 2, 3), **{&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3})
&quot;&quot;&quot;
(1, 2, 3)
{'a': 1, 'b': 2, 'c': 3}
&quot;&quot;&quot;
</code></pre>
<p>当然啦，在调用的时候如果对一个元组或者列表、甚至是字符串使用 *，那么会将这个可迭代对象直接打散，相当于传递了多个位置参数。同理如果对一个字典使用 **，那么相当于传递了多个关键字参数。</p>
<p>下面我们就来看看扩展参数是如何实现的，还是进入到 _PyEval_EvalCodeWithName 这个函数里面来。</p>
<pre><code class="language-c">PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,  // 位置参数的相关信息
           PyObject *const *kwnames, PyObject *const *kwargs,  // 关键字参数的相关信息  
           Py_ssize_t kwcount, int kwstep,  // 关键字参数的个数
           PyObject *const *defs, Py_ssize_t defcount,  // 默认值等信息  
           PyObject *kwdefs, PyObject *closure,  // 闭包相关信息
           PyObject *name, PyObject *qualname)  // 函数的名称信息
{
    // ...
    // 判断是否出现了 **kwargs
    if (co-&gt;co_flags &amp; CO_VARKEYWORDS) {
        // 创建一个字典，用于 kwargs
        kwdict = PyDict_New();
        if (kwdict == NULL)
            goto fail;
        // i 是参数总个数
        i = total_args;
        // 如果还有 *args，那么 i 要加上 1，因为 **kwargs 要定义在 *args 的后面
        if (co-&gt;co_flags &amp; CO_VARARGS) {
            i++;
        }
        // 如果没有 *args，那么 kwdict 要位于索引为 i 的位置
        // 如果有 *args，那么 kwdit 位于索引为 i + 1 的位置
        SETLOCAL(i, kwdict);
    }
    else {
        // 如果没有 **kwargs 的话，那么 kwdict 就是 NULL
        kwdict = NULL;
    }
    // 这段逻辑之前介绍了，是将位置参数（不包含扩展位置参数）拷贝到 f_localsplus 中
    if (argcount &gt; co-&gt;co_argcount) {
        n = co-&gt;co_argcount;
    }
    else {
        n = argcount;
    }
    for (j = 0; j &lt; n; j++) {
        x = args[j];
        Py_INCREF(x);
        SETLOCAL(j, x);
    }

    // 关键来了，这里是负责将多余的位置参数拷贝到 args 里面去
    if (co-&gt;co_flags &amp; CO_VARARGS) {
        // 申请一个容量为 argcount - n 的元组
        u = _PyTuple_FromArray(args + n, argcount - n);
        if (u == NULL) {
            goto fail;
        }
        // 放到 f -&gt; f_localsplus 里面去，索引为 total_args
        SETLOCAL(total_args, u);
    }

    // 下面就是拷贝扩展关键字参数，使用索引遍历，按照顺序依次取出
    // 通过判断传递的关键字参数的符号是否出现在函数定义的参数中
    // 来判断传递的这个参数究竟是普通的关键字参数，还是扩展关键字参数
    // 比如 def foo(a, b, c, **kwargs)，调用方式为 foo(1, 2, c=3, d=4)
    // 由于 c 出现在了函数定义的参数中，所以 c 是一个普通的关键字参数
    // 但是 d 没有，因此 d 是扩展关键字参数，要设置到 kwargs 这个字典里面
    kwcount *= kwstep;
    // 按照索引遍历，将参数名和参数值依次取出
    for (i = 0; i &lt; kwcount; i += kwstep) {
        PyObject **co_varnames;
        PyObject *keyword = kwnames[i];
        PyObject *value = kwargs[i];
        Py_ssize_t j;
        // 参数名必须是字符串
        if (keyword == NULL || !PyUnicode_Check(keyword)) {
            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() keywords must be strings&quot;,
                          co-&gt;co_name);
            goto fail;
        }

        // 拿到符号表，得到所有的符号，这样就知道函数参数都有哪些
        co_varnames = ((PyTupleObject *)(co-&gt;co_varnames))-&gt;ob_item;
        // 我们看到内部又是一层 for 循环
        // 首先外层循环是遍历所有的关键字参数，也就是我们传递的参数
        // 而内层循环则是遍历符号表，看指定的参数名在符号表中是否存在
        for (j = co-&gt;co_posonlyargcount; j &lt; total_args; j++) {
            PyObject *name = co_varnames[j];
            // 如果相等，说明参数在符号表中已存在
            if (name == keyword) {
                // 然后跳转到 kw_found，将参数值设置在 f_localsplus 中索引为 j 的位置
                // 并且在标签内部，还会检测该参数有没有通过位置参数传递
                // 如果已经通过位置参数传递了，那么显然该参数就被传递了两次
                goto kw_found;
            }
        }

        /* Slow fallback, just in case */
        /* 逻辑和上面一样 */
        for (j = co-&gt;co_posonlyargcount; j &lt; total_args; j++) {
            PyObject *name = co_varnames[j];
            int cmp = PyObject_RichCompareBool( keyword, name, Py_EQ);
            if (cmp &gt; 0) {
                goto kw_found;
            }
            else if (cmp &lt; 0) {
                goto fail;
            }
        }

        assert(j &gt;= total_args);
        // 走到这里，说明上面的 for 循环不成立，参数不在符号表中，也就是传入了不存在的关键字参数
        // 那么这时候要检测 **kwargs，如果 kwdict 是 NULL，说明函数没有 **kwargs，那么直接报错
        if (kwdict == NULL) {
            if (co-&gt;co_posonlyargcount
                &amp;&amp; positional_only_passed_as_keyword(tstate, co,
                                                     kwcount, kwnames))
            {
                goto fail;
            }
            // 也就是下面这个错误，{func} 收到了一个预料之外的关键字参数
            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() got an unexpected keyword argument '%S'&quot;,
                          co-&gt;co_name, keyword);
            goto fail;
        }
        // kwdict 不为 NULL，证明定义了 **kwargs，那么将参数名和参数值设置到这个字典里面去
        // 然后 continue 进入下一个关键字参数的判断逻辑
        if (PyDict_SetItem(kwdict, keyword, value) == -1) {
            goto fail;
        }
        continue;

      kw_found:
        // 获取符号对应的值，但是发现不为 NULL，说明已经通过位置参数传递了
        if (GETLOCAL(j) != NULL) {
            // 那么这里就抛出一个 TypeError，表示某个参数接收了多个值
            _PyErr_Format(tstate, PyExc_TypeError,
                          &quot;%U() got multiple values for argument '%S'&quot;,
                          co-&gt;co_name, keyword);
            // 比如说：def foo(a, b, c=1, d=2)，调用方式是 foo(1, 2, c=3)，那么肯定没问题
            // 因为开始会把位置参数拷贝到 f_localsplus 里面
            // 所以此时 f_localsplus（第一段内存）是 [1, 2, NULL, NULL]
            // 然后设置关键字参数的时候，j 对应的索引为 2
            // 那么 GETLOCAL(j) 就是 NULL，上面的 if 不成立，所以不会报错            
            // 但如果这样传递：foo(1, 2, 3, c=3)，那么 f_localsplus 就是 [1, 2, 3, NULL]
            // 而 GETLOCAL(j) 就是 3，不为 NULL，说明 j 这个位置已经通过位置参数传递了
            // 既然有值了，那么关键字参数就不能传递了，否则就重复了
            goto fail;
        }
        // 将 value 设置在 f_localsplus 中索引为 j 的位置
        // 还是那句话，f_localsplus 存储的值（PyObject *）和符号表存储的符号，在顺序上是一致的
        // 比如变量 c 在符号表中索引为 2 的位置，那么 f_localsplus[2] 保存的就是变量 c 的值   
        Py_INCREF(value);
        SETLOCAL(j, value);
    }

    // ...
}
</code></pre>
<p>总的来说，虚拟机对参数进行处理的时候，机制还是有点复杂的。其实扩展关键字参数的传递机制和普通关键字参数有很大的关系，我们之前分析参数的默认值时，已经看到了关键字参数的传递机制，这里又再次看到了。</p>
<p>对于关键字参数，不论是否扩展，都会把符号和值按照对应顺序分别放在两个数组里面。然后虚拟机按照索引依次遍历存放符号的数组，对遍历出的每一个符号都会和符号表 co_varnames 中的符号逐个进行比对，如果发现在符号表中找不到传递的关键字参数的符号，那么就说明这是一个扩展关键字参数。然后就是我们在源码中看到的那样，如果函数定义了 **kwargs，那么 kwdict 就不为空，会把扩展关键字参数直接设置进去，否则报错：提示接收到了一个不期待的关键字参数。</p>
<p>_PyEval_EvalCodeWithName 里面的内容还是蛮多的，我们每次都是截取指定的部分进行分析，可以自己再对着源码仔细读一遍。总之核心逻辑如下：</p>
<ul>
<li>1）获取所有通过位置参数传递的参数个数，然后循环遍历将它们从运行时栈依次拷贝到 f_localsplus 中；</li>
<li>2）计算出可以通过位置参数传递的参数个数，如果&quot;实际传递的位置参数的个数&quot; 大于 &quot;可以通过位置参数传递的参数个数&quot;，那么会检测是否存在 *args。如果存在，那么将多余的位置参数拷贝到 args 指向的元组中；如果不存在，则报错：TypeError: function() takes 'm' positional argument but 'n' were given，其中 n 大于 m，表示接收了多个位置参数；</li>
<li>3）如果&quot;实际传递的位置参数的个数&quot; 小于等于 &quot;可以通过位置参数传递的参数个数&quot;，那么程序继续往下执行，检测关键字参数，它是通过两个数组来实现的，参数名和参数值是分开存储的；</li>
<li>4）然后进行遍历，两层 for 循环，第一层 for 循环遍历存放关键字参数名的数组，第二层 for 循环遍历符号表，会将传递的参数名和符号表中的每一个符号进行比较；</li>
<li>5）如果指定了不在符号表中的参数名，那么会检测是否定义了 **kwargs，如果没有则报错：TypeError: function() got an unexpected keyword argument 'xxx'，表示接收了一个不期望的关键字参数 xxx；如果定义了 **kwargs，那么会设置在字典中；</li>
<li>6）如果参数名在符号表中存在，那么跳转到 kw_found 标签，然后获取该符号对应的 value。如果 value 不为 NULL，那么证明该参数已经通过位置参数传递了，会报错：TypeError: function() got multiple values for argument 'xxx'，提示函数的参数 xxx 接收了多个值；</li>
<li>7）最终所有的参数都会存在 f_localsplus 中，然后检测是否存在对应的 value 为 NULL 的符号，如果存在，那么检测是否具有默认值，有则使用默认值，没有则报错；</li>
</ul>
<p>以上就是函数参数的处理流程，用起来虽然简单，但分析具体实现时还是有点头疼的。当然啦，这部分内容其实也没有深挖的必要，大致了解就好。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-57"><a class="header" href="#楔子-57">楔子</a></h2>
<p>在之前的文章中一直反复提到四个字：名字空间。一段代码的执行结果不光取决于代码中的符号，更多的是取决于代码中符号的语义，而这个运行时的语义正是由名字空间决定的。</p>
<p>名字空间由虚拟机在运行时动态维护，但有时我们希望将名字空间静态化。换句话说，我们希望有的代码不受名字空间变化带来的影响，始终保持一致的功能该怎么办呢？随便举个例子：</p>
<pre><code class="language-Python">def login(user_name, password, user):
    if not (user_name == &quot;satori&quot; and password == &quot;123&quot;):
        return &quot;用户名密码不正确&quot;
    else:
        return f&quot;欢迎: {user}&quot;

print(login(&quot;satori&quot;, &quot;123&quot;, &quot;古明地觉&quot;))  # 欢迎: 古明地觉
print(login(&quot;satori&quot;, &quot;123&quot;, &quot;古明地恋&quot;))  # 欢迎: 古明地恋
</code></pre>
<p>我们注意到每次都需要输入 username 和 password，因此可以通过嵌套函数来设置一个基准值。</p>
<pre><code class="language-Python">def deco(user_name, password):
    def login(user):
        if not (user_name == &quot;satori&quot; and password == &quot;123&quot;):
            return &quot;用户名密码不正确&quot;
        else:
            return f&quot;欢迎: {user}&quot;
    return login

login = deco(&quot;satori&quot;, &quot;123&quot;)
print(login(&quot;古明地觉&quot;))  # 欢迎: 古明地觉
print(login(&quot;古明地恋&quot;))  # 欢迎: 古明地恋
</code></pre>
<p>尽管函数 login 里面没有 user_name 和 password 这两个局部变量，但是不妨碍我们使用它，因为外层函数 deco 里面有。</p>
<p>也就是说，函数 login 作为函数 deco 的返回值被返回的时候，有一个名字空间就已经和 login 紧紧地绑定在一起了。执行内层函数 login 的时候，对于自身 local 空间中不存在的变量，会从和自己绑定的 local 空间里面去找，这就是一种将名字空间静态化的方法。这个名字空间和内层函数捆绑之后的结果我们称之为闭包（closure）。</p>
<blockquote>
<p>为了描述方便，上面说的是 local 空间，但我们知道，局部变量不是从那里查找的，而是从 f_localsplus 里面。只是我们可以按照 LEGB 的规则去理解，这一点心理清楚就行。</p>
</blockquote>
<p>也就是说：<font color="blue">闭包=外部作用域+内层函数</font>。并且在介绍函数的时候提到，PyFunctionObject 是虚拟机专门为字节码指令的传输而准备的大包袱，global 名字空间、默认参数等都和字节码指令捆绑在一起，同样的，也包括闭包。</p>
<h2 id="实现闭包的基石"><a class="header" href="#实现闭包的基石">实现闭包的基石</a></h2>
<p>闭包的创建通常是利用嵌套函数来完成的，我们说过局部变量是通过数组静态存储的，而闭包也是如此。前面说过，栈桢的 f_localsplus 字段是一个柔性数组，既然是数组，那么就是一段连续的内存，只是这段内存在概念上分成了四个部分，分别用于：局部变量、cell 变量、free 变量、运行时栈。</p>
<p><img src="./images/219.png" alt="" /></p>
<p>怎么证明这一点呢？我们看一下栈桢创建函数 _PyFrame_New_NoTrack 就好了，里面有几行代码泄漏了天机。</p>
<pre><code class="language-C">Py_ssize_t extras, ncells, nfrees;
// cell 变量的个数
ncells = PyTuple_GET_SIZE(code-&gt;co_cellvars);
// free 变量的个数
nfrees = PyTuple_GET_SIZE(code-&gt;co_freevars);
// code-&gt;co_nlocals 表示局部变量的个数
// code-&gt;co_stacksize 表示运行时栈的长度
// 这几个加起来便是 f_localsplus 数组的长度，再乘以 8 就是应该为 f_localsplus 申请的内存大小
extras = code-&gt;co_stacksize + code-&gt;co_nlocals + ncells + nfrees;
</code></pre>
<p>局部变量和运行时栈对应的内存我们已经剖析过了，本次来聊一聊 cell 变量和 free 变量，它们是和闭包相关的。老规矩，先来看一段代码：</p>
<pre><code class="language-python">def foo():
    name = &quot;古明地觉&quot;
    age = 17
    gender = &quot;female&quot;

    def bar():
        nonlocal name
        nonlocal age
        print(gender)

    return bar

print(foo.__code__.co_cellvars)  # ('age', 'gender', 'name')
print(foo().__code__.co_freevars)  # ('age', 'gender', 'name')
print(foo.__code__.co_freevars)  # ()
print(foo().__code__.co_cellvars)  # ()
</code></pre>
<p>和闭包相关的两个字段是 co_cellvars 和 co_freevars，其中 co_cellvars 保存了外层作用域中被内层作用域引用的变量的名字，co_freevars 保存了内层作用域中引用的外层作用域的变量的名字。</p>
<p>所以对于外层函数来说，应该使用 co_cellvars，对于内层函数来说，应该使用 co_freevars。当然无论是外层函数还是内层函数都有 co_cellvars 和 co_freevars，这是肯定的，因为都是函数。只不过外层函数需要使用 co_cellvars 获取，因为它包含的是外层函数中被内层函数引用的变量的名称；内层函数需要使用 co_freevars 获取，它包含的是内层函数中引用的外层函数的变量的名称。</p>
<p>如果使用外层函数 foo 获取 co_freevars 的话，那么得到的结果显然就是个空元组了，除非 foo 也作为某个函数的内层函数，并且内部引用了外层函数的变量。同理内层函数 bar 也是一样的道理，它获取 co_cellvars 得到的也是空元组，因为对于 bar 而言不存在内层函数。</p>
<p>我们再看个例子：</p>
<pre><code class="language-python">def foo():
    name = &quot;古明地觉&quot;
    age = 17

    def bar():
        nonlocal name
        nonlocal age
        gender = &quot;female&quot;

        def inner():
            nonlocal gender

        return inner

    return bar

print(foo().__code__.co_cellvars)  # ('gender',)
print(foo().__code__.co_freevars)  # ('age', 'name')
</code></pre>
<p>对于函数 bar 而言，它是函数 inner 的外层函数，同时也是函数 foo 的内层函数。所以它在获取 co_cellvars 和 co_freevars 属性时，得到的元组都不为空。因为内层函数 inner 引用了函数 bar 里面的变量 gender，同时函数 bar 也作为内层函数引用了函数 foo 里的 name 和 age。</p>
<p>那么问题来了，闭包变量所需要的空间申请在哪个地方呢？没错，显然是 f_localsplus，它是一个柔性数组，在概念上被分成了四份，分别用于：局部变量、cell 变量、free 变量、运行时栈。所以闭包变量同样是以静态的方式实现的。</p>
<h2 id="闭包的实现过程"><a class="header" href="#闭包的实现过程">闭包的实现过程</a></h2>
<p>介绍完实现闭包的基石之后，我们可以开始追踪闭包的具体实现过程了，当然还是要先看一下闭包对应的字节码。</p>
<pre><code class="language-Python">import dis

code_string = &quot;&quot;&quot;
def some_func():
    name = &quot;satori&quot;
    age = 17
    gender = &quot;female&quot;
    def inner():
        print(name, age)

    return inner

func = some_func()
func()
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>字节码指令如下，为了阅读方便，我们省略了源代码行号。</p>
<pre><code class="language-C">   // 加载函数 some_func 对应的 PyCodeObject，压入运行时栈
   0 LOAD_CONST               0 (&lt;code object some_func at 0x7f9...&gt;)
   // 加载函数的名称 &quot;some_func&quot;，压入运行时栈
   2 LOAD_CONST               1 ('some_func')
   // 从栈顶弹出函数名和 PyCodeObject，构造 PyFunctionObject，并压入运行时栈
   4 MAKE_FUNCTION            0
   // 从栈顶弹出 PyFunctionObject，然后使用变量 some_func 保存
   6 STORE_NAME               0 (some_func)
   // 加载全局变量 some_func
   8 LOAD_NAME                0 (some_func)
   // 调用
  10 CALL_FUNCTION            0
   // 弹出栈顶的返回值，并使用变量 func 保存
  12 STORE_NAME               1 (func)
   // 加载全局变量 func
  14 LOAD_NAME                1 (func)
   // 调用
  16 CALL_FUNCTION            0
   // 从栈顶弹出返回值，丢弃
  18 POP_TOP
   // 隐式地 return None
  20 LOAD_CONST               2 (None)
  22 RETURN_VALUE

   // ********** 外层函数 some_func 对应的字节码 **********
Disassembly of &lt;code object some_func at 0x7f9...&gt;:
   // 加载字符串常量 &quot;satori&quot;
   0 LOAD_CONST               1 ('satori')
   // 注意这里不是 STORE_FAST，而是 STORE_DEREF
   // 它的作用肯定是将符号 &quot;name&quot; 和字符串常量绑定起来
   // STORE_NAME、STORE_FAST、STORE_DEREF 做的事情是一样的
   // 都是将符号和值绑定起来，只是绑定的方式不一样
   // 比如 STORE_NAME 是通过字典完成绑定，STORE_FAST 是通过数组完成绑定
   // 那么 STORE_DEREF 是怎么绑定的呢？稍后分析  
   2 STORE_DEREF              1 (name)
   // 加载常量 17
   4 LOAD_CONST               2 (17)
   // 使用变量 age 保存
   6 STORE_DEREF              0 (age)
   // name 和 age 被内层函数引用了，所以是 STORE_DEREF
   // 但 gender 没有，所以它对应的是 STORE_FAST
   8 LOAD_CONST               3 ('female')
  10 STORE_FAST               0 (gender)
   // 加载 cell 变量，压入运行时栈
  12 LOAD_CLOSURE             0 (age)
  14 LOAD_CLOSURE             1 (name)
   // 弹出 cell 变量，构建元组并入栈
  16 BUILD_TUPLE              2
   // 加载函数 inner 对应的 PyCodeObject
  18 LOAD_CONST               4 (&lt;code object inner at 0x7f9...&gt;)
   // 加载函数名
  20 LOAD_CONST               5 ('some_func.&lt;locals&gt;.inner')
   // 构造函数
  22 MAKE_FUNCTION            8 (closure)
   // 将函数使用变量 inner 保存
  24 STORE_FAST               1 (inner)
   // return inner
  26 LOAD_FAST                1 (inner)
  28 RETURN_VALUE
   
   // ********** 内层函数 inner 对应的字节码 **********
Disassembly of &lt;code object inner at 0x7f9...&gt;:
   // 加载内置变量 print
   0 LOAD_GLOBAL              0 (print)
   // 显然它和 LOAD_NAME、LOAD_FAST 的关系也是类似的
   // 也是负责加载变量，然后压入运行时栈  
   2 LOAD_DEREF               1 (name)
   4 LOAD_DEREF               0 (age)
   // 调用 print 函数
   6 CALL_FUNCTION            2
   // 从栈顶弹出返回值，丢弃
   8 POP_TOP
  10 LOAD_CONST               0 (None)
  12 RETURN_VALUE
</code></pre>
<p>字节码的内容并不难，里面的大部分指令都见过了，但是有三个例外，分别是 STORE_DEREF、LOAD_CLOSURE、LOAD_DEREF。</p>
<p>首先 STORE_DEREF 和 LOAD_DEREF 也是用来创建和加载变量，对于当前这个例子来说，变量就是 name 和 age。因此很容易得出结论，如果一个局部变量被内层函数所引用，那么指令将不再是 LOAD_FAST 和 STORE_FAST，而是 LOAD_DEREF 和 STORE_DEREF。至于 LOAD_CLOSURE 是做什么用的，稍后会解释。</p>
<p>我们先来分析一下外层函数 some_func 对应的字节码。</p>
<p><img src="./images/220.png" alt="" /></p>
<p>函数 some_func 里面有三个局部变量，但只有 name 和 age 被内层函数引用了，所以创建时使用的指令是 STORE_DEREF，我们看一下该指令都做了什么。</p>
<pre><code class="language-C">// 所以 freevars 指向了 f_localsplus 的第二段内存的起始位置
freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;

case TARGET(STORE_DEREF): {
    // 从栈顶弹出元素
    PyObject *v = POP();
    // 获取 cell 变量，它指向了 PyCellObject 结构体实例
    PyObject *cell = freevars[oparg];
    // 获取 PyCellObject 实例内部维护的值（初始为 NULL）
    PyObject *oldobj = PyCell_GET(cell);
    // 将 PyCellObject 实例内部维护的值设置成 v
    PyCell_SET(cell, v);
    Py_XDECREF(oldobj);
    DISPATCH();
}
</code></pre>
<p>再来看一下 PyCellObject 的定义。</p>
<pre><code class="language-C">// Include/cellobject.h

typedef struct {
    PyObject_HEAD
    PyObject *ob_ref;
} PyCellObject;

#define PyCell_GET(op) (((PyCellObject *)(op))-&gt;ob_ref)
#define PyCell_SET(op, v) (((PyCellObject *)(op))-&gt;ob_ref = v)
</code></pre>
<p>因此在两个 STORE_DEREF 执行完之后，f_localsplus 会变成下面这样：</p>
<p><img src="./images/221.png" alt="" /></p>
<p>相信你明白 STORE_FAST 和 STORE_DEREF 之间的区别了，如果是 STORE_FAST，那么中间就没有 PyCellObject 这一层，f_localsplus 保存的 PyObject * 指向的就是具体的对象。</p>
<blockquote>
<p>另外创建变量 name 时，STORE_DEREF 的指令参数为 1，创建变量 age 时，STORE_DEREF 的指令参数为 0，所以 name 的值会设置在 cell 变量的内存区域中索引为 1 的位置，age 的值则是设置在索引为 0 的位置。</p>
</blockquote>
<p>然后是 gender = &quot;female&quot;，它就很简单了，由于符号 &quot;gender&quot; 对应局部变量，在符号表中的索引为 0，那么直接让 f_localsplus[0] 指向字符串 &quot;female&quot; 即可。</p>
<p><img src="./images/222.png" alt="" /></p>
<p>f_localsplus 保存了局部变量的值，而符号在符号表中的索引，和对应的值在 f_localsplus 中的索引是一致的，所以正常情况下，局部变量赋值就是 <code>f_localsplus[i] = v</code>。但对于 cell 变量来说，它指向的是 PyCellObject，所以赋值是 <code>f_localsplus[i]-&gt;ob_ref = v</code>。</p>
<p>到此变量 name、age、gender 均已赋值完毕，f_localsplus[0]、f_localsplus[2]、f_localsplus[3] 分别对应变量 gender、age、name。可能有人觉得这个索引好奇怪啊，我们实际测试一下。</p>
<pre><code class="language-Python">def some_func():
    name = &quot;satori&quot;
    age = 17
    gender = &quot;female&quot;
    def inner():
        print(name, age)

    return inner

print(
    some_func.__code__.co_varnames
)  # ('gender', 'inner')
</code></pre>
<p>我们看到 some_func 的符号表里面只有 gender 和 inner，因此 f_localsplus[0] 表示变量 gender。至于 f_localsplus[1] 则表示变量 inner，只不过此时它指向的对象还没有创建，所以暂时为 NULL。</p>
<p>至于变量 name 和 age，由于它们被内层函数引用了，所以它们是 cell 变量，并且位置是相对于 <code>f_localsplus + co_nlocals</code> 开始的，而 co_nlocals 表示局部变量的个数。所以在 f_localsplus 中，cell 变量的位置是在局部变量之后的，这完全符合我们之前说的 f_localsplus 的内存布局。并且我们看到无论是局部变量还是 cell 变量，都是通过数组索引访问的，并且索引在编译时就确定了，以指令参数的形式保存在字节码指令集中。</p>
<p>接下来执行偏移量为 12 和 14 的两条指令，它们都是 LOAD_CLOSURE。</p>
<pre><code class="language-C">case TARGET(LOAD_CLOSURE): {
    // 加载 PyCellObject *，即 cell 变量
    PyObject *cell = freevars[oparg];
    // 增加引用计数，然后压入运行时栈
    Py_INCREF(cell);
    PUSH(cell);
    DISPATCH();
}
</code></pre>
<p>LOAD_CLOSURE 执行完毕后，接着执行 <font color="blue">16 BUILD_TUPLE</font>，将 cell 变量从栈中弹出，构建元组并入栈。然后继续执行 <font color="blue">18 LOAD_CONST</font> 和 <font color="blue">20 LOAD_CONST</font>，将内层函数 inner 对应的 PyCodeObject 和函数名压入运行时栈。</p>
<p>接着执行 <font color="blue">22 MAKE_FUNCTION</font>，开始构建函数，我们看一下 MAKE_FUNCTION 指令，它的指令参数为 8。</p>
<pre><code class="language-C">case TARGET(MAKE_FUNCTION): {
    // 弹出函数名
    PyObject *qualname = POP();
    // 弹出 PyCodeObject 对象
    PyObject *codeobj = POP();
    // 构建函数
    PyFunctionObject *func = (PyFunctionObject *)
        PyFunction_NewWithQualName(codeobj, f-&gt;f_globals, qualname);

    Py_DECREF(codeobj);
    Py_DECREF(qualname);
    if (func == NULL) {
        goto error;
    }
    // 由于指令参数为 8，所以 oparg &amp; 0x08 为真
    // 那么在加载函数名和 PyCodeObject 对象入栈之前，一定先加载了一个元组入栈
    // 元组里面包含了内层函数 inner 使用的外层函数的变量
    // 当然这里的变量已经不再是普通的变量了，而是 cell 变量，它内部的 ob_ref 字段才是我们需要的
    if (oparg &amp; 0x08) {
        assert(PyTuple_CheckExact(TOP()));
        func -&gt;func_closure = POP();
    }
    if (oparg &amp; 0x04) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_annotations = POP();
    }
    if (oparg &amp; 0x02) {
        assert(PyDict_CheckExact(TOP()));
        func-&gt;func_kwdefaults = POP();
    }
    if (oparg &amp; 0x01) {
        assert(PyTuple_CheckExact(TOP()));
        func-&gt;func_defaults = POP();
    }

    PUSH((PyObject *)func);
    DISPATCH();
}
</code></pre>
<p>所以 PyFunctionObject 再一次承担了工具人的角色，创建内层函数 inner 时，会将包含 cell 变量的元组赋值给 func_closure 字段。此时便将内层函数需要使用的变量和内层函数绑定在了一起，而这个绑定的结果我们就称之为闭包。</p>
<p>但是从结构上来看，闭包仍是一个函数，所谓绑定，其实只是修改了它的 func_closure 字段。当内层函数创建完毕后，当前栈桢的 f_localsplus 布局如下。</p>
<p><img src="./images/223.png" alt="" /></p>
<p>函数即变量，对于函数 some_func 而言，内层函数 inner 也是一个局部变量，由于符号 inner 位于符号表中索引为 1 的位置。因此当函数对象创建完毕时，会修改 f_localsplus[1]，让它保存函数对象的地址。不难发现，对于局部变量来说，如何访问内存在编译阶段就确定了。</p>
<p>然后是内层函数 inner，它内部的 func_closure 字段指向一个元组，元组里面的每个元素会指向 PyCellObject。</p>
<h2 id="调用闭包"><a class="header" href="#调用闭包">调用闭包</a></h2>
<p>闭包的创建过程我们已经了解了，下面用 Python 代码再解释一下。</p>
<pre><code class="language-Python">def some_func():
    name = &quot;satori&quot;
    age = 17
    gender = &quot;female&quot;
    def inner():
        print(name, age)
        
    return inner

func = some_func()
# some_func 调用之后会返回内层函数 inner
# 只不过 inner 的 func_closure 字段保存了 cell 变量
# 而 cell 变量指向的 PyCellObject 对外层作用域的局部变量进行了冻结
# 所以我们也会称呼 inner 函数为闭包，但要知道闭包仍然是个函数
print(func.__name__)  # inner
print(func.__class__)  # &lt;class 'function'&gt;

print(
    func.__closure__[0]
)  # &lt;cell at 0x7f9f445b2c70: int object at 0x7f9f44e693c0&gt;
print(
    func.__closure__[1]
)  # &lt;cell at 0x7f9f446d4f10: str object at 0x7f9f445a20b0&gt;

print(func.__closure__[0].cell_contents)  # 17
print(func.__closure__[1].cell_contents)  # satori

# 同理我们也可以修改
func.__closure__[0].cell_contents = 16
func.__closure__[1].cell_contents = &quot;koishi&quot;
print(func.__closure__[0].cell_contents)  # 16
print(func.__closure__[1].cell_contents)  # koishi
</code></pre>
<p>调用 inner 函数时，外层函数 some_func 已经执行结束，但它的局部变量 name 和 age 仍可被内层函数 inner 访问，背后的原因我们算是彻底明白了。因为 name 和 age 被内层函数引用了，所以虚拟机将它们封装成了 PyCellObject *，即 cell 变量，而 cell 变量指向的 cell 对象内部的 ob_ref 字段对应原来的变量。当创建内层函数时，会将引用的 cell 变量组成元组，保存在内层函数的 func_closure 字段中。</p>
<p>所以当内层函数在访问 name 和 age 时，访问的其实是 PyCellObject 的 ob_ref 字段，至于变量 name 和 age 分别对应哪一个 PyCellObject，这些在编译阶段便确定了，同样是基于索引访问的。</p>
<p>由于 inner 函数属于内层函数，所以调用时会走通用通道（当然外层函数也是如此），在里面会对闭包做一些处理。</p>
<pre><code class="language-C">PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,
           PyObject *const *kwnames, PyObject *const *kwargs,
           Py_ssize_t kwcount, int kwstep,
           PyObject *const *defs, Py_ssize_t defcount,
           PyObject *kwdefs, PyObject *closure,
           PyObject *name, PyObject *qualname)
{
    // ...
    
    // 在执行外层函数 some_func 时，创建变量 name 和 age 使用的是 STORE_DEREF 指令
    // 该指令内部会操作 PyCellObject，那么问题来了，PyCellObject 所需的内存是什么时候申请的呢
    // 显然就是在这里，由于编译时已经知道了 cell 变量的个数，所以会提前申请内存
    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_cellvars); ++i) {
        PyObject *c;
        Py_ssize_t arg;
        if (co-&gt;co_cell2arg != NULL &amp;&amp;
            (arg = co-&gt;co_cell2arg[i]) != CO_CELL_NOT_AN_ARG) {
            c = PyCell_New(GETLOCAL(arg));
            SETLOCAL(arg, NULL);
        }
        else {
            // 创建一个 PyCellObject，内部 ob_ref 字段的值为 NULL
            // 所以如果是局部变量在未完成赋值时，它在 f_localsplus 中的值就是 NULL
            // 而如果是 cell 变量，不管有没有完成赋值，它在 f_localsplus 中的值都是 PyCellObject *
            // 只不过在没完成赋值时，PyCellObject 的 ob_ref 字段会是 NULL
            // 而等到完成赋值时，PyCellObject 的 ob_ref 字段会指向具体的值
            c = PyCell_New(NULL);
        }
        if (c == NULL)
            goto fail;
        // 原本 f_localsplus 中的值全部为 NULL，但那些被内层函数引用的变量，成为了 cell 变量
        // 所以要将它在 f_localsplus 中的值，从 NULL 替换成 PyCellObject *
        // 而 cell 变量位于局部变量之后，所以从 co_nlocals 开始设置
        SETLOCAL(co-&gt;co_nlocals + i, c);
    }
    
    // co_cellvars 针对的是外层函数，co_freevars 针对的是内层函数
    // 所以外层函数 some_func 的 co_cellvars 为 2，co_freevars 为 0
    // 内层函数 inner 的 co_cellvars 为 0，co_freevars 为 2
    // 因此在调用外层函数 some_func 时，会进入上面的 for 循环，而下面的 for 循环则不会进入
    // 在调用内层函数 inner 时，会进入下面的 for 循环，而上面的 for 循环则不会进入
    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_freevars); ++i) {
        // 而针对内层函数的这层 for 循环所做的事情也很简单
        // 首先获取元组 closure 里面的 cell 变量
        PyObject *o = PyTuple_GET_ITEM(closure, i);
        Py_INCREF(o);
        // 拷贝到 f_localsplus 的第三段内存，即位于 cell 变量之后的内存
        freevars[PyTuple_GET_SIZE(co-&gt;co_cellvars) + i] = o;
    }
}    
</code></pre>
<p>总结：外层函数在执行时，会将那些被内层函数引用的变量变成 cell 变量，然后放在 f_localsplus 的第二段内存中，注意：此时的 f_localsplus 是外层函数的 f_localsplus。然后在构建内层函数时，会将 cell 变量打包成一个元组，交给内层函数的 func_closure 字段。</p>
<p>等执行内层函数创建栈帧的时候，再将 func_closure 字段中的 cell 变量拷贝到 f_localsplus 的第三段内存中，成为 free 变量。当然不管是 cell 变量还是 free 变量，它指向的都是 PyCellObject。只不过对于外层函数而言，它位于 f_localsplus 的第二段内存，所以叫 cell 变量；对于内层函数而言，它位于 f_localsplus 的第三段内存，所以叫 free 变量。</p>
<p>处理完之后，内层函数 inner 的 f_localsplus 的布局如下：</p>
<p><img src="./images/224.png" alt="" /></p>
<p>我们看一下内层函数 inner 的字节码指令。</p>
<p><img src="./images/225.png" alt="" /></p>
<p>对于内层函数 inner 来说，显然关键就在于 LOAD_DEREF，它和 LOAD_NAME、LOAD_FAST、LOAD_GLOBAL 一样，都是加载变量的值，只是加载方式不同，我们看一下该指令。</p>
<pre><code class="language-C">case TARGET(LOAD_DEREF): {
    // 加载 PyCellObject *
    PyObject *cell = freevars[oparg];
    // 获取 PyCellObject 对象的 ob_ref 字段的值
    PyObject *value = PyCell_GET(cell);
    if (value == NULL) {
        format_exc_unbound(tstate, co, oparg);
        goto error;
    }
    Py_INCREF(value);
    PUSH(value);
    DISPATCH();
}
</code></pre>
<p>STORE_DEREF 是设置 PyCellObject 的 ob_ref，那么 LOAD_DEREF 自然就是获取 PyCellObject 的 ob_ref。</p>
<p>另外再补充一点，我们说 f_localsplus 是一个连续的数组，只是按照用途被划分成了四个区域：保存局部变量的内存空间、保存 cell 变量的内存空间、保存 free 变量的内存空间、运行时栈。但对于当前的内层函数 inner 来说，它是没有局部变量和 cell 变量的，所以 f_localsplus 开始的位置便是 free 区域。</p>
<p>当然不管是局部变量、cell 变量，还是 free 变量，它们都按照顺序保存在 f_localsplus 中，并且在编译阶段便知道它们在 f_localsplus 中的位置。比如我们将内层函数 inner 的逻辑修改一下。</p>
<pre><code class="language-Python">def some_func():
    name = &quot;satori&quot;
    age = 17
    gender = &quot;female&quot;
    def inner():
        a, b, c = 1, 2, 3
        print(a, b, c, name, age)
    return inner
</code></pre>
<p>在 inner 里面创建了三个局部变量，那么它的字节码会变成什么样子呢？这里我们直接看 print 函数执行时的字节码即可。</p>
<p><img src="./images/226.png" alt="" /></p>
<p>因为 inner 里面没有函数了，所以它不存在 cell 变量，里面只有局部变量和 free 变量。</p>
<p><img src="./images/227.png" alt="" /></p>
<p>所以虽然我们说 f_localsplus 被分成了四份，但是 cell 区域和 free 区域很少会同时存在。对于外层函数 some_func 来说，它没有 free 变量，所以 free 区域长度为 0。而对于内层函数 inner 来说，它没有 cell 变量，所以 cell 区域长度为 0。只有函数的里面存在内层函数，并且外面存在外层函数，那么它才有可能同时包含 cell 变量和 free 变量。</p>
<p>但为了方便描述，我们仍然认为 f_localsplus 被分成了四个区域，只不过对于外层函数 some_func 而言，它的 free 区域长度为 0；对于内层函数 inner 而言，它的 cell 区域长度为 0。</p>
<p>当然这些都是概念上的东西，大家理解就好。但不管在概念上 f_localsplus  怎么划分，它本质上就是一个 C 数组，是一段连续的内存，用于存储局部变量、cell 变量、free 变量（这三种变量不一定同时存在），以及作为运行时栈。最重要的是，这三种变量都是基于数组实现的静态访问，并且怎么访问在编译阶段就已经确定，因为访问数组的索引会作为指令参数存储在字节码指令集中。</p>
<ul>
<li>比如访问变量 a，底层会访问 <code>f_localsplus[0]</code>；</li>
<li>比如访问变量 age，底层会访问 <code>f_localsplus[3]-&gt;ob_ref</code>；</li>
</ul>
<p>这便是静态访问。</p>
<h2 id="装饰器"><a class="header" href="#装饰器">装饰器</a></h2>
<p>装饰器是 Python 的一个亮点，但并不神秘，因为它本质上就是高阶函数加上闭包，只不过给我们提供了一个优雅的语法糖。至于为什么要有装饰器，我觉得有句话说的非常好，装饰器存在的最大意义就是可以在不改动原函数的代码和调用方式的情况下，为函数增加一些新的功能。</p>
<pre><code class="language-Python">def deco(func):
    print(&quot;都闪开，我要开始装饰了&quot;)

    def inner(*args, **kwargs):
        print(&quot;开始了&quot;)
        ret = func(*args, **kwargs)
        print(&quot;结束&quot;)
        return ret

    return inner

# 这一步等价于 foo = deco(foo)
# 因此上来就会打印 deco 里面的 print
@deco
def foo(a, b):
    print(f&quot;a = {a}，b = {b}&quot;)
print(&quot;---------&quot;)
&quot;&quot;&quot;
都闪开，我要开始装饰了
---------
&quot;&quot;&quot;

# 此时再调用 foo，已经不再是原来的 foo 了
# 而是 deco 里面的闭包 inner
foo(1, 2)
&quot;&quot;&quot;
开始了
a = 1，b = 2
结束
&quot;&quot;&quot;
</code></pre>
<p>如果不使用装饰器的话：</p>
<pre><code class="language-Python">def deco(func):
    print(&quot;都闪开，我要开始装饰了&quot;)

    def inner(*args, **kwargs):
        print(&quot;开始了&quot;)
        ret = func(*args, **kwargs)
        print(&quot;结束&quot;)
        return ret

    return inner

def foo(a, b):
    print(f&quot;a = {a}，b = {b}&quot;)

foo = deco(foo)
&quot;&quot;&quot;
都闪开，我要开始装饰了
&quot;&quot;&quot;
foo(1, 2)
&quot;&quot;&quot;
开始了
a = 1，b = 2
结束
&quot;&quot;&quot;
</code></pre>
<p>打印结果告诉我们，装饰器只是类似于 foo=deco(foo) 的一个语法糖罢了。</p>
<p>至于字节码这里就不看了，还是那句话，<strong>@</strong> 只是个语法糖，它和我们直接调用 foo=deco(foo) 是等价的，所以理解装饰器（decorator）的关键就在于理解闭包（closure）。</p>
<p>另外函数在被装饰器装饰之后，整个函数其实就已经变了，而为了保留原始信息我们一般会从 functools 模块中导入一个 wraps 函数。当然装饰器还可以写的更复杂，比如带参数的装饰器、类装饰器等等，不过这些都属于 Python 层级的东西了，我们就不说了。</p>
<p>另外装饰器还可以不止一个，如果一个函数被多个装饰器装饰，会有什么表现呢？</p>
<pre><code class="language-Python">def deco1(func):
    def inner():
        return f&quot;&lt;deco1&gt;{func()}&lt;/deco1&gt;&quot;
    return inner

def deco2(func):
    def inner():
        return f&quot;&lt;deco2&gt;{func()}&lt;/deco2&gt;&quot;
    return inner

def deco3(func):
    def inner():
        return f&quot;&lt;deco3&gt;{func()}&lt;/deco3&gt;&quot;
    return inner

@deco1
@deco2
@deco3
def foo():
    return &quot;古明地觉&quot;

print(foo())
</code></pre>
<p>解释器还是从上到下解释，当执行到 @deco1 的时候，肯定要装饰了，但它下面不是函数，也是一个装饰器，于是表示：要不哥们，你先装饰。然后执行 @deco2，但它下面还是一个装饰器，于是重复了刚才的话，把皮球踢给 @deco3。当执行 @deco3 的时候，发现下面终于是一个普通的函数了，于是装饰了。</p>
<p>deco3 装饰完毕之后，<font color="blue">foo = deco3(foo)</font>。然后 deco2 发现 deco3 已经装饰完毕，那么会对 deco3 装饰的结果再进行装饰，此时 <font color="blue">foo = deco2(deco3(foo))</font>；同理，再经过 deco1 的装饰，最终得到了 <font color="blue">foo = deco1(deco2(deco3(foo)))</font>。</p>
<p>于是最终输出：</p>
<blockquote>
<p>&lt;deco1&gt;&lt;deco2&gt;&lt;deco3&gt;古明地觉&lt;/deco3&gt;&lt;/deco2&gt;&lt;/deco1&gt;</p>
</blockquote>
<p>所以当有多个装饰器的时候，会从下往上装饰；然后执行的时候，会从上往下执行。</p>
<h2 id="小结-57"><a class="header" href="#小结-57">小结</a></h2>
<p>本篇文章我们就介绍了闭包，比想象中的要更加简单。因为闭包仍是一个函数，只是将外层作用域的局部变量变成了 cell 变量，然后保存在内部的 func_closure 字段中。</p>
<p>然后执行内层函数的时候，再将 func_closure 里的 PyCellObject * 拷贝到 f_localsplus 的 free 区域，此时我们叫它 free 变量。但不管什么变量，虚拟机在编译时便知道应该如何访问指定的内存。</p>
<p>当然还有装饰器，它本质上就是一个语法糖，理解装饰器的关键就在于理解闭包。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-58"><a class="header" href="#楔子-58">楔子</a></h2>
<p>下面来聊一聊 Python 的生成器，它是我们后续理解协程的基础。生成器的话，估计大部分人在写程序的时候都不怎么用，但其实生成器一旦用好了，确实能给程序带来性能上的提升，那么下面就来看一看吧。</p>
<h2 id="生成器的基础知识"><a class="header" href="#生成器的基础知识">生成器的基础知识</a></h2>
<p>我们知道，如果函数的内部出现了 yield 关键字，那么它就不再是普通的函数了，而是一个生成器函数，调用之后会返回一个生成器对象。比如：我们读取一个大文件。</p>
<pre><code class="language-python">def read_file(file):
    return open(file, encoding=&quot;utf-8&quot;).readlines()

print(read_file(&quot;假装是大文件.txt&quot;))
&quot;&quot;&quot;
['人生是什么?\n', '大概是闪闪发光的同时\n', '又让人感到痛苦的东西吧']
&quot;&quot;&quot;
</code></pre>
<p>当前版本的 read_file 函数，将文件内容全部读取出来了，并返回一个列表。在文件不大的情况下，这种做法没有任何问题，但如果文件大小高达几百 GB，那么这种做法就不合适了。于是我们可以通过 yield 关键字，将普通函数变成一个生成器函数。</p>
<pre><code class="language-python">from typing import Iterator, Generator

def read_file(file):
    with open(file, encoding=&quot;utf-8&quot;) as f:
        for line in f:
            yield line

data = read_file(&quot;假装是大文件.txt&quot;)
# 返回一个生成器对象
print(data)
&quot;&quot;&quot;
&lt;generator object read_file at 0x0000019B4FA8BAC0&gt;
&quot;&quot;&quot;

# 使用 for 循环遍历
for line in data:
    # 文件每一行自带换行符，所以这里的 print 就不用换行符了
    print(line, end=&quot;&quot;)
&quot;&quot;&quot;
人生是什么?
大概是闪闪发光的同时
又让人感到痛苦的东西吧
&quot;&quot;&quot;
</code></pre>
<p>由于生成器是一种特殊的迭代器，所以也可以使用它的 __next__ 方法。</p>
<pre><code class="language-python">def gen():
    yield 123
    yield 456
    yield 789
    return &quot;result&quot;

# 调用生成器函数时，会创建一个生成器
# 生成器虽然创建了，但是里面的代码并没有执行
g = gen()

# 调用 __next__ 方法时才会执行
# 当遇到 yield，会将生成器暂停、并返回 yield 后面的值
print(g.__next__())  # 123

# 此时生成器处于暂停状态，如果我们不驱动它的话，它是不会前进的
# 再次执行 __next__，生成器恢复执行，并在下一个 yield 处暂停
print(g.__next__())  # 456

# 生成器会记住自己的执行进度，它总是在遇到 yield 时暂停
# 调用 __next__ 时恢复执行，直到遇见下一个 yield
print(g.__next__())  # 789

# 显然再调用 __next__ 时，已经找不到下一个 yield 了
# 那么生成器会抛出 StopIteration，并将返回值设置在里面
try:
    g.__next__()
except StopIteration as e:
    print(f&quot;返回值：{e.value}&quot;)  # 返回值：result
</code></pre>
<p>可以看到，基于生成器，我们能够实现惰性求值。当然啦，生成器不仅仅有 __next__ 方法，它还有 send 和 throw 方法，我们先来说一说 send。</p>
<pre><code class="language-python">def gen():
    res1 = yield &quot;yield 1&quot;
    print(f&quot;***** {res1} *****&quot;)
    res2 = yield &quot;yield 2&quot;
    return res2

g = gen()
# 此时程序在第一个 yield 处暂停
print(g.__next__())
&quot;&quot;&quot;
yield 1
&quot;&quot;&quot;

# 调用 g.send(val) 依旧可以驱动生成器执行
# 同时还可以传递一个值，交给第一个 yield 左边的 res1
# 然后寻找第二个 yield
print(g.send(&quot;嘿嘿&quot;))
&quot;&quot;&quot;
***** 嘿嘿 *****
yield 2
&quot;&quot;&quot;
# 上面输出了两行，第一行是生成器里面的 print 打印的

try:
    # 此时生成器在第二个 yield 处暂停，调用 g.send 驱动执行
    # 同时传递一个值交给第二个 yield 左边的 res2，然后寻找第三个 yield
    # 但是生成器里面没有第三个 yield 了，于是抛出 StopIteration
    g.send(&quot;蛤蛤&quot;)
except StopIteration as e:
    print(f&quot;返回值：{e.value}&quot;)
&quot;&quot;&quot;
返回值：蛤蛤
&quot;&quot;&quot;
</code></pre>
<p>生成器永远在 yield 处暂停，并将 yield 后面的值返回。如果想驱动生成器继续执行，可以调用 __next__ 或 send，会去寻找下一个 yield，然后在下一个 yield 处暂停。依次往复，直到找不到 yield 时，抛出 StopIteration，并将返回值包在里面。</p>
<p>但是这两者的不同之处在于，send 可以接收参数，假设生成器在 <font color="blue">res = yield 123</font> 这里停下来了。当调用 __next__ 和 send 的时候，都可以驱动执行，但调用 send 时可以传递一个 value，并将 value 赋值给变量 res。而 __next__ 没有这个功能，如果是调用 __next__ 的话，那么 res 得到的就是一个 None。</p>
<p>所以 res = yield 123 这一行语句需要两次驱动生成器才能完成，第一次驱动会让生成器执行到 yield 123，然后暂停执行，将 123 返回。第二次驱动才会给变量 res 赋值，此时会寻找下一个 yield 然后暂停。</p>
<h3 id="生成器的预激"><a class="header" href="#生成器的预激">生成器的预激</a></h3>
<p>刚创建生成器的时候，里面的代码还没有执行，它的 f_lasti 是 -1。还记得这个 f_lasti 吗？它表示最近一条执行完毕的字节码指令的偏移量。</p>
<pre><code class="language-python">def gen():
    res1 = yield 123
    res2 = yield 456
    return &quot;result&quot;

g = gen()
# 生成器函数和普通函数一样，执行时也会创建栈帧
# 通过 g.gi_frame 可以很方便的获取
print(g.gi_frame.f_lasti)  # -1
</code></pre>
<p>f_lasti 是 -1，表示生成器刚被创建，还没有执行任何指令。而第一次驱动生成器执行，叫做生成器的预激。但在生成器还没有被预激时，我们调用 send，里面只能传递一个 None，否则报错。</p>
<pre><code class="language-python">def gen():
    res1 = yield 123
    res2 = yield 456
    return &quot;result&quot;

g = gen()
try:
    g.send(&quot;小云同学&quot;)
except TypeError as e:
    print(e)
&quot;&quot;&quot;
can't send non-None value to a just-started generator
&quot;&quot;&quot;
</code></pre>
<p>对于尚未被预激的生成器，我们只能传递一个 None，也就是 g.send(None)。或者调用 g.__next__()，因为不管何时它传递的都是 None。其实也很好理解，我们之所以传值是为了赋给 yield 左边的变量，这就意味着生成器必须至少被驱动一次、在某个 yield 处停下来才可以。而未被预激的生成器，它里面的代码压根就没有执行，所以第一次驱动的时候只能传递一个 None 进去。</p>
<p>如果查看生成器的源代码的话，也能证明这一点：</p>
<p><img src="./images/228.png" alt="" /></p>
<p>源码中的 arg 就是驱动生成器执行时传递的值，如果它不为 None，那么报错。</p>
<h3 id="生成器的-throw-方法"><a class="header" href="#生成器的-throw-方法">生成器的 throw 方法</a></h3>
<p>除了 __next__ 和 send 方法之外，生成器还有一个 throw 方法，该方法的作用和前两者类似，也是驱动生成器执行，并在下一个 yield 处暂停。但它在调用的时候，需要传递一个异常进去。</p>
<pre><code class="language-python">def gen():
    try:
        yield 123
    except ValueError as e:
        print(f&quot;异常：{e}&quot;)
    yield 456
    return &quot;result&quot;

g = gen()
# 生成器在 yield 123 处暂停
g.__next__()
# 向生成器传递一个异常
# 如果当前生成器的暂停位置处无法捕获传递的异常，那么会将异常抛出来
# 如果能够捕获，那么会驱动生成器执行，并在下一个 yield 处暂停
# 当前生成器位于 yield 123 处，而它所在的位置能够捕获异常
# 所以不会报错，结果就是 456 会赋值给 val
val = g.throw(ValueError(&quot;一个 ValueError&quot;))
&quot;&quot;&quot;
异常：一个 ValueError
&quot;&quot;&quot;
print(val)
&quot;&quot;&quot;
456
&quot;&quot;&quot;
</code></pre>
<p>关于生成器的 __next__、send、throw 三个方法的用法我们就说完了，还是比较简单的。</p>
<h3 id="关闭生成器"><a class="header" href="#关闭生成器">关闭生成器</a></h3>
<p>生成器也是可以关闭的，我们来看一下。</p>
<pre><code class="language-python">def gen():
    yield 123
    yield 456
    return &quot;result&quot;

g = gen()
# 生成器在 yield 123 处停止
print(g.__next__())  # 123
# 关闭生成器
g.close()
# 生成器一旦关闭，就代表执行完毕了，它的栈帧会被重置为 None
print(g.gi_frame)  # None
try:
    # 再次调用 __next__，会抛出 StopIteration
    g.__next__()
except StopIteration as e:
    # 此时 e.value 为 None
    print(e.value)  # None
</code></pre>
<p>无论是显式地关闭生成器，还是正常情况下生成器执行完毕，内部的栈帧都会被重置为 None。而驱动一个已经执行结束的生成器，会抛出 StopIteration 异常，并且异常的 value 属性为 None。</p>
<h3 id="generatorexit-异常"><a class="header" href="#generatorexit-异常">GeneratorExit 异常</a></h3>
<p>这里再来说一说 GeneratorExit 异常，如果我们关闭一个生成器（或者生成器被删除时），那么会往里面扔一个 GeneratorExit 进去。</p>
<pre><code class="language-python">def gen():
    try:
        yield 123
    except GeneratorExit as e:
        print(&quot;生成器被删除了&quot;)

g = gen()
# 生成器在 yield 123 处暂停
g.__next__()
# 关闭生成器，会往里面扔一个 GeneratorExit
g.close()
&quot;&quot;&quot;
生成器被删除了
&quot;&quot;&quot;
</code></pre>
<p>这里我们捕获了传递的 GeneratorExit，所以 print 语句执行了，但如果没有捕获呢？</p>
<pre><code class="language-python">def gen():
    yield 123

g = gen()
g.__next__()
g.close()
</code></pre>
<p>此时无事发生，但是注意：如果是手动调用 throw 方法扔一个 GeneratorExit 进去，异常还是会抛出来的。</p>
<p>那么问题来了，生成器为什么要提供这样一种机制呢？直接删就完了，干嘛还要往生成器内部丢一个异常呢？答案是为了资源的清理和释放。在 Python 还未提供原生协程，以及 asyncio 还尚未流行起来的时候，很多开源的协程框架都是基于生成器实现的协程。而创建连接的逻辑，一般都会写在 yield 后面。</p>
<pre><code class="language-python">def _create_connection():
    # 一些逻辑
    yield conn
    # 一些逻辑
</code></pre>
<p>但是这些连接在不用的时候，要不要进行释放呢？答案是肯定的，所以便可以这么做。</p>
<pre><code class="language-python">def _create_connection():
    # 一些逻辑
    try: 
        yield conn
    except GeneratorExit:
        conn.close()
    # 一些逻辑
</code></pre>
<p>这样当我们关闭或删除生成器的时候，就能够自动对连接进行释放了。</p>
<p>不过还有一个需要注意的点，就是在捕获 GeneratorExit 之后，不可以再执行 yield，否则会抛出 RuntimeError。</p>
<pre><code class="language-python">def gen():
    try:
        yield 123
    except GeneratorExit:
        print(&quot;生成器被删除&quot;)
        yield

g = gen()
g.__next__()
g.close()
&quot;&quot;&quot;
生成器被删除
Traceback (most recent call last):
  File &quot;...&quot;, line 10, in &lt;module&gt;
    g.close()
RuntimeError: generator ignored GeneratorExit
&quot;&quot;&quot;
</code></pre>
<p>调用 close 方法时，如果没有成功捕获 GeneratorExit，那么生成器会直接关闭，不会有任何事情发生。但如果捕获了 GeneratorExit，那么可以在对应的语句块里做一些资源清理逻辑，但不应该再出现 yield。</p>
<p>而上面的例子中出现了 yield，所以解释器会抛出 RuntimeError，因为没捕获 GeneratorExit 还好，解释器不会有什么抱怨。但如果捕获了 GeneratorExit，说明我们知道生成器是被关闭了，既然知道，那里面还出现 yield 的意义何在呢？</p>
<p>当然啦，如果出现了 yield，但没有执行到，则不会抛 RuntimeError。</p>
<pre><code class="language-python">def gen():
    try:
        yield 123
    except GeneratorExit:
        print(&quot;生成器被删除&quot;)
        return
        yield

g = gen()
g.__next__()
g.close()
print(&quot;------------&quot;)
&quot;&quot;&quot;
生成器被删除
------------
&quot;&quot;&quot;
</code></pre>
<p>遇见 yield 之前就返回了，所以此时不会出现 RuntimeError。</p>
<blockquote>
<p>注意：GeneratorExit 继承自 BaseException，它无法被 Exception 捕获。</p>
</blockquote>
<h2 id="yield-from-的用法"><a class="header" href="#yield-from-的用法">yield from 的用法</a></h2>
<p>当函数内部出现了 yield 关键字，那么它就是一个生成器函数，对于 yield from 而言亦是如此。那么问题来了，这两者之间有什么区别呢？</p>
<pre><code class="language-python">from typing import Generator

def gen1():
    yield [1, 2, 3]

def gen2():
    yield from [1, 2, 3]

g1 = gen1()
g2 = gen2()
# 两者都是生成器
print(isinstance(g1, Generator))  # True
print(isinstance(g2, Generator))  # True

print(g1.__next__())  # [1, 2, 3]
print(g2.__next__())  # 1
</code></pre>
<p>结论很清晰，yield 对后面的值没有要求，会直接将其返回。而 yield from 后面必须跟一个可迭代对象（否则报错），然后每次返回可迭代对象的一个值。</p>
<pre><code class="language-python">def gen():
    yield from [1, 2, 3]
    return &quot;result&quot;

g = gen()
print(g.__next__())  # 1
print(g.__next__())  # 2
print(g.__next__())  # 3
try:
    g.__next__()
except StopIteration as e:
    print(e.value)  # result
</code></pre>
<p>除了要求必须跟一个可迭代对象，然后每次只返回一个值之外，其它表现和 yield 是类似的。而对于当前这个例子来说，<font color="blue">yield from [1, 2, 3]</font> 等价于 <font color="blue">for item in [1, 2, 3]: yield item</font>。</p>
<p>所以有人觉得 yield from 貌似没啥用啊，它完全可以用 for 循环加 yield 进行代替。很明显不是这样的，yield from 背后做了非常多的事情，我们稍后说。这里先出一道思考题：</p>
<p><img src="./images/229.png" alt="" /></p>
<p>这时候便可以通过 yield 和 yield from 来实现这一点。</p>
<pre><code class="language-python">def flatten(data):
    for item in data:
        if isinstance(item, list):
            yield from flatten(item)
        else:
            yield item


data = [1, [[[[[3, 3], 5]]], [[[[[[[[[[[[6]]]]], 8]]], &quot;aaa&quot;]]]], 250]]
print(list(flatten(data)))  # [1, 3, 3, 5, 6, 8, 'aaa', 250]
</code></pre>
<p>怎么样，是不是很简单呢？</p>
<h2 id="委托生成器"><a class="header" href="#委托生成器">委托生成器</a></h2>
<p>如果单从语法上来看的话，会发现 yield from 貌似没什么特殊的地方，但其实 yield from 还可以作为委托生成器。委托生成器会在调用方和子生成器之间建立一个双向通道，什么意思呢？我们举例说明。</p>
<pre><code class="language-python">def gen():
    yield 123
    yield 456
    return &quot;result&quot;

def middle():
    res = yield from gen()
    print(f&quot;接收到子生成器的返回值: {res}&quot;)

# middle 里面出现了 yield from gen()
# 此时 middle() 便是委托生成器，gen() 是子生成器
g = middle()

# 而 yield from 会在调用方和子生成器之间建立一个双向通道
# 两者是可以互通的，调用 g.send、g.throw 都会直接传递给子生成器
print(g.__next__())  # 123
print(g.__next__())  # 456

# 问题来了，如果再调用一次 __next__ 会有什么后果呢？
# 按照之前的理解，应该会抛出 StopIteration
print(g.__next__())
&quot;&quot;&quot;
接收到子生成器的返回值: result
Traceback (most recent call last):
  File &quot;...&quot;, line 21, in &lt;module&gt;
    print(g.__next__())
StopIteration
&quot;&quot;&quot;
</code></pre>
<p>在第三次调用 __next__ 的时候，确实抛了异常，但是委托生成器收到了子生成器的返回值。也就是说，委托生成器在调用方和子生成器之间建立了双向通道，两者是直接通信的，并且当子生成器出现 StopIteration 时，委托生成器还要负责兜底。</p>
<p>委托生成器会将子生成器抛出的 StopIteration 里面的 value 取出来，然后赋值给左侧的变量 res，并在自己内部继续寻找 yield。换句话说，当子生成器 return 之后，委托生成器会拿到返回值，并将子生成器抛出的异常给捕获掉。但是还没完，因为还要找到下一个 yield，那么从哪里找呢？显然是从委托生成器的内部寻找，于是接下来就变成了调用方和委托生成器之间的通信。</p>
<p>如果在委托生成器内部能找到下一个 yield，那么会将值返回给调用方。如果找不到，那么就重新构造一个 StopIteration，将异常抛出去。此时异常的 value 属性，就是委托生成器的返回值。</p>
<pre><code class="language-python">def gen():
    yield 123
    return &quot;result&quot;

def middle():
    res = yield from gen()
    return f&quot;委托生成器返回了子生成器的返回值：{res}&quot;

g = middle()
print(g.__next__())  # 123
try:
    g.__next__()
except StopIteration as e:
    print(e.value)  # 委托生成器返回了子生成器的返回值：result
</code></pre>
<p>大部分情况下，我们并不关注委托生成器的返回值，我们更关注的是子生成器。于是可以换种写法：</p>
<pre><code class="language-python">def gen():
    yield 123
    yield 456
    yield 789
    return &quot;result&quot;

def middle():
    yield (yield from gen())

g = middle()
for v in g:
    print(v)
&quot;&quot;&quot;
123
456
789
result
&quot;&quot;&quot;
</code></pre>
<p>所以委托生成器负责在调用方和子生成器之间建立一个双向通道，通道一旦建立，调用方可以和子生成器直接通信。虽然调用的是委托生成器的 __next__、send、throw 等方法，但影响的都是子生成器。</p>
<p>并且委托生成器还可以对子生成器抛出的 StopIteration 异常进行兜底，会捕获掉该异常，然后拿到返回值，这样就无需手动捕获子生成器的异常了。但问题是委托生成器还要找到下一个 yield，并将值返回给调用方，此时这个重担就落在了它自己头上。</p>
<p>如果找不到，还是要将异常抛出来的，只不过抛出的 StopIteration 是委托生成器构建的。而子生成器抛出的 StopIteration，早就被委托生成器捕获掉了。于是我们可以考虑在 yield from 的前面再加上一个 yield，这样就不会抛异常了。</p>
<h2 id="为什么要有委托生成器"><a class="header" href="#为什么要有委托生成器">为什么要有委托生成器</a></h2>
<p>我们上面已经了解了委托生成器的用法，不过问题来了，这玩意为啥会存在呢？上面的逻辑，即便不使用 yield from 也可以完成啊。</p>
<p>其实是因为我们上面的示例代码比较简单（为了演示用法），当需求比较复杂时，将生成器内部的部分操作委托给另一个生成器是有必要的，这也是委托生成器的由来。而委托生成器不仅要能保证调用方和子生成器之间直接通信，还要能够以一种优雅的方式获取子生成器的返回值，于是新的语法 yield from 就诞生了。</p>
<p>但其实 yield from 背后为我们做得事情还不止这么简单，它不单单是建立双向通道、获取子生成器的返回值，它还会处理子生成器内部出现的异常，详细内容可以查看 PEP380。</p>
<blockquote>
<p>https://peps.python.org/pep-0380/</p>
</blockquote>
<p>这里我们直接给出结论，并通过代码演示一下。</p>
<p><font color="darkblue"><strong>1）子生成器 yield 后面的值，会直接返回给调用方；调用方 send 发送的值，也会直接传给子生成器。</strong></font></p>
<pre><code class="language-python">def gen():
    res = yield 123
    yield [res]
    return &quot;result&quot;

def middle():
    yield (yield from gen())

g = middle()
# 子生成器 yield 后面的值，会直接返回给调用方
print(g.__next__())  # 123
# 调用方 send 发送的值，也会直接传给子生成器
print(g.send(&quot;小云同学&quot;))  # ['小云同学']
</code></pre>
<p>另外还要补充一个细节，如果 yield from 一个已经消耗完毕的生成器，会直接返回 None。</p>
<pre><code class="language-python">def gen():
    yield 123
    return &quot;result&quot;

def middle():
    sub = gen()
    res = yield from sub
    yield res + &quot; from gen()&quot;
    # 到这里的话，sub = gen() 这个生成器已经被消耗完毕了
    # 如果我们继续 yield from 的话，会直接返回 None
    res = yield from sub
    yield f&quot;res: {res}&quot;

g = middle()
print(g.__next__())  # 123
print(g.__next__())  # result from gen()
# 此处执行 g.__next__() 时
# 委托生成器内部会执行第二个 res = yield from sub
# 但问题是 sub 之前就已经被消耗完了，所以会直接返回 None，然后寻找下一个 yield
print(g.__next__())  # res: None
</code></pre>
<p>所以不要对生成器做二次消费。</p>
<p><font color="darkblue"><strong>2）子生成器结束时，最后的 return value 等价于 raise StopIteration(value)。然后该异常会被 yield from 捕获，并将 value 赋值给 yield from 左侧的变量。并且在拿到子生成器的返回值时，委托生成器会继续运行，寻找下一个 yield。</strong></font></p>
<pre><code class="language-python">def gen():
    yield 123
    return &quot;result&quot;

def middle():
    res = yield from gen()
    yield res + &quot; from middle()&quot;

g = middle()
print(g.__next__())  # 123
# 子生成器 gen() 在 return 时会抛出 StopIteration
# 然后在委托生成器内部被捕获，并将返回值赋给 res
# 接着继续寻找下一个 yield
print(g.__next__())  # result from middle()
</code></pre>
<p>另外补充一点，生成器在 return 时，等价于抛出一个 StopIteration。但异常必须在 return 的时候隐式抛出，如果是在生成器内部 raise StopIteration 则是不合法的。</p>
<pre><code class="language-python">def gen():
    yield 123
    raise StopIteration(&quot;result&quot;)

g = gen()
print(g.__next__())  # 123
print(g.__next__())
&quot;&quot;&quot;
Traceback (most recent call last):
  File &quot;......&quot;, line 3, in gen
    raise StopIteration(&quot;result&quot;)
StopIteration: result

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;......&quot;, line 7, in &lt;module&gt;
    print(g.__next__())
RuntimeError: generator raised StopIteration
&quot;&quot;&quot;
</code></pre>
<p>此时会引发一个 RuntimeError。</p>
<p><font color="darkblue"><strong>3）如果子生成器在执行的过程中，内部出现了异常，那么会将异常丢给委托生成器。委托生成器会尝试处理该异常，如果处理不了，那么再调用子生成器的 throw 方法将异常扔回去。</strong></font></p>
<pre><code class="language-python">def gen():
    yield 123
    raise ValueError(&quot;出了个错&quot;)
    return &quot;result&quot;

def middle():
    yield from gen()

g = middle()
print(g.__next__())  # 123
# 此时子生成器会抛出 ValueError，而委托生成器没有异常捕获逻辑，无法处理
# 于是会调用子生成器的 throw 方法，将异常重新扔回去，最终由调用方来处理
try:
    print(g.__next__())  # 123
except ValueError as e:
    print(e)  # 出了个错
</code></pre>
<p>那如果委托生成器可以处理子生成器抛出的异常呢？</p>
<pre><code class="language-python">def gen():
    yield 123
    raise ValueError(&quot;出了个错&quot;)
    return &quot;result&quot;

def middle():
    try:
        yield from gen()
    except ValueError as e:
        yield f&quot;异常：{e}&quot;
    # 当子生成器抛出异常时，它就已经结束了
    yield &quot;result from middle()&quot;

g = middle()
print(g.__next__())  # 123
print(g.__next__())  # 异常：出了个错
print(g.__next__())  # result from middle()
</code></pre>
<p>如果委托生成器可以处理子生成器抛出的异常，那么接下来就是调用方和委托生成器之间的事情了。再比如我们将生成器 close 掉，看看结果会怎样，我们知道它会 throw 一个 GeneratorExit。</p>
<pre><code class="language-python">def gen():
    yield 123
    return &quot;result&quot;

def middle():
    try:
        yield from gen()
    except GeneratorExit as e:
        print(f&quot;子生成器结束了&quot;)

g = middle()
print(g.__next__())  # 123
# 关闭子生成器，会 throw 一个 GeneratorExit
# 然后这个 GeneratorExit 会向上透传给委托生成器
g.close()
&quot;&quot;&quot;
子生成器结束了
&quot;&quot;&quot;
# 注意：委托生成器也是同理
# 一旦捕获了 GeneratorExit，后续不应该再出现 yield
</code></pre>
<p>yield from 算是 Python 里面特别难懂的一个语法了，但如果理解了 yield from，后续理解 await 就会简单很多。</p>
<h2 id="生成器表达式"><a class="header" href="#生成器表达式">生成器表达式</a></h2>
<p>Python 里面还有一个生成器表达式，我们来看一下。</p>
<pre><code class="language-python">from typing import Generator

g = (x for x in range(10))
print(isinstance(g, Generator))  # True
print(g)  # &lt;generator object &lt;genexpr&gt; at 0x...&gt;

print(g.__next__())  # 0
print(g.__next__())  # 1
</code></pre>
<p>如果表达式是在一个函数里面，那么生成器表达式周围的小括号可以省略掉。</p>
<pre><code class="language-python">import random

d = [random.randint(1, 10) for _ in range(100)]
# 我们想统计里面大于 5 的元素的总和
# 下面两种做法都是可以的
print(
    sum((x for x in d if x &gt; 5)),
    sum(x for x in d if x &gt; 5)
)  # 397 397
</code></pre>
<p>这两种做法是等价的，字节码完全一样。</p>
<p>但要注意，生成器表达式还存在一些陷阱，一不小心就可能踩进去。至于是什么陷阱呢？很简单，一句话：使用生成器表达式创建生成器的时候，in 后面的变量就已经确定了，但其它的变量则不会。举个栗子：</p>
<pre><code class="language-python">g = (巭孬嫑夯烎 for x in [1, 2, 3])
</code></pre>
<p>执行这段代码不会报错，尽管 for 前面那一坨没有定义，但不要紧，因为生成器是惰性执行的。可如果我们又调用了 g.__next__()，那么很明显就会报错了，会抛出 NameError。</p>
<pre><code>g = (x for x in lst)
</code></pre>
<p>但是这段代码会报错：NameError: name 'lst' is not defined，因为 in 后面的变量在创建生成器的时候就已经确定好了。而在创建生成器的时候，发现 lst 没有定义，于是抛出 NameError。</p>
<p>所以，陷阱就来了：</p>
<pre><code class="language-python">i = 1
g = (x + i for x in [1, 2, 3])
i = 10
# 输出的不是 (2, 3, 4)
print(tuple(g))  # (11, 12, 13)
</code></pre>
<p>因为生成器只有在执行的时候，才会去确定变量 i 究竟指向谁，而调用 tuple(g) 的时候 i 已经被修改了。</p>
<pre><code class="language-python">lst = [1, 2, 3]
g = (x for x in lst)
lst = [4, 5, 6]
print(tuple(g))  # (1, 2, 3)
</code></pre>
<p>但这里输出的又是 (1, 2, 3)，因为在创建生成器的时候，in 后面的变量就已经确定了，这里会和 lst 指向同一个列表。而第三行改变的只是变量 lst 的指向，和生成器无关。</p>
<pre><code class="language-python">g = (x for x in [1, 2, 3, 4])
for i in [1, 10]:
    g = (x + i for x in g)

print(tuple(g))
</code></pre>
<p>思考一下，上面这段代码会打印啥？来分析一下。</p>
<ul>
<li>初始的 g，可以看成是 (1, 2, 3, 4)，因为 in 后面是啥，在创建生成器的时候就确定了；</li>
<li>第一次循环之后，g 就相当于 (1+i, 2+i, 3+i, 4+i)；</li>
<li>第二次循环之后，g 就相当于 (1+i+i, 2+i+i, 3+i+i, 4+i+i)；</li>
</ul>
<p>而循环结束后，变量 i 会指向 10，所以打印结果就是 (21, 22, 23, 24)。</p>
<h2 id="生成器与协程"><a class="header" href="#生成器与协程">生成器与协程</a></h2>
<p>在 Python 还没有引入原生协程的时候，很多开源框架都是基于生成器模拟的协程，最经典的莫过于 Tornado。然而事实上，即便是原生协程，在底层也是基于生成器实现的。</p>
<pre><code class="language-python">async def native_coroutine():
    return &quot;古明地觉&quot;

try:
    native_coroutine().__await__().__next__()
except StopIteration as e:
    print(e.value)  # 古明地觉
</code></pre>
<p>这里没有创建事件循环，而是直接驱动协程执行。我们再演示一段代码，看看让生成器协程和原生协程混合使用会是什么效果。</p>
<pre><code class="language-python">import asyncio
import time
import types

async def some_task():
    &quot;&quot;&quot;
    某个耗时较长的任务
    &quot;&quot;&quot;
    await asyncio.sleep(3)
    return &quot;task result&quot;

async def native_coroutine():
    &quot;&quot;&quot;
    原生协程
    &quot;&quot;&quot;
    result = await some_task()
    return f&quot;{result} from native coroutine&quot;

@types.coroutine  # 或者使用 @asyncio.coroutine
def generator_coroutine():
    &quot;&quot;&quot;
    生成器模拟的协程
    &quot;&quot;&quot;
    result = yield from some_task()
    return f&quot;{result} from generator coroutine&quot;

async def main():
    start = time.time()
    result = await asyncio.gather(
        native_coroutine(), generator_coroutine()
    )
    end = time.time()
    print(result)
    print(f&quot;耗时：{end - start}&quot;)

asyncio.run(main())
&quot;&quot;&quot;
['task result from native coroutine', 'task result from generator coroutine']
耗时：3.0016210079193115
&quot;&quot;&quot;
</code></pre>
<p>从效果上来看，两种方式是等价的。yield from 会驱动协程对象执行，当协程执行 return 的时候，会抛出一个 StopIteration 异常。然后 yield from 再将异常捕获掉，并取出里面的返回值。</p>
<p>但使用装饰器 + yield from 这种方式不够优雅，并且 yield from 即用于生成器，又用于协程，容易给人造成困惑。为此 Python 从 3.5 开始引入了原生协程，使用 async def 定义协程，使用 await 驱动协程执行。</p>
<p>关于协程的更多细节，后续在介绍协程的时候再说，总之我们现在应该使用原生协程，至于 yield from 就让它留在历史的尘埃中吧，我们只需要知道整个演进过程即可。</p>
<h2 id="小结-58"><a class="header" href="#小结-58">小结</a></h2>
<p>以上我们就从 Python 的角度梳理了一遍生成器相关的知识，下一篇文章我们将从源码的角度来分析生成器的具体实现。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-59"><a class="header" href="#楔子-59">楔子</a></h2>
<p>上一篇文章我们介绍了生成器的基本概念和相关用法，如果一个函数内部出现了 yield 关键字，那么它就是生成器函数，调用之后会返回生成器。生成器可以通过 yield 关键字暂停执行，并且还可以通过 __next__ 方法从上一次暂停的位置重新恢复执行。</p>
<p>关于普通函数和生成器函数，我们举一个生动的例子。</p>
<p>普通函数可以想象成一匹马，只要调用了，那么不把里面的代码执行完毕誓不罢休，而函数内部的 return xxx，就是调用之后的返回值。</p>
<p>生成器函数则好比一头驴，调用的时候并没有动，只是返回一个生成器对象，然后需要每次拿鞭子抽一下（调用一次 __next__），才往前走一步。通过不断地驱动生成器，最终将里面的代码执行完毕，然后将设置了返回值的 StopIteration 抛出来。</p>
<p>另外我们也可以把生成器看成是可以暂停的函数，其中 yield 就类似于 return，只不过可以有多个 yield。当执行到一个 yield 时，将值返回、同时暂停在此处。然后当调用 __next__ 驱动时，从暂停的地方继续执行，直到找到下一个 yield。如果找不到下一个 yield，就会抛出 StopIteration 异常。</p>
<pre><code class="language-python">def gen():
    print(&quot;生成器开始执行了&quot;)

    name = &quot;古明地觉&quot;
    print(&quot;创建了一个局部变量 name&quot;)
    yield name
    
    age = 16
    print(&quot;创建了一个局部变量age&quot;)
    yield age

    gender = &quot;female&quot;
    print(&quot;创建了一个局部变量gender&quot;)
    yield gender


# 生成器函数也是一个函数
print(gen)  # &lt;function gen at 0x7f31171ac550&gt;
print(type(gen))  # &lt;class 'function'&gt;

# 调用生成器函数并不会立刻执行，而是会返回一个生成器对象
g = gen()
print(g)  # &lt;generator object gen at 0x7f31170b0740&gt;
print(g.__class__)  # &lt;class 'generator'&gt;
</code></pre>
<p>那么本次就来看看生成器底层是怎么实现的？</p>
<h2 id="生成器函数的创建"><a class="header" href="#生成器函数的创建">生成器函数的创建</a></h2>
<p>调用生成器函数会返回生成器，那么我们就要先看看生成器函数是如何构建的，它和普通函数有什么区别？</p>
<pre><code class="language-python">import dis

code_string = &quot;&quot;&quot;
def gen():
    yield 123
&quot;&quot;&quot;

dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
</code></pre>
<p>看一下字节码指令：</p>
<pre><code class="language-c">  0 LOAD_CONST               0 (&lt;code object gen at 0x7f3...&gt;)
  2 LOAD_CONST               1 ('gen')
  4 MAKE_FUNCTION            0
  6 STORE_NAME               0 (gen)
  8 LOAD_CONST               2 (None)
 10 RETURN_VALUE

Disassembly of &lt;code object gen at 0x7f3...&gt;:
 0 LOAD_CONST               1 (123)
 2 YIELD_VALUE
 4 POP_TOP
 6 LOAD_CONST               0 (None)
 8 RETURN_VALUE
&gt;&gt;&gt; 
</code></pre>
<p>字节码指令依旧分为两部分，这里我们只看模块对应的字节码指令。可以发现，构建生成器函数时的指令和构建普通函数是一模一样的，原因也很好解释，因为生成器函数也是函数。当然啦，还有协程函数、异步生成器函数，它们在构建时的字节码指令都是一样的，因为它们都是函数，类型都是 &lt;class 'function'&gt;。</p>
<p>然后调用生成器函数，返回生成器对象；调用协程函数，返回协程对象；调用异步生成器函数，返回异步生成器对象；调用普通函数，会立刻执行内部代码，返回的就是函数的返回值。</p>
<p>那么问题来了，既然它们都是函数，那虚拟机在调用时是如何区分彼此的呢？毕竟返回的对象不同。还记得 PyCodeObject 的 co_flags 吗？它除了可以判断一个函数是否定义了 *args、**kwargs，更重要的是它还可以判断函数的类型。</p>
<pre><code class="language-python">def gen():
    yield

# 生成器函数，co_flags &amp; 0x20 为真
# 调用会得到生成器，而生成器的类型是 &lt;class 'generator'&gt;
print(gen.__code__.co_flags &amp; 0x20)  # 32


async def coro():
    return
  
# 协程函数，co_flags &amp; 0x80 为真
# 调用会得到协程，而协程的类型是 &lt;class 'coroutine'&gt;
print(coro.__code__.co_flags &amp; 0x80)  # 128


async def async_gen():
    yield
    
# 异步生成器函数，co_flags &amp; 0x200 为真
# 调用会得到异步生成器，而异步生成器的类型是 &lt;class 'async_generator'&gt;
print(async_gen.__code__.co_flags &amp; 0x200)  # 512
</code></pre>
<p>这些都是在语法解析的时候确定的，当编译器看到一个函数里面出现了 yield，那么它就知道这是生成器函数。于是创建 PyCodeObject 的时候，会设置 co_flags，让它 <font color="blue">&amp; 0x20</font> 为真。</p>
<pre><code class="language-C">//Include/code.h

#define CO_OPTIMIZED    0x0001
#define CO_NEWLOCALS    0x0002
#define CO_VARARGS      0x0004
#define CO_VARKEYWORDS  0x0008
#define CO_NESTED       0x0010
#define CO_GENERATOR    0x0020
</code></pre>
<p>我们看到 CO_GENERATOR 的值为 0x20，如果想判断一个函数是否是生成器函数，那么就可以通过 co_flags &amp; 0x20 是否为真来判断。</p>
<p>当生成器函数创建完毕后就要调用了，会得到一个生成器。还记得函数的调用流程吗？</p>
<p><img src="./images/230.png" alt="" /></p>
<p>由于这是一个生成器函数，因此调用时不会进入快速通道，而是会进入通用通道。</p>
<pre><code class="language-C">PyObject *
_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,
           PyObject *const *args, Py_ssize_t argcount,
           PyObject *const *kwnames, PyObject *const *kwargs,
           Py_ssize_t kwcount, int kwstep,
           PyObject *const *defs, Py_ssize_t defcount,
           PyObject *kwdefs, PyObject *closure,
           PyObject *name, PyObject *qualname)
{
    // ...
    // 根据 co_flags 检测函数的种类，如果是生成器函数、协程函数、异步生成器函数三者之一
    if (co-&gt;co_flags &amp; (CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR)) {
        PyObject *gen;
        int is_coro = co-&gt;co_flags &amp; CO_COROUTINE;
        Py_CLEAR(f-&gt;f_back);
        if (is_coro) {
            // 如果是协程函数，创建协程
            gen = PyCoro_New(f, name, qualname);
        } else if (co-&gt;co_flags &amp; CO_ASYNC_GENERATOR) {
            // 如果是异步生成器函数，创建异步生成器
            gen = PyAsyncGen_New(f, name, qualname);
        } else {
            // 否则说明是生成器函数，那么创建生成器
            gen = PyGen_NewWithQualName(f, name, qualname);
        }
        if (gen == NULL) {
            return NULL;
        }
        // 被 GC 跟踪
        _PyObject_GC_TRACK(f);
        // 返回
        return gen;
    }
    // ...
}
</code></pre>
<p>在编译时将函数种类体现在 co_flags 中，调用时再根据 co_flags 创建不同的对象。</p>
<h2 id="生成器的底层结构"><a class="header" href="#生成器的底层结构">生成器的底层结构</a></h2>
<p>通过源码我们得知，生成器对象是通过调用 PyGen_NewWithQualName 创建的，不过在看这个函数之前，我们先看一下生成器的底层结构。</p>
<pre><code class="language-C">// Include/genobject.h

#define _PyGenObject_HEAD(prefix)                                           \
    PyObject_HEAD                                                           \
    struct _frame *prefix##_frame;                                          \
    char prefix##_running;                                                  \
    PyObject *prefix##_code;                                                \
    PyObject *prefix##_weakreflist;                                         \
    PyObject *prefix##_name;                                                \
    PyObject *prefix##_qualname;                                            \
    _PyErr_StackItem prefix##_exc_state;

typedef struct {
    _PyGenObject_HEAD(gi)
} PyGenObject;
</code></pre>
<p>如果我们将其整理一下，等价于如下：</p>
<pre><code class="language-c">typedef struct {
    // 头部信息
    PyObject_HEAD
    // 生成器执行时对应的栈帧对象
    struct _frame *gi_frame; 
    // 标识生成器是否在运行当中
    char gi_running;  
    // 生成器函数的 PyCodeObject 对象
    PyObject *gi_code; 
    // 弱引用相关，不深入讨论
    PyObject *gi_weakreflist; 
    // 生成器的名字
    PyObject *gi_name; 
    // 生成器的全限定名
    PyObject *gi_qualname; 
    // 生成器执行出现异常时的异常栈，更准确的说，其实是异常栈的一个 entry
    // 里面包含了 exc_type、exc_value、exc_traceback
    // 以及通过 previous_item 指针指向上一个 entry
    _PyErr_StackItem *gi_exc_state; 
} PyGenObject;
</code></pre>
<p>所以生成器在底层对应 PyGenObject，它的类型则是 PyGen_Type。至此，生成器的结构就非常清晰了，我们来画一张图：</p>
<p><img src="./images/231.png" alt="" /></p>
<p>无论是普通函数还是生成器函数，在调用时，虚拟机都会为其创建栈帧，因为栈帧是函数执行的上下文。只是对于生成器函数来说，由于它的 co_flags 带有 CO_GENERATOR 标识，所以知道这是一个生成器函数。在调用时不会立刻执行里面的字节码，而是会创建一个生成器对象，并将栈帧交由 gi_frame 字段保存，然后将生成器返回。</p>
<p>我们可以从 Python 层面来验证得到的结论。</p>
<pre><code class="language-python">def gen():
    yield

# 在内部会创建栈帧，但是和普通函数不同
# 虚拟机不会立即执行字节码，而是创建一个生成器
# 然后让 &quot;生成器 -&gt; gi_frame = 栈帧&quot;
g = gen()


# 通过 gi_frame 即可拿到栈帧
print(g.gi_frame)  # &lt;frame at 0x7f3...&gt;

# 由于生成器还没有运行，所以栈帧的 f_back 是 None
# 如果是普通函数的栈帧，那么它的 f_back 应该是模块对应的栈帧
# 因为对于普通函数而言，能拿到它的栈帧，说明一定执行了
# 而生成器则不同，它还没有运行，所以 f_back 是 None
print(g.gi_frame.f_back)  # None

# f_lasti 表示上一条已执行完毕的字节码指令的偏移量
# -1 代表尚未执行
print(g.gi_frame.f_lasti)  # -1

# 所以 gi_running 也是 False
print(g.gi_running)  # False


# 还可以获取 PyCodeObject，有三种方式
print(
    g.gi_code is g.gi_frame.f_code is gen.__code__
)  # True
</code></pre>
<p>所以生成器相当于对栈帧进行了一个封装，当我们驱动它执行时，会将内部的栈帧插入到栈帧链中执行。一旦遇到 yield，停止运行，将栈帧从栈帧链中移除。</p>
<p>然后再次驱动执行，继续将内部的栈帧插入到栈帧链中执行字节码指令，由于 f_lasti 记录了上一条已执行完毕的指令的偏移量，所以会从上次中断的位置开始执行。如果又遇到了 yield，那么依旧停止运行，将栈帧从栈帧链中移除。</p>
<p>就这样不断重复，直到执行完毕。而生成器一旦执行完毕（return 之后），会将栈帧设置为 None。</p>
<pre><code class="language-python">def gen():
    yield

g = gen()

print(g.gi_frame is None)  # False

for _ in g:
    pass

print(g.gi_frame is None)  # True
</code></pre>
<p>所以生成器只能顺序遍历一次，从这里我们也可以看出原因，因为遍历完之后栈帧都没了。</p>
<pre><code class="language-python">g = (x for x in [1, 2, 3])

print(tuple(g))  # (1, 2, 3)
print(tuple(g))  # ()
</code></pre>
<p>还是很好理解的。</p>
<h2 id="生成器的创建"><a class="header" href="#生成器的创建">生成器的创建</a></h2>
<p>然后再来看看生成器的创建过程，我们上面提到，生成器是在通用通道里面调用 PyGen_NewWithQualName 创建的，来看看这个函数长什么样子。</p>
<pre><code class="language-C">// Objects/genobject.c

PyObject *
PyGen_NewWithQualName(PyFrameObject *f, PyObject *name, PyObject *qualname)
{
    return gen_new_with_qualname(&amp;PyGen_Type, f, name, qualname);
}
</code></pre>
<p>该函数接收三个参数，分别是栈帧对象、__name__、__qualname__。注意这个栈帧对象，它是在通用通道里面创建好的，然后将其作为参数传递到 PyGen_NewWithQualName 里面进行调用。</p>
<p>而该函数又调用了 gen_new_with_qualname，所以具体逻辑在这个函数里面，来看一下。</p>
<pre><code class="language-C">// Objects/genobject.c

static PyObject *
gen_new_with_qualname(PyTypeObject *type, PyFrameObject *f,
                      PyObject *name, PyObject *qualname)
{
    // 为生成器对象申请内存
    PyGenObject *gen = PyObject_GC_New(PyGenObject, type);
    if (gen == NULL) {
        Py_DECREF(f);
        return NULL;
    }
    // 将栈帧交给 gi_frame 保存，所以普通函数和生成器函数调用时都会创建栈帧
    // 但普通函数调用时，会在栈帧里面将字节码全部执行完毕
    // 而生成器函数调用时，会返回生成器对象，并将栈帧保存在里面
    gen-&gt;gi_frame = f;
    // 注意这里，又让栈帧的 f_gen 字段保存生成器对象
    // 如果是普通函数，那么 f_gen 显然为空
    f-&gt;f_gen = (PyObject *) gen;
    Py_INCREF(f-&gt;f_code);
    // 让生成器的 gi_code 也保存 PyCodeObject
    gen-&gt;gi_code = (PyObject *)(f-&gt;f_code);
    // 初始时，gi_running 为 0
    gen-&gt;gi_running = 0;
    // 弱引用列表为空
    gen-&gt;gi_weakreflist = NULL;
    // gi_exc_state 和异常栈相关，内部字段初始为 NULL
    gen-&gt;gi_exc_state.exc_type = NULL;
    gen-&gt;gi_exc_state.exc_value = NULL;
    gen-&gt;gi_exc_state.exc_traceback = NULL;
    gen-&gt;gi_exc_state.previous_item = NULL;
    // 设置 gi_name
    if (name != NULL)
        gen-&gt;gi_name = name;
    else
        gen-&gt;gi_name = ((PyCodeObject *)gen-&gt;gi_code)-&gt;co_name;
    Py_INCREF(gen-&gt;gi_name);
    // 设置 gi_qualname 
    if (qualname != NULL)
        gen-&gt;gi_qualname = qualname;
    else
        gen-&gt;gi_qualname = gen-&gt;gi_name;
    Py_INCREF(gen-&gt;gi_qualname);
    // 让生成器对象被 GC 跟踪
    _PyObject_GC_TRACK(gen);
    // 返回
    return (PyObject *)gen;
}
</code></pre>
<p>所以生成器就是对栈帧进行了一个封装，通过 yield 和 __next__、send，我们可以操控栈帧的执行。但普通函数没有给我们这个机会，它在创建完栈帧之后，不将字节码全执行完是不会罢休的。</p>
<h2 id="生成器的执行"><a class="header" href="#生成器的执行">生成器的执行</a></h2>
<p>由于调用 __next__、send 方法可以驱动生成器执行，因此相关细节就隐藏在这两个函数当中。</p>
<p><img src="./images/232.png" alt="" /></p>
<p>__next__ 对应类型对象 PyGen_Type 的 tp_iternext，而 send 是一个普通的方法，所以它位于 tp_methods 中。通过源码可以看出，如果调用 __next__，底层会执行 gen_iternext，如果调用 send，底层会执行 _PyGen_Send。</p>
<pre><code class="language-C">// Objects/genobject.c

static PyObject *
gen_iternext(PyGenObject *gen)
{
    return gen_send_ex(gen, NULL, 0, 0);
}

PyObject *
_PyGen_Send(PyGenObject *gen, PyObject *arg)
{
    return gen_send_ex(gen, arg, 0, 0);
}
</code></pre>
<p>无论哪种方式，在底层最终都是通过 gen_send_ex 函数完成的，只是 __next__ 不接收参数，因此 gen_iternext 在调用时传递了一个空。而 send 接收一个参数，因此 _PyGen_Send 在调用时传了一个 arg。</p>
<p>所以核心逻辑显然在 gen_send_ex 函数里面。</p>
<pre><code class="language-C">static PyObject *
gen_send_ex(PyGenObject *gen, PyObject *arg, int exc, int closing)
{
    // 获取线程状态对象
    PyThreadState *tstate = _PyThreadState_GET();
    // 获取生成器内部保存的栈帧对象
    PyFrameObject *f = gen-&gt;gi_frame;
    // 返回值
    PyObject *result;
    // ...
  
    // 重点来了，f 就是生成器内部的栈帧，f-&gt;f_back 表示生成器内部栈帧的上一级栈帧
    // 而 tstate-&gt;frame 表示当前栈帧，也就是调用 __next__ 或者 send 时所在的栈帧
    // 假设我们是在模块作用域中调用了生成器的 __next__ 方法，那么 tstate-&gt;frame 就是模块对应的栈帧
    // 而当下面这行代码执行完毕后，tstate-&gt;frame 就变成了生成器内部栈帧的上一级栈帧
    // 生成器内部的栈帧则变成了当前栈帧，所以这是不是就相当于将生成器内部的栈帧插入到栈帧链当中了呢？
    f-&gt;f_back = tstate-&gt;frame;
    // 生成器正在运行
    gen-&gt;gi_running = 1;
    gen-&gt;gi_exc_state.previous_item = tstate-&gt;exc_info;
    tstate-&gt;exc_info = &amp;gen-&gt;gi_exc_state;
    // 而插入到栈帧链之后要干啥？显然是在栈帧中执行字节码
    // 栈帧对象保存着生成器的执行上下文，f_lasti 字段则跟踪生成器内部代码的执行进度
    // 当遇到 yield 之后，将后面的值返回给 result
    result = PyEval_EvalFrameEx(f, exc);
    tstate-&gt;exc_info = gen-&gt;gi_exc_state.previous_item;
    gen-&gt;gi_exc_state.previous_item = NULL;
    gen-&gt;gi_running = 0;
  
    // ...
}  
</code></pre>
<p>至于剩下的逻辑我们显然再清楚不过了，最终会调用帧评估函数在栈帧对象中执行字节码。每执行完一条指令就自增 f_lasti 字段、next_instr 字段，直到字节码全部执行完毕、或者中间出现异常时结束循环。当然啦，遇到 yield 也会结束循环。</p>
<p>举例说明：</p>
<pre><code class="language-python">def gen():
    yield 1
    yield 2
    yield 3
   
g = gen()
print(g.gi_frame.f_back)  # None
g.__next__()
</code></pre>
<p>g = gen() 之后会创建一个生成器，但此时生成器的代码还没有执行，所以生成器内部栈帧的上一级栈帧为空。等到调用生成器的 __next__ 方法时，会接入到栈帧链并开始执行。另外，由于我们是在模块作用域中调用的 __next__，所以当前栈帧链里面其实只有一个栈帧，就是模块的栈帧。</p>
<p><img src="./images/233.png" alt="" /></p>
<p>所以接入栈帧链，其实就是让生成器内部栈帧的 f_back 字段，指向调用 __next__ 或 send 时所在的栈帧。比如当前是在模块作用域中调用的 __next__，那么就让 f_back 字段指向模块栈帧。就好像在模块的栈帧之上，创建了一个新的栈帧一样，开始执行，直到遇见 yield。</p>
<h2 id="生成器的暂停"><a class="header" href="#生成器的暂停">生成器的暂停</a></h2>
<p>先看看生成器内部的字节码长什么样子？</p>
<pre><code class="language-python">def gen():
    name = &quot;古明地觉&quot;
    yield name
    
    age = 16
    res = yield age
    
    gender = &quot;female&quot;
    yield gender
</code></pre>
<p>字节码如下：</p>
<pre><code class="language-C">  // 加载字符串常量 &quot;古明地觉&quot;
  0 LOAD_CONST               1 ('古明地觉')
  // 使用局部变量 name 保存
  2 STORE_FAST               0 (name)
  // 对应 yield name
  // 加载局部变量 name，然后将值 yield 出去
  // 注意：执行完 YIELD_VALUE 之后，生成器会暂停
  4 LOAD_FAST                0 (name)
  6 YIELD_VALUE
  // 这里为啥会出现 POP_TOP 呢？
  // 因为驱动生成器执行时，我们是可以传值的
  // 但是 yield name 左边没有变量接收，所以是 POP_TOP
  8 POP_TOP

  // 加载整数常量 16
 10 LOAD_CONST               2 (16)
  // 使用局部变量 age 保存
 12 STORE_FAST               1 (age)
  // 加载局部变量 age，然后将值 yield 出去
 14 LOAD_FAST                1 (age)
 16 YIELD_VALUE
  // 但这里需要注意，因为是 res = yield age
  // 所以这里是 STORE_FAST，会将调用方传递的值使用 res 变量保存
 18 STORE_FAST               2 (res)
  
  // 加载字符串常量 &quot;female&quot;
 20 LOAD_CONST               3 ('female')
  // 使用局部变量 gender 保存
 22 STORE_FAST               3 (gender)
  // 加载局部变量 gender，然后将值 yield 出去
 24 LOAD_FAST                3 (gender)
 26 YIELD_VALUE
  // 弹出调用方传递的值
 28 POP_TOP
  
  // return None
 30 LOAD_CONST               0 (None)
 32 RETURN_VALUE
</code></pre>
<p>指令很好理解，显然重点是在 YIELD_VALUE 上面，我们看一下这个指令：</p>
<pre><code class="language-C">case TARGET(YIELD_VALUE): {
    // 执行 yield value 之前，会先将 value 压入运行时栈
    // 然后这里再将 value 从栈里面弹出
    retval = POP();
    // 异步生成器逻辑，当前不用关注
    if (co-&gt;co_flags &amp; CO_ASYNC_GENERATOR) {
        PyObject *w = _PyAsyncGenValueWrapperNew(retval);
        Py_DECREF(retval);
        if (w == NULL) {
            retval = NULL;
            goto error;
        }
        retval = w;
    }
    // stack_pointer 指向运行时栈的栈顶
    // 因为要跳出循环了，所以赋值给 f-&gt;f_stacktop
    f-&gt;f_stacktop = stack_pointer;
    // 直接通过 goto 语句跳出 for 循环，来到 exit_yielding 标签
    goto exit_yielding;
}
</code></pre>
<p>紧接着，帧评估函数会将当前栈帧（也就是生成器内部的栈帧）从栈帧链中移除，至于移除方式也很简单，只需要将它的 f_back 设置为 None 即可，然后回退到上一级栈帧。</p>
<p><img src="./images/234.png" alt="" /></p>
<p>同理，当再次调用 __next__ 或者 send 方法时，生成器将恢复执行，底层会调用 gen_send_ex 函数。然后虚拟机会把生成器的栈帧对象挂到栈帧链中，并最终调用帧评估函数逐条执行字节码。</p>
<p><img src="./images/235.png" alt="" /></p>
<p>通过不断调用 __next__，最终将整个生成器内部的代码执行完毕，我们实际演示一下这个过程。</p>
<pre><code class="language-Python">def gen():
    name = &quot;古明地觉&quot;
    yield name
    
    age = 16
    res = yield age
    
    gender = &quot;female&quot;
    yield gender
  
  
g = gen()

# 生成器尚未执行，f_lasti 初始为 -1
print(g.gi_frame.f_lasti)  # -1    

# 调用 __next__，会将生成器内部栈帧插入到栈帧链中，开始执行
# 那什么时候暂停呢？如果站在 Python 的角度，肯定是在 yield 处暂停
# 但如果从虚拟机的角度，应该是在 YIELD_VALUE 的结束位置暂停
g.__next__()
# f_lasti 表示上一条已执行的指令的偏移量，而上一条执行的指令是 YIELD_VALUE，因此是 6
print(g.gi_frame.f_lasti)  # 6
print(g.gi_frame.f_locals)  # {'name': '古明地觉'}

# 第二个 YIELD_VALUE 的偏移量是 16
g.__next__()
print(g.gi_frame.f_lasti)  # 16
print(g.gi_frame.f_locals)  # {'name': '古明地觉', 'age': 16}

# 第三个 YIELD_VALUE 的偏移量是 26
g.__next__()
print(g.gi_frame.f_lasti)  # 26
print(g.gi_frame.f_locals)  # {'name': '古明地觉', 'age': 16, 'res': None, 'gender': 'female'}

# 再次调用 g.__next__()，生成器执行完毕
try:
    g.__next__()
except StopIteration:
    pass
  
# 一旦执行完毕，gi_frame 会设置为 None，因此生成器只能顺序遍历一次
print(g.gi_frame)  # None
</code></pre>
<p>遇见 yield 产生中断，调用 __next__、send 恢复执行，并且在这个过程中，f_lasti 也在不断变化，并始终维护着生成器的执行进度。而基于 f_lasti，生成器就可以记住自己的中断位置，并在下一次被驱动的时候，能够从中断的位置恢复执行。</p>
<p>而以上也正是协程能够实现的理论基础，虽然 Python 在 3.5 提供了基于 async def 的原生协程，但它底层依旧是使用了生成器。</p>
<h2 id="小结-59"><a class="header" href="#小结-59">小结</a></h2>
<p>以上我们就从源码的角度剖析了生成器的实现原理，下面总结一下。</p>
<p>1）Python 具有词法作用域，当函数内部出现 yield 关键字时，会给对应的 PyCodeObject 增加一个 CO_GENERATOR 标识。这个标识让虚拟机在调用时能够分辨出是普通函数、还是生成器函数。</p>
<p>2）和普通函数一样，生成器函数在调用时，也会由虚拟机创建栈帧，作为执行上下文。但和普通函数不同的是，调用生成器函数时创建的栈帧不会立即进入帧评估函数执行字节码。而是以栈帧为参数，创建生成器对象。</p>
<p>3）可以调用 __next__、send 方法驱动生成器执行，虚拟机会将生成器的栈帧插入栈帧链，也就是将它的 f_back 设置为调用 __next__、send 时所在的栈帧。然后生成器的栈帧就变成了当前栈帧，于是开始执行字节码。</p>
<p>4）执行到 YIELD_VALUE 指令时，说明生成器该暂停了。于是修改 f_stacktop，通过一个 goto 语句跳出执行指令的 for 循环，回退到上一级栈帧，然后将 yield 右边的值压入运行时栈。并且还会将生成器内部栈帧的 f_back 设置为空，以及设置 f_lasti 等字段。</p>
<p>5）当再次调用 __next__ 或者 send 方法时，虚拟机仍会修改 f_back，将生成器的栈帧重新插入到栈帧链中，然后继续执行生成器内部的字节码。但是从什么地方开始执行呢？显然是从上一次中断的位置，那么上一次中断的位置虚拟机要如何得知呢？没错，显然是通过 f_lasti，直接从偏移量为 f_lasti + 2 的指令开始执行即可。所以执行时，会从上一个 YIELD_VALUE 的下一条指令开始执行，另外由于要获取调用者传递的值，因此 YIELD_VALUE 的下一条指令一般是 POP_TOP 或者 STORE_FAST。</p>
<p>6）随着不断驱动生成器执行，总有执行完毕的那一刻。而当生成器执行完毕后，gi_frame 会被设置为 None，因此生成器只能顺序遍历一次。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>从现在开始，我们将进入新的篇章，来分析 Python 的类是怎么实现的？我们知道 Python 是一个面向对象的语言，而 C 不是，那么在 Python 的底层，是如何使用 C 来支持面向对象功能的呢？带着这些疑问，我们下面开始剖析类的实现机制。</p>
<p>另外，在 Python2 中存在着经典类（classic class）和新式类（new style class），但是到 Python3，经典类已经消失了，因此我们只介绍新式类。</p>
<p>下面先来重温一下对象的关系模型。</p>
<p>在面向对象的理论中，有两个核心概念：类和实例。类可以看成是一个模板，那么实例就是根据这个模板创建出来的对象，可以想象成 Docker 的镜像和容器。但是在 Python 里面，类和实例都是对象，类叫做类对象、或者类型对象，实例叫做实例对象。</p>
<p>而对象之间存在以下两种关系：</p>
<ul>
<li>is-kind-of：对应面向对象理论中父类和子类之间的关系；</li>
<li>is-instance-of：对应面向对象理论中类和实例之间的关系；</li>
</ul>
<pre><code class="language-Python">class Girl(object):
    def say(self):
        return &quot;古明地觉&quot;

girl = Girl()
print(girl.say())  # 古明地觉
</code></pre>
<p>显然 Girl 和 object 之间是 is-kind-of 关系，即 object 是 Girl 的父类。另外 Python3 里面所有的类（除了 object）都是默认继承 object，即便这里不显式继承 object，也会默认继承，为了说明我们就写上了。</p>
<p>除了 object 是 Girl 的父类，我们还能看出 girl 和 Girl 之间存在 is-instance-of 关系，即 girl 是 Girl 的实例。当然如果再进一步的话，girl 和 object 之间也存在 is-instance-of 关系，girl 也是 object 的实例。</p>
<pre><code class="language-Python">class Girl(object):
    pass

girl = Girl()
print(issubclass(Girl, object))  # True
print(type(girl))  # &lt;class '__main__.Girl'&gt;
print(isinstance(girl, Girl))  # True
print(isinstance(girl, object))  # True
</code></pre>
<p>girl 是 Girl 这个类实例化得到的，所以 type(girl) 得到的是类对象 Girl。但 girl 也是 object 的实例对象，因为 Girl 继承了 object。至于这其中的原理，后面会慢慢介绍到。</p>
<p>Python 也提供了一些手段可以探测这些关系，除了上面的 type 之外，还可以使用对象的 __class__ 属性探测一个对象和其它的哪些对象之间存在 is-instance-of 关系。而通过对象的 __bases__ 属性则可以探测一个对象和其它的哪些对象之间存在着 is-kind-of 关系。</p>
<p>当然 Python 还提供了两个内置函数 issubclass 和 isinstance 来验证两个对象之间是否存在着我们期望的关系。</p>
<pre><code class="language-Python">class Girl(object):
    pass

girl = Girl()
print(girl.__class__)  # &lt;class '__main__.Girl'&gt;
print(Girl.__class__)  # &lt;class 'type'&gt;

# __base__ 只显示直接继承的第一个类
print(Girl.__base__)  # &lt;class 'object'&gt;
# __bases__ 会显示直接继承的所有类
print(Girl.__bases__)  # (&lt;class 'object'&gt;,)
</code></pre>
<p>我们画一张图：</p>
<p><img src="./images/236.png" alt="" /></p>
<p>关于 type 和 object 的关系，我们在最开始介绍对象模型的时候已经说过了。</p>
<p>type 在底层的结构体是 PyType_Type、object 在底层的结构体是 PyBaseObject_Type。在创建 object 的时候，将内部的 ob_type 设置成了 &amp;PyType_Type；在创建 type 的时候，将内部的 tp_base 设置成了 &amp;PyBaseObject_Type。</p>
<p>因此这两者的定义是彼此依赖的，两者是同时出现的，我们后面还会看到。</p>
<p>紧接着我们考察一下类对象 Girl 的行为，我们看到它支持属性设置：</p>
<pre><code class="language-Python">class Girl(object):
    pass

print(hasattr(Girl, &quot;name&quot;))  # False
Girl.name = &quot;古明地觉&quot;
print(hasattr(Girl, &quot;name&quot;))  # True
print(Girl.name)  # 古明地觉
</code></pre>
<p>类都已经定义完了，我们后续还可以进行属性添加，这在其它的静态语言中是不可能做到的。那 Python 是如何做到的呢？我们说能够对属性进行动态添加，你会想到什么？是不是字典呢？正如 global 名字空间一样，我们猜测类应该也有自己的属性字典，往类里面设置属性的时候，等价于向字典中添加键值对，同理其它操作也与之类似。</p>
<pre><code class="language-Python">class Girl(object):
    pass

print(Girl.__dict__.get(&quot;name&quot;, &quot;不存在&quot;))  # 不存在
Girl.name = &quot;古明地觉&quot;
print(Girl.__dict__.get(&quot;name&quot;))  # 古明地觉
</code></pre>
<p>和操作全局变量是类似的，但是有一点需要注意：我们不能直接通过类的属性字典来设置属性。</p>
<pre><code class="language-python">try:
    Girl.__dict__[&quot;name&quot;] = &quot;古明地觉&quot;
except Exception as e:
    print(e)  # 'mappingproxy' object does not support item assignment
</code></pre>
<p>虽然叫做属性字典，但其实是 mappingproxy 对象，该对象本质上是对字典进行了封装，在字典的基础上移除了增删改操作，也就是只保留了查询功能。如果我们想给类增加属性，可以采用直接赋值的方式，或者调用 setattr 函数也是可以的。</p>
<ul>
<li>Girl.age = 17</li>
<li>setattr(Girl, &quot;age&quot;, 17)</li>
</ul>
<p>这两种做法都可以，但是 Girl.__dict__[&quot;age&quot;] = 17 这种做法不行，因为 Girl.__dict__ 返回的不是字典，而是封装了字典的 mappingproxy 对象。不过 Python 的标准库提供了一个 gc 模块，可以拿到 mappingproxy 内部的字典。</p>
<pre><code class="language-Python">import gc

class Girl(object):
    pass

# gc.get_referents(obj)：返回 obj 引用的对象
# 对于 mappingproxy 来说，它引用的显然就是内部的字典
gc.get_referents(Girl.__dict__)[0][&quot;name&quot;] = &quot;古明地觉&quot;
print(Girl.name)  # 古明地觉
</code></pre>
<p>并且这种做法除了适用于自定义类对象，还适用于内置类对象，但是工作中不要这么做，知道有这么个操作就行。除了设置属性之外，我们还可以设置函数。</p>
<pre><code class="language-Python">class Girl(object):
    pass

Girl.info = lambda name: f&quot;我是{name}&quot;
print(Girl.info(&quot;古明地觉&quot;))  # 我是古明地觉


# 如果是实例调用的话，会和我们想象的不太一样
# 因为实例调用的时候会将函数包装成方法
try:
    Girl().info(&quot;古明地觉&quot;)
except TypeError as e:
    print(e)
    &quot;&quot;&quot;
    &lt;lambda&gt;() takes 1 positional argument but 2 were given
    &quot;&quot;&quot;

# 实例在调用的时候会将自身也作为参数传进去
# 所以第一个参数 name 实际上接收的是 Girl 的实例对象
# 只不过第一个参数按照规范来讲应该叫做 self
# 但即便你起别的名字也是无所谓的
print(Girl().info())
&quot;&quot;&quot;
我是&lt;__main__.Girl object at 0x000001920BB88760&gt;
&quot;&quot;&quot;
</code></pre>
<p>所以我们可以有两种做法：</p>
<pre><code class="language-Python">class Girl(object):
    pass

# 将其包装成一个静态方法，这样类和实例都可以调用
Girl.info = staticmethod(lambda name: f&quot;我是{name}&quot;)
print(Girl.info(&quot;古明地觉&quot;))  # 我是古明地觉
print(Girl().info(&quot;古明地觉&quot;))  # 我是古明地觉

# 如果是给实例用的，那么带上一个 self 参数即可
Girl.info = lambda self, name: f&quot;我是{name}&quot;
print(Girl().info(&quot;古明地觉&quot;))  # 我是古明地觉
</code></pre>
<p>此外还可以通过 type 来动态地往类里面进行属性的增加、修改和删除。</p>
<pre><code class="language-Python">class Girl(object):
    def say(self):
        pass

print(hasattr(Girl, &quot;say&quot;))  # True

# delattr(Girl, &quot;say&quot;) 与之等价
type.__delattr__(Girl, &quot;say&quot;)

print(hasattr(Girl, &quot;say&quot;))  # False

# 我们设置一个属性吧，以下等价于 Girl.name = &quot;古明地觉&quot;
setattr(Girl, &quot;name&quot;, &quot;古明地觉&quot;)
print(Girl.name)  # 古明地觉
</code></pre>
<p>事实上调用 getattr、setattr、delattr 等价于调用其类型对象的 __getattr__、__setattr__、__delattr__。</p>
<p>所以，一个对象支持哪些行为，取决于其类型对象定义了哪些操作。并且通过对象的类型对象，可以动态地给该对象进行属性的设置。Python 所有类型对象的类型对象都是 type，通过 type 我们便可以控制类的生成过程，即便类已经创建完毕了，也依旧可以进行属性设置。</p>
<p>但是注意：上面说的仅仅针对我们自定义的类，内置的类是不行的。</p>
<pre><code class="language-python">try:
    int.name = &quot;古明地觉&quot;
except Exception as e:
    print(e)
    &quot;&quot;&quot;
    can't set attributes of built-in/extension type 'int'
    &quot;&quot;&quot;

try:
    int.__add__ = &quot;xxx&quot;
except Exception as e:
    print(e)
    &quot;&quot;&quot;
    can't set attributes of built-in/extension type 'int'
    &quot;&quot;&quot;
</code></pre>
<p>通过报错信息可以看到，不可以设置内置类和扩展类的属性。因为内置类对象在解释器启动之后，就已经初始化好了。至于扩展类就是我们使用 Python/C API 编写的扩展模块中的类，它和内置类是等价的。</p>
<p>因此内置的类和使用 class 定义的类本质上是一样的，都是 PyTypeObject 对象，它们的类型在 Python 里面都是 type。但区别就是内置的类在底层是静态初始化的，我们不能进行属性的动态设置。</p>
<p>但是为什么不可以对内置类和扩展类进行属性设置呢？首先我们要知道 Python 的动态特性是虚拟机赐予的，而虚拟机的工作是将 PyCodeObject 对象翻译成 C 的代码进行执行，所以 Python 的动态特性就是在这一步发生的。</p>
<p>而内置的类（int、str、list 等等）在解释器启动之后就已经静态初始化好了，直接指向 C 一级的数据结构，同理扩展类也是如此。它们相当于绕过了解释执行这一步，所以它们的属性不可以动态添加。</p>
<p>不光内置的类本身，还有它的实例对象也是如此。</p>
<pre><code class="language-Python">a = 123
print(hasattr(a, &quot;__dict__&quot;))  # False
</code></pre>
<p>我们看到它连自己的属性字典都没有，因为内置类对象的实例对象，其内部有哪些属性，解释器记得清清楚楚。它们在底层都已经写死了，并且不允许修改，因此虚拟机完全没有必要为其实现属性字典（节省了内存占用）。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>Python 的类里面有很多以双下划线开头、双下划线结尾的函数，我们称之为魔法函数。Python 的每一个操作符，都被抽象成了一个魔法函数。</p>
<p>比如整数可以相减，这就代表 int 这个类里面肯定定义了 __sub__ 函数；字符串不能相减，代表 str 这个类里面没有 __sub__ 函数；而整数和字符串都可以执行加法操作，显然 int、str 内部都定义了__add__ 函数。</p>
<pre><code class="language-Python">class MyInt(int):
    def __sub__(self, other):
        return int.__sub__(self, other) * 3

a = MyInt(4)
b = MyInt(1)
print(a - b)  # 9
</code></pre>
<p>我们自己实现了一个类，继承自 int。当执行 a - b 的时候，肯定执行 MyInt 的 __sub__，然后调用 int 的 __sub__，得到结果之后再乘上3，逻辑上完全正确。</p>
<p>但是问题来了，首先调用 int.__sub__ 的时候，我们知道底层肯定是调用 long_as_number 中的 long_sub 函数。而 int.__sub__(self, other) 里面的参数类型显然都应该是 int，但我们传递的是 MyInt，那么虚拟机是怎么做的呢？</p>
<p>目前带着这些疑问，先来看一张草图，后面会一点一点揭开：</p>
<p><img src="./images/237.png" alt="" /></p>
<p>图中的 &quot;__sub__&quot; 对应的 value 并不是一个直接指向 long_sub 函数的指针，而是指向一个结构体，至于指向 long_sub 函数的指针则在该结构体内部。而这个结构体是谁，以及具体细节，我们后面会详细说。</p>
<p>另外我们知道，一个对象能否被调用，取决于它的类对象（或者说类型对象）中是否定义了__call__ 函数。因此：所谓调用，就是执行类型对象的 tp_call 指向的函数。</p>
<pre><code class="language-python">class Girl:
    def __call__(self, *args, **kwargs):
        return &quot;古明地觉的编程教室&quot;

girl = Girl()
print(girl())  # 古明地觉的编程教室
</code></pre>
<p>而整数对象是不可调用的，这意味着 int 这个类里面没有 __call__ 函数，换言之 PyLong_Type 里面的 tp_call 为 NULL。</p>
<pre><code class="language-Python"># 但我们通过反射，发现 int 是有 __call__ 函数的啊
print(hasattr(int, &quot;__call__&quot;))  # True

# 其实这个 __call__ 不是 int 里面的，而是 type 的
print(&quot;__call__&quot; in dir(int))  # False
print(&quot;__call__&quot; in dir(type))  # True
</code></pre>
<p>如果一个对象不存在某个属性，那么会自动到对应的类型对象里面去找。int 的类型是 type，而 type 里面有 __call__，因此 <font color="blue">hasattr(int, &quot;__call__&quot;)</font> 结果为 True。</p>
<pre><code class="language-python">a1 = int(&quot;123&quot;) 
a2 = type.__call__(int, &quot;123&quot;) 
a3 = int.__call__(&quot;123&quot;) 

print(a1, a2, a3)  # 123 123 123
</code></pre>
<p>里面的 a1 和 a2 是等价的，因为调用某个对象等价于调用其类型对象的 __call__ 函数；而 a3 和 a2 也是等价的，因为 type 是 int 的类型对象，而 int 没有 __call__，所以会去类型对象 type 里面查找。</p>
<p>观察 a3 和 a2，我们发现这是不是就类似于类型对象和实例对象之间的关系呢？所以我们说 class 具有二象性，站在实例对象的角度上，它就是类型对象；站在元类 type 的角度上，它就是实例对象。</p>
<p>而实例对象在调用方法时，会将自身作为第一个参数传进去，所以 int.__call__(&quot;123&quot;) 等价于 type.__call__(int, &quot;123&quot;)。</p>
<p>那么问题来了，为啥整数在调用的时候会报错呢？首先整数在调用的时候，会执行 int 里面的 __call__，而 int 里面没有 __call__，所以报错了。可能这里有人好奇，难道不会到 type 里面找吗？答案是不会的，因为 type 是元类，是用来生成类的。</p>
<p>类对象在调用时，会执行 <font color="blue">type.__call__</font>。实例对象在调用时，会执行<font color="blue">类对象.__call__</font>，但如果类对象没有 __call__，就不会再去元类里面找了，而是会去父类里面找。</p>
<pre><code class="language-Python">class A:

    def __call__(self, *args, **kwargs):
        print(self)
        return &quot;古明地觉的编程教室&quot;

class B(A):
    pass

class C(B):
    pass

c = C()
print(c())
&quot;&quot;&quot;
&lt;__main__.C object at 0x104d7e7a0&gt;
古明地觉的编程教室
&quot;&quot;&quot;
</code></pre>
<p>可以看到，给 C 的实例对象加括号的时候，会调用 C 里面的 __call__ 函数。但是 C 里面没有 __call__，那么这个时候会从父类里面找，而不是元类。因此最终执行 A 的 __call__，但 self 仍是 C 的实例对象，关于这个 self 是我们后续的重点，会详细剖析。</p>
<p><font color="darkblue"><strong>结论：在属性查找时，首先从对象本身进行查找，没有的话会从该对象的类型对象中进行查找，还没有的话就从类型对象所继承的父类中进行查找。</strong></font></p>
<pre><code class="language-python">class A:

    def __call__(self, *args, **kwargs):
        print(self)
        return &quot;古明地觉的编程教室&quot;

class B(A):
    pass

class C(B):
    pass

c = C()
print(c())
</code></pre>
<p>还是以这段代码为例：当调用类型对象 C 的时候，本质上是执行 C.__class__（也就是 type）里面的 __call__ 函数。</p>
<p>当调用实例对象 c 的时候，本质上是执行 c.__class__（也就是类型对象 C）里面的 __call__ 函数，但是 C 里面没有，这个时候怎么做呢？显然是沿着继承链进行属性查找，去找 C 继承的类里面的 __call__ 函数。</p>
<p><img src="./images/238.png" alt="" /></p>
<p>可能有人好奇，为什么没有 object？答案是 object 内部没有 __call__，object 和 int 一样，都是调用了 type.__call__。</p>
<pre><code class="language-python"># 因为 object 的类型是 type
# 所以 object.__call__() 会执行 type.__call__(object)
print(object.__call__)
# &lt;method-wrapper '__call__' of type object 0x1034641a0&gt;
</code></pre>
<p>所以，所有的类对象都是可以调用的，因为 type 是类对象的类对象，而 type 内部有 __call__ 函数。至于实例对象能否调用，就看其类对象、以及类对象所继承的父类是否定义了 __call__ 函数。</p>
<p>比如 str(&quot;xxx&quot;) 是合法的，因为 str 的类对象 type 里面定义了 __call__。但 &quot;xxx&quot;() 则不合法、会报错，因为字符串的类对象 str、以及 str 所继承的父类里面没有 __call__。但是注意，虽然 &quot;xxx&quot;() 会报错，但这不是一个在编译时就能够检测出来的错误，而是在运行时才能检测出来。至于原因，下面解释一下。</p>
<p>我们知道类对象都会有 tp_dict，这个字段指向一个 PyDictObject，表示该对象支持哪些操作，而这个 PyDictObject 必须要在运行时动态构建。所以都说 Python 效率慢，一个原因是所有对象都分配在堆上；还有一个原因就是类型无法在编译期间确定，导致大量操作都需要在运行时动态化处理，从而也就造成了 Python 运行时效率不高。</p>
<p>而且我们发现，像 int、str、dict 等内置类对象可以直接使用，这是因为解释器在启动时，会对这些内置类对象进行初始化的动作。这个初始化的动作会动态地在这些类对象对应的 PyTypeObject 中填充一些重要的东西，其中就包括 tp_dict，从而让这些类对象具备生成实例对象的能力。</p>
<p>而初始化的动作就从函数 PyType_Ready 拉开序幕，虚拟机会调用 PyType_Ready 对内置类对象进行初始化。实际上 PyType_Ready 不仅仅会处理内置类对象，还会处理自定义类对象，并且 PyType_Ready 对内置类对象和自定义类对象的作用还不同。</p>
<p>内置类对象在底层是已经被静态定义好了的，所以在解释器启动的时候会直接创建。只不过我们说它还不够完善，因为有一部分属性需要在运行时设置，比如 tp_base，所以还需要再打磨一下，而这一步就交给了 PyType_Ready。</p>
<p>但是对于我们自定义的类就不同了，PyType_Ready 做的工作只是很小的一部分，因为使用 class 自定义的类（假设是 class A），解释器一开始是不知道的。解释器在启动的时候，不可能直接就创建一个 PyA_Type 出来，因此对于自定义的类来说，需要在解释执行的时候进行内存申请、创建、初始化等等一系列步骤。</p>
<p>下一篇文章我们来分析类型对象是如何初始化的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-60"><a class="header" href="#楔子-60">楔子</a></h2>
<p>在上一篇文章中我们说到，内置类对象虽然在底层静态定义好了，但还不够完善。解释器在启动之后还要再打磨一下，然后才能得到我们平时使用的类型对象，而这个过程被称为类型对象的初始化。</p>
<p>类型对象的初始化，是通过 Objects/typeobject.c 中的 PyType_Ready 函数实现的，它主要完成以下三个工作：</p>
<ul>
<li>给类型对象设置类型和基类信息；</li>
<li>类对象属性字典的填充；</li>
<li>类对象 MRO 的设置与属性继承；</li>
</ul>
<p>我们来逐一解释。</p>
<h2 id="给类型对象设置类型和基类信息"><a class="header" href="#给类型对象设置类型和基类信息">给类型对象设置类型和基类信息</a></h2>
<p>介绍 type 和 object 之间的恩怨纠葛时，我们说类对象的基类是在初始化的时候设置的，来看一下。</p>
<pre><code class="language-C">int
PyType_Ready(PyTypeObject *type)
{
    // 注意：参数 type 只是一个普通的 C 变量，和 Python 的 &lt;class 'type'&gt; 无关
    // dict：属性字典，即 __dict__，bases：继承的所有基类，即 __bases__
    PyObject *dict, *bases;
    // 继承的第一个基类，即 __base__
    PyTypeObject *base;
    Py_ssize_t i, n;

    // ...
    // 获取类型对象中 tp_base 字段指定的基类
    base = type-&gt;tp_base;
    // 如果基类为空、并且该类本身不是 &lt;class 'object'&gt;
    if (base == NULL &amp;&amp; type != &amp;PyBaseObject_Type) {
        // 那么将该类的基类设置为 &lt;class 'object'&gt;、即 &amp;PyBaseObject_Type
        base = type-&gt;tp_base = &amp;PyBaseObject_Type;
        Py_INCREF(base);
    }

    // 如果基类不是 NULL，也就是指定了基类，但是基类的属性字典是 NULL
    // 说明该类的基类尚未初始化，那么会先对基类进行初始化
    // 注意这里的 tp_dict，它表示每个类都会有的属性字典
    // 而属性字典不等于 NULL，是类型对象初始化完成的重要标志
    if (base != NULL &amp;&amp; base-&gt;tp_dict == NULL) {
        if (PyType_Ready(base) &lt; 0)
            goto error;
    }
    // Py_TYPE 是一个宏，会返回对象的 ob_type
    // 如果该类型对象的 ob_type 为空，但是基类不为空（显然这里是针对于自定义类型对象）
    // 那么将该类型对象的 ob_type 设置为基类的 ob_type
    // 为什么要做这一步，我们后面会详细说
    if (Py_TYPE(type) == NULL &amp;&amp; base != NULL)
        Py_TYPE(type) = Py_TYPE(base);
    // 获取 __bases__，检测是否为空
    bases = type-&gt;tp_bases;
    // 如果为空，则根据 __base__ 进行设置
    if (bases == NULL) {
        // 如果 base 也为空，说明当前的类对象一定是 &lt;class 'object'&gt;
        // 那么 bases 就是空元祖
        if (base == NULL)
            bases = PyTuple_New(0);
        // 如果 base 不为空，那么 bases 就是 (base,)
        else
            bases = PyTuple_Pack(1, base);
        if (bases == NULL)
            goto error;
        // 设置 tp_bases
        type-&gt;tp_bases = bases;
    }
    // 设置属性字典，后续再聊
    dict = type-&gt;tp_dict;
    if (dict == NULL) {
        dict = PyDict_New();
        if (dict == NULL)
            goto error;
        type-&gt;tp_dict = dict;
    }
    // ...
}
</code></pre>
<p>对于指定了 tb_base 的类对象，当然就使用指定的基类，而对于没有指定 tp_base 的类对象，虚拟机会为其设置一个默认的基类：&amp;PyBaseObject_Type ，也就是 Python 的 object。</p>
<p>所以对于 PyType_Type 而言，它的 tp_base 会指向 PyBaseObject_Type，这在 Python 中体现的就是 type 继承 object、或者说 object 是 type 的父类。但是所有的类的 ob_type 又都指向了 PyType_Type，包括 object，因此我们又说 type 是包括 object 在内的所有类对象的类对象（元类）。</p>
<p>而在获得了基类之后，会判断基类是否被初始化，如果没有，则需要先对基类进行初始化，而判断初始化是否完成的条件是 tp_dict 是否不等于 NULL。对于内置类对象来说，在解释器启动的时候，就已经作为全局对象存在了，所以它们的初始化不需要做太多工作，只需小小的完善一下即可，比如设置基类、类型、以及对 tp_dict 进行填充。</p>
<p>在基类设置完毕后，会继续设置 ob_type，而源码是这么设置的：<font color="blue">Py_TYPE(type) = Py_TYPE(base)</font>，也就是将基类的 ob_type 设置成了当前类的 ob_type，那么这一步的意义何在呢？直接设置成 &lt;class 'type'&gt; 不就完了吗？</p>
<pre><code class="language-Python">class MyType(type):
    pass

class A(metaclass=MyType):
    pass

class B(A):
    pass


print(type(A))  # &lt;class '__main__.MyType'&gt;
print(type(B))  # &lt;class '__main__.MyType'&gt;
</code></pre>
<p>我们看到 B 继承了 A，而 A 的类型是 MyType，那么 B 的类型也成了 MyType。也就是说 A 是由 XX 生成的，那么 B 在继承 A 之后，B 也会由 XX 生成，所以源码中的那一步就是用来做这件事情的。另外，这里之所以用 XX 代替，是因为 Python 里面不仅仅只有 type 是元类，那些继承了 type 的子类也可以是元类。</p>
<p>而且如果你熟悉 flask 的话，你会发现 flask 源码里面就有类似于这样的操作：</p>
<pre><code class="language-Python">class MyType(type):
    def __new__(mcs, name, bases, attrs):
        # 关于第一个参数我们需要说一下，对于一般的类来说这里应该是 cls
        # 但这里是元类，所以应该用 mcs，意思就是 metaclass
        # 我们额外设置一些属性吧，关于元类后续会介绍
        # 虽然目前还没有看底层实现，但至少使用方法应该知道
        attrs.update({&quot;name&quot;: &quot;古明地觉&quot;})
        return super().__new__(mcs, name, bases, attrs)

def with_metaclass(meta, bases=(object,)):
    return meta(&quot;&quot;, bases, {})

class Girl(with_metaclass(MyType, (int,))):
    pass


print(type(Girl))  # &lt;class '__main__.MyType'&gt;
print(getattr(Girl, &quot;name&quot;))  # 古明地觉
print(Girl(&quot;123&quot;))  # 123
</code></pre>
<p>所以逻辑很清晰了，虚拟机就是将基类的 metaclass 设置为子类的 metaclass。以 PyType_Type 为例，其 metaclass 就是 object 的 metaclass，也是它自己。而在源码的 PyBaseObject_Type 定义中也可以看到，其 ob_type 被设置成了 &amp;PyType_Type。</p>
<p>tb_base 和 ob_type 设置完毕之后，会设置 tb_bases。tb_base 对应 __base__，tb_bases 对应 __bases__，我们用 Python 演示一下，这两者的区别。</p>
<pre><code class="language-Python">class A:
    pass

class B(A):
    pass

class C:
    pass

class D(B, C):
    pass

  
print(D.__base__)  # &lt;class '__main__.B'&gt;
print(D.__bases__)  # (&lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;)
print(C.__base__)  # &lt;class 'object'&gt;
print(C.__bases__)  # (&lt;class 'object'&gt;,)
print(B.__base__)  # &lt;class '__main__.A'&gt;
print(B.__bases__)  # (&lt;class '__main__.A'&gt;,)
</code></pre>
<p>我们看到 D 同时继承多个类，那么 tp_base 就是先出现的那个基类。而 tp_bases 则是继承的所有基类，但是基类的基类是不会出现的，比如 object。然后我们看看 C，因为 C 没有显式地继承任何类，那么 tp_bases 就是 NULL。但是 Python3 里面所有的类都默认继承了object，所以 tp_base 就是 object，而 tp_bases 显然是 (object,)。</p>
<p>以上就是 tp_base、ob_type、tp_bases 的设置，还是比较简单的，它们在设置完毕之后，就要对 tp_dict 进行填充了。而填充 tp_dict 是一个极其繁复的过程，我们继续往下看。</p>
<h2 id="类对象属性字典tp_dict的填充"><a class="header" href="#类对象属性字典tp_dict的填充">类对象属性字典（tp_dict）的填充</a></h2>
<p>在给类对象设置完基类、以及类型信息之后，就开始填充属性字典了，这是一个非常复杂的过程。</p>
<pre><code class="language-C">int
PyType_Ready(PyTypeObject *type)
{
    PyObject *dict, *bases;
    PyTypeObject *base;
    Py_ssize_t i, n;
    // ...
    // 初始化 tp_dict
    dict = type-&gt;tp_dict;
    if (dict == NULL) {
        dict = PyDict_New();
        if (dict == NULL)
            goto error;
        type-&gt;tp_dict = dict;
    }
    // 将与 type 相关的操作加入到 tp_dict 中
    // 注意：这里的 type 是 PyType_Ready 的参数 type
    // 它可以是 Python 的 &lt;class 'type'&gt;、也可以是 &lt;class 'int'&gt;
    if (add_operators(type) &lt; 0)
        goto error;
    if (type-&gt;tp_methods != NULL) {  // 类的成员函数
        if (add_methods(type, type-&gt;tp_methods) &lt; 0)
            goto error;
    }
    if (type-&gt;tp_members != NULL) {  // 实例对象可以绑定的属性
        if (add_members(type, type-&gt;tp_members) &lt; 0)
            goto error;
    }
    if (type-&gt;tp_getset != NULL) {  // 类似于 @property
        if (add_getset(type, type-&gt;tp_getset) &lt; 0)
            goto error;
    }  
    // ...
}  
</code></pre>
<p>在这个阶段，完成了将魔法函数的函数名和函数体加入 tp_dict 的过程，里面的 add_operators 、 add_methods 、 add_members 、 add_getset 都是完成填充 tp_dict 的动作。</p>
<p>那么这时候一个问题就出现了，以整数的 __sub__ 为例，我们知道它会对应底层的 C 函数 long_sub，可虚拟机是如何知道 __sub__ 和 long_sub 之间存在关联的呢？其实这种关联显然是一开始就已经定好了的，存放在一个名为 slotdefs 的数组中。</p>
<h3 id="slot-与操作排序"><a class="header" href="#slot-与操作排序">slot 与操作排序</a></h3>
<p>在进入填充 tp_dict 的复杂操作之前，我们先来看一个概念：slot。slot 可以视为 PyTypeObject 中定义的操作，一个魔法函数对应一个 slot，比如 __add__、__sub__ 等等，都会对应一个 slot。我们看看 slot 的底层结构，它是由 slotdef 这个结构体来实现的，内部除了函数指针之外，它还包含了其它信息。</p>
<pre><code class="language-C">// Objects/typeobject.c
typedef struct wrapperbase slotdef;

//Include/descrobject.h
struct wrapperbase {
    const char *name;
    int offset;
    void *function;
    wrapperfunc wrapper;
    const char *doc;
    int flags;
    PyObject *name_strobj;
};
// 从定义上看，slot 不是一个 PyObject
</code></pre>
<p>slot 中存储着 PyTypeObject 的操作对应的各种信息，并且 PyTypeObject 对象中的每一个操作都会有一个 slot 与之对应。然后是里面每个字段的含义：</p>
<ul>
<li>name：暴露给 Python 的名称，比如 &quot;__sub__&quot;、&quot;__str__&quot; 等等。</li>
<li>offset：承载具体实现的 C 函数在 XXX 中的偏移量，至于这个 XXX 是什么，一会儿说。</li>
<li>function：承载具体实现的 C 函数。</li>
</ul>
<p>这里又整出来一个 PyHeapTypeObject，它是做什么的，别着急，我们先来看看如何创建一个 slot。Python 在底层提供了多个宏，其中最基本的是 TPSLOT 和 ETSLOT。</p>
<pre><code class="language-C">// Objects/typeobject.c
#define TPSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \
    {NAME, offsetof(PyTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \
     PyDoc_STR(DOC)}

#define ETSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \
    {NAME, offsetof(PyHeapTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \
     PyDoc_STR(DOC)}
</code></pre>
<p>所以 slot 里面的 offset 字段表示承载具体实现的 C 函数在 PyTypeObject 或 PyHeapTypeObject 中的偏移量。</p>
<pre><code class="language-C">// Include/cpython/object.h
typedef struct _heaptypeobject {
    PyTypeObject ht_type;
    PyAsyncMethods as_async;
    PyNumberMethods as_number;
    PyMappingMethods as_mapping;
    PySequenceMethods as_sequence; 
    PyBufferProcs as_buffer;
    PyObject *ht_name, *ht_slots, *ht_qualname;
    struct _dictkeysobject *ht_cached_keys;
} PyHeapTypeObject;
</code></pre>
<p>这个 PyHeapTypeObject 是为自定义类对象准备的，它的第一个字段就是 PyTypeObject，至于其它的则是操作簇。至于为什么要有这么一个对象，原因是自定义类对象和相关的操作簇在内存中是连续的，必须在运行时动态分配内存，所以它是为自定义类准备的（具体细节后续剖析）。</p>
<p>那么这里就产生了一个问题，假设我们定义了一个类继承自 int，根据继承关系，显然自定义的类是具有 PyNumberMethods 这个操作簇的，它可以使用 __add__、__sub__ 之类的魔法函数。</p>
<p>但操作簇是定义在 PyTypeObject 里面的，而此时的 offset 却是基于 PyHeapTypeObject 得到的偏移量，那么通过这个 offset 显然无法准确找到操作簇里面的函数指针，比如 long_add、long_sub 等等。那我们要这个 offset 还有何用呢？答案非常诡异，这个 offset 是用来对操作进行排序的。排序？我整个人都不好了。</p>
<p><img src="./images/239.png" alt="" /></p>
<p>不过在理解为什么要对操作进行排序之前，需要先看看底层预定义的 slot 集合 slotdefs。</p>
<pre><code class="language-C">// Objects/typeobject.c
#define BINSLOT(NAME, SLOT, FUNCTION, DOC) \
    ETSLOT(NAME, as_number.SLOT, FUNCTION, wrap_binaryfunc_l, \
           NAME &quot;($self, value, /)\n--\n\nReturn self&quot; DOC &quot;value.&quot;)

#define RBINSLOT(NAME, SLOT, FUNCTION, DOC) \
    ETSLOT(NAME, as_number.SLOT, FUNCTION, wrap_binaryfunc_r, \
           NAME &quot;($self, value, /)\n--\n\nReturn value&quot; DOC &quot;self.&quot;)

#define SQSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \
    ETSLOT(NAME, as_sequence.SLOT, FUNCTION, WRAPPER, DOC)

#define MPSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \
    ETSLOT(NAME, as_mapping.SLOT, FUNCTION, WRAPPER, DOC)


static slotdef slotdefs[] = {
    // ...
  
    /* name = &quot;__repr__&quot;
     * offset = offsetof(PyTypeObject, tp_repr)
     * function = slot_tp_repr
     * wrapper = wrap_unaryfunc
     */
    TPSLOT(&quot;__repr__&quot;, tp_repr, slot_tp_repr, wrap_unaryfunc,
           &quot;__repr__($self, /)\n--\n\nReturn repr(self).&quot;),
  
    /* name = &quot;__hash__&quot;
     * offset = offsetof(PyTypeObject, tp_hash)
     * function = slot_tp_hash
     * wrapper = wrap_hashfunc
     */
    TPSLOT(&quot;__hash__&quot;, tp_hash, slot_tp_hash, wrap_hashfunc,
           &quot;__hash__($self, /)\n--\n\nReturn hash(self).&quot;),
    FLSLOT(&quot;__call__&quot;, tp_call, slot_tp_call, (wrapperfunc)(void(*)(void))wrap_call,
           &quot;__call__($self, /, *args, **kwargs)\n--\n\nCall self as a function.&quot;,
           PyWrapperFlag_KEYWORDS),
    TPSLOT(&quot;__str__&quot;, tp_str, slot_tp_str, wrap_unaryfunc,
           &quot;__str__($self, /)\n--\n\nReturn str(self).&quot;),
    TPSLOT(&quot;__getattribute__&quot;, tp_getattro, slot_tp_getattr_hook,
           wrap_binaryfunc,
           &quot;__getattribute__($self, name, /)\n--\n\nReturn getattr(self, name).&quot;),
    // ...
  
    /* name = &quot;__new__&quot;
     * offset = offsetof(PyTypeObject, tp_new)
     * function = slot_tp_new
     * wrapper = NULL
     */
    TPSLOT(&quot;__new__&quot;, tp_new, slot_tp_new, NULL,
           &quot;__new__(type, /, *args, **kwargs)\n--\n\n&quot;
           &quot;Create and return new object.  See help(type) for accurate signature.&quot;),
  
    /* name = &quot;__del__&quot;
     * offset = offsetof(PyTypeObject, tp_finalize)
     * function = slot_tp_finalize
     * wrapper = wrap_del
     */
    TPSLOT(&quot;__del__&quot;, tp_finalize, slot_tp_finalize, (wrapperfunc)wrap_del, &quot;&quot;),
  
    // ...
  
    /* name = &quot;__add__&quot;
     * offset = offsetof(PyHeapTypeObject, as_number.nb_add)
     * function = slot_nb_add
     * wrapper = wrap_binaryfunc_l
     */  
    BINSLOT(&quot;__add__&quot;, nb_add, slot_nb_add,
           &quot;+&quot;),
    /* name = &quot;__radd__&quot;
     * offset = offsetof(PyHeapTypeObject, as_number.nb_add)
     * function = slot_nb_add
     * wrapper = wrap_binaryfunc_r
     */  
    RBINSLOT(&quot;__radd__&quot;, nb_add, slot_nb_add,
           &quot;+&quot;),
    BINSLOT(&quot;__sub__&quot;, nb_subtract, slot_nb_subtract,
           &quot;-&quot;),
    RBINSLOT(&quot;__rsub__&quot;, nb_subtract, slot_nb_subtract,
           &quot;-&quot;),
    BINSLOT(&quot;__mul__&quot;, nb_multiply, slot_nb_multiply,
           &quot;*&quot;),
    RBINSLOT(&quot;__rmul__&quot;, nb_multiply, slot_nb_multiply,
           &quot;*&quot;),
    BINSLOT(&quot;__mod__&quot;, nb_remainder, slot_nb_remainder,
           &quot;%&quot;),
    RBINSLOT(&quot;__rmod__&quot;, nb_remainder, slot_nb_remainder,
           &quot;%&quot;),
    // ...
    /* name = &quot;__getitem__&quot;
     * offset = offsetof(PyHeapTypeObject, as_mapping.mp_subscript)
     * function = slot_mp_subscript
     * wrapper = wrap_binaryfunc
     */ 
    MPSLOT(&quot;__getitem__&quot;, mp_subscript, slot_mp_subscript,
           wrap_binaryfunc,
           &quot;__getitem__($self, key, /)\n--\n\nReturn self[key].&quot;),
    
    // ...
    /* name = &quot;__getitem__&quot;
     * offset = offsetof(PyHeapTypeObject, as_sequence.sq_item)
     * function = slot_sq_item
     * wrapper = wrap_sq_item
     */ 
    SQSLOT(&quot;__getitem__&quot;, sq_item, slot_sq_item, wrap_sq_item,
           &quot;__getitem__($self, key, /)\n--\n\nReturn self[key].&quot;),
}
</code></pre>
<p>在 slotdefs 中可以发现，操作名和操作并不是一一对应的，存在多个操作对应同一个操作名、或者多个操作名对应同一个操作的情况。那么在填充 tp_dict 时，就会出现问题，比如 __getitem__，在 tp_dict 中与其对应的是 mp_subscript 还是 sq_item 呢？这两者都是通过 [] 进行操作的，比如字典根据 key 获取 value、列表基于索引获取元素，对应的都是 __getitem__。</p>
<p>为了解决这个问题，就需要利用 slot 中的 offset 信息对 slot（也就是操作）进行排序。回顾一下 PyHeapTypeObject 的定义，与一般的 struct 定义不同，它的各个字段的顺序是非常关键的，在顺序中隐含着操作优先级的问题。</p>
<p><img src="./images/240.png" alt="" /></p>
<p>在 PyHeapTypeObject 中，PyMappingMethods 的位置在 PySequenceMethods 之前，mp_subscript 是 PyMappingMethods 中的一个函数指针，而 sq_item 又是 PySequenceMethods 中的一个函数指针。那么最终计算出来的偏移量就存在如下关系：</p>
<pre><code class="language-C">offset(mp_subscript) &lt; offset(sq_item)
</code></pre>
<p>因此如果在一个 PyTypeObject 中，既定义了 mp_subscript，又定义了 sq_item，那么虚拟机将选择 mp_subscript 与 __getitem__ 建立联系。我们举个栗子：</p>
<pre><code class="language-Python">class A(list):

    def __getitem__(self, item):
        return item


a = A([])
print(a)  # []
print(a[0])  # 0
print(a[&quot;xxx&quot;])  # xxx
</code></pre>
<p>我们自定义的类实现了 __getitem__，所以会对应 mp_subscript 或 sq_item，那么到底是哪一种呢？显然根据偏移量的关系，虚拟机最终选择了让 mp_subscript 和 __getitem__ 建立联系。</p>
<p>事实上不看偏移量我们也知道答案，因为 sq_item 表示基于索引取值，如果 [] 里面的值是字符串，那么铁定报错。但这里没有报错，说明和 __getitem__ 建立联系的不是 sq_item。</p>
<blockquote>
<p>注：如果是针对内置类对象，则没有这么复杂，因为它们的操作在底层是静态写死的。但对于自定义类对象来说，需要有一个基于偏移量排序、查找的过程。</p>
</blockquote>
<h3 id="slot-变成-descriptor"><a class="header" href="#slot-变成-descriptor">slot 变成 descriptor</a></h3>
<p>看一下之前的一张图：</p>
<p><img src="./images/241.png" alt="" /></p>
<p>当时说 &quot;__sub__&quot; 对应的 value 并不是一个直接指向 long_sub 函数的指针，而是指向一个结构体，至于指向 long_sub 函数的指针则在该结构体内部。那么问题来了，这个结构体是不是上面的 slot 呢？</p>
<p>我们知道在 slot 中，包含了一个操作的相关信息。但是很可惜，在 tp_dict 中，与 &quot;__sub__&quot; 关联在一起的，一定不会是 slot，因为它不是一个 PyObject，无法将其指针放在字典中。如果再深入思考一下，会发现 slot 也无法被调用。因为它不是一个 PyObject，那么它就没有 ob_type 这个字段，也就无从谈起什么 tp_call 了，所以 slot 是无论如何也无法满足 Python 中可调用（callable）这一条件的。</p>
<p>前面我们说过，虚拟机在 tp_dict 中找到对应的操作后，会调用该操作，所以 tp_dict 中与 &quot;__sub__&quot; 对应的只能是包装了 slot 的 PyObject（的指针），我们称之为 wrapper descriptor。在 Python 内部存在多种 wrapper descriptor，它在底层对应的结构体为 PyWrapperDescrObject。</p>
<pre><code class="language-c">// Include/descrobject.h
typedef struct {
    PyObject_HEAD
    PyTypeObject *d_type;
    PyObject *d_name;
    PyObject *d_qualname;
} PyDescrObject;

#define PyDescr_COMMON PyDescrObject d_common

typedef struct {
    // 相当于 PyDescrObject d_common
    PyDescr_COMMON;
    // slot
    struct wrapperbase *d_base;
    // 函数指针
    void *d_wrapped;
} PyWrapperDescrObject;
</code></pre>
<p>以上就是 wrapper descriptor 在底层的定义，一个 wrapper descriptor 包含一个 slot，其创建是通过 PyDescr_NewWrapper 完成的。</p>
<pre><code class="language-C">// Objects/descrobject.c
PyObject *
PyDescr_NewWrapper(PyTypeObject *type, struct wrapperbase *base, void *wrapped)
{
    // 声明 wrapper descriptor 指针
    PyWrapperDescrObject *descr;
    // 调用 descr_new 申请内存
    descr = (PyWrapperDescrObject *)descr_new(&amp;PyWrapperDescr_Type,
                                             type, base-&gt;name);
    // 设置字段属性
    if (descr != NULL) {
        descr-&gt;d_base = base;
        descr-&gt;d_wrapped = wrapped;
    }
    return (PyObject *)descr;
}

static PyDescrObject *
descr_new(PyTypeObject *descrtype, PyTypeObject *type, const char *name)
{
    PyDescrObject *descr;
    // 为 PyDescrObject 申请内存
    descr = (PyDescrObject *)PyType_GenericAlloc(descrtype, 0);
    // 设置字段属性
    if (descr != NULL) {
        Py_XINCREF(type);
        descr-&gt;d_type = type;
        descr-&gt;d_name = PyUnicode_InternFromString(name);
        if (descr-&gt;d_name == NULL) {
            Py_DECREF(descr);
            descr = NULL;
        }
        else {
            descr-&gt;d_qualname = NULL;
        }
    }
    return descr;
}
</code></pre>
<p>Python 内部的各种 wrapper descriptor 都会包含 PyDescrObject，也就是类型对象相关的一些信息；d_base 对应 slot；而 d_wrapped 则存放着最重要的东西：操作对应的函数指针，比如 PyLong_Type，其 <font color="blue">tp_dict[&quot;__sub__&quot;].d_wrapped</font> 就是 &amp;long_sub。</p>
<pre><code class="language-python">print(int.__sub__)
print(str.__add__)
print(str.__getitem__)
print(tuple.__hash__)
&quot;&quot;&quot;
&lt;slot wrapper '__sub__' of 'int' objects&gt;
&lt;slot wrapper '__add__' of 'str' objects&gt;
&lt;slot wrapper '__getitem__' of 'str' objects&gt;
&lt;slot wrapper '__hash__' of 'tuple' objects&gt;
&quot;&quot;&quot;
</code></pre>
<p>我们看到这些魔法函数都是一个 wrapper descriptor 对象，也就是对 slot 包装之后的描述符。wrapper descriptor 对象在底层对应 PyWrapperDescrObject，其类型是 PyWrapperDescr_Type，tp_call 为 wrapperdescr_call。</p>
<pre><code class="language-Python">print(int.__sub__.__class__)
print(str.__add__.__class__)
print(str.__getitem__.__class__)
print(tuple.__hash__.__class__)
&quot;&quot;&quot;
&lt;class 'wrapper_descriptor'&gt;
&lt;class 'wrapper_descriptor'&gt;
&lt;class 'wrapper_descriptor'&gt;
&lt;class 'wrapper_descriptor'&gt;
&quot;&quot;&quot;
# int.__sub__ 等价于 int.__dict__[&quot;__sub__&quot;]
print(int.__dict__[&quot;__sub__&quot;].__class__)
&quot;&quot;&quot;
&lt;class 'wrapper_descriptor'&gt;
&quot;&quot;&quot;
</code></pre>
<p>打印的结果是 &lt;class 'wrapper_descriptor'&gt;，说明类型对象 wrapper_descriptor 在底层对应 PyWrapperDescr_Type。</p>
<p><img src="./images/242.png" alt="" /></p>
<p>所以内置类对象的属性字典中存储的是字符串到 wrapper descriptor 的映射。</p>
<h3 id="建立联系"><a class="header" href="#建立联系">建立联系</a></h3>
<p>slotdefs 里面包含了一堆 slot，每个 slot 对应类型对象定义的一个操作，比如 __getattr__、__new__、__add__、__getitem__ 等等。当然啦，虚拟机还会对 slotdefs 进行排序，排序之后再从头到尾遍历 slotdefs，基于每个 slot 创建一个 wrapper descriptor。然后在 tp_dict 中再建立从操作名到 wrapper descriptor 的映射，这个过程是在 add_operators 中完成的。</p>
<p><img src="./images/243.png" alt="" /></p>
<p>我们看一下 add_operators 的逻辑。</p>
<pre><code class="language-C">static int slotdefs_initialized = 0;

static void
init_slotdefs(void)
{
    slotdef *p;
    if (slotdefs_initialized)
        return;
    for (p = slotdefs; p-&gt;name; p++) {
        assert(!p[1].name || p-&gt;offset &lt;= p[1].offset);
        // slot 有一个 name 字段和一个 name_strobj 字段
        // 它们都是暴露给 Python 的操作名，只不过一个是 C 字符串，一个是 Python 字符串
        // 基于 C 字符串创建 Python 字符串
        p-&gt;name_strobj = PyUnicode_InternFromString(p-&gt;name);
        if (!p-&gt;name_strobj || !PyUnicode_CHECK_INTERNED(p-&gt;name_strobj))
            Py_FatalError(&quot;Out of memory interning slotdef names&quot;);
    }
    // 该操作只会执行一次
    slotdefs_initialized = 1;
}

static int
add_operators(PyTypeObject *type)
{
    // 属性字典
    PyObject *dict = type-&gt;tp_dict;
    // slot，在底层是一个 slotdef 结构体
    slotdef *p;
    // wrapper descriptor
    PyObject *descr;
    void **ptr;
    // 而 init_slotdefs 就是基于 C 字符串创建 Python 字符串
    // p-&gt;name_strobj = PyUnicode_InternFromString(p-&gt;name);
    init_slotdefs();
    for (p = slotdefs; p-&gt;name; p++) {
        // 如果 slot 中没有指定 wrapper，则无需处理
        if (p-&gt;wrapper == NULL)
            continue;
        // 获取 slot 对应的操作在 PyTypeObject 中的函数指针
        ptr = slotptr(type, p-&gt;offset);
        if (!ptr || !*ptr)
            continue;
        // 如果 tp_dict 中已经存在操作名，则放弃
        if (PyDict_GetItemWithError(dict, p-&gt;name_strobj))
            continue;
        if (PyErr_Occurred()) {
            return -1;
        }
        if (*ptr == (void *)PyObject_HashNotImplemented) {
            if (PyDict_SetItem(dict, p-&gt;name_strobj, Py_None) &lt; 0)
                return -1;
        }
        else {
            // 创建 wrapper descriptor
            descr = PyDescr_NewWrapper(type, p, *ptr);
            if (descr == NULL)
                return -1;
            // 将 &quot;操作名&quot;: wapper descriptor 放入 tp_dict 中
            if (PyDict_SetItem(dict, p-&gt;name_strobj, descr) &lt; 0) {
                Py_DECREF(descr);
                return -1;
            }
            Py_DECREF(descr);
        }
    }
    if (type-&gt;tp_new != NULL) {
        if (add_tp_new_wrapper(type) &lt; 0)
            return -1;
    }
    return 0;
}
</code></pre>
<p>在 add_operators 中，首先调用 init_slotdefs，然后遍历 slotdefs 数组，通过 slotptr 获取该 slot 对应的操作在 PyTypeObject 中的函数指针。紧接着创建 wrapper descriptor，然后在 tp_dict 中建立从操作名（slotdef.name_strobj）到操作（wrapper descriptor）的映射。</p>
<p>但需要注意的是，在创建 wrapper descriptor 之前，虚拟机会检查在 tp_dict 中是否存在同名操作，如果存在了，则不会再次建立从操作名到操作的关联。也正是这种检查机制与排序机制相结合，虚拟机才能在拥有相同操作名的多个操作中选择优先级最高的操作。</p>
<p>add_operators 里面的大部分动作都很简单、直观，而最难的动作隐藏在 slotptr 这个函数当中，它的功能是完成从 <font color="blue">slot</font> 到 <font color="blue">slot 对应操作的真实函数指针</font>的转换。我们知道在 slot 中存放着用来操作的 offset，但不幸的是，对于自定义类的操作簇来说，这个 offset 是相对于 PyHeapTypeObject 的偏移，而操作的真实函数指针却是在 PyTypeObject 中指定的。</p>
<p>此外 PyTypeObject 和 PyHeapTypeObject 也不是同构的，因为 PyHeapTypeObject 中包含了 PyNumberMethods 结构体，但 PyTypeObject 只包含了 PyNumberMethods * 指针。所以 slot 中存储的关于操作的 offset 对 PyTypeObject 来说，不能直接用，必须先转换。</p>
<p>举个栗子，假如有以下调用（slotptr 一会说）：</p>
<pre><code class="language-C">slotptr(&amp;PyLong_Type, offset(PyHeapTypeObject, long_sub))
</code></pre>
<p>首先会判断这个偏移量是否大于 <font color="blue">offset(PyHeapTypeObject, as_number)</font>，所以会从 PyHeapTypeObject 对象中获取 as_number 字段的指针 p，然后在 p 的基础上进行偏移就可以得到实际的函数地址。所以偏移量 delta 为：</p>
<pre><code class="language-C">offset(PyHeapTypeObject, long_sub) - offset(PyHeapTypeObject, as_number)
</code></pre>
<p>而这个复杂的过程就在 slotptr 中完成：</p>
<pre><code class="language-c">static void **
slotptr(PyTypeObject *type, int ioffset)
{
    char *ptr;
    long offset = ioffset;

    /* Note: this depends on the order of the members of PyHeapTypeObject! */
    assert(offset &gt;= 0);
    assert((size_t)offset &lt; offsetof(PyHeapTypeObject, as_buffer));
    // 从 PyHeapTypeObject 中排在后面的 PySequenceMethods 开始判断
    // 然后向前，依次判断 PyMappingMethods 和 PyNumberMethods
    /*
     * 为什么要这么做呢？假设我们首先从 PyNumberMethods 开始判断
     * 如果一个操作的 offset 大于 as_numbers 在 PyHeapTypeObject 中的偏移量
     * 那么我们还是没办法确认这个操作到底是属于谁的
     * 只有从后往前进行判断，才能解决这个问题。
     */ 
    if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_sequence)) {
        ptr = (char *)type-&gt;tp_as_sequence;
        offset -= offsetof(PyHeapTypeObject, as_sequence);
    }
    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_mapping)) {
        ptr = (char *)type-&gt;tp_as_mapping;
        offset -= offsetof(PyHeapTypeObject, as_mapping);
    }
    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_number)) {
        ptr = (char *)type-&gt;tp_as_number;
        offset -= offsetof(PyHeapTypeObject, as_number);
    }
    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_async)) {
        ptr = (char *)type-&gt;tp_as_async;
        offset -= offsetof(PyHeapTypeObject, as_async);
    }
    else {
        ptr = (char *)type;
    }
    if (ptr != NULL)
        ptr += offset;
    return (void **)ptr;
}
</code></pre>
<p>好了，到现在我们应该能够摸清楚虚拟机在改造 PyTypeObject 对象时，对 tp_dict 做了什么了，我们以 PyLong_Type 举例说明：</p>
<p><img src="./images/244.png" alt="" /></p>
<p>在 add_operators 完成之后，PyLong_Type 如图所示。</p>
<p>从 PyLong_Type.tp_as_number 中延伸出去的部分是在编译时就已经确定好了的，而从 tp_dict 中延伸出去的部分则是在 <font color="blue">Python 运行时环境初始化</font>的时候才建立的。这个运行时环境初始化后面会单独说，现在就把它理解为解释器启动时做的准备工作即可。</p>
<p>另外， PyType_Ready 在通过 add_operators 添加了 PyTypeObject 中定义的一些 operator 后，还会通过 add_methods、add_numbers 和 add_getsets 添加 PyTypeObject 中定义的 tp_methods、tp_members 和 tp_getset 函数集。</p>
<p>这些过程和 add_operators 类似，不过最后添加到 tp_dict 中的就不再是 PyWrapperDescrObject ，而分别是 PyMethodDescrObject、PyMemberDescrObject、PyGetSetDescrObject 。</p>
<pre><code class="language-Python">print(int.__add__)
print((123).__add__)
&quot;&quot;&quot;
&lt;slot wrapper '__add__' of 'int' objects&gt;
&lt;method-wrapper '__add__' of int object at 0x100be5030&gt;
&quot;&quot;&quot;

print(int.__add__.__class__)
print((123).__add__.__class__)
&quot;&quot;&quot;
&lt;class 'wrapper_descriptor'&gt;
&lt;class 'method-wrapper'&gt;
&quot;&quot;&quot;
</code></pre>
<p>实例在调用函数的时候，会将函数包装成方法，它是一个 wrapper method。所以 __add__ 对于 int 类型对象而言，叫魔法函数，对于整数对象而言，叫魔法方法。</p>
<pre><code class="language-c">// 像 str.__add__、int.__sub__，它们都是 wrapper descriptor
// 在底层对应 PyWrapperDescrObject 结构体实例

// 而像 &quot;hello&quot;.__add__、(123).__sub__，它们都是 wrapper method
// 在底层对应 wrapperobject 结构体实例
// 但是我们看到 wrapperobject 只是多了一个 self 而已
// 所以 &quot;hello&quot;.upper() 等价于 str.upper(&quot;hello&quot;)
typedef struct {
    PyObject_HEAD
    PyWrapperDescrObject *descr;
    PyObject *self;
} wrapperobject;
// 关于函数和方法的区别后续还会细说
</code></pre>
<p>从目前来看，基本上算是解析完了，但是还有一点：</p>
<pre><code class="language-Python">class A(int):
    def __sub__(self, other):
        return self, other

a = A(123)
print(a - 456)  # (123, 456)
</code></pre>
<p>从结果上很容易看出，进行减法操作时，调用的是我们重写的 __sub__。这意味着虚拟机在初始化 A 的时候，对 tp_as_number 中的 nb_subtract 进行了特殊处理。那为什么虚拟机会知道要对 nb_subtract 进行特殊处理呢？当然肯定有小伙伴会说：这是因为我们重写了 __sub__ 啊，确实如此，但这是 Python 层面上的，如果站在虚拟机层面的话，答案还是在 slot 身上。</p>
<p><img src="./images/245.png" alt="" /></p>
<p>虚拟机在初始化类对象 A 时，会检测出 A 的 tp_dict 中存在 __sub__。在后面剖析自定义类对象的创建时会看到，因为在定义 class A 的时候，重写了 __sub__ 这个操作，所以在 A 的 tp_dict 中，__sub__ 一开始就会存在，虚拟机会检测到。</p>
<p>然后再根据 __sub__ 对应的 slot 顺藤摸瓜，找到 nb_substract，并且将这个函数指针替换为 slot 中指定的 &amp;slot_nb_subtract。所以当后来虚拟机找 A 的 nb_substract 的时候，实际上找到的是 slot_nb_subtract。而在 slot_nb_subtract 中，会寻找 __sub__ 对应的描述符，然后找到在 A 中重写的函数（一个 PyFunctionObject *）。这样一来，就完成了对 int 的 __sub__ 行为的替换。</p>
<p>所以对于 A 来说，内存布局就是下面这样。</p>
<p><img src="./images/246.png" alt="" /></p>
<p>当然这仅仅是针对于 __sub__，至于其它操作还是会指向 PyLong_Type 中指定的函数。所以如果某个函数在 A 里面没有重写的话，那么会从 PyLong_Type 中寻找。</p>
<p>以上就是属性字典的填充，这个过程还是稍微有点复杂的。</p>
<h2 id="类对象-mro-的设置与属性继承"><a class="header" href="#类对象-mro-的设置与属性继承">类对象 MRO 的设置与属性继承</a></h2>
<p>当完成属性字典的设置，就开始确定 MRO 了，即 method resolve order。</p>
<h3 id="类对象-mro-的设置"><a class="header" href="#类对象-mro-的设置">类对象 MRO 的设置</a></h3>
<p>MRO 表示类继承之后，属性或方法的查找顺序。如果 Python 是单继承的话，那么这不是问题，直接一层一层向上找即可。但 Python 是支持多继承的，那么在多继承时，继承的顺序就成为了一个必须考虑的问题。</p>
<pre><code class="language-Python">class A:
    def foo(self):
        print(&quot;A&quot;)

class B(A):
    def foo(self):
        print(&quot;B&quot;)

class C(A):
    def foo(self):
        print(&quot;C&quot;)
        self.bar()

    def bar(self):
        print(&quot;bar C&quot;)

class D(C, B):
    def bar(self):
        print(&quot;bar D&quot;)

d = D()
d.foo()
&quot;&quot;&quot;
C
bar D
&quot;&quot;&quot;
</code></pre>
<p>首先打印的是字符串 &quot;C&quot;，表示调用的是 C 的 foo，说明把 C 写在前面，会先从 C 里面查找。但是下面打印了 &quot;bar D&quot;，这是因为 C 里面的 self 实际上是 D 的实例对象。</p>
<p>因为 D 在找不到 foo 函数的时候，会到父类里面找，但是同时也会将 self 传递过去。调用 self.bar 的时候，这个 self 是 D 的实例对象，所以还是会先到 D 里面找，如果找不到再去父类里面找。</p>
<p>而对于虚拟机而言，则是会在 PyType_Ready 中通过 mro_internal 函数确定 mro。虚拟机将创建一个 PyTupleObject 对象，里面存放一组类对象，这些类对象的顺序就是虚拟机确定的 mro。而这个元组，最终会被交给 tp_mro 字段保存。</p>
<p>由于确定 MRO 的 mro_internal 函数非常复杂，这里我们就不看源码了，只要能从概念上理解它即可。另外 Python 早期有经典类和新式类两种，现在则只存在新式类，而经典类和新式类采用的搜索策略是不同的，举个例子：</p>
<p><img src="./images/247.png" alt="" /></p>
<p>图中的箭头表示继承关系，比如：A 同时继承 B 和 C、B 继承 D、C 继承 E。</p>
<p>对于上图来说，经典类和新式类的查找方式是一样的，至于两边是否一样多则不重要。查找方式是先从 A 找到 I，再从 C 查找到 G。我们实际演示一下，由于经典类只在 Python2 中存在，所以下面只演示新式类。</p>
<pre><code class="language-python">I = type(&quot;I&quot;, (), {})
H = type(&quot;H&quot;, (I,), {})
F = type(&quot;F&quot;, (H,), {})
G = type(&quot;G&quot;, (), {})
D = type(&quot;D&quot;, (F,), {})
E = type(&quot;E&quot;, (G,), {})
B = type(&quot;B&quot;, (D,), {})
C = type(&quot;C&quot;, (E,), {})
A = type(&quot;A&quot;, (B, C), {})

for _ in A.__mro__:
    print(_)

&quot;&quot;&quot;
&lt;class '__main__.A'&gt;
&lt;class '__main__.B'&gt;
&lt;class '__main__.D'&gt;
&lt;class '__main__.F'&gt;
&lt;class '__main__.H'&gt;
&lt;class '__main__.I'&gt;
&lt;class '__main__.C'&gt;
&lt;class '__main__.E'&gt;
&lt;class '__main__.G'&gt;
&lt;class 'object'&gt;
&quot;&quot;&quot;
</code></pre>
<p>A 继承两个类，然后这两个类分别继续继承，如果最终没有继承公共的类（忽略 object），那么经典类和新式类是一样的。像这种泾渭分明、各自继承各自的，都是先一条路找到黑，然后再去另外一条路找。</p>
<p>但如果是下面这种，分久必合、两者最终又继承了同一个类，那么经典类还是跟以前一样，按照每一条路都走到黑的方式。但是对于新式类，则是先从 A 找到 H，而 I 这个两边最终都继承的类不找了，然后从 C 找到 I，也就是在另一条路找到头。</p>
<p><img src="./images/248.png" alt="" /></p>
<p>我们测试一下：</p>
<pre><code class="language-Python"># 新式类
I = type(&quot;I&quot;, (), {})
H = type(&quot;H&quot;, (I,), {})
F = type(&quot;F&quot;, (H,), {})
G = type(&quot;G&quot;, (I,), {})   # 这里让 G 继承 I
D = type(&quot;D&quot;, (F,), {})
E = type(&quot;E&quot;, (G,), {})
B = type(&quot;B&quot;, (D,), {})
C = type(&quot;C&quot;, (E,), {})
A = type(&quot;A&quot;, (B, C), {})

for _ in A.__mro__:
    print(_)

&quot;&quot;&quot;
&lt;class '__main__.A'&gt;
&lt;class '__main__.B'&gt;
&lt;class '__main__.D'&gt;
&lt;class '__main__.F'&gt;
&lt;class '__main__.H'&gt;
&lt;class '__main__.C'&gt;
&lt;class '__main__.E'&gt;
&lt;class '__main__.G'&gt;
&lt;class '__main__.I'&gt;
&lt;class 'object'&gt;
&quot;&quot;&quot;
</code></pre>
<p>但是 Python 的多继承比我们想象的要复杂，原因就在于可以任意继承，如果 B 和 C 再分别继承两个类呢？那么我们这里的线路就又要多出两条了。不过既然要追求刺激，就贯彻到底喽，我们来看一下，如何从混乱不堪的继承关系中，找到正确的继承顺序。</p>
<blockquote>
<p>由于 Python3 只有新式类，因此下面我们会以介绍新式类为主，经典类了解一下即可。</p>
</blockquote>
<p>很多文章可能告诉你经典类采用深度优先算法，新式类采用广度优先算法，真的是这样吗？我们举一个例子：</p>
<p><img src="./images/249.png" alt="" /></p>
<p>假设我们调用 A() 的 foo 方法，但是 A 里面没有，那么理所应当会去 B 里面找。但是 B 里面也没有，而 C 和 D 里面有，那么这个时候是去 C 里面找还是去 D 里面找呢？根据我们之前的结论，显然是去 D 里面找，可如果按照广度优先的逻辑来说，那么应该是去 C 里面找啊。所以广度优先理论在这里就不适用了，因为 B 继承了 D，而 B 和 C 并没有直接关系，我们应该把 B 和 D 看成一个整体。</p>
<p>而 Python 的 MRO 实际上是采用了一种叫做 C3 的算法，这个 C3 算法比较复杂（其实也不算复杂），但是我个人总结出一个更加好记的结论，如下：</p>
<blockquote>
<p>当沿着一条继承链寻找类时，默认会沿着该继承链一直找下去。但如果发现某个类出现在了另一条继承链当中，那么当前的继承链的搜索就会结束，然后在&quot;最开始&quot;出现分歧的地方转向下一条继承链的搜索。</p>
</blockquote>
<p>这是我个人总结的，或许光看字面意思的话会比较难理解，但是通过例子就能明白了。</p>
<p><img src="./images/250.png" alt="" /></p>
<p>箭头表示继承关系，继承顺序是从左到右，比如这里的 A 就相当于 <font color="blue">class A(B, C)</font>，下面我们来从头到尾分析一下 A 的 MRO。</p>
<ul>
<li>1）因为是 A 的 MRO，所以查找时，第一个类就是 A；</li>
<li>2）然后 A 继承 B 和 C，由于是两条路，因此我们说 A 这里就是一个分歧点。但由于 B 在前，所以接下来是 B，而现在 MRO 的顺序就是 A B；</li>
<li>3）但是 B 这里也出现了分歧点，不过不用管，因为我们说会沿着继承链不断往下搜索，现在 MRO 的顺序是A B D；</li>
<li>4）然后从 D 开始继续寻找，这里注意了，按理说会找到 G 的。但是 G 不止被一个类继承，也就是说沿着当前的继承链查找 G 时，发现 G 还出现在了其它的继承链当中。怎么办？显然要回到最初的分歧点，转向下一条继承链的搜索；</li>
<li>5）最初的分歧点是 A，那么该去找 C 了，现在 MRO 的顺序就是 A B D C；</li>
<li>6）注意 C 这里也出现了分歧点，而 A 的两条分支已经结束了，所以现在 C 就是最初的分歧点了。而 C 继承自 E 和 F，显然要搜索 E，那么此时 MRO 的顺序就是 A B D C E；</li>
<li>7）然后从 E 开始搜索，显然要搜索 G，此时 MRO 顺序变成 A B D C E G；</li>
<li>8）从 G 要搜索 I，此时 MRO 的顺序是 A B D C E G I；</li>
<li>9）从 I 开始搜索谁呢？由于 J 出现在了其它的继承链中，那么要回到最初的分歧点，也就是 C。那么下面显然要找 F，此时 MRO 的顺序是 A B D C E G I F；</li>
<li>10）F 只继承了 H，那么肯定要找 H，此时 MRO 的顺序是 A B D C E G I F H；</li>
<li>11）H 显然只能找 J 了，因此最终 A 的 MRO 的顺序就是 A B D C E G I F H J object；</li>
</ul>
<p>我们实际测试一下：</p>
<pre><code class="language-Python">J = type(&quot;J&quot;, (object, ), {})
I = type(&quot;I&quot;, (J, ), {})
H = type(&quot;H&quot;, (J, ), {})
G = type(&quot;G&quot;, (I, ), {})
F = type(&quot;F&quot;, (H, ), {})
E = type(&quot;E&quot;, (G, H), {})
D = type(&quot;D&quot;, (G, ), {})
C = type(&quot;C&quot;, (E, F), {})
B = type(&quot;B&quot;, (D, E), {})
A = type(&quot;A&quot;, (B, C), {})

# A B D C E G I F H J
for _ in A.__mro__:
    print(_)
&quot;&quot;&quot;
&lt;class '__main__.A'&gt;
&lt;class '__main__.B'&gt;
&lt;class '__main__.D'&gt;
&lt;class '__main__.C'&gt;
&lt;class '__main__.E'&gt;
&lt;class '__main__.G'&gt;
&lt;class '__main__.I'&gt;
&lt;class '__main__.F'&gt;
&lt;class '__main__.H'&gt;
&lt;class '__main__.J'&gt;
&lt;class 'object'&gt;
&quot;&quot;&quot;
</code></pre>
<p>为了加深理解，我们再举个更复杂的例子：</p>
<p><img src="./images/251.png" alt="" /></p>
<ul>
<li>1）首先是 A，A 继承 B1、B2、B3，会先走 B1，此时 MRO 是 A B1。并且现在 A 是分歧点；</li>
<li>2）从 B1 处本来应该去找 C1，但是 C1 还被其它类继承，也就是出现在了其它的继承链当中。因此要回到最初的分歧点 A，从下一条继承链开始找，显然要找 B2，此时 MRO 就是 A B1 B2；</li>
<li>3）从 B2 开始，显然要找 C1，此时 MRO 的顺序就是 A B1 B2 C1；</li>
<li>4）从C1开始，显然要找 D1，因为 D1 只被 C1 继承，也就是说，它没有出现在另一条继承链当中，因此此时 MRO 的顺序是 A B1 B2 C1 D1；</li>
<li>5）对于 D1 而言，显然接下来是不会去找 E 的，因为 E 还出现在另外的继承链当中。咋办? 回到最初的分歧点，注意这里的分歧点还是 A，因为 A 的分支还没有走完。显然此时要走 B3，那么 MRO 的顺序就是 A B1 B2 C1 D1 B3；</li>
<li>6）从 B3 开始找，显然要找 C2，注意：A 的分支已经走完，此时 B3 就成了新的最初分歧点。现在 MRO 的顺序是 A B1 B2 C1 D1 B3 C2；</li>
<li>7）C2 会找 D2吗？显然不会，因为 D2 还被 C3 继承，所以它出现在了其它的继承链中。于是要回到最初的分歧点，这里是 B3，显然下面要找 C3。另外由于 B3 的分支也已经走完，所以现在 C3 就成了新的最初分歧点。此时 MRO 的顺序是 A B1 B2 C1 D1 B3 C2 C3；</li>
<li>8）从 C3 开始，显然要找 D2，此时 MRO 的顺序是 A B1 B2 C1 D1 B3 C2 C3 D2；</li>
<li>9）但是 D2 不会找 E，因此回到最初分歧点 C3，下面要找 D3。而 D3 找完之后显然只能再找 E 了，因此最终 MRO 的顺序是 A B1 B2 C1 D1 B3 C2 C3 D2 D3 E object；</li>
</ul>
<p>下面测试一下：</p>
<pre><code class="language-Python">E = type(&quot;E&quot;, (), {})
D1 = type(&quot;D1&quot;, (E,), {})
D2 = type(&quot;D2&quot;, (E,), {})
D3 = type(&quot;D3&quot;, (E,), {})
C1 = type(&quot;C1&quot;, (D1, D2), {})
C2 = type(&quot;C2&quot;, (D2,), {})
C3 = type(&quot;C3&quot;, (D2, D3), {})
B1 = type(&quot;B1&quot;, (C1,), {})
B2 = type(&quot;B2&quot;, (C1, C2), {})
B3 = type(&quot;B3&quot;, (C2, C3), {})
A = type(&quot;A&quot;, (B1, B2, B3), {})

for _ in A.__mro__:
    print(_)
&quot;&quot;&quot;
&lt;class '__main__.A'&gt;
&lt;class '__main__.B1'&gt;
&lt;class '__main__.B2'&gt;
&lt;class '__main__.C1'&gt;
&lt;class '__main__.D1'&gt;
&lt;class '__main__.B3'&gt;
&lt;class '__main__.C2'&gt;
&lt;class '__main__.C3'&gt;
&lt;class '__main__.D2'&gt;
&lt;class '__main__.D3'&gt;
&lt;class '__main__.E'&gt;
&lt;class 'object'&gt;
&quot;&quot;&quot;
</code></pre>
<p>以上就是计算 MRO 所采用的策略，关于源码部分我们就不看了，复杂是一方面，重点是没什么太大必要。个人觉得，关于多继承从目前这个层面上来理解已经足够了。另外通过以上可以看出，Python 支持非常复杂的继承关系。但是实际使用多继承的时候，我们最好还是要斟酌一下，因为多继承如果设计的不好，容易使得类的继承关系变得非常混乱。</p>
<blockquote>
<p>为此，Python 提供了一种模式叫做 Mixin，可以网上搜索一下。比较简单，这里就不展开了。</p>
</blockquote>
<p><font color="darkblue"><strong>self 在多继承里面的一些坑</strong></font></p>
<p>在执行父类函数时传入的 self 参数，是很多初学者容易犯的错误。</p>
<pre><code class="language-Python">class A:
    def foo(self):
        print(&quot;A: foo&quot;)
        self.bar()

    def bar(self):
        print(&quot;A: bar&quot;)


class B:
    def bar(self):
        print(&quot;B: bar&quot;)


class C(A, B):
    def bar(self):
        print(&quot;C: bar&quot;)


C().foo()
&quot;&quot;&quot;
A: foo
C: bar
&quot;&quot;&quot;
</code></pre>
<p>C 的实例对象在调用 foo 的时候，首先会去 C 里面查找，但是 C 没有，所以按照 MRO 的顺序会去 A 里面找。而 A 里面存在，所以调用，但是调用时传递的 self 是 C 的实例对象，因为是 C 的实例对象调用的。所以里面的 self.bar，这个 self 还是 C 的实例对象，那么调用 bar 的时候，会去哪里找呢？显然还是从 C 里面找，所以 self.bar() 的时候打印的是字符串 <font color="blue">C: bar</font>，而不是 <font color="blue">A: bar</font>。</p>
<p>同理再来看一个关于 super 的栗子：</p>
<pre><code class="language-Python">class A:
    def foo(self):
        super(A, self).foo()


class B:
    def foo(self):
        print(&quot;B: foo&quot;)


class C(A, B):
    pass


try:
    A().foo()
except Exception as e:
    print(e)  # 'super' object has no attribute 'foo'

# 首先 A 的父类是 object
# 所以 super(A, self).foo() 的时候会去执行 object 的 foo
# 而 object 没有 foo，所以报错


# 但如果是 C 的实例调用呢？
C().foo()  # B: foo
</code></pre>
<p>如果是 C() 调用 foo 的话，最终却执行了 B 的 foo，这是什么原因呢？首先 C 里面没有 foo，那么会去执行 A 的 foo，但是执行时候的 self 是 C 的实例对象，super 里面的 self 也是 C 里面的 self。</p>
<p>然后我们知道对于 C 而言，其 MRO 是 C、A、B、object。所以此时的 <font color="blue">super(A, self).foo()</font> 就表示：沿着 C 的 MRO 去找 foo 函数，但是 super 里面有一个 A，表示不要从头开始找，而是从 A 的后面开始找，所以下一个就找到 B 了。</p>
<p><strong>所以说 super 不一定就是父类，而是要看里面的 self 是谁。总之：super(xxx, self) 一定是 type(self) 对应的 MRO 中，xxx 的下一个类。再举个栗子：</strong></p>
<pre><code class="language-Python">class A:
    def foo(self):
        # 从 B 里面找 foo
        super(A, self).foo()
        # 从 C 里面找 foo
        super(B, self).foo()


class B:
    def foo(self):
        print(&quot;B: foo&quot;)


class C:
    def foo(self):
        print(&quot;C: foo&quot;)


class D(A, B, C):
    pass



D().foo()
&quot;&quot;&quot;
B: foo
C: foo
&quot;&quot;&quot;
</code></pre>
<p>当 D() 调用 foo 的时候，D 里面没有，那么按照继承关系一定是去 A 里面找。而 self 是 D 的 self，那么 <font color="blue">super(A, self)</font> 就是 D 对应的 MRO 中，A 的下一个类，也就是 B；<font color="blue">super(B, self)</font> 就是 D 对应的 MRO 中，B 的下一个类，也就是 C。</p>
<p><font color="darkblue"><strong>基类冲突</strong></font></p>
<p>虽然可以继承多个类，但是这些类之间有可能发生冲突，举个栗子：</p>
<pre><code class="language-Python">class A(int, str):
    pass
# TypeError: multiple bases have instance lay-out conflict
</code></pre>
<p>我们发现执行的时候报错了，这个类虚拟机压根就不会让你创建，原因很简单，它们的实例对象在内存布局上发生冲突了。</p>
<p>比如 A(&quot;123&quot;) 这个实例，虚拟机是把它看成整数呢？还是字符串呢？因为 A 同时继承 int 和 str，就意味着其实例既可以像整数一样使用除法，也可以像字符串一样调用 join 方法。但是整数没有 join，字符串也无法使用除法，因此这个类是不合理的。继承的多个基类，在实例对象的内存布局上产生了冲突。</p>
<p>虽然上面给出了解释，但如果仔细推敲，会发现这个解释有些站不住脚，因为我们自定义的类没有这个问题。如果是自定义的类，别说继承两个，就算继承十个毫无关系的类，也不会出现冲突，这又是什么原因呢？其实两者的差别，就在于内置类对象的实例对象是没有属性字典的，但是自定义类对象的实例对象有。</p>
<pre><code class="language-Python">class Base1:
    __slots__ = (&quot;a&quot;,)


class Base2:
    __slots__ = (&quot;a&quot;,)


class A(Base1, Base2):
    pass
# TypeError: multiple bases have instance lay-out conflict
</code></pre>
<p>此时 Base1 和 Base2 的实例，和内置类对象的实例是类似的，都没有属性字典，或者说实例对象可以绑定哪些属性已经定好了。同时继承 Base1 和 Base2 也会发生冲突。</p>
<p>结论：对于实例对象没有属性字典的类对象，最多同时继承一个。但是也有特例，如果类对象不接收任何参数，即使它的实例对象没有属性字典，也没有影响。</p>
<pre><code class="language-Python">class Base1:
    __slots__ = (&quot;a&quot;,)


class Base2:
    __slots__ = ()


# 合法
class A(Base2, int):
    pass


# 不合法
class B(Base1, int):
    pass
</code></pre>
<p>Base1 的实例对象显然可以绑定一个属性 a，意味着 Base1 可以接收一个参数；Base2 的实例对象无法绑定任何属性，意味着 Base2 不接收任何参数。</p>
<p>因此 <font color="blue">class A(Base1, int)</font> 是不合法的，因为 Base1 和 int 的实例没有属性字典，但它们都接收参数。同理 <font color="blue">class A (Base1, str)</font>、<font color="blue">class A(Base1, dict)</font> 也一样。但是  <font color="blue">class A(Base2, str)</font> 没有影响，因为 Base2 的实例无法绑定任何属性，因此也就不存在内存布局上的冲突。</p>
<p><font color="darkblue"><strong>当继承的基类之间存在父子关系时</strong></font></p>
<p>看个栗子：</p>
<pre><code class="language-Python">class Base:
    pass


class A(Base):
    pass


class B(Base, A):
    pass
&quot;&quot;&quot;
TypeError: Cannot create a consistent method resolution
order (MRO) for bases Base, A
&quot;&quot;&quot;
</code></pre>
<p>这个错误的原因应该不难理解，B 继承了 Base 和 A，但是 Base 和 A 之间又是父子关系。比如 B 在找不到某个方法时，会到 Base 里面找，Base 找不到再去 A 里面找。但如果 A 再找不到，就又回到了 Base，因为 A 继承 Base，那么此时就出现了闭环，这是不允许的。</p>
<p>但如果把 B 的创建改成 <font color="blue">class B(A, Base)</font> 则没问题，所以当继承的多个类之间也存在继承关系时，子类要在父类的前面。当然啦，最正确的做法应该是只继承子类，比如这里的 class B(A)。因为 A 已经继承了 Base，所以 B 只需继承 A 即可，无需再继承 Base。像 <font color="blue">class B(A, Base)</font> 这种做法虽然不会报错，但明显有些画蛇添足。</p>
<h3 id="继承基类操作"><a class="header" href="#继承基类操作">继承基类操作</a></h3>
<p>子类在找不到某个属性或方法时，会去基类里面找，但这背后的原理是什么呢？答案简单到超乎你想象，就是单纯的拷贝。虚拟机在确定 MRO 之后，就会遍历 MRO 顺序列表，里面存储了该类的所有直接基类、间接基类（也就是基类的基类）。而虚拟机会将自身没有、但是基类中存在的操作拷贝到该类当中，从而完成对基类操作的继承动作。</p>
<p>而这个继承的动作是发生在 inherit_slots 中。</p>
<pre><code class="language-C">int
PyType_Ready(PyTypeObject *type)
{
    // 计算 MRO
    if (mro_internal(type, NULL) &lt; 0)
        goto error;

    // inherit_special 会从基类继承 tp_new、tp_traverse、tp_clear 等
    if (type-&gt;tp_base != NULL)
        inherit_special(type, type-&gt;tp_base);

    // 获取 MRO 顺序列表
    bases = type-&gt;tp_mro;
    assert(bases != NULL);
    assert(PyTuple_Check(bases));
    n = PyTuple_GET_SIZE(bases);
    // 遍历所有的基类，包括直接基类、间接基类
    // 由于 MRO 的第一个类是其本身，所以遍历是从第二项开始的
    for (i = 1; i &lt; n; i++) {
        PyObject *b = PyTuple_GET_ITEM(bases, i);
        if (PyType_Check(b))
            // 继承基类操作
            inherit_slots(type, (PyTypeObject *)b);
    }
    // ...
}    
</code></pre>
<p>在 inherit_slots 中会拷贝相当多的操作，这里就以整型为例：</p>
<pre><code class="language-C">static void
inherit_slots(PyTypeObject *type, PyTypeObject *base)
{
    PyTypeObject *basebase;

#undef SLOTDEFINED
#undef COPYSLOT
#undef COPYNUM
#undef COPYSEQ
#undef COPYMAP
#undef COPYBUF

#define SLOTDEFINED(SLOT) \
    (base-&gt;SLOT != 0 &amp;&amp; \
     (basebase == NULL || base-&gt;SLOT != basebase-&gt;SLOT))

#define COPYSLOT(SLOT) \
    if (!type-&gt;SLOT &amp;&amp; SLOTDEFINED(SLOT)) type-&gt;SLOT = base-&gt;SLOT

#define COPYASYNC(SLOT) COPYSLOT(tp_as_async-&gt;SLOT)
#define COPYNUM(SLOT) COPYSLOT(tp_as_number-&gt;SLOT)
#define COPYSEQ(SLOT) COPYSLOT(tp_as_sequence-&gt;SLOT)
#define COPYMAP(SLOT) COPYSLOT(tp_as_mapping-&gt;SLOT)
#define COPYBUF(SLOT) COPYSLOT(tp_as_buffer-&gt;SLOT)
    
    if (type-&gt;tp_as_number != NULL &amp;&amp; base-&gt;tp_as_number != NULL) {
        basebase = base-&gt;tp_base;
        if (basebase-&gt;tp_as_number == NULL)
            basebase = NULL;
        COPYNUM(nb_add);
        COPYNUM(nb_subtract);
        COPYNUM(nb_multiply);
        COPYNUM(nb_remainder);
        COPYNUM(nb_divmod);
        COPYNUM(nb_power);
        COPYNUM(nb_negative);
        COPYNUM(nb_positive);
        COPYNUM(nb_absolute);
        COPYNUM(nb_bool);
        COPYNUM(nb_invert);
        COPYNUM(nb_lshift);
        COPYNUM(nb_rshift);
        COPYNUM(nb_and);
        COPYNUM(nb_xor);
        COPYNUM(nb_or);
        COPYNUM(nb_int);
        COPYNUM(nb_float);
        COPYNUM(nb_inplace_add);
        COPYNUM(nb_inplace_subtract);
        COPYNUM(nb_inplace_multiply);
        COPYNUM(nb_inplace_remainder);
        COPYNUM(nb_inplace_power);
        COPYNUM(nb_inplace_lshift);
        COPYNUM(nb_inplace_rshift);
        COPYNUM(nb_inplace_and);
        COPYNUM(nb_inplace_xor);
        COPYNUM(nb_inplace_or);
        COPYNUM(nb_true_divide);
        COPYNUM(nb_floor_divide);
        COPYNUM(nb_inplace_true_divide);
        COPYNUM(nb_inplace_floor_divide);
        COPYNUM(nb_index);
        COPYNUM(nb_matrix_multiply);
        COPYNUM(nb_inplace_matrix_multiply);
    }
    // ...
}    
</code></pre>
<p>我们在里面看到了很多熟悉的东西，这些都是在继承时需要拷贝的操作。比如布尔类型，PyBool_Type 中并没有设置 nb_add，但是 PyLong_Type 中设置了，而 bool 继承 int。所以布尔值是可以直接进行运算的，当然和整数、浮点数运算也是可以的。因此在 Numpy 中，判断一个数组里面有多少个满足条件的元素，可以使用 Numpy 提供的向量化操作进行比较，会得到一个具有相同长度的数组，里面的每一个元素为表示是否满足条件的布尔值。然后直接通过 sum 运算即可，因为运算的时候，True 会被解释成 1，False 会被解释成 0。</p>
<pre><code class="language-Python">import numpy as np

arr = np.array([2, 4, 7, 3, 5])

print(arr &gt; 4)  # [False False  True False  True]
print(np.sum(arr &gt; 4))  # 2
# 也可以和整数直接运算
print(2.2 + True)  # 3.2
</code></pre>
<p>所以在 Python 中，整数可以和布尔值进行运算，看似不可思议，但又在情理之中。</p>
<h3 id="填充基类的子类列表"><a class="header" href="#填充基类的子类列表">填充基类的子类列表</a></h3>
<p>到这里，PyType_Ready 还剩下最后一个重要的动作：设置基类的子类列表。</p>
<p>在 PyTypeObject 中，有一个 tp_subclasses，这个字段在 PyType_Ready 完成之后，将会是一个 list 对象，其中存放着所有直接继承该类的类对象。</p>
<pre><code class="language-Python">class Base:
    pass

class A(Base):
    pass

class B(A):
    pass

# A 继承 Base
print(Base.__subclasses__())
&quot;&quot;&quot;
[&lt;class '__main__.A'&gt;]
&quot;&quot;&quot;
</code></pre>
<p>tp_subclasses 对应 Python 的  __subclasses__，当调用的时候会打印直接继承自己的类。注意是直接继承，间接继承不算，所以上面打印的列表里面只有 A 没有 B。那么问题来了，这一步是何时发生的呢？Base 怎么知道 A 继承了它呢？很简单，A 在继承 Base 的操作之后，也会将自身设置到 Base 的 tp_subclasses 中。</p>
<p>而在 PyType_Ready 中，这一步是通过调用 add_subclass 实现的。</p>
<pre><code class="language-C">int
PyType_Ready(PyTypeObject *type)
{
    // ...
    // 拿到所有的基类
    bases = type-&gt;tp_bases;
    n = PyTuple_GET_SIZE(bases);
    // 挨个遍历，将自身加入到基类的 tp_subclasses 中
    // 因为一个类可以直接继承很多基类，而每个基类都要添加
    for (i = 0; i &lt; n; i++) {
        PyObject *b = PyTuple_GET_ITEM(bases, i);
        if (PyType_Check(b) &amp;&amp;
            add_subclass((PyTypeObject *)b, type) &lt; 0)
            goto error;
    }
    // ...
}    
</code></pre>
<p>当然啦，一个类可以继承多个基类，一个基类也可以被多个子类继承，比如 object。</p>
<pre><code class="language-Python">print(object.__subclasses__())
</code></pre>
<p>打印会输出非常多的内容，因为 Python 里面所有的类都继承 object，而在创建这些类的时候，都会将自身加入到 object 的 tp_subclasses 里面。</p>
<h2 id="小结-60"><a class="header" href="#小结-60">小结</a></h2>
<p>到这里，我们算是完整地剖析了 PyType_Ready 的动作，可以看到，虚拟机对类对象进行了多种繁杂的改造工作，主要包括以下几部分：</p>
<ul>
<li>设置类型信息、基类以及基类列表；</li>
<li>填充属性字典；</li>
<li>确定 MRO 顺序列表；</li>
<li>基于 MRO 顺序列表从基类继承操作；</li>
<li>设置基类的子类列表，或者说，将自身加入到基类的 tp_subclasses 中；</li>
</ul>
<blockquote>
<p>除了以上这些，还会继承 tp_as_number 等方法簇。</p>
</blockquote>
<p>不同的类型，有些操作也会有一些不同的行为，但整体是一致的。因此具体到某个特定类型，可以自己跟踪 PyType_Ready 的具体过程。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-61"><a class="header" href="#楔子-61">楔子</a></h2>
<p>Python 除了提供很多内置的类之外，还支持我们定义属于自己的类，那么底层是如何做的呢？下面就来看看。</p>
<p>老规矩，如果想知道底层是怎么做的，那么就必须要通过观察字节码来实现。这里我们随便定义一个类，然后反编译一下：</p>
<pre><code class="language-Python">class Girl:
    name = &quot;古明地觉&quot;

    def __init__(self):
        print(f&quot;__init__: {self.name}&quot;)

    def foo(self):
        print(&quot;foo&quot;)

    def bar(self, name):
        self.name = name
        print(self.name)

girl = Girl()
girl.foo()
girl.bar(&quot;古明地恋&quot;)
&quot;&quot;&quot;
__init__: 古明地觉
foo
古明地恋
&quot;&quot;&quot;
</code></pre>
<p>通过之前对函数机制的分析，我们知道对于一个包含函数定义的 Python 源文件，在编译之后会得到一个和源文件对应的 PyCodeObject 对象，其内部的常量池中存储了和函数对应的 PyCodeObject 对象。那么对于包含类的 Python 源文件，编译之后的结果又是怎么样的呢？</p>
<p>显然可以照葫芦画瓢，根据以前的经验我们可以猜测模块对应的 PyCodeObject 对象的常量池中肯定存储了类对应的 PyCodeObject 对象，类对应的 PyCodeObject 对象的常量池中则存储了 __init__、foo、bar 三个函数对应的 PyCodeObject 对象。然而事实也确实如此。</p>
<p><img src="./images/252.png" alt="" /></p>
<p>在介绍函数的时候，我们看到函数的声明（def 语句）和函数的实现虽然在逻辑上是一个整体，但它们的字节码指令却是分离在两个 PyCodeObject 对象中的。</p>
<p>在类中，同样存在这样的分离现象。声明类的 class 语句，编译后的字节码指令存储在模块对应的 PyCodeObject 中；而类的实现、也就是类里面的逻辑，编译后的字节码指令则存储在类对应的 PyCodeObject 中。所以我们在模块级别中只能找到类，无法直接找到类里面的属性。</p>
<p>另外还可以看到，类的成员函数和一般的函数相同，也会有这种声明和实现分离的现象。正所谓函数即变量，类也是如此，def、class 本质上都是定义一个变量，该变量指向具体的 PyFunctionObject 或者 PyTypeObject。</p>
<pre><code class="language-python">code_string = &quot;&quot;&quot;
class Girl:
    name = &quot;古明地觉&quot;

    def __init__(self):
        print(f&quot;__init__: {self.name}&quot;)

    def foo(self):
        print(&quot;foo&quot;)

    def bar(self, name):
        self.name = name
        print(self.name)
&quot;&quot;&quot;
# 模块对应的 PyCodeObject 对象
code = compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;)

# 常量池里面存储了 Girl 对应的 PyCodeObject 对象
print(code.co_consts[0])  # &lt;code object Girl at 0x1029d80e0, ...&gt;

# Girl 对应的 PyCodeObject 对象的常量池里面存储了几个函数对应的 PyCodeObject 对象
print(code.co_consts[0].co_consts[2])  # &lt;code object __init__ at 0x102905580, ...&gt;
print(code.co_consts[0].co_consts[4])  # &lt;code object foo at 0x102906290, ...&gt;
print(code.co_consts[0].co_consts[6])  # &lt;code object bar at 0x1029d8030, ...&gt;
</code></pre>
<p>相信这些内容已经没有什么难度了，总之函数、类在编译之后都会对应一个 PyCodeObject。由于函数、类可以嵌套，那么 PyCodeObject 也是可以嵌套的，并且也会作为一个常量被收集起来，存储在外层的 PyCodeObject 的常量池当中。</p>
<h2 id="自定义类对象的动态元信息"><a class="header" href="#自定义类对象的动态元信息">自定义类对象的动态元信息</a></h2>
<p>自定义类对象的元信息指的就是关于这个类的信息描述，比如名称、所拥有的属性、方法，该类实例化时要为实例对象申请的内存空间大小等。有了这些元信息，才能创建自定义类对象，否则我们是没办法创建的。</p>
<p>注意：元信息是一个非常重要的概念，在很多框架中都会出现。比如说 Hive，数据的元信息就是存储在 MySQL 里面。而在编程语言中，也正是通过元信息才实现了反射等动态特性，尤其是 Python，将元信息的概念发挥地淋漓尽致，因此 Python 也提供了其它编程语言所不具备的高度灵活的动态特征。</p>
<p>我们将类简化一下，看看它的字节码长什么样子。</p>
<pre><code class="language-Python">code_string = &quot;&quot;&quot;
class Girl:

    def foo(self):
        print(&quot;Hi foo&quot;)

    def bar(self):
        print(&quot;Hi bar&quot;)
&quot;&quot;&quot;
code = compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;)

for const in code.co_consts:
    print(const)
&quot;&quot;&quot;
&lt;code object Girl at 0x10643e290, ...&gt;
Girl
None
&quot;&quot;&quot;
for const in code.co_consts[0].co_consts:
    print(const)
&quot;&quot;&quot;
Girl
&lt;code object foo at 0x1033d23f0, ...&gt;
Girl.foo
&lt;code object bar at 0x1033d1580, ...&gt;
Girl.bar
None
&quot;&quot;&quot;
</code></pre>
<p>观察一下类的常量池，第一个元素显然是类名，一个字符串；第二和第三个元素则是函数 foo 对应的 PyCodeObject 以及全限定名；第四和第五个元素则是函数 bar 对应的 PyCodeObject 以及全限定名；最后一个是 None，而 None 是一定会有的。</p>
<p>然后是字节码如下：</p>
<pre><code class="language-C">  // 模块对应的字节码
  0 LOAD_BUILD_CLASS
  2 LOAD_CONST               0 (&lt;code object Girl at 0x7f1...&gt;)
  4 LOAD_CONST               1 ('Girl')
  6 MAKE_FUNCTION            0
  8 LOAD_CONST               1 ('Girl')
 10 CALL_FUNCTION            2
 12 STORE_NAME               0 (Girl)
 14 LOAD_CONST               2 (None)
 16 RETURN_VALUE

  // class Girl 对应的字节码
Disassembly of &lt;code object Girl at 0x7f1...&gt;:
  0 LOAD_NAME                0 (__name__)
  2 STORE_NAME               1 (__module__)
  4 LOAD_CONST               0 ('Girl')
  6 STORE_NAME               2 (__qualname__)

  8 LOAD_CONST               1 (&lt;code object foo at 0x7f1...&gt;)
 10 LOAD_CONST               2 ('Girl.foo')
 12 MAKE_FUNCTION            0
 14 STORE_NAME               3 (foo)

 16 LOAD_CONST               3 (&lt;code object bar at 0x7f1...&gt;)
 18 LOAD_CONST               4 ('Girl.bar')
 20 MAKE_FUNCTION            0
 22 STORE_NAME               4 (bar)
 24 LOAD_CONST               5 (None)
 26 RETURN_VALUE

  // Girl.foo 对应的字节码
Disassembly of &lt;code object foo at 0x7f1...&gt;:
  0 LOAD_GLOBAL              0 (print)
  2 LOAD_CONST               1 ('Hi foo')
  4 CALL_FUNCTION            1
  6 POP_TOP
  8 LOAD_CONST               0 (None)
 10 RETURN_VALUE
  
  // Girl.bar 对应的字节码
Disassembly of &lt;code object bar at 0x7f1...&gt;:
  0 LOAD_GLOBAL              0 (print)
  2 LOAD_CONST               1 ('Hi bar')
  4 CALL_FUNCTION            1
  6 POP_TOP
  8 LOAD_CONST               0 (None)
 10 RETURN_VALUE
</code></pre>
<p>结构很清晰，总共 4 个 PyCodeObject，分别对应模块、类 Girl、函数 Girl.foo、函数 Girl.bar。</p>
<p><img src="./images/253.png" alt="" /></p>
<p>下面我们来对字节码逐一分析，首先是模块的字节码：</p>
<pre><code class="language-C">  // 一条新指令，会将内置函数 __build_class__ 压入栈中
  // 至于这个 __build_class__ 是干啥的，一会说
  0 LOAD_BUILD_CLASS
  // 加载 Girl 对应的 PyCodeObject 对象
  2 LOAD_CONST               0 (&lt;code object Girl at 0x7f1...&gt;)
  // 加载字符串 &quot;Girl&quot;
  4 LOAD_CONST               1 ('Girl')
  // 问题来了，我们看到是 MAKE_FUNCTION
  // 不是说要构建类吗？为什么是 MAKE_FUNCTION 呢？
  6 MAKE_FUNCTION            0
  // 再次加载字符串 &quot;Girl&quot;
  8 LOAD_CONST               1 ('Girl')
  // 以构建的 PyFunctionObject 和字符串 &quot;Girl&quot; 为参数
  // 调用 __build_class__，创建一个类
 10 CALL_FUNCTION            2
  // 将创建的类使用变量 Girl 进行保存
 12 STORE_NAME               0 (Girl)
  // 隐式地 return None
 14 LOAD_CONST               2 (None)
 16 RETURN_VALUE
</code></pre>
<p>关键指令是 LOAD_BUILD_CLASS，它的逻辑很简单，就是将内置函数 __build_class__ 压入运行时栈。紧接着通过两个 LOAD_CONST 将 Girl 对应的 PyCodeObject 对象和字符串 &quot;Girl&quot; 压入栈中，再用 MAKE_FUNCTION 将其弹出，构造一个 PyFunctionObject 并入栈。</p>
<p>所以此时栈里面还剩下两个元素，也就是<font color="blue">刚入栈的函数</font>和<font color="blue">内置函数 __build_class__</font>。而这个刚入栈的函数指针，就是基于 Girl 的 PyCodeObject 构建的。不过还是那个问题，Girl 明明是个类，为啥要 MAKE_FUNCTION 呢？接下来的两条指令会告诉你答案。</p>
<p>构建完函数之后又通过 LOAD_CONST 将字符串 &quot;Girl&quot; 压入栈中，显然它代表类名。而此时栈里面有三个元素：</p>
<p><img src="./images/254.png" alt="" /></p>
<p>然后接着执行 CALL_FUNCTION，指令参数是 2。不用想，肯定是以<font color="blue">构建的函数</font>和<font color="blue">字符串&quot;Girl&quot;</font> 为参数，调用 __build_class__。而 __build_class__ 会创建一个类并返回，然后压入运行时栈，最后再通过 STORE_NAME 将创建的类对象使用变量 Girl 保存。</p>
<p>所以类不是上来就构建的，根据 PyCodeObject 和名称构造出来的实际上是一个 PyFunctionObject，尽管使用的是类的 PyCodeObject。当 PyFunctionObject 构造完毕时，再在其之上构造 PyTypeObject，而这一步由 __build_class__ 负责。</p>
<p><img src="./images/255.png" alt="" /></p>
<p>所以，可以得出如下结论：</p>
<pre><code class="language-Python">class A:
    pass

# 在底层将会被翻译成
A = __build_class__(&lt;PyFunctionObject A&gt;, &quot;A&quot;)


# 如果是
class A(int):
    pass
  
# 在底层将会被翻译成
A = __build_class__(&lt;PyFunctionObject A&gt;, &quot;A&quot;, int)
</code></pre>
<p>我们实际操作一下：</p>
<pre><code class="language-python">MyInt = __build_class__(lambda: None, &quot;MyInt&quot;, int)

print(MyInt)  # &lt;class '__main__.MyInt'&gt;
print(MyInt.__base__)  # &lt;class 'int'&gt;
print(MyInt(3) + 5)  # 8
</code></pre>
<p>有点意思。</p>
<p><img src="./images/256.png" alt="" /></p>
<p>如果参数类型不正确的话，会报出如下错误：</p>
<pre><code class="language-python">try:
    __build_class__()
except TypeError as e:
    print(e)
&quot;&quot;&quot;
__build_class__: not enough arguments
&quot;&quot;&quot;

try:
    # 第一个参数 func 必须是函数
    __build_class__(&quot;&quot;, &quot;&quot;)
except TypeError as e:
    print(e)    
&quot;&quot;&quot;
__build_class__: func must be a function
&quot;&quot;&quot;

try:
    # 第二个参数 name 必须是字符串
    __build_class__(lambda: None, 123)
except TypeError as e:
    print(e)

&quot;&quot;&quot;
__build_class__: name is not a string
&quot;&quot;&quot;
</code></pre>
<p>记住这几个报错信息，后面会看到。此外我们也能看出，__build_class__ 的第一个参数叫 func、第二个参数叫 name。总之 __build_class__ 的作用就是将一个函数对象变成一个类对象。</p>
<p>再来看看类对象的字节码：</p>
<pre><code class="language-c">Disassembly of &lt;code object Girl at 0x7f1...&gt;:
  // 将 __name__、即模块的名字压入栈中
  0 LOAD_NAME                0 (__name__)
  // 使用类的 __module__ 进行保存
  // 所以通过类的 __module__，能找到该类属于哪一个模块
  2 STORE_NAME               1 (__module__)
  // 加载字符串 &quot;Girl&quot;
  4 LOAD_CONST               0 ('Girl')
  // 作为类的全限定名
  6 STORE_NAME               2 (__qualname__)
  
  // 加载 Girl.foo 函数的 PyCodeObject 和字符串 &quot;Girl.foo&quot;
  8 LOAD_CONST               1 (&lt;code object foo at 0x7f1...&gt;)
 10 LOAD_CONST               2 ('Girl.foo')
  // 构造函数
 12 MAKE_FUNCTION            0
  // 使用变量 foo 保存
 14 STORE_NAME               3 (foo)
  
  // 和上面构造 foo 类似
 16 LOAD_CONST               3 (&lt;code object bar at 0x7f1...&gt;)
 18 LOAD_CONST               4 ('Girl.bar')
 20 MAKE_FUNCTION            0
 22 STORE_NAME               4 (bar)
 24 LOAD_CONST               5 (None)
 26 RETURN_VALUE
</code></pre>
<p>我们在介绍函数的时候提过：&quot;函数的局部变量是不可变的，在编译的时候就已经确定了，以一种静态的方式存放在 f_localsplus 中。而 f_locals 初始为 NULL，函数里面的局部变量是通过静态的方式来访问的&quot;。</p>
<p>但是类则不一样，类是可以动态修改的，可以随时增加属性、方法，这就意味着类是不可能通过静态方式来查找属性的。事实上也确实如此，类有一个属性字典，而对于类来说，变量是从属性字典中查找的。</p>
<pre><code class="language-python">class Girl:

    def foo(self):
        print(&quot;Hi foo&quot;)

    def bar(self):
        print(&quot;Hi bar&quot;)

print(__name__)  # __main__
print(Girl.__module__)  # __main__
print(Girl.__qualname__)  # Girl
print(Girl.foo is Girl.__dict__[&quot;foo&quot;])  # True
</code></pre>
<p>所以整体过程就是：先将 PyCodeObject 构建成函数，再通过 __build_class__ 将函数变成一个类，当 __build_class__ 结束之后我们的自定义类就破茧而出了。</p>
<p>因此剩下的问题就是 __build_class__ 是如何将一个函数变成类的，想要知道答案，那么只能去源码中一探究竟了。不过在看源码之前，我们还需要了解一样东西：metaclass。</p>
<h2 id="metaclass"><a class="header" href="#metaclass">metaclass</a></h2>
<p>元类，被誉为是深度的魔法，但是个人觉得有点夸张了。首先元类是做什么的，它是用来控制我们自定义类的生成过程的，默认情况下，自定义的类都是由 type 创建的。但是我们可以手动指定某个类的元类，不过在介绍元类之前，我们还需要看一下 Python 的两个特殊的魔法方法：__new__ 和 __init__。</p>
<h3 id="__new__-和-__init__"><a class="header" href="#__new__-和-__init__">__new__ 和 __init__</a></h3>
<p>类在实例化的时候会自动调用 __init__，但其实在调用 __init__ 之前会先调用 __new__。</p>
<ul>
<li>__new__：为实例对象申请一片内存；</li>
<li>__init__：为实例对象设置属性；</li>
</ul>
<pre><code class="language-Python">class A:

    def __new__(cls, *args, **kwargs):
        print(&quot;__new__&quot;)

    def __init__(self):
        print(&quot;__init__&quot;)

A()
&quot;&quot;&quot;
__new__
&quot;&quot;&quot;
</code></pre>
<p>然而我们看到只有 __new__ 被调用了，__init__ 则没有。原因就在于 __new__ 里面必须将 A 的实例对象返回，才会执行 __init__，并且执行的时候会自动将 __new__ 的返回值作为参数传给 __init__ 当中的 self。</p>
<pre><code class="language-Python">class A:

    def __new__(cls, *args, **kwargs):
        print(&quot;__new__&quot;)
        # 这里的参数 cls 就表示 A 这个类本身
        # object.__new__(cls) 便是根据 cls 创建 cls 的实例对象
        return object.__new__(cls)

    def __init__(self):
        # 然后执行 __init__，里面的 self 指的就是实例对象
        # 执行 __init__ 时，__new__ 的返回值会自动作为参数传递给 self
        print(&quot;__init__&quot;)

A()
&quot;&quot;&quot;
__new__
__init__
&quot;&quot;&quot;
</code></pre>
<p>所以一个对象是什么，取决于其类型对象的 __new__ 返回了什么。</p>
<pre><code class="language-Python">class A:

    def __new__(cls, *args, **kwargs):
        print(&quot;__new__&quot;)
        # 这里必须返回 A 的实例对象，否则 __init__ 函数是不会执行的
        return 123

    def __init__(self):
        print(&quot;__init__&quot;)

a = A()
print(a + 1)
&quot;&quot;&quot;
__new__
124
&quot;&quot;&quot;
</code></pre>
<p>我们看到 A 在实例化之后得到的是一个整数，原因就是 __new__ 返回了 123。</p>
<h3 id="创建类的另一种方式"><a class="header" href="#创建类的另一种方式">创建类的另一种方式</a></h3>
<p>创建类的时候除了通过 class 关键字之外，我们还可以使用 type 这个古老却又强大的类来创建。</p>
<pre><code class="language-python"># type 这个类里面可以接收一个参数或者三个参数
# 如果接收一个参数，那么表示查看类型
# 如果接收三个参数，那么表示创建一个类
try:
    A = type(&quot;A&quot;, &quot;&quot;)
except Exception as e:
    print(e)  # type() takes 1 or 3 arguments
</code></pre>
<p>查看类型就不说了，下面看看如何用 type 创建一个类：</p>
<pre><code class="language-Python"># type 接收三个参数：类名、继承的基类、属性
class A(list):
    name = &quot;古明地觉&quot;

# 上面这个类翻译过来就是
A = type(&quot;A&quot;, (list,), {&quot;name&quot;: &quot;古明地觉&quot;})
print(A)  # &lt;class '__main__.A'&gt;
print(A.__name__)  # A
print(A.__base__)  # &lt;class 'list'&gt;
print(A.name)  # 古明地觉
</code></pre>
<p>所以还是很简单的，我们还可以自定义一个类继承 type。</p>
<pre><code class="language-Python">class MyType(type):
    def __new__(mcs, name, bases, attr):
        print(name)
        print(bases)
        print(attr)

# 指定 metaclass，表示 A 这个类由 MyType 创建
# 我们说 __new__ 是为实例对象开辟内存的
# 那么 MyType 的实例对象是谁呢？显然就是这里的 A
# 因为 A 指定了 metaclass 为 MyType，所以 A 的类型就是 MyType
class A(int, object, metaclass=MyType):
    name = &quot;古明地觉&quot;
&quot;&quot;&quot;
A
(&lt;class 'int'&gt;, &lt;class 'object'&gt;)
{'__module__': '__main__', '__qualname__': 'A', 'name': '古明地觉'}
&quot;&quot;&quot;
# 我们看到一个类在创建的时候会向元类的 __new__ 中传递三个值
# 分别是类名、继承的基类、类的属性
# 但此时 A 并没有被创建出来
print(A)  # None
</code></pre>
<p>我们说 __new__ 一定要将创建的实例对象返回才可以，这里的 MyType 是元类，所以类对象 A 就是 MyType 的实例对象，MyType 的 __new__ 就负责为类对象 A 分配空间。但是显然这里并没有分配，而且返回的还是一个 None，如果我们返回的是 123，那么 print(A) 就是 123。</p>
<pre><code class="language-python">class MyType(type):
    def __new__(mcs, name, bases, attr):
        return []

class A(metaclass=MyType):
    pass

# A 是由 MyType 生成的，MyType 返回的是 []
# 因此 A 就是 []
print(A)  # []
</code></pre>
<p>所以<font color="blue">元类和类的关系</font>与<font color="blue">类和实例对象的关系</font>，之间是很相似的，因为完全可以把类对象看成是元类的实例对象。因此 A 既然指定了 metaclass 为 MyType，就表示 A 这个类由 MyType 创建，那么 MyType 的 __new__ 函数返回了什么，A 就是什么。</p>
<pre><code class="language-Python">class MyType(type):

    def __new__(mcs, name, bases, attr):
        return &quot;嘿嘿嘿&quot;

class A(metaclass=MyType):
    pass

print(A + &quot;哟哟哟&quot;)  # 嘿嘿嘿哟哟哟
</code></pre>
<p>这便是 Python 语言具备的高度动态特性，那么问题来了，如果我想把 A 创建出来、像普通的类一样使用的话，该咋办呢？因为默认情况下类由 type 创建，底层帮你做好了，但现在则需要我们来手动指定。</p>
<p>显然，这里创建还是要依赖于 type，只不过需要我们手动指定，而且在手动指定的同时还可以增加一些我们自己的操作。</p>
<pre><code class="language-python">class MyType(type):

    def __new__(mcs, name, bases, attr):
        name = name * 2
        bases = (list,)
        attr.update({&quot;name&quot;: &quot;古明地觉&quot;, &quot;nickname&quot;: &quot;小五萝莉&quot;})

        # 这里直接交给 type 即可，然后 type 来负责创建
        # 所以 super().__new__ 实际上会调用 type.__new__
        return super().__new__(mcs, name, bases, attr)
        # 但是我们将第一个参数换成了 mcs，就是这里的 MyType
        # 等价于 type.__new__(mcs, name, bases, attr)，表示将元类指定为 MyType
        # 注意：不能写 type(name, bases, attr)，因为这样的话类还是由 type 创建的
        # type(name, bases, attr) 等价于 type.__new__(type, name, bases, attr)

class Girl(metaclass=MyType):
    pass

# 我们看到类的名字变了，默认情况下是 &quot;Girl&quot;
# 但创建的时候将 name 乘了个 2
print(Girl.__name__)  # GirlGirl

# 显然 Girl 也继承 list
print(Girl(&quot;你好呀&quot;))  # ['你', '好', '呀']

# 同理 Girl 还有两个属性
print(Girl.name, Girl.nickname)  # 古明地觉 小五萝莉
</code></pre>
<p>记得前面说过，一个类在没有指定 metaclass 的时候，如果它的父类指定了，那么这个类的 metaclass 等于父类的 metaclass。</p>
<pre><code class="language-python">class MyType(type):

    def __new__(mcs, name, bases, attr):
        name = name * 2
        bases = (list,)
        attr.update({&quot;name&quot;: &quot;古明地觉&quot;, &quot;nickname&quot;: &quot;小五萝莉&quot;})
        return super().__new__(mcs, name, bases, attr)

class Girl(metaclass=MyType):
    pass

class A(Girl):
    pass
 
print(A.__class__)  # &lt;class '__main__.MyType'&gt;
print(A.__name__)  # AA
</code></pre>
<p>并且当时还举了个 flask 的例子，提到了一种更加优雅的写法。</p>
<pre><code class="language-Python">class MyType(type):

    def __new__(mcs, name, bases, attr):
        return super().__new__(mcs, name, bases, attr)

def with_metaclass(meta, bases):
    return meta(&quot;tmp&quot;, bases, {&quot;gender&quot;: &quot;female&quot;})


# with_metaclass(MyType, (list,)) 会返回一个类
# 这个类由 MyType 创建，并且继承自 list
# 那么 Girl 再继承这个类，等价于 Girl 也由 MyType 创建
class Girl(with_metaclass(MyType, (list,))):
    pass

print(Girl.__class__)  # &lt;class '__main__.MyType'&gt;
# 所以 with_metaclass(meta, bases) 本身没有太大意义，只是为了帮助我们找到元类和继承的类
# 但毕竟继承它了，就意味着也可以找到它的属性
print(Girl.gender)  # female
</code></pre>
<p>注意：我们说负责创建类对象的是元类，而元类要么是 type、要么是继承自 type 的子类。</p>
<pre><code class="language-Python">class MyType(type):

    def __new__(mcs, name, bases, attr):
        return super().__new__(mcs, name, bases, attr)

# type 直接加括号表示由 type 创建，所以需要通过 __new__ 手动指定
# 并且将 __new__ 的第一个参数换成 MyType
Girl = type.__new__(MyType,
                    &quot;GirlGirlGirl&quot;,
                    (list,),
                    {&quot;add&quot;: lambda self, value: value + 123})

print(Girl.__name__)  # GirlGirlGirl

g = Girl()
print(g.add(123))  # 246

try:
    type.__new__(int, &quot;A&quot;, (object,), {})
except TypeError as e:
    # 指定为 int 则报错，告诉我们 int 不是 type 的子类
    # 因为只有两种情况：要么是 type、要么是 type 的子类
    print(e)  # type.__new__(int): int is not a subtype of type
</code></pre>
<p>怎么样，是不是觉得元类很简单呢？其实元类没有什么复杂的，只需要把元类和类对象之间的关系，想象成类对象和实例对象即可。类对象的 __new__ 里面返回了啥，实例就是啥。那么同理，元类的 __new__ 里面返回了啥，类对象就是啥。</p>
<p>为了更好地理解这一点，我们再举个栗子：</p>
<pre><code class="language-Python">class MyType(type):
    def __new__(mcs, name, bases, attr):
        if &quot;foo&quot; in attr:
            attr.pop(&quot;foo&quot;)
        return super().__new__(mcs, name, bases, attr)


class Girl(metaclass=MyType):

    def foo(self):
        return &quot;foo&quot;

    def bar(self):
        return &quot;bar&quot;

print(Girl().bar())  # bar

try:
    print(Girl().foo())
except AttributeError as e:
    print(e)  # 'Girl' object has no attribute 'foo'
</code></pre>
<p>惊了，我们看到居然没有 foo 这个属性，我们明显定义了啊，显然原因就是我们在创建类的时候将其 pop 掉了。首先创建一个类需要三个元素：类名、继承的基类、类的一些属性（以字典的形式），然后会将这三个元素交给元类进行创建。但是我们在创建的时候偷偷地将 foo 从 attr 里面给 pop 掉了，因此创建出来的类是没有 foo 这个成员函数的。</p>
<p>元类确实蛮有趣的，而且也没有想象中的那么难，可以多了解一下。基于元类，我们可以实现很多高级操作，可以让代码逻辑变得更加优雅。</p>
<h3 id="特殊的魔法函数"><a class="header" href="#特殊的魔法函数">特殊的魔法函数</a></h3>
<p>此外我们再来看两个和元类有关的魔法函数，分别是 __prepared__ 和 __init_sublcass__，先来看第一个。</p>
<pre><code class="language-Python">class MyType(type):

    @classmethod
    def __prepare__(mcs, name, bases):
        print(&quot;__prepared__&quot;)
        # 必须返回一个 mapping，至于它是干什么的我们后面说
        return {}

    def __new__(mcs, name, bases, attr):
        print(&quot;__new__&quot;)
        return super().__new__(mcs, name, bases, attr)


class Girl(metaclass=MyType):
    pass

&quot;&quot;&quot;
__prepared__
__new__
&quot;&quot;&quot;
</code></pre>
<p>我们看到 __prepare__ 会在 __new__ 之前被调用，那么它是做什么的呢？答案是添加属性，我们解释一下。</p>
<pre><code class="language-Python">class MyType(type):

    @classmethod
    def __prepare__(mcs, name, bases):
        return {&quot;name&quot;: &quot;古明地觉&quot;}

    def __new__(mcs, name, bases, attr):
        return super().__new__(mcs, name, bases, attr)


class Girl(metaclass=MyType):
    pass

print(Girl.name)  # 古明地觉
</code></pre>
<p>现在应该知道 __prepare__ 是干什么的了，它接收一个 name、一个 bases，返回一个 mapping。我们知道 name、bases、attr 会传递给 __new__，但是在 __new__ 之前会先经过 __prepared__。而 __prepared__ 会返回一个映射，假设叫 m，那么会将 attr 和 m 合并，相当于执行了 attr.update(m)，然后再将 name、bases、attr 交给 __new__。</p>
<p>此外 __prepared__ 这个方法是被 @classmethod 装饰的，并且里面一定要返回一个 mapping，否则报错：TypeError: MyType.__prepared__() must return a mapping, not xxx。</p>
<p>说完了 __prepare__ 之后，再来看看 __init_sublcass__，它类似于一个钩子函数，在一些简单的场景下可以代替元类。</p>
<pre><code class="language-Python">class Base:

    def __init_subclass__(cls, **kwargs):
        print(cls)
        print(kwargs)

# 当类被创建的时候，会触发其父类的__init_subclass__
class A(Base):
    pass
&quot;&quot;&quot;
&lt;class '__main__.A'&gt; 
{}
&quot;&quot;&quot;

class B(Base, name=&quot;古明地觉&quot;, age=16):
    pass

&quot;&quot;&quot;
&lt;class '__main__.B'&gt; 
{'name': '古明地觉', 'age': 16}
&quot;&quot;&quot;
</code></pre>
<p>所以父类的 __init_sublcass__ 里面的 cls 并不是父类本身，而是继承它的类。kwargs 就是额外设置的一些属性，因此我们可以实现一个属性添加器。</p>
<pre><code class="language-Python">class Base:

    def __init_subclass__(cls, **kwargs):
        for k, v in kwargs.items():
            setattr(cls, k, v)

class A(Base, name=&quot;古明地觉&quot;, age=16,
        __str__=lambda self: &quot;hello world&quot;):
    pass


print(A.name, A.age)  # 古明地觉 16
print(A())  # hello world
</code></pre>
<p>当然除了属性添加器，我们还可以实现一个属性拦截器。</p>
<pre><code class="language-Python">class Base:

    def __init_subclass__(cls, **kwargs):
        if hasattr(cls, &quot;shit&quot;) and hasattr(cls.shit, &quot;__code__&quot;):
            raise Exception(f&quot;{cls.__name__} 不允许定义 'shit' 函数&quot;)

class A(Base):
    def shit(self):
        pass
&quot;&quot;&quot;
Traceback (most recent call last):
  File &quot;...&quot;, line 9, in &lt;module&gt;
    class A(Base):
  File &quot;...&quot;, line 5, in __init_subclass__
    raise Exception(f&quot;{cls.__name__} 不允许定义 'shit' 函数&quot;)
Exception: A 不允许定义 'shit' 函数
&quot;&quot;&quot;
</code></pre>
<p>以上就是元类相关的知识，记得在前面的文章中已经说过了，这里再啰嗦一遍，这样一会儿看源码的时候会轻松一些。</p>
<h2 id="源码解密类的创建过程"><a class="header" href="#源码解密类的创建过程">源码解密类的创建过程</a></h2>
<p>回顾一下类是怎么创建的，首先会通过指令 LOAD_BUILD_CLASS 将内置函数 __build_class__ 压入运行时栈，然后将类对应的 PyCodeObject 包装成一个 PyFunctionObject，最后再调用 __build_class__ 将 PyFunctionObject 变成 PyTypeObject，也就是我们使用的类对象。</p>
<pre><code class="language-python">class A: pass
class B: pass
class C: pass
class D: pass
class E: pass
class F: pass

MyClass = __build_class__(lambda: None, &quot;MyClass&quot;, A, B, C, D, E, F)
print(MyClass)  # &lt;class '__main__.MyClass'&gt;

for cls in MyClass.__mro__:
    print(cls)
    &quot;&quot;&quot;
    &lt;class '__main__.MyClass'&gt;
    &lt;class '__main__.A'&gt;
    &lt;class '__main__.B'&gt;
    &lt;class '__main__.C'&gt;
    &lt;class '__main__.D'&gt;
    &lt;class '__main__.E'&gt;
    &lt;class '__main__.F'&gt;
    &lt;class 'object'&gt;
    &quot;&quot;&quot;
</code></pre>
<p>我们以运行时栈的变化，来描述一下上述过程：</p>
<p><img src="./images/257.png" alt="" /></p>
<p>那么接下来的重点就是 __build_class__，它是如何将一个函数变成类的，我们来看一下。内置函数的相关实现，位于 Python/bitinmodule.c 中。</p>
<p><img src="./images/258.png" alt="" /></p>
<p>builtins 是一个模块，__build_class__ 是该模块里的一个函数，所以它位于 PyModuleDef 的 m_methods 字段中。关于模块的相关细节后续聊，总之我们看到 __build_class__ 在底层对应 builtin__build_class__。</p>
<pre><code class="language-C">static PyObject *
builtin___build_class__(PyObject *self, PyObject *const *args, Py_ssize_t nargs,
                        PyObject *kwnames)
{
    PyObject *func, *name, *bases, *mkw, *meta, *winner, *prep, *ns, *orig_bases;
    PyObject *cls = NULL, *cell = NULL;
    int isclass = 0;   /* initialize to prevent gcc warning */
    // class A: 会被翻译成 builtin.__build_class__(PyFunctionObject, &quot;A&quot;)
    // 所以这个函数至少需要两个参数
    if (nargs &lt; 2) {
        // 参数不足，报错，还记得这个报错信息吗？之前测试过的
        PyErr_SetString(PyExc_TypeError,
                        &quot;__build_class__: not enough arguments&quot;);
        return NULL;
    }
    // 类对应的 PyFunctionObject
    func = args[0];   /* Better be callable */
    if (!PyFunction_Check(func)) {
        // 如果不是 PyFunctionObject，报错
        PyErr_SetString(PyExc_TypeError,
                        &quot;__build_class__: func must be a function&quot;);
        return NULL;
    }
    // 类对应的名字，__build_class__ 的时候，类肯定要有名字
    name = args[1];
    if (!PyUnicode_Check(name)) {
        // 必须是一个 PyUnicodeObject，否则报错
        PyErr_SetString(PyExc_TypeError,
                        &quot;__build_class__: name is not a string&quot;);
        return NULL;
    }
    // args[0]表示 PyFunctionObject *，args[1] 表示 class name
    // 从 args + 2 开始是继承的基类，至于个数显然是 nargs - 2，所以这里是拿到所有的基类
    orig_bases = _PyTuple_FromArray(args + 2, nargs - 2);
    if (orig_bases == NULL)
        return NULL;
    // 这个 update_bases 比较有趣，我们一会儿单独说
    bases = update_bases(orig_bases, args + 2, nargs - 2);
    if (bases == NULL) {
        Py_DECREF(orig_bases);
        return NULL;
    }
    // 获取 metaclass
    if (kwnames == NULL) {
        meta = NULL;
        mkw = NULL;
    }
    else {
        mkw = _PyStack_AsDict(args + nargs, kwnames);
        if (mkw == NULL) {
            Py_DECREF(bases);
            return NULL;
        }

        meta = _PyDict_GetItemIdWithError(mkw, &amp;PyId_metaclass);
        if (meta != NULL) {
            Py_INCREF(meta);
            if (_PyDict_DelItemId(mkw, &amp;PyId_metaclass) &lt; 0) {
                Py_DECREF(meta);
                Py_DECREF(mkw);
                Py_DECREF(bases);
                return NULL;
            }
            /* metaclass is explicitly given, check if it's indeed a class */
            isclass = PyType_Check(meta);
        }
        else if (PyErr_Occurred()) {
            Py_DECREF(mkw);
            Py_DECREF(bases);
            return NULL;
        }
    }
    // 如果 meta 为 NULL，这意味着没有指定 metaclass
    if (meta == NULL) {
        // 然后尝试获取基类，如果没有基类，那么元类就是 &amp;PyType_Type
        if (PyTuple_GET_SIZE(bases) == 0) {
            meta = (PyObject *) (&amp;PyType_Type);
        }
        // 否则获取第一个继承的基类的 metaclass
        else {
            // 拿到第一个基类
            PyObject *base0 = PyTuple_GET_ITEM(bases, 0);
            // 拿到第一个基类的 __class__
            meta = (PyObject *) (base0-&gt;ob_type);
        }
        // meta 也是一个类
        Py_INCREF(meta);
        isclass = 1;
    }
  
    // 如果设置了元类，那么 isclass 为 1，if 为真
    if (isclass) {
        // 选择出了元类，下面这一步就要解决元类冲突
        // 假设有两个继承 type 的元类 MyType1 和 MyType2
        // 然后 Base1 的元类是 MyType1，而 Base2 的元类是 MyType2
        // 那么如果 class A(Base1, Base2) 的话，就会报错
        // 因为在 Python 中有一个要求，假设 class A(Base1, Base2, ..., BaseN)
        // Base1 的元类叫 MyType1、...、BaseN 的元类叫 MyTypeN
        // 那么必须满足：
        /*
        MyType1 是 MyType2 的子类或者父类;
        MyType1 是 MyType3 的子类或者父类;
        MyType1 是 MyType4 的子类或者父类;
        ....
        MyType1 是 MyTypeN 的子类或者父类;
        */
        // 而之所以存在这一限制，原因是为了避免属性冲突
        winner = (PyObject *)_PyType_CalculateMetaclass((PyTypeObject *)meta,
                                                        bases);
        if (winner == NULL) {
            Py_DECREF(meta);
            Py_XDECREF(mkw);
            Py_DECREF(bases);
            return NULL;
        }
        if (winner != meta) {
            Py_DECREF(meta);
            meta = winner;
            Py_INCREF(meta);
        }
    }
    // 寻找 __prepare__
    if (_PyObject_LookupAttrId(meta, &amp;PyId___prepare__, &amp;prep) &lt; 0) {
        ns = NULL;
    }
    // 如果 __prepare__ 为 NULL，那么等价于返回一个空字典
    else if (prep == NULL) {
        ns = PyDict_New();
    }
    else {
        // 否则调用 __prepare__，将字典返回
        PyObject *pargs[2] = {name, bases};
        ns = _PyObject_FastCallDict(prep, pargs, 2, mkw);
        Py_DECREF(prep);
    }
    if (ns == NULL) {
        Py_DECREF(meta);
        Py_XDECREF(mkw);
        Py_DECREF(bases);
        return NULL;
    }
    // 如果 __prepare__ 返回的不是一个字典，那么报错，这个错误信息我们也见过了
    if (!PyMapping_Check(ns)) {
        PyErr_Format(PyExc_TypeError,
                     &quot;%.200s.__prepare__() must return a mapping, not %.200s&quot;,
                     isclass ? ((PyTypeObject *)meta)-&gt;tp_name : &quot;&lt;metaclass&gt;&quot;,
                     Py_TYPE(ns)-&gt;tp_name);
        goto error;
    }
    // ...
    return cls;
}
</code></pre>
<p>可以看到，一个简单的类定义，虚拟机究竟做了多少事情啊，不过显然这还没完。自定义类对象的元信息分为两部分，分别是动态元信息和静态元信息。虚拟机在获得了属性表（动态元信息）之后，就知道了所有的属性。</p>
<p>但对于自定义类对象的类型是什么，应该如何创建、要分配多少内存，却没有任何的头绪，因为这部分隐藏在 metaclass 里面。</p>
<p>而在 builtin___build_class__中，metaclass 正是关于自定义类对象的另一部分元信息，我们称之为静态元信息。在静态元信息中，隐藏着所有的类对象应该如何创建的信息，注意：是所有的类对象。从源码中我们可以看到，如果指定了 metaclass，那么会选择指定的 metaclass；如果没有指定，那么会使用第一个继承的基类的 metaclass 作为该 class 的 metaclass。</p>
<p>对于实例对象，所有的元信息都存储在对应的类对象中。但是对于类对象来说，其元信息的静态元信息存储在对应的元类中，动态元信息则存储在本身的 local 名字空间中。</p>
<p>可为什么这么做呢？为什么对于类对象来说，其元信息要游离成两部分呢？都存在 metaclass 里面不香吗？这是因为用户在 .py 文件中可以定义不同的 class，这个元信息必须、且只能是动态的，所以它不适合保存在 metaclass 中。而存储在 metaclass 里面的，一定是诸如类对象的创建策略等所有 class 都会共用的元信息。</p>
<p>注意：我们说元信息游离成两部分指的是自定义类对象，内置类对象的元信息都存储在 metaclass 中。</p>
<p>因为内置类对象是静态提供的，它们都具备相同的接口集合（底层都是 PyTypeObject 结构体实例），支持什么操作一开始就定义好了。只不过有的可以用，有的不能用。比如 PyLongObject 可以使用 nb_add，但是 PyDictObject 不能，而 PyDictObject 可以使用 mp_subscript，但是 PyLongObject 不可以。</p>
<p>尽管如此，但这不影响它们的所有元信息都存储在元类中。而用户自定义的类对象，接口是动态的，不可能在 metaclass 中静态指定。</p>
<h3 id="update_bases"><a class="header" href="#update_bases">update_bases</a></h3>
<p>然后再来说一说源码中的 update_bases，它比较有意思。</p>
<pre><code class="language-Python">class Foo:
    name = &quot;古明地觉&quot;

class Bar:
    def __mro_entries__(self, bases):
        return Foo, tuple

class MyClass(Bar()):
    pass

print(MyClass(&quot;123&quot;))  # ('1', '2', '3')
print(MyClass.name)  # 古明地觉
</code></pre>
<p>我们在继承的时候，都是继承一个类，但是这里的 MyClass 居然继承了一个实例对象。相信结果你已经猜出来了，如果继承的是实例，那么会去调用实例的 <code>__mro_entries__</code>。因此 MyClass 继承的其实是 Foo、tuple，并且 <code>__mro_entries__</code> 必须返回一个元组，否则报错。</p>
<p>另外，如果一个类继承了一个拥有 <code>__mro_entries__</code> 的实例，那么该类会多出一个属性叫 <code>__orig_bases__</code>。我们回顾一下 builtin___build_class__ 里面的几行关键代码：</p>
<p><img src="./images/259.png" alt="" /></p>
<p>里面有两个变量 orig_bases 和 bases，我们知道 Python 的类都有 __bases__ 属性，对应这里的 bases；但鲜为人知的是，它还有一个属性叫 __orig_bases__，对应这里的 orig_bases。</p>
<pre><code class="language-Python">class Foo:
    name = &quot;古明地觉&quot;

class Bar:

    def __mro_entries__(self, bases):
        return Foo, tuple

class MyClass(Bar()):
    pass

print(MyClass.__orig_bases__)
print(MyClass.__bases__)
&quot;&quot;&quot;
(&lt;__main__.Bar object at 0x0000014FCC387E80&gt;,)
(&lt;class '__main__.Foo'&gt;, &lt;class 'tuple'&gt;)
&quot;&quot;&quot;
</code></pre>
<p>__orig_bases__ 和 __bases__ 的区别显而易见，__orig_bases__ 在经过 update_bases 函数处理之后，得到的就是 __bases__。</p>
<p>__orig_bases__ 表示继承的对象，该对象可以是一个类对象，也可以是一个实例对象；如果是实例对象，那么在 update_bases 函数中，会调用它的 <code>__mro_entries__</code> 方法，该方法返回一个包含类对象的元组，然后设置到 __bases__ 中。</p>
<p>以上就是函数 update_bases 的作用，但有两点需要注意。</p>
<ul>
<li>1）只有继承了拥有 <code>__mro_entries__</code> 方法的实例的类，才有 __orig_bases__ 属性；</li>
<li>2）这样的类，在 Python 里面不能手动调用 type 来创建；</li>
</ul>
<p>我们来解释一下，首先是第一点：</p>
<pre><code class="language-python">print(hasattr(MyClass, &quot;__orig_bases__&quot;))
print(hasattr(Foo, &quot;__orig_bases__&quot;))
print(hasattr(Bar, &quot;__orig_bases__&quot;))
&quot;&quot;&quot;
True
False
False
&quot;&quot;&quot;
</code></pre>
<p>我们看到只有 MyClass 有 __orig_bases__ 属性，因为它继承了拥有 <code>__mro_entries__</code> 方法的实例，而 Foo 和 Bar 则没有。</p>
<p>然后是第二点，这样的类不可以手动调用 type 来创建。</p>
<pre><code class="language-Python">class Foo:
    name = &quot;古明地觉&quot;

class Bar:
    def __mro_entries__(self, bases):
        return Foo, tuple

try:
    MyClass = type(&quot;MyClass&quot;, (Bar(),), {})
except TypeError as e:
    print(e)  # type() doesn't support MRO entry resolution; use types.new_class()

# 所以这样的类应该通过 class 关键字创建
# 如果必须手动创建的话，那么可以使用 types.new_class
import types
MyClass = types.new_class(&quot;MyClass&quot;, (Bar(),), {})
print(MyClass.name)  # 古明地觉
print(MyClass(&quot;123&quot;))  # ('1', '2', '3')
</code></pre>
<p>以上就是 update_bases 函数所干的事情，但是问题来了，如果继承的实例对象没有 <code>__mro_entries__</code> 方法怎么办？</p>
<pre><code class="language-Python">class Base:

    def __init__(self, *args):
        if len(args) == 0:
            return
        elif len(args) == 3:
            name, bases, attrs = args
        else:
            raise ValueError(&quot;args 的长度必须是 0 或 3&quot;)
        self.name = name
        self.bases = bases
        self.attrs = attrs

base = Base()

class MyClass(base):
    pass

print(type(MyClass) is Base)  # True
print(MyClass.name)  # MyClass
print(MyClass.bases == (base,))  # True
print(MyClass.attrs)  # {'__module__': '__main__', '__qualname__': 'MyClass'}
</code></pre>
<p>显然 MyClass 继承的是 Base 的实例对象，并且 Base 里面也没有定义 <code>__mro_entries__</code>，那么虚拟机就不会再使用 type 来创建 MyClass 了。而是会使用 Base 来创建，所以得到的 MyClass 就是一个 Base 的实例对象。</p>
<p>现在算是彻底理解 update_bases 的作用了，因为不能保证继承的都是类，所以还需要进行检测，如果不是类，那么就执行上面的逻辑。但是说实话，这个特性几乎不用，因为既然要继承，那么就应该继承类。虽然通过 <code>__mro_entries__</code> 可以整一些花活，甚至也能简化逻辑，但最好还是不要用，因为它会让代码变得难以理解。</p>
<h3 id="type_call"><a class="header" href="#type_call">type_call</a></h3>
<p>builtin___build_class__ 的逻辑我们上面省略了一部分，至于省略部分的逻辑也很简单，既然元类以及相关参数都准备好了，那么接下来就是对类进行创建了。</p>
<p>我们知道调用一个对象，本质上会执行其类对象的 __call__。所以调用类对象创建实例对象，会执行 type.__call__(cls, ...)。调用元类创建类对象，会执行 type.__call__(type, ...)，因为元类的类对象还是它本身。所以不管调用的是元类、还是类对象，都会执行元类的 __call__，在底层对应 &amp;PyType_Type 的 tp_call 字段，它指向了 type_call 函数。</p>
<pre><code class="language-C">// Objects/typeobject.c
static PyObject *
type_call(PyTypeObject *type, PyObject *args, PyObject *kwds)
{
    PyObject *obj;
    // tp_new 负责创建实例，所以它不能为空
    if (type-&gt;tp_new == NULL) {
        PyErr_Format(PyExc_TypeError,
                     &quot;cannot create '%.100s' instances&quot;,
                     type-&gt;tp_name);
        return NULL;
    }
    // 调用 tp_new 为实例对象申请内存
    obj = type-&gt;tp_new(type, args, kwds);
    // 确保返回值符合 Python 的调用约定
    obj = _Py_CheckFunctionResult((PyObject*)type, obj, NULL);
    if (obj == NULL)
        return NULL;
    // 如果调用的是 &amp;PyType_Type，并且只接收了一个位置参数
    // 那么显然是查看对象类型，执行完 __new__ 之后直接返回
    if (type == &amp;PyType_Type &amp;&amp;
        PyTuple_Check(args) &amp;&amp; PyTuple_GET_SIZE(args) == 1 &amp;&amp;
        (kwds == NULL ||
         (PyDict_Check(kwds) &amp;&amp; PyDict_GET_SIZE(kwds) == 0)))
        return obj;

    // 记得我们之前说过，__new__ 里面一定要返回类的实例对象
    // 否则是不会执行 __init__ 函数的，从这里我们也看到了
    // 如果 obj 的类型不是对应的类、或者其子类，那么直接返回
    if (!PyType_IsSubtype(Py_TYPE(obj), type))
        return obj;
    //然后获取 obj 的类型
    type = Py_TYPE(obj);
    // 如果内部存在 __init__ 函数，那么执行
    if (type-&gt;tp_init != NULL) {
        int res = type-&gt;tp_init(obj, args, kwds);
        if (res &lt; 0) {
            assert(PyErr_Occurred());
            Py_DECREF(obj);
            obj = NULL;
        }
        else {
            assert(!PyErr_Occurred());
        }
    }
    // 执行完构造函数之后，再将对象返回
    // 返回的 obj 可以是类对象、也可以是实例对象
    return obj;
}
</code></pre>
<p>type_call 里面的逻辑非常简单，就是先调用对象的 tp_new 创建实例，然后执行 tp_init（如果有）。至于返回的是类对象还是实例对象，则取决于 type_call 的第一个参数，如果第一个参数是元类，那么返回的就是类对象，否则是实例对象。因此创建的核心逻辑就隐藏在对象的 tp_new 中，不同对象的 tp_new 指向的函数不同。但对于创建类对象而言，显然执行的是 &amp;PyType_Type 的 tp_new，它指向的是 type_new 函数。</p>
<p>这个 type_new 就是我们创建自定义类对象的第一案发现场，源码位于 typeobject.c 中。这个函数的代码比较长，我们会有删减，像那些检测的代码就省略掉了。</p>
<pre><code class="language-C">static PyObject *
type_new(PyTypeObject *metatype, PyObject *args, PyObject *kwds)
{
    // 都是类的一些动态元信息
    PyObject *name, *bases = NULL, *orig_dict, *dict = NULL;
    PyObject *qualname, *slots = NULL, *tmp, *newslots, *cell;
    PyTypeObject *type = NULL, *base, *tmptype, *winner;
    PyHeapTypeObject *et;
    PyMemberDef *mp;
    Py_ssize_t i, nbases, nslots, slotoffset, name_size;
    int j, may_add_dict, may_add_weak, add_dict, add_weak;
    _Py_IDENTIFIER(__qualname__);
    _Py_IDENTIFIER(__slots__);
    _Py_IDENTIFIER(__classcell__);

    //如果 metatype 是 &lt;class 'type'&gt; 的话
    if (metatype == &amp;PyType_Type) {
        // 获取位置参数和关键字参数个数
        const Py_ssize_t nargs = PyTuple_GET_SIZE(args);
        const Py_ssize_t nkwds = kwds == NULL ? 0 : PyDict_GET_SIZE(kwds);
        // 位置参数的个数为 1，关键字参数的个数为 0，你想到了什么？是不是 type(xxx) 呢
        if (nargs == 1 &amp;&amp; nkwds == 0) {
            PyObject *x = PyTuple_GET_ITEM(args, 0);
            Py_INCREF(Py_TYPE(x));
            // 这显然是初学 Python 时就知道的，查看一个变量指向的对象的类型
            return (PyObject *) Py_TYPE(x);
        }

        // 如果上面的 if 不满足，会走这里，表示现在不再是查看类型了，而是创建类
        // 那么要求位置参数必须是 3 个，否则报错
        if (nargs != 3) {
            PyErr_SetString(PyExc_TypeError,
                            &quot;type() takes 1 or 3 arguments&quot;);
            return NULL;
        }
    }

    // 确定参数类型，因为传递的三个参数是有类型要求的
    // 必须是 PyUnicodeObject、PyTupleObject、PyDictObject
    if (!PyArg_ParseTuple(args, &quot;UO!O!:type.__new__&quot;, &amp;name, &amp;PyTuple_Type,
                          &amp;bases, &amp;PyDict_Type, &amp;orig_dict))
        return NULL;

    // 处理基类
    nbases = PyTuple_GET_SIZE(bases);
    // 如果没有继承基类，那么会默认继承 object
    // 所以将 __base__ 设置为 object，将 __bases__ 设置为 (object,)
    if (nbases == 0) {
        base = &amp;PyBaseObject_Type;
        bases = PyTuple_Pack(1, base);
        if (bases == NULL)
            return NULL;
        nbases = 1;
    }
    else {
        _Py_IDENTIFIER(__mro_entries__);
        // 如果继承了基类，那么循环遍历 bases
        for (i = 0; i &lt; nbases; i++) {
            // 拿到每一个基类
            tmp = PyTuple_GET_ITEM(bases, i);
            // 如果基类的类型为 &amp;PyType_Type，进行下一次循环
            if (PyType_Check(tmp)) {
                continue;
            }
            // 如果基类的类型不是 &amp;PyType_Type，说明继承的不是类
            // 于是寻找 __mro_entries__
            if (_PyObject_LookupAttrId(tmp, &amp;PyId___mro_entries__, &amp;tmp) &lt; 0) {
                return NULL;
            }
            if (tmp != NULL) {
                PyErr_SetString(PyExc_TypeError,
                                &quot;type() doesn't support MRO entry resolution; &quot;
                                &quot;use types.new_class()&quot;);
                Py_DECREF(tmp);
                return NULL;
            }
        }
        // 计算应该使用的元类，该函数会查看当前类使用的元类（metatype）和所有基类使用的元类
        // 根据元类继承规则选择最&quot;具体&quot;的元类作为 winner
        // 例如基类使用了自定义元类，而当前类使用默认的 type，那么自定义元类会胜出
        winner = _PyType_CalculateMetaclass(metatype, bases);
        if (winner == NULL) {
            return NULL;
        }
        // 胜出的元类（winner）和原始元类（metatype）比较
        // 如果胜出的元类和原始元类不同，并且胜出的元类有自己的 tp_new（不是默认的 type_new）
        if (winner != metatype) {
            if (winner-&gt;tp_new != type_new) /* Pass it to the winner */
                // 那么就调用胜出的元类的 tp_new 方法来创建类
                return winner-&gt;tp_new(winner, args, kwds);
            // 否则就用胜出的元类替换原始元类继续执行
            metatype = winner;
        }

        // 每个类都有 __base__ 和 __bases__，前者表示直接继承的第一个类，后者表示直接继承的所有类
        // 那么下面这行代码是做什么呢？直接 base = bases[0] 就好了
        // 其实这个 best_base 所做的事情没有这么简单，它还负责检测基类之间是否发生了冲突
        base = best_base(bases);
        if (base == NULL) {
            return NULL;
        }

        Py_INCREF(bases);
    }

    dict = PyDict_Copy(orig_dict);
    if (dict == NULL)
        goto error;

    // 处理定义了 __slots__ 的逻辑，一旦定义了__slots__，那么类的实例对象就没有属性字典了
    slots = _PyDict_GetItemIdWithError(dict, &amp;PyId___slots__);
    nslots = 0;
    add_dict = 0;
    add_weak = 0;
    may_add_dict = base-&gt;tp_dictoffset == 0;
    may_add_weak = base-&gt;tp_weaklistoffset == 0 &amp;&amp; base-&gt;tp_itemsize == 0;
    if (slots == NULL) {
        // ...
    }
    else {
        // ...
    }

    // 为自定义类对象申请内存
    type = (PyTypeObject *)metatype-&gt;tp_alloc(metatype, nslots);
    if (type == NULL)
        goto error;

    /* Keep name and slots alive in the extended type object */
    et = (PyHeapTypeObject *)type;
    Py_INCREF(name);
    et-&gt;ht_name = name;
    et-&gt;ht_slots = slots;
    slots = NULL;

    /* 初始化 tp_flags */
    type-&gt;tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HEAPTYPE |
        Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HAVE_GC;

    // 设置 PyTypeObject 的各个字段
    type-&gt;tp_as_async = &amp;et-&gt;as_async;
    type-&gt;tp_as_number = &amp;et-&gt;as_number;
    type-&gt;tp_as_sequence = &amp;et-&gt;as_sequence;
    type-&gt;tp_as_mapping = &amp;et-&gt;as_mapping;
    type-&gt;tp_as_buffer = &amp;et-&gt;as_buffer;
    type-&gt;tp_name = PyUnicode_AsUTF8AndSize(name, &amp;name_size);
    if (!type-&gt;tp_name)
        goto error;
    if (strlen(type-&gt;tp_name) != (size_t)name_size) {
        PyErr_SetString(PyExc_ValueError,
                        &quot;type name must not contain null characters&quot;);
        goto error;
    }

    /* 设置基类和基类列表 */
    type-&gt;tp_bases = bases;
    bases = NULL;
    Py_INCREF(base);
    type-&gt;tp_base = base;

    /* 设置属性字典 */
    Py_INCREF(dict);
    type-&gt;tp_dict = dict;

    // 设置 __module__
    if (_PyDict_GetItemIdWithError(dict, &amp;PyId___module__) == NULL) {
        // ...
    }

    // 设置 __qualname__，即 &quot;全限定名&quot;
    qualname = _PyDict_GetItemIdWithError(dict, &amp;PyId___qualname__);
    if (qualname != NULL) {
        if (!PyUnicode_Check(qualname)) {
            PyErr_Format(PyExc_TypeError,
                         &quot;type __qualname__ must be a str, not %s&quot;,
                         Py_TYPE(qualname)-&gt;tp_name);
            goto error;
        }
    }
    else if (PyErr_Occurred()) {
        goto error;
    }
    // ...

    // 如果自定义的 class 中重写了 __new__
    // 将 __new__ 对应的函数改造为静态方法，并替换掉默认的 __new__
    tmp = _PyDict_GetItemIdWithError(dict, &amp;PyId___new__);
    if (tmp != NULL &amp;&amp; PyFunction_Check(tmp)) {
        tmp = PyStaticMethod_New(tmp);
        if (tmp == NULL)
            goto error;
        if (_PyDict_SetItemId(dict, &amp;PyId___new__, tmp) &lt; 0) {
            Py_DECREF(tmp);
            goto error;
        }
        Py_DECREF(tmp);
    }
    else if (tmp == NULL &amp;&amp; PyErr_Occurred()) {
        goto error;
    }

    // 获取 __init_subclass__，如果子类继承了父类，那么会触发父类的__init_subclass__
    tmp = _PyDict_GetItemIdWithError(dict, &amp;PyId___init_subclass__);
    if (tmp != NULL &amp;&amp; PyFunction_Check(tmp)) {
        tmp = PyClassMethod_New(tmp);
        if (tmp == NULL)
            goto error;
        if (_PyDict_SetItemId(dict, &amp;PyId___init_subclass__, tmp) &lt; 0) {
            Py_DECREF(tmp);
            goto error;
        }
        Py_DECREF(tmp);
    }
    else if (tmp == NULL &amp;&amp; PyErr_Occurred()) {
        goto error;
    }
    
    // 设置 __class_getitem__，这个类似于 __getitem__
    // __class_getitem__ 支持类通过 cls[&quot;xxx&quot;] 的方式访问
    tmp = _PyDict_GetItemIdWithError(dict, &amp;PyId___class_getitem__);
    if (tmp != NULL &amp;&amp; PyFunction_Check(tmp)) {
        tmp = PyClassMethod_New(tmp);
        if (tmp == NULL)
            goto error;
        if (_PyDict_SetItemId(dict, &amp;PyId___class_getitem__, tmp) &lt; 0) {
            Py_DECREF(tmp);
            goto error;
        }
        Py_DECREF(tmp);
    }
    else if (tmp == NULL &amp;&amp; PyErr_Occurred()) {
        goto error;
    }
    
    // ...
    // 为自定义类对象的实例对象设置内存大小信息 
    type-&gt;tp_basicsize = slotoffset;
    type-&gt;tp_itemsize = base-&gt;tp_itemsize;
    type-&gt;tp_members = PyHeapType_GET_MEMBERS(et);

    // ...
    // 调用 PyType_Ready 对自定义类对象进行初始化
    if (PyType_Ready(type) &lt; 0)
        goto error;

    /* Put the proper slots in place */
    fixup_slot_dispatchers(type);

    if (type-&gt;tp_dictoffset) {
        et-&gt;ht_cached_keys = _PyDict_NewKeysForClass();
    }

    if (set_names(type) &lt; 0)
        goto error;

    if (init_subclass(type, kwds) &lt; 0)
        goto error;

    Py_DECREF(dict);
    return (PyObject *)type;

error:
    Py_XDECREF(dict);
    Py_XDECREF(bases);
    Py_XDECREF(slots);
    Py_XDECREF(type);
    return NULL;
}
</code></pre>
<p>我们看到，如果是内置的类对象，那么不会走当前的 type_new，因为它们本身就已经定义好了，只需调用 PyType_Ready 初始化一下即可。但是对于自定义类对象来说，在初始化之前要先做很多工作。</p>
<p>虚拟机首先会解析出类名、基类列表和属性字典，然后根据基类列表以及传入的 metaclass 确定最佳的 metaclass 和 base。</p>
<p>随后，虚拟机会调用 <code>metatype-&gt;tp_alloc</code>  为要创建的类对象分配内存，需要注意的是，在 &amp;PyType_Type 中，我们会发现 tp_alloc 是一个 NULL，这显然不正常。但是不要忘记，虚拟机会通过 PyType_Ready 对所有的类对象进行初始化，在这个初始化过程中，有一项动作是从基类继承各种操作。由于 type.__bases__中的第一个基类是 object，所以 type 会继承 object 的 tp_alloc 操作，即 PyType_GenericAlloc。</p>
<p>对于所有继承 object 的类对象来说， PyType_GenericAlloc 将申请 <code>metatype-&gt;tp_basicsize + metatype-&gt;tp_itemsize</code> 大小的内存空间，而这个大小实际就是 <code>sizeof(PyHeapTypeObject) + sizeof(PyMemerDef)</code>。因此到这里应该明白 PyHeapTypeObject 这个老铁到底是干嘛用的了，之前因为偏移量的问题，折腾了不少功夫，甚至让人觉得这有啥用啊，但是现在意识到了，这个老铁是为自定义类对象准备的。</p>
<p>接下来就是设置自定义类对象的各个字段，其中包括了在 tp_dict 上设置属性字典，也就是 __dict__。另外要注意的是，这里还计算了类对象对应的实例对象所需要的内存大小信息，换言之，自定义类在创建实例对象时，需要为这个实例对象申请多大的内存空间呢？对于任意一个继承了 object 的自定义类对象来说，这个大小为 <code>PyBaseObject_Type-&gt;tp_basicsize + 16</code>，其中的 16 是 <font color="blue">2 * sizeof(PyObject *)</font>。</p>
<p>而之所以后面要跟着两个 PyObject * 的大小，是因为这些空间的地址被设置给了 tp_dictoffset 以及 tp_weaklistoffset。这一点将在介绍实例对象时进行解析，它是和实例对象的属性字典密切相关的。</p>
<p>最后，虚拟机还会调用 PyType_Ready 对自定义类对象进行和内置类对象一样的初始化动作，到此自定义类对象才算正式创建完毕。因此内置类对象是底层静态定义好的，启动之后再调用 PyType_Ready 完善一下即可；但自定义类对象则不同，它需要运行时动态创建，这是一个复杂的过程。但最后，两者都会调用 PyType_Ready。</p>
<p>那么内置类对象和自定义类对象在内存布局上有什么区别呢？毕竟都是类对象。</p>
<p><img src="./images/260.png" alt="" /></p>
<p>本质上，无论是自定义类对象还是内置类对象，在虚拟机内部，都可以用一个 PyTypeObject 来表示。</p>
<p>但不同的是，内置类对象对应的 PyTypeObject 以及关联的操作簇的内存位置都是在编译时确定的，它们在内存中的位置是分离的。而自定义类对象对应的 PyTypeObject 以及关联的操作簇的内存位置是连续的，必须在运行时动态分配内存。</p>
<p>另外，自定义类对象对应的 PyTypeObject 和相关操作簇组合起来，被称为 PyHeapTypeObject。</p>
<pre><code class="language-C">typedef struct _heaptypeobject {
    PyTypeObject ht_type;
    PyAsyncMethods as_async;
    PyNumberMethods as_number;
    PyMappingMethods as_mapping;
    PySequenceMethods as_sequence; 
    PyBufferProcs as_buffer;
    PyObject *ht_name, *ht_slots, *ht_qualname;
    struct _dictkeysobject *ht_cached_keys;
} PyHeapTypeObject;
</code></pre>
<p>内置类对象有哪些操作是静态定义好的，所以相关操作是分离的。但自定义类对象的相关操作簇必须紧随其后，且顺序也有讲究，只有这样才能通过偏移量 offset 准确找到指定的操作。</p>
<p>现在我们也对 Python 的可调用（callable）这个概念有一个感性认识了，可调用这个概念是一个相当通用的概念，不拘泥于对象、大小，只要类型对象定义了 tp_call，就能进行调用操作。我们已经看到，调用 metaclass 得到类对象，调用类对象得到实例对象，如果类对象也定义了 tp_call，那么还可以继续对实例对象进行调用。</p>
<h2 id="小结-61"><a class="header" href="#小结-61">小结</a></h2>
<p>以上我们就聊了聊自定义类对象的底层实现与 metaclass，还是有点复杂的，有兴趣可以多读一读源码。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-62"><a class="header" href="#楔子-62">楔子</a></h2>
<p>介绍完类对象之后，我们来介绍实例对象。之前费了老鼻子劲将类对象剖析了一遍，但这仅仅是万里长征的第一步，因为虚拟机执行时，在内存中兴风作浪的是一个个的实例对象，而类对象只是幕后英雄。</p>
<p>但是在源码分析实例对象之前，我们需要先补充一些描述符相关的知识，因为后续会涉及到。所以这一篇文章暂时不涉及任何的 CPython 源码，先从 Python 的层面理解它，然后再看底层实现会轻松很多。</p>
<h2 id="问世间描述符为何物"><a class="header" href="#问世间描述符为何物">问世间描述符为何物？</a></h2>
<p>什么是描述符呢？很简单，一个类中，只要出现了 __get__、__set__、__delete__ 三者中的任意一个，那么它的实例就被称之为描述符。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)
        print(instance)
        print(value)


class Girl:
    # 此时的 name 属性就被描述符代理了
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age

g = Girl(&quot;satori&quot;, 16)
&quot;&quot;&quot;
__set__
&lt;__main__.Girl object at 0x0000021D8D225E40&gt;
satori
&quot;&quot;&quot;
</code></pre>
<p>当程序执行 self.name = name 的时候，并没有把值设置到 self 的属性字典里面，而是执行了描述符的 __set__ 方法。参数 instance 是调用时的实例对象，也就是这里的 g，至于 value 显然就是给 self.name 赋的值。</p>
<pre><code class="language-Python">print(g.age)  # 16
</code></pre>
<p>对于 self.age，由于它没有被代理，所以会正常设置到属性字典里面去，因此打印 16。但如果是 g.name 呢？</p>
<pre><code class="language-Python">g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x0000016C4C565E40&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>由于实例的 name 属性被代理了，那么获取的时候，会触发描述符的 __get__ 方法。参数 instance 就是调用时的实例对象，也就是这里的 g，至于 owner 则是 g 的类型，也就是 Girl。</p>
<p>现在我们可以得到如下结论，如果实例的属性被具有 __get__ 和 __set__ 方法的描述符代理了。那么给被代理的属性赋值的时候，会执行描述符的 __set__ 方法，获取属性则会执行描述符的 __get__ 方法。</p>
<h2 id="属性字典"><a class="header" href="#属性字典">属性字典</a></h2>
<p>我们给实例添加属性的时候，本质上都是添加到了实例的属性字典 __dict__ 中。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)
        print(instance)
        print(value)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age

g = Girl(&quot;satori&quot;, 16)
&quot;&quot;&quot;
__set__
&lt;__main__.Girl object at 0x000001D07DA35E40&gt;
satori
&quot;&quot;&quot;

print(g.__dict__)
&quot;&quot;&quot;
{'age': 16}
&quot;&quot;&quot;
</code></pre>
<p>可以看到，由于实例的 name 属性被代理了，所以它没有设置在属性字典中。如果没有被代理，按照 Python 的逻辑，会自动设置到实例的属性字典里面，但是现在被代理了，因此走的是描述符的 __set__ 方法，所以没有设置到字典里面去。</p>
<pre><code class="language-Python">g.__dict__[&quot;name&quot;] = &quot;satori&quot;
# 其实，不光实例对象，类也是，属性都在对应的属性字典里面
# self.name = &quot;xxx&quot; 就等价于 self.__dict__[&quot;name&quot;] = &quot;xxx&quot;
# self.__dict__ 里面的属性，都可以通过 self. 的方式来获取
print(g.__dict__)  # {'age': 16, 'name': 'satori'}
</code></pre>
<p>因此可以通过获取属性字典的方式，来给实例对象设置值。所以虽然实例对象的 name 属性被代理了，但我们通过属性字典的方式绕过去了，让它没有走描述符的 __set__ 方法。如果是获取属性呢？</p>
<pre><code class="language-Python">name = g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x00000155235E5E40&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
print(name)  # None
</code></pre>
<p>可以看到还是跟之前一样，因为被代理了，无法通过 <font color="blue">self.</font> 的方式来获取。而 name 打印的是 None，因为 __get__ 返回的是 None。那怎么办呢？还是使用字典的方式。</p>
<pre><code class="language-python">print(g.__dict__[&quot;name&quot;])  # satori
</code></pre>
<p>因此对于类和实例对象来说，都有各自的属性字典，操作属性本质上就是操作属性字典。</p>
<pre><code class="language-Python">class A:

    def add(self, a, b):
        return a + b

a = A()
print(A.add(a, 10, 20))  # 30
# A.add 等价于 A.__dict__[&quot;add&quot;]
print(A.__dict__[&quot;add&quot;](a, 10, 20))  # 30

print(a.add(10, 20))  # 30
</code></pre>
<p>那么问题来了，a.__dict__[&quot;add&quot;] 可不可以呢？答案是不可以的，因为这只能表示从自身的属性字典中查找，但 a 的属性字典里面没有 &quot;add&quot;，所以会报错的。而 a.add 虽然也是操作自身的属性字典，但它还隐含了<font color="blue">当自身的属性字典中没有 &quot;add&quot; 时，会去类里面查找</font>这一逻辑。</p>
<pre><code class="language-Python">try:
    a.__dict__[&quot;add&quot;]
except KeyError as e:
    print(f&quot;没有 {e} 这个属性&quot;)  # 没有 'add' 这个属性   

# 我们可以手动添加，注意这个 add 是实例里面的，不是类里面的
# 所以调用时不会将自身作为第一个参数传递过去
a.__dict__[&quot;add&quot;] = lambda a, b, c: a + b + c
print(a.add(10, 20, 30))  # 60
</code></pre>
<p>所以当实例对象里面已经有了，就不会再到类里面找了。当然啦，函数也有自己的属性字典，只不过一般都是空的。</p>
<p>再来补充一个点：</p>
<pre><code class="language-Python">class Seq:

    def __len__(self):
        return 123

s = Seq()

# 之前说过，如果 cls 是 obj 的类对象，那么 obj.xxx() 本质上是 cls.xxx(obj)
# 前者是后者的语法糖，之后介绍实例对象的时候还会说
# 因此这里的 s.__len__()，本质上是 Seq.__len__(s)
print(Seq.__len__(s))  # 123
print(s.__len__())  # 123

# 而对于 len(s) 而言，本质上也是 Seq.__len__(s)
print(len(s))  # 123

# 但是 len(s) 和 s.__len__() 之间没有任何关系
# len(s) 执行的是 Seq.len(s)，不是 s.__len__()
s.__len__ = lambda: 456
print(s.__len__())  # 456
print(len(s))  # 123
</code></pre>
<p>所以即便 s 有 __len__，但如果 Seq 没有 __len__ 的话，那么 len(s) 也是会报错的。当然啦，不光是这里的 len 和 __len__，像 getattr 和 __getattr__、setattr 和 __setattr__、iter 和 __iter__、next 和 __next__，它们之间都是类似的。</p>
<h2 id="描述符的优先级"><a class="header" href="#描述符的优先级">描述符的优先级</a></h2>
<p>描述符也是有优先级的，我们说当一个类里面出现了 __get__、__set__、__delete__ 任意一种，就被称为描述符。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    # def __set__(self, instance, value):
    #     print(&quot;__set__&quot;)
    #     print(instance)
    #     print(value)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age
</code></pre>
<p>这里将描述符的 __set__ 去掉了，如果描述符内部有 __set__，那么称这个描述符为<font color="blue">数据描述符</font>。如果只出现了 __get__ 或 __delete__，而没有 __set__，那么称之为<font color="blue">非数据描述符</font>。</p>
<pre><code class="language-Python">g = Girl(&quot;satori&quot;, 16)
print(g.name, g.age)  # satori 16
</code></pre>
<p>由于没有 __set__，显然属性和值会被正常设置到属性字典里面去，这没有问题。但是我们发现，在获取属性的时候居然没有走 __get__，它明明定义了啊。其实原因很简单，这里代理属性的描述符是非数据描述符，所以没有执行 __get__。</p>
<p>也就是说，当一个实例对象去访问被代理的某个属性的时候（通过 <strong>.</strong> 的方式），如果是数据描述符，那么会走描述符的 __get__ 方法；如果是非数据描述符，那么会优先从属性字典里面获取，所以 self.name 打印的结果是字符串 &quot;satori&quot;。</p>
<p>因此我们得出了一个结论，优先级：<strong>非数据描述符 &lt; 实例属性 &lt; 数据描述符</strong>。</p>
<p>现在我们知道了，描述符和实例属性之间的关系。但如果是类属性呢？</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)
        print(instance)
        print(value)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age

name = Girl.name
&quot;&quot;&quot;
__get__
None
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
Girl.name = &quot;satori&quot;
print(Girl.name)  # satori
</code></pre>
<p>我们注意到，类去访问的话，由于 name 被代理了，访问依旧会触发 __get__ 方法。但是，我们通过类来设置的时候却没有触发 __set__ 方法，所以类的优先级大于数据描述符。</p>
<p>并且，由于类已经将 name 给替换掉了，所以它变成了一个普通的类属性，不再被描述符所代理。因此，此时实例也不会受到描述符的影响，因为 Girl 这个类已经将描述符替换成普通的字符串了。</p>
<pre><code class="language-Python">g = Girl(&quot;koishi&quot;, 15)
print(g.name, g.age)  # koishi 15
</code></pre>
<p>因此结论如下：非数据描述符 &lt; 实例属性 &lt; 数据描述符 &lt; 类属性 &lt; 未设置。</p>
<p>咦，这个未设置是什么鬼？首先类是可以更改被代理的属性的，类有权利将这个属性替换成别的，并且在替换的过程中不会触发描述符的 __set__，所以我们说优先级：<strong>类属性 &gt; 数据描述符</strong>。但如果类没有将被代理的属性替换成别的，还是让它等于一个描述符，那么类调用的时候就会触发描述符的 __get__，所以优先级：<strong>类属性 &lt; 未设置</strong>。</p>
<p>对于实例而言，如果是数据描述符，设置属性会走 __set__，获取属性会走 __get__。即使我们通过手动获取属性字典的方式，绕过了 __set__，但通过 <strong>.</strong> 的方式获取属性的时候依旧会触发 __get__。所以优先级：<strong>实例属性 &lt; 数据描述符</strong>。</p>
<p>如果是非数据描述符，由于没有 __set__，那么实例属性会被设置到属性字典里面。而一旦设置到属性字典里面，那么访问的时候发现在属性字典中能找到该属性，就不会再走描述符的 __get__ 了。所以优先级：<strong>非数据描述符 &lt; 实例属性</strong>。</p>
<p>不过还遗漏了一点，如果实例属性没有被设置到属性字典里面，会是什么情况呢？举个栗子：</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        # self.name = name
        self.age = age


g = Girl(&quot;koishi&quot;, 15)
g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x00000164BF366410&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;

g.name = &quot;satori&quot;
print(g.name)  # satori

# 添加一个 __set__
Descriptor.__set__ = lambda *args: None
g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x00000164BF366410&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>由于是非数据描述符，所以实例优先去自身的属性字典里面查找 name，但是没有，因为 name 这个属性我们并没有将它设置到属性字典中，所以在访问的时候还是走描述符的 __get__。</p>
<p>但是当设置完 g.name 之后，属性字典里面有 name 了，那么就不会再走 __get__ 了。而后面又手动给 Descriptor 增加了一个 __set__，那么描述符就从非数据描述符变成了数据描述符，这时候再执行 g.name，就又走 __get__ 方法了。所以不愧是动态语言，但也是导致性能问题的根源之一。</p>
<p>到目前为止可能有一些绕，再总结一下（一会还会啰嗦一遍）。</p>
<p>首先这里的优先级指的是<font color="blue">能否正常修改被描述符代理的属性</font>，由于类在修改的时候不会触发描述符的 __set__，但是实例修改时会触发，所以优先级：<font color="blue">实例属性 &lt; 数据描述符 &lt; 类属性</font>。而如果是非数据描述符，实例在修改的时候则不会触发 __set__，因为非数据描述符压根没有 __set__，所以优先级：<font color="blue">非数据描述符 &lt; 实例属性</font>。</p>
<p>因此这个优先级是这么来的，最后还有一个未设置。</p>
<p>以实例对象为例，虽然它的优先级高于非数据描述符，但如果没有将属性设置到属性字典里面去的话，那么由于自身找不到，会去类里面找，结果发现这个属性被描述符代理了，那么依旧会触发描述符的 __get__。</p>
<p>再以类为例：</p>
<pre><code class="language-python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        # self.name = name
        self.age = age

Girl.name

&quot;&quot;&quot;
__get__
None
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>类的优先级肯定高于非数据描述符，但这个优先级指的是<font color="blue">能否正常修改被描述符代理的属性</font>，虽然类可以修改，但是它没有修改。因此在获取 Girl.name 时，发现它被代理了，那么依旧会触发描述符的 __get__。</p>
<h2 id="被代理的属性"><a class="header" href="#被代理的属性">被代理的属性</a></h2>
<p>可能有人好奇 name = Descriptor() 里的 name，到底是实例的 name，还是类的 name。</p>
<p>首先既然是 name = Descriptor()，那么这肯定是一个类属性。但我们无论是使用类还是使用实例，貌似都可以触发描述符的方法啊。那么从描述符的角度来说，这个 name 到底是针对谁的呢？其实，答案可以说两者都是吧，我们举例说明。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)
        print(instance)
        print(value)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age

Girl.name
&quot;&quot;&quot;
__get__
None
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;

print(Girl.__dict__[&quot;name&quot;])
&quot;&quot;&quot;
&lt;__main__.Descriptor object at 0x000002885D16F670&gt;
&quot;&quot;&quot;
</code></pre>
<p>可以看到，直接访问的话会触发 __get__，但是通过属性字典获取的话，拿到的就是一个 Descriptor 对象，这是毫无疑问的。然后再看实例：</p>
<pre><code class="language-Python">g = Girl(&quot;satori&quot;, 16)
&quot;&quot;&quot;
__set__
&lt;__main__.Girl object at 0x0000020A57C75E40&gt;
satori
&quot;&quot;&quot;
</code></pre>
<p>用大白话解释就是，实例去访问自身的 name 属性，但是发现类里面有一个和自己同名、而且被数据描述符代理的属性，所以实例自身的这个属性也相当于被描述符代理了。</p>
<pre><code class="language-Python">Girl.name = &quot;satori&quot;
g = Girl(&quot;satori&quot;, 16)
</code></pre>
<p>此时设置属性、访问属性没有再触发描述符的方法，这是因为类属性的优先级比两种描述符的优先级都要高，从而把 name 给修改了。那么此时再去设置实例属性的话，类里面已经没有和自己同名并且被描述符代理的 name 了，所以会直接设置到属性字典里面。</p>
<p>我们再进一步验证上面的结论。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)
        print(instance)
        print(value)


class Girl:
    name = Descriptor()

    def __init__(self, age):
        self.age = age

# 此时实例已经没有 name 属性了
g = Girl(16)
print(g.age)  # 16
g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x00000274FBA45E40&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
# 但依旧触发描述符的 __get__ 方法，这是肯定的
# 因为实例根本没有 name 这个属性，于是会到类里面找
# 但是被代理了，那么走描述符的 __get__ 方法

# 通过属性字典的方式，向实例里面设置一个 name 属性
g.__dict__[&quot;name&quot;] = &quot;satori&quot;
g.name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x00000274FBA45E40&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;

# 此时获取属性又触发了描述符的方法，显然不需要解释了
# 因为类里面有一个和自己同名、且被描述符代理的属性
</code></pre>
<p>但上面的是数据描述符，如果是非数据描述符就另当别论了。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)


class Girl:
    name = Descriptor()

    def __init__(self, name, age):
        self.name = name
        self.age = age

g = Girl(&quot;satori&quot;, 16)
print(g.name)  # satori
</code></pre>
<p>因为是非数据描述符，所以实例的优先级更高。虽然在获取属性时发现类中有一个和自己同名，并且被描述符代理的属性（这里是 name），但是这个描述符是非数据描述符，所以会先到自己的属性字典里面找，如果找到了直接返回。</p>
<blockquote>
<p>如果是数据描述符，那么无论实例的属性字典里有没有 name，都会无条件走描述符的 __get__，因为实例的优先级低于数据描述符。</p>
</blockquote>
<pre><code class="language-Python">Girl.name
&quot;&quot;&quot;
__get__
None
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>但是类在调用的时候，依旧触发了 __get__，因为类的优先级小于<strong>未设置</strong>。或者说 Girl.name 拿到的依旧是一个描述符，那么当然会触发 __get__，可如果将 Girl.name 改成别的，就不会触发了。</p>
<h2 id="类和实例获取被代理属性的区别"><a class="header" href="#类和实例获取被代理属性的区别">类和实例获取被代理属性的区别？</a></h2>
<p>首先 name = Descriptor()，类和实例都可以访问，如果访问 name 时发现它是一个描述符，那么就会触发 __get__ 方法。但是这两者有什么区别呢？</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)
        print(instance)
        print(owner)


class Girl:
    name = Descriptor()

Girl.name
&quot;&quot;&quot;
__get__
None
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;

Girl().name
&quot;&quot;&quot;
__get__
&lt;__main__.Girl object at 0x000001B4D7F95DB0&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>不难发现 __get__ 里面的 instance 就是实例，owner 就是类。如果实例获取，那么 instance 就是实例，如果类去获取 instance 就是 None。对于 __set__ 来说，instance 依旧是实例，value 就是我们给实例被代理的属性设置的值。</p>
<h2 id="如何获取被代理属性的名称"><a class="header" href="#如何获取被代理属性的名称">如何获取被代理属性的名称？</a></h2>
<p>相信到这里，描述符的原理已经清楚了，但还有一些内容没有说。</p>
<p>我们知道，如果是数据描述符，只能使用属性字典的方式，但那是在描述符不做逻辑处理的情况下。现在我们来看看如何让描述符支持实例对象通过 <strong>.</strong> 的方式访问自身被代理的属性。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;获取值&quot;)
        return instance.__dict__[&quot;name&quot;]

    def __set__(self, instance, value):
        print(&quot;设置值&quot;)
        instance.__dict__[&quot;name&quot;] = value


class Girl:
    name = Descriptor()


g = Girl()
g.name = &quot;satori&quot;
&quot;&quot;&quot;
设置值
&quot;&quot;&quot;

print(g.name)
&quot;&quot;&quot;
获取值
satori
&quot;&quot;&quot;
</code></pre>
<p>如果我们不加那两个 print，那么表现出来的结果和不使用描述符是一样的。</p>
<p>但是这里有一个问题，那就是描述符中的 instance.__dict__[&quot;name&quot;]，这里我们把 key 写死了，如果我们想对 age 进行代理呢？举个栗子：</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        return instance.__dict__[&quot;name&quot;]

    def __set__(self, instance, value):
        instance.__dict__[&quot;name&quot;] = value


class Girl:
    age = Descriptor()

g = Girl()
g.age = 16
print(g.__dict__)  # {'name': 16}
print(g.name)  # 16
</code></pre>
<p>我们明明是给 age 设置属性，但影响的却是 name，原因是描述符中已经将 key 写死了。所以我们需要让描述符获取到它代理的属性的名称，此时 __set_name__ 的作用就来了。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        return instance.__dict__[&quot;name&quot;]

    def __set__(self, instance, value):
        instance.__dict__[&quot;name&quot;] = value

    def __set_name__(self, owner, name):
        print(owner)
        print(name)


class Girl:
    age = Descriptor()

&quot;&quot;&quot;
&lt;class '__main__.Girl'&gt;
age
&quot;&quot;&quot;
</code></pre>
<p>当 Girl 这个类被创建时，__set_name__ 就执行了，所以它是在 __get__ 和 __set__ 之前执行的。参数 owner 依旧是类本身，参数 name 指的就是被代理的属性的名称。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        return instance.__dict__[self.name]

    def __set__(self, instance, value):
        instance.__dict__[self.name] = value

    def __set_name__(self, owner, name):
        # 此时的 name 就是字符串 &quot;gender&quot;
        # 因为被代理的属性是 gender
        self.name = name


class Girl:
    gender = Descriptor()

g = Girl()
g.gender = &quot;female&quot;
print(g.__dict__)  # {'gender': 'female'}
</code></pre>
<p>此时的实例属性就被正确地设置进去了，但就我个人而言，更喜欢 __init__ 的方式。</p>
<pre><code class="language-Python">class Descriptor:

    def __init__(self, name):
        self.name = name

    def __get__(self, instance, owner):
        return instance.__dict__[self.name]

    def __set__(self, instance, value):
        instance.__dict__[self.name] = value


class Girl:
    name = Descriptor(&quot;name&quot;)
    age = Descriptor(&quot;age&quot;)

    def __init__(self, name, age):
        self.name = name
        self.age = age

g = Girl(&quot;satori&quot;, 16)
print(g.name, g.age)  # satori 16
</code></pre>
<p>到此描述符的内容就全部介绍完毕了。</p>
<h2 id="描述符的作用"><a class="header" href="#描述符的作用">描述符的作用</a></h2>
<p>虽然上面花了很大的笔墨介绍了描述符的原理以及使用方式，但是这个描述符有啥用呢？我们用描述符能够实现什么功能呢？</p>
<p>其实描述符能够做的事情非常多，比如做 web 开发时的表单验证。当然啦，描述符和字典一样，不光我们在用，底层也在大量使用描述符，比如 property、staticmethod、classmethod 等等。至于这些内容后续再说，下面我们就简单举个小例子，演示一下描述符的用法。</p>
<p>众所周知，Python 创建变量的时候，不需要指定类型，原因就是类型是和对象绑定的，而不是和变量。虽然现在有了类型注解，但这只是一个规范，并没有实际的约束力，比如：</p>
<p><img src="./images/261.png" alt="" /></p>
<p>这里要求 name 是 str 类型，然而我们传入的值却是 int 类型，PyCharm 也很智能地提示我们类型不对。但我们就传入 int 类型的值，解释器能拿我们怎么样吗？显然不能，这个程序是可以正常执行的，因此类型注解并没有在语法层面上限制你。</p>
<p>但由于类型不对，导致的 bug 数不胜数。比如判断两个字符串是否相等，但其中一个是 bytes 类型，我们忘记 decode 了，那么显然就永远不会相等了。而在 Python 里面，这种做法又是合法的，因此就很容易产生意想不到的效果。比如 Instagram 公司在从 Python2 切换到 Python3 时就遇到过这个问题，这是该公司的工程师在 PyCon 2017 大会上分享的，有兴趣可以去看一看。</p>
<p>而对于静态语言来说，比如 Golang，就不会出现这个问题。因为在 Golang 里面 []byte 和 string 是不能比较的，编译时就不会通过。当然啦，这是由于语言的特性不同导致的，并没有说谁好谁坏。那么下面我们就来改造一下，让 Python 的类在实例化的时候也能像静态语言一样进行类型检查。</p>
<pre><code class="language-Python">class TypeChecker:

    def __init__(self, name, excepted_type):
        self.name = name
        self.excepted_type = excepted_type

    def __get__(self, instance, owner):
        return instance.__dict__[self.name]

    def __set__(self, instance, value):
        # 在赋值的时候，对 value 进行判断
        # 如果 value 的类型是 self.excepted_type，那么合法，否则类型错误
        if not isinstance(value, self.excepted_type):
            tp = type(value).__name__
            excepted_tp = self.excepted_type.__name__
            raise TypeError(f&quot;{self.name} 接收的值应该是 {excepted_tp} 类型，而不是 {tp} 类型&quot;)

        instance.__dict__[self.name] = value


class Girl:
    name = TypeChecker(&quot;name&quot;, str)
    age = TypeChecker(&quot;age&quot;, int)

    def __init__(self, name: str, age: int):
        self.name = name
        self.age = age

try:
    g = Girl(16, 16)
except TypeError as e:
    print(e)  # name 接收的值应该是 str 类型, 而不是 int 类型
</code></pre>
<p>但是这么做还不够优雅，如果我们有大量的类都需要进行类型检测，那么每一个类里面都要提前声明好被描述符代理的属性。这会比较麻烦，于是可以考虑使用装饰器。</p>
<pre><code class="language-Python">class TypeChecker:

    def __init__(self, name, excepted_type):
        self.name = name
        self.excepted_type = excepted_type

    def __get__(self, instance, owner):
        return instance.__dict__[self.name]

    def __set__(self, instance, value):
        if not isinstance(value, self.excepted_type):
            tp = type(value).__name__
            excepted_tp = self.excepted_type.__name__
            raise TypeError(f&quot;{self.name} 接收的值应该是 {excepted_tp} 类型，而不是 {tp} 类型&quot;)

        instance.__dict__[self.name] = value


def type_checker(cls):
    # cls 就是要被 type_checker 装饰的类
    # 拿到 __init__ 函数
    __init__ = getattr(cls, &quot;__init__&quot;, None)
    # 如果 __init__ 为空，或者它不是一个函数，那么直接将类返回
    if __init__ is None or not hasattr(__init__, &quot;__code__&quot;):
        return cls

    # 拿到 __init__ 函数的 __annotations__
    annotations = cls.__init__.__annotations__
    # 进行遍历，给类设置被描述符代理的属性
    for name, excepted_type in annotations.items():
        setattr(cls, name, TypeChecker(name, excepted_type))
    return cls


# 以后在创建类的时候，直接打上这个装饰器就行了
# 但是显然这个装饰器依赖类型注解
# 如果没有类型注解的话，那么该属性是不会被代理的
@type_checker
class Girl:

    def __init__(self, name: str, age: int):
        self.name = name
        self.age = age

try:
    g = Girl(16, 16)
except TypeError as e:
    print(e)  # name 接收的值应该是 str 类型, 而不是 int 类型
</code></pre>
<p>怎么样，现在实现起来是不是更优雅一点了呢？</p>
<p>对了，我们上面一直在说 __get__、__set__，而把 __delete__ 忽略了。</p>
<pre><code class="language-Python">class Descriptor:

    def __get__(self, instance, owner):
        print(&quot;__get__&quot;)

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)

    def __delete__(self, instance):
        print(&quot;__delete__&quot;)


class Girl:
    name = Descriptor()

g = Girl()
g.name = &quot;satori&quot;
&quot;&quot;&quot;
__set__
&quot;&quot;&quot;

g.name
&quot;&quot;&quot;
__get__
&quot;&quot;&quot;

del g.name
&quot;&quot;&quot;
__delete__
&quot;&quot;&quot;
</code></pre>
<p>显然在删除一个属性时，会执行 __delete__，比较简单，就不多说了。__delete__ 一般不会单独出现，而且事实上 __delete__ 用的也不多。</p>
<h2 id="小结-62"><a class="header" href="#小结-62">小结</a></h2>
<p>以上就是描述符的全部内容了，这个功能总是容易被遗忘，但通过描述符我们可以实现很多炫酷的功能。所以 Python 里面的花活还是很多的，深入起来会发现不是那么简单，而像 Golang 虽然是静态语言，但它真的要比 Python 简单很多。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><p>本篇文章来聊一聊实例对象是如何创建的，这部分内容其实在最开始介绍对象关系模型的时候说过了，这里再来回顾一遍。我们知道创建实例对象有两种方式：</p>
<ul>
<li>通过 Python / C API 创建，只适用于内置类对象的实例对象；</li>
<li>通过调用类型对象创建，适用于所有的实例对象；</li>
</ul>
<p>以创建列表为例：</p>
<pre><code class="language-Python">lst1 = []
lst2 = list()
</code></pre>
<p>这两种都是合法的，但 lst1 指向的列表是通过 Python / C API 创建的，lst2 指向的列表是通过调用类型对象创建的。</p>
<p>在工作中，更推荐使用 Python / C API 创建。因为内置类对象的实例对象，在底层是预先定义好的，结构体内部有哪些字段已经写死了，直接创建就行了，所以它的速度比调用类型对象要快。而解释器也能区分出实例对象的种类，比如看到 <strong>[]</strong> 时，就知道是列表；看到 <strong>()</strong> 时，就知道是元组；看到 <strong>{}</strong> 时，就知道是字典。</p>
<p>而通过 Python / C API 创建虽然更快，但这是内置类对象的实例对象才享有的特权。对于自定义类而言，想创建其实例对象，只能通过调用类型对象的方式。这是显而易见的，因为解释器不可能把我们自定义类的实例对象在底层预先定义好。</p>
<p>相信实例对象的创建应该大致了解了，下面我们就来看一下具体的实现细节，这里针对的是第二种创建方式。因为通过 Python / C API 创建没什么复杂的，调用类型对象创建才是我们的重点，而这种方式也是所有的实例对象都支持的。</p>
<p>下面就以自定义类对象为例，看看实例对象是如何创建的。</p>
<pre><code class="language-python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age


g = Girl(&quot;satori&quot;, 16)
</code></pre>
<p>编译之后的字节码如下，这里只看模块的字节码。</p>
<pre><code class="language-C">  // 加载内置函数 __build_class__ 
  0 LOAD_BUILD_CLASS
  // 加载 Girl 的 PyCodeObject
  2 LOAD_CONST               0 (&lt;code object Girl at 0x7f9...&gt;)
  // 加载名称 &quot;Girl&quot;
  4 LOAD_CONST               1 ('Girl')
  // 构建函数
  6 MAKE_FUNCTION            0
  // 再次加载名称 &quot;Girl&quot;
  8 LOAD_CONST               1 ('Girl')
  // 以 PyFunctionObject 和 &quot;Girl&quot; 为参数
  // 调用 __build_class__ 构建 PyTypeObject
 10 CALL_FUNCTION            2
  // 将构建的类使用变量 Girl 保存
 12 STORE_NAME               0 (Girl)
  
  // 这里对应 g = Girl(&quot;satori&quot;, 16)
  // 加载变量 Girl，指向一个类对象
 14 LOAD_NAME                0 (Girl)
  // 加载参数 &quot;satori&quot; 和 16
 16 LOAD_CONST               2 ('satori')
 18 LOAD_CONST               3 (16)
  // 调用，即便调用的是类，指令也是 CALL_FUNCTION
 20 CALL_FUNCTION            2
  // 将返回值（实例）交给变量 g 保存
 22 STORE_NAME               1 (g)
  // return None
 24 LOAD_CONST               4 (None)
 26 RETURN_VALUE
</code></pre>
<p>字节码非常简单，而且调用一个类和调用一个函数，字节码是类似的。都是将自身和参数依次 LOAD 进来，然后 CALL_FUNCTION。执行完毕之后，模块的名字空间如下：</p>
<p><img src="./images/262.png" alt="" /></p>
<p>调用对象，本质上是执行对应类对象的 __call__。因此，在 Python 里面调用类对象会执行 type.__call__，而在 __call__ 里面会执行类对象的 __new__ 创建实例对象，然后执行 __init__（如果存在）给实例绑定属性，最后返回。</p>
<p>而对应虚拟机的层面，在 CALL_FUNCTION 中，显然会执行 &amp;PyType_Type 的 tp_call，而在 tp_call 中会执行类对象的 tp_new 创建实例对象，然后执行 tp_init（如果存在）给实例绑定属性，最后返回。</p>
<p>但需要注意的是，Girl 这个类本身是没有 __new__ 的。在创建它时，虚拟机会调用 PyType_Ready 进行初始化，而其中一项动作就是继承基类，所以 Girl.__new__ 实际上就是 object.__new__。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age


print(Girl.__new__ is object.__new__)  # True
</code></pre>
<p>而当我们重写 __new__ 时，最后也需要调用 <strong>object.__new__(cls)</strong> 来为实例开辟内存。</p>
<blockquote>
<p>object 在底层对应 &amp;PyBaseObject_Type，object.__new__ 对应 object_new。</p>
</blockquote>
<p>因此创建类对象和创建实例对象的不同之处就在于 tp_new 不同。创建类对象，虚拟机调用的是 type_new；创建实例对象，虚拟机则调用 object_new。至于字节码指令，两者是一致的。下面我们看一下源码，由于调用类对象会执行元类的 tp_call（对应 type_call），我们就从这看起。话说这部分源码记得之前看过了，这里再简单回顾一下。</p>
<pre><code class="language-C">static PyObject *
type_call(PyTypeObject *type, PyObject *args, PyObject *kwds)
{
    // ...
    // 调用类型对象的 __new__ 为实例申请内存
    obj = type-&gt;tp_new(type, args, kwds);
    // ...
    // 判断是否定义了初始化函数 __init__
    type = Py_TYPE(obj);
    if (type-&gt;tp_init != NULL) {
        // 如果有 __init__，则执行
        int res = type-&gt;tp_init(obj, args, kwds);
        if (res &lt; 0) {
            assert(PyErr_Occurred());
            Py_DECREF(obj);
            obj = NULL;
        }
        else {
            assert(!PyErr_Occurred());
        }
    }
    // 返回实例
    return obj;
}
</code></pre>
<p>注意里面的 tp_init，因为新式类都继承 object，所以在执行 PyType_Ready 时也会继承 &amp;PyBaseObject_Type 的 object_init 操作。</p>
<p>但正如我们之前说的那样，因为类重写了 __init__，所以会调用 fixup_slot_dispatchers ，让 tp_init 指向 slotdef 中与 __init__ 对应的 slot_tp_init。并且还会设置tp_alloc，这与内存分配有关，而这些都是在 type_new 中发生的，来看一下。 </p>
<pre><code class="language-c">static PyObject *
type_new(PyTypeObject *metatype, PyObject *args, PyObject *kwds)
{
    // ........

    // 调用 type_new 创建类对象，这里的变量 type 便指向创建的类
    // 然后注意 tp_alloc 字段，它维护一个内存分配函数
    // 当为实例对象分配内存时，使用的就是 tp_alloc
    // 调用类对象会执行 object_new，在里面会执行内存分配函数 tp_alloc
    // 而在代码中，它被设置为 PyType_GenericAlloc，接收一个类型作为参数
    // 调用时会根据传入的类型为其实例分配内存，因为类型包含了实例的元信息
    // 另外创建完实例之后，还会将实例的 ob_type 设置为传入的类型
    type-&gt;tp_alloc = PyType_GenericAlloc;
    type-&gt;tp_free = PyObject_GC_Del;
    type-&gt;tp_traverse = subtype_traverse;
    type-&gt;tp_clear = subtype_clear;
    // ...
    // 将 object 的 tp_init 改成 slot_tp_init
    fixup_slot_dispatchers(type);
    // ...
}
</code></pre>
<p>经过 fixup_slot_dispatchers 改造之后，自定义类的 tp_init 会指向 slot_tp_init，而在 slot_tp_init 中会去寻找我们自定义的 __init__。</p>
<pre><code class="language-C">static int
slot_tp_init(PyObject *self, PyObject *args, PyObject *kwds)
{
    _Py_IDENTIFIER(__init__);
    int unbound;
    // 虚拟机会调用 lookup_method 函数，从自定义类对象的 MRO 中搜索属性 __init__
    PyObject *meth = lookup_method(self, &amp;PyId___init__, &amp;unbound);
    PyObject *res;

    if (meth == NULL)
        return -1;
    // 调用
    if (unbound) {
        res = _PyObject_Call_Prepend(meth, self, args, kwds);
    }
    else {
        res = PyObject_Call(meth, args, kwds);
    }
    Py_DECREF(meth);
    if (res == NULL)
        return -1;
    // 如果返回的不是 None，那么报错，这个信息熟悉不
    if (res != Py_None) {
        PyErr_Format(PyExc_TypeError,
                     &quot;__init__() should return None, not '%.200s'&quot;,
                     Py_TYPE(res)-&gt;tp_name);
        Py_DECREF(res);
        return -1;
    }
    Py_DECREF(res);
    return 0;
}
</code></pre>
<p>所以在定义类时，如果重写了 __init__ 函数，那么创建实例对象时搜索的结果就是重写后的函数；如果没有重写那么执行 object 的 __init__ 操作，而在 object 的 __init__ 中，虚拟机则什么也不做，会直接返回。</p>
<p>到了这里可以小结一下，类对象创建实例对象的两个步骤：</p>
<ul>
<li>instance = cls.__new__(cls, *args, **kwargs)</li>
<li>cls.__init__(instance, *args, **kwargs)，如果一个类没有 __init__，那么就没有这一步，比如 tuple</li>
</ul>
<p>需要注意的是，对于 <font color="blue">metaclass（元类）创建类对象</font>，这两个步骤同样是适用的。因为 <font color="blue">metaclass 创建类对象</font>的过程和<font color="blue">类对象创建实例对象</font>是一样的，我们说 class 具有二象性。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-63"><a class="header" href="#楔子-63">楔子</a></h2>
<p>之前在讨论名字空间的时候提到，在 Python 中，形如 <strong>x.y</strong> 样式的表达式被称之为<strong>属性引用</strong>，其中 x 指向某个对象，y 为对象的某个属性。</p>
<p>那么下面来看看虚拟机是怎么实现属性引用的？</p>
<h2 id="属性引用"><a class="header" href="#属性引用">属性引用</a></h2>
<p>还是看一个简单的类，然后观察它的字节码。</p>
<pre><code class="language-Python">class Girl:
    
    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16
        
    def get_info(self):
        return f&quot;name: {self.name}, age: {self.age}&quot;
    
g = Girl()
# 获取 name 属性
name = g.name
# 获取 get_info 方法并调用
g.get_info()
</code></pre>
<p>想要了解背后都发生了什么，最直接的途径就是查看字节码，这里只看模块对应的字节码。</p>
<pre><code class="language-C">  // class Girl: 对应的字节码，这里就不赘述了
  0 LOAD_BUILD_CLASS
  2 LOAD_CONST               0 (&lt;code object Girl at 0x7f9562476240, file &quot;&quot;, line 2&gt;)
  4 LOAD_CONST               1 ('Girl')
  6 MAKE_FUNCTION            0
  8 LOAD_CONST               1 ('Girl')
 10 CALL_FUNCTION            2
 12 STORE_NAME               0 (Girl)
      
  // g = Girl() 对应的字节码，不再赘述
 14 LOAD_NAME                0 (Girl)
 16 CALL_FUNCTION            0
 18 STORE_NAME               1 (g)

  // name = g.name 对应的字节码
  // 加载变量 g
 20 LOAD_NAME                1 (g)
  // 获取 g.name，加载属性用的是 LOAD_ATTR
 22 LOAD_ATTR                2 (name)
  // 将结果交给变量 name 保存
 24 STORE_NAME               2 (name)
  
  // g.get_info() 对应的字节码
  // 加载变量 g
 26 LOAD_NAME                1 (g)
  // 获取方法 g.get_info，加载方法用的是 LOAD_METHOD
 28 LOAD_METHOD              3 (get_info)
  // 调用方法，注意指令是 CALL_METHOD，不是 CALL_FUNCTION
  // 但显然 CALL_METHOD 内部也是调用了 CALL_FUNCTION
 30 CALL_METHOD              0
  // 从栈顶弹出返回值
 32 POP_TOP
 34 LOAD_CONST               2 (None)
 36 RETURN_VALUE
</code></pre>
<p>除了 LOAD_METHOD 和 LOAD_ATTR，其它的指令我们都见过了，因此下面重点分析这两条指令。</p>
<pre><code class="language-C">case TARGET(LOAD_METHOD): {
    // 从符号表中获取符号，因为是 g.get_info
    // 那么这个 name 就指向字符串对象 &quot;get_info&quot;
    PyObject *name = GETITEM(names, oparg);
    // 获取栈顶元素 obj，显然这个 obj 就是代码中的实例对象 g
    PyObject *obj = TOP();
    // meth 是一个 PyObject * 指针，显然它要指向一个方法
    PyObject *meth = NULL;
    
    // 这里是获取和 &quot;get_info&quot; 绑定的方法，然后让 meth 指向它
    // 具体做法是调用 _PyObject_GetMethod，传入二级指针 &amp;meth
    // 然后让 meth 存储的地址变成指向具体方法的地址
    int meth_found = _PyObject_GetMethod(obj, name, &amp;meth);
    
    //如果 meth == NULL，raise AttributeError
    if (meth == NULL) {
        /* Most likely attribute wasn't found. */
        goto error;
    }
    
    // 注意：无论是 Girl.get_info、还是 g.get_info，对应的指令都是 LOAD_METHOD
    // 类去调用的话，说明得到的是一个未绑定的方法，说白了就等价于函数
    // 实例去调用的话，会得到一个绑定的方法，相当于对函数进行了封装
    // 关于绑定和未绑定我们后面会详细介绍
    if (meth_found) {
        // 如果 meth_found 为 1，说明 meth 是一个绑定的方法，obj 就是 self
        // 将 meth 设置为栈顶元素，然后再将 obj 压入栈中
        SET_TOP(meth);
        PUSH(obj);  // self
    }
    else {
        // 否则说明 meth 是一个未绑定的方法
        // 那么将栈顶元素设置为 NULL，然后将 meth 压入栈中
        SET_TOP(NULL);
        Py_DECREF(obj);
        PUSH(meth);
    }
    DISPATCH();
}
</code></pre>
<p>获取方法是 LOAD_METHOD 指令 ，获取属性则是 LOAD_ATTR 指令，来看一下。</p>
<pre><code class="language-C">case TARGET(LOAD_ATTR): {
    // 可以看到和 LOAD_METHOD 本质上是类似的，但更简单一些
    // name 依旧是符号，这里指向字符串对象 &quot;name&quot;
    PyObject *name = GETITEM(names, oparg);
    // 从栈顶获取变量 g
    PyObject *owner = TOP();
    // res 显然就是属性的值了，即 g.name
    // 通过 PyObject_GetAttr 进行获取
    PyObject *res = PyObject_GetAttr(owner, name);
    Py_DECREF(owner);
    // 设置为栈顶元素
    SET_TOP(res);
    if (res == NULL)
        goto error;
    DISPATCH();
}
</code></pre>
<p>所以这两个指令本身是很简单的，而核心在 PyObject_GetAttr 和 _PyObject_GetMethod 上面，前者用于获取属性、后者用于获取方法。先来看一下 PyObject_GetAttr 具体都做了什么事情。</p>
<pre><code class="language-C">// Objects/object.c
PyObject *
PyObject_GetAttr(PyObject *v, PyObject *name)
{
    // v: 对象，name: 属性名
    
    // 获取实例对象 v 的类型对象
    PyTypeObject *tp = Py_TYPE(v);
    // name 必须是一个字符串
    if (!PyUnicode_Check(name)) {
        PyErr_Format(PyExc_TypeError,
                     &quot;attribute name must be string, not '%.200s'&quot;,
                     name-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
    // 通过类型对象的 tp_getattro 字段获取实例对应的属性
    if (tp-&gt;tp_getattro != NULL)
        return (*tp-&gt;tp_getattro)(v, name);
    // tp_getattr 和 tp_getattro 功能一样，但后者可以支持中文
    if (tp-&gt;tp_getattr != NULL) {
        const char *name_str = PyUnicode_AsUTF8(name);
        if (name_str == NULL)
            return NULL;
        return (*tp-&gt;tp_getattr)(v, (char *)name_str);
    }
    // 属性不存在，抛出异常
    PyErr_Format(PyExc_AttributeError,
                 &quot;'%.50s' object has no attribute '%U'&quot;,
                 tp-&gt;tp_name, name);
    return NULL;
}
</code></pre>
<p>PyTypeObject 里面定义了两个与属性访问相关的操作：tp_getattro 和 tp_getattr。其中前者是优先选择的属性访问动作，而后者已不推荐使用。这两者的区别在 PyObject_GetAttr 中已经显示得很清楚了，主要在属性名的使用上。</p>
<ul>
<li>tp_getattro 所使用的属性名是一个 PyUnicodeObject *；</li>
<li>而 tp_getattr 所使用的属性名是一个 char *。</li>
</ul>
<p>如果这两个字段同时被定义，那么优先使用 tp_getattro。问题来了，自定义类对象的 tp_getattro 对应哪一个 C 函数呢？显然我们要去找 object。</p>
<p>object 在底层对应 PyBaseObject_Type，它的 tp_getattro 为 PyObject_GenericGetAttr，因此虚拟机在创建 Girl 这个类时，也会将此操作继承下来。</p>
<pre><code class="language-C">// Objects/object.c
PyObject *
PyObject_GenericGetAttr(PyObject *obj, PyObject *name)
{
    return _PyObject_GenericGetAttrWithDict(obj, name, NULL, 0);
}

PyObject *
_PyObject_GenericGetAttrWithDict(PyObject *obj, PyObject *name,
                                 PyObject *dict, int suppress)
{
    // 拿到 obj 的类型对象，对于当前的例子来说，显然是 class Girl
    PyTypeObject *tp = Py_TYPE(obj);
    // 描述符
    PyObject *descr = NULL;
    // 返回值
    PyObject *res = NULL;
    // 描述符的 __get__ 
    descrgetfunc f;
    Py_ssize_t dictoffset;
    PyObject **dictptr;
    // name 必须是字符串
    if (!PyUnicode_Check(name)){
        PyErr_Format(PyExc_TypeError,
                     &quot;attribute name must be string, not '%.200s'&quot;,
                     name-&gt;ob_type-&gt;tp_name);
        return NULL;
    }
    Py_INCREF(name);
    // 属性字典不为空，是初始化是否完成的重要标志
    // 如果为空，说明还没有初始化，那么需要先初始化
    if (tp-&gt;tp_dict == NULL) {
        if (PyType_Ready(tp) &lt; 0)
            goto done;
    }
    // 从 mro 顺序列表中获取属性对应的值，并检测是否为描述符
    // 如果属性不存在、或者存在但对应的值不是描述符，则返回 NULL
    descr = _PyType_Lookup(tp, name);

    f = NULL;
    if (descr != NULL) {
        Py_INCREF(descr);
        // 如果 descr 不为 NULL，说明该属性被代理了
        // descr 是描述符，f 就是它的 __get__ 方法
        // f = descr.__class__.__get__ 
        f = descr-&gt;ob_type-&gt;tp_descr_get;
        // __get__ 对应 PyTypeObject 的 tp_descr_get
        // __set__ 对应 PyTypeObject 的 tp_descr_set  
        // 如果 f 不为 NULL，并且 descr 是数据描述符
        if (f != NULL &amp;&amp; PyDescr_IsData(descr)) {
            // 那么直接调用描述符的 __get__ 方法，返回结果
            res = f(descr, obj, (PyObject *)obj-&gt;ob_type);
            if (res == NULL &amp;&amp; suppress &amp;&amp;
                    PyErr_ExceptionMatches(PyExc_AttributeError)) {
                PyErr_Clear();
            }
            goto done;
        }
    }
    // 走到这里说明要获取的属性没有被代理，或者说代理它的是非数据描述符
    // 当然还有一种情况，这种情况上一篇文章貌似没提到
    // 就是属性被数据描述符代理，但是该数据描述符没有 __get__
    // 那么仍会优先从实例对象自身的 __dict__ 中寻找属性
    if (dict == NULL) {
        /* Inline _PyObject_GetDictPtr */
        dictoffset = tp-&gt;tp_dictoffset;
        // 如果 dict 为 NULL，并且 dictoffset 不为 0
        // 说明继承自变长对象，那么要调整 tp_dictoffset
        if (dictoffset != 0) {
            if (dictoffset &lt; 0) {
                Py_ssize_t tsize;
                size_t size;

                tsize = ((PyVarObject *)obj)-&gt;ob_size;
                if (tsize &lt; 0)
                    tsize = -tsize;
                size = _PyObject_VAR_SIZE(tp, tsize);
                _PyObject_ASSERT(obj, size &lt;= PY_SSIZE_T_MAX);

                dictoffset += (Py_ssize_t)size;
                _PyObject_ASSERT(obj, dictoffset &gt; 0);
                _PyObject_ASSERT(obj, dictoffset % SIZEOF_VOID_P == 0);
            }
            dictptr = (PyObject **) ((char *)obj + dictoffset);
            dict = *dictptr;
        }
    }
    // dict 不为 NULL，从属性字典中获取
    if (dict != NULL) {
        Py_INCREF(dict);
        res = PyDict_GetItemWithError(dict, name);
        if (res != NULL) {
            Py_INCREF(res);
            Py_DECREF(dict);
            goto done;
        }
        else {
            Py_DECREF(dict);
            if (PyErr_Occurred()) {
                if (suppress &amp;&amp; PyErr_ExceptionMatches(PyExc_AttributeError)) {
                    PyErr_Clear();
                }
                else {
                    goto done;
                }
            }
        }
    }
    // 程序走到这里，说明什么呢？显然意味着实例的属性字典里面没有要获取的属性
    // 但如果下面的 f != NULL 成立，说明属性被代理了
    // 并且代理属性的描述符是非数据描述符，它的优先级低于实例
    // 所以实例会先到自身的属性字典中查找，找不到再去执行描述符的 __get__
    if (f != NULL) {
        // 第一个参数是描述符本身，也就是 __get__ 里面的 self
        // 第二个参数是实例对象，也就是 __get__ 里面的 instance
        // 第三个参数是类对象，也就是 __get__ 里面的 owner
        res = f(descr, obj, (PyObject *)Py_TYPE(obj));
        if (res == NULL &amp;&amp; suppress &amp;&amp;
                PyErr_ExceptionMatches(PyExc_AttributeError)) {
            PyErr_Clear();
        }
        goto done;
    }
    // 程序能走到这里，说明属性字典里面没有要找的属性，并且也没有执行描述符的 __get__
    // 但如果 describe 还不为 NULL，这说明什么呢？
    // 显然该属性仍被描述符代理了，只是这个描述符没有 __get__，如果是这种情况，那么会返回描述符本身
    if (descr != NULL) {
        res = descr;
        descr = NULL;
        goto done;
    }
    // 找不到，就报错
    if (!suppress) {
        PyErr_Format(PyExc_AttributeError,
                     &quot;'%.50s' object has no attribute '%U'&quot;,
                     tp-&gt;tp_name, name);
    }
  done:
    Py_XDECREF(descr);
    Py_DECREF(name);
    return res;
}
</code></pre>
<p>这里面有两个我们上一篇文章没有提到的地方，下面补充一下：</p>
<pre><code class="language-Python">class Descriptor:

    def __set__(self, instance, value):
        print(&quot;__set__&quot;)


class B:
    name = Descriptor()

b = B()
# b 的属性字典没有 name，描述符也没有 __get__
# 那么这个时候会返回描述符本身
print(b.name)  # &lt;__main__.Descriptor object at 0x0...&gt;

# 此时属性字典里面有 name 了
b.__dict__[&quot;name&quot;] = &quot;古明地觉&quot;
# 由于 name 是被数据描述符代理的，按理说获取属性时会执行数据描述符的 __get__
# 但是这个数据描述符压根没有 __get__，因此还是会从属性字典中查找
print(b.name)  # 古明地觉
</code></pre>
<p>以上就是获取属性的逻辑，很好理解，用一张流程图总结一下。</p>
<p><img src="./images/263.png" alt="" /></p>
<p>获取方法也与之类似，调用的是 _PyObject_GetMethod，这里就不再看了。</p>
<h2 id="再论描述符"><a class="header" href="#再论描述符">再论描述符</a></h2>
<p>前面我们看到，在 PyType_Ready 中，虚拟机会填充 tp_dict，其中与操作名对应的是一个个的描述符。那时我们看到的是描述符这个概念在 Python 内部是如何实现的，现在我们将要剖析的是描述符在 Python 的类机制中究竟会起到怎样的作用。</p>
<p>虚拟机对自定义类对象或实例对象进行属性访问时，描述符将对属性访问的行为产生重大影响。一般而言，如果一个类存在 __get__、__set__、__delete__ 操作（不要求三者同时存在），那么它的实例便可以称之为描述符。在 slotdefs 中，我们会看到这三种魔法方法对应的操作。</p>
<pre><code class="language-C">TPSLOT(&quot;__get__&quot;, tp_descr_get, slot_tp_descr_get, wrap_descr_get,
           &quot;__get__($self, instance, owner, /)\n--\n\nReturn an attribute of instance, which is of type owner.&quot;),
TPSLOT(&quot;__set__&quot;, tp_descr_set, slot_tp_descr_set, wrap_descr_set,
       &quot;__set__($self, instance, value, /)\n--\n\nSet an attribute of instance to value.&quot;),
TPSLOT(&quot;__delete__&quot;, tp_descr_set, slot_tp_descr_set,
       wrap_descr_delete,
       &quot;__delete__($self, instance, /)\n--\n\nDelete an attribute of instance.&quot;),
</code></pre>
<p>而在虚拟机访问实例对象的属性时，描述符的一个作用就是影响虚拟机对属性的选择。从 PyObject_GenericGetAttr 源码中可以看到，虚拟机会先在实例对象自身的 __dict__ 中寻找属性，也会在实例对象的类型对象的 mro 顺序列表中寻找属性，我们将前一种属性称之为<strong>实例属性</strong>，后一种属性称之为<strong>类属性</strong>。所以在属性的选择上，有如下规律：</p>
<ul>
<li>虚拟机优先按照实例属性、类属性的顺序选择属性，即实例属性优先于类属性；</li>
<li>如果发现有一个同名、并且被数据描述符代理的类属性，那么该描述符会优先于实例属性被虚拟机选择；</li>
</ul>
<p>这两条规则在对属性进行设置时仍然会被严格遵守，换句话说，如果执行 <font color="blue">ins.xxx = yyy</font> 时，在 type(ins) 中也出现了 xxx 属性、并且还被数据描述符代理了。那么不好意思，此时虚拟机会选择描述符，并执行它的 __set__ 方法；如果是非数据描述符，那么就不再走 __set__ 了，而是设置属性（因为压根没有 __set__），也就是 <font color="blue">a.__dict__['xxx'] = yyy</font>。</p>
<h2 id="小结-63"><a class="header" href="#小结-63">小结</a></h2>
<p>以上就是实例对象的属性访问，但是还没结束，我们下一篇文章来重点讨论一下 self。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-64"><a class="header" href="#楔子-64">楔子</a></h2>
<p>上一篇文章介绍了实例对象的属性访问，那么本篇文章来讨论一下 self。我们知道实例在调用方法时，会自动将自身传给 self 参数，那么你有没有想过这背后的原理呢？下面就来详细分析一下。</p>
<h2 id="函数变身"><a class="header" href="#函数变身">函数变身</a></h2>
<p>还是以之前的代码为例：</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def get_info(self):
        return f&quot;name = {self.name}, age = {self.age}&quot;

g = Girl(&quot;satori&quot;, 16)
res = g.get_info()
print(res)  # name = satori, age = 16
</code></pre>
<p>我们在调用 g.get_info 的时候，并没有给 self 传递参数，那么 self 到底是不是真正有效的参数呢？还是说它仅仅只是一个语法意义上的占位符而已？</p>
<p>不用想，self 肯定是货真价实的参数，只不过自动帮你传递了。根据使用 Python 的经验，我们知道第一个参数就是实例本身，那么这是怎么实现的呢？想要弄清这一点，还是要从字节码入手。而调用方法的字节码是 CALL_METHOD，那么玄机就隐藏在这里面。</p>
<p><img src="./images/264.png" alt="" /></p>
<p>调用时的指令参数是 0，表示不需要传递参数。注意：这里说的不需要传递参数，指的是不需要我们手动传递。</p>
<pre><code class="language-C">case TARGET(CALL_METHOD): {
    PyObject **sp, *res, *meth;
    // 栈指针，指向运行时栈的栈顶
    sp = stack_pointer;    
    meth = PEEK(oparg + 2);
    // 如果 meth 为 NULL，说明是函数
    if (meth == NULL) {
        // 运行时栈从栈底到栈顶：NULL、callable、arg1、arg2、...、argN
        res = call_function(tstate, &amp;sp, oparg, NULL);
        stack_pointer = sp;
        (void)POP(); /* POP the NULL. */
    }
    // 否则说明是方法
    else {
        // 运行时栈从栈底到栈顶：method、self、arg1、arg2、...、argN
        res = call_function(tstate, &amp;sp, oparg + 1, NULL);
        stack_pointer = sp;
    }

    PUSH(res);
    if (res == NULL)
        goto error;
    DISPATCH();
}

</code></pre>
<p>为了对比，我们再把 CALL_FUNCTION 指令的源码贴出来。</p>
<pre><code class="language-C">case TARGET(CALL_FUNCTION): {
    PREDICTED(CALL_FUNCTION);
    PyObject **sp, *res;
    sp = stack_pointer;
    res = call_function(tstate, &amp;sp, oparg, NULL);
    stack_pointer = sp;
    PUSH(res);
    if (res == NULL) {
        goto error;
    }
    DISPATCH();
}
</code></pre>
<p>通过对比发现了端倪，这两者都调用了 call_function，但是传递的参数不一样。如果是类调用，那么这两个指令是等价的；但如果是实例调用，CALL_METHOD 的第三个参数是 oparg + 1，而 CALL_FUNCTION 是 oparg。</p>
<p>背后的原因不需要多说，因为实例在调用时会将自身传给 self，所以参数个数应该是 oparg + 1。但是这还不足以支持我们找出问题所在，如果你仔细看一下函数的类型对象 PyFunction_Type，会发现里面隐藏着一个秘密。</p>
<pre><code class="language-C">PyTypeObject PyFunction_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;function&quot;,
    sizeof(PyFunctionObject),
    //...
    //...
    
    //注意注意注意，看下面这行
    func_descr_get,                          /* tp_descr_get */
    0,                                       /* tp_descr_set */
    offsetof(PyFunctionObject, func_dict),   /* tp_dictoffset */
    0,                                       /* tp_init */
    0,                                       /* tp_alloc */
    func_new,                                /* tp_new */
};
</code></pre>
<p>我们说 tp_descr_get 对应 __get__，而它被设置成了 func_descr_get，这意味着函数是一个描述符，因为它的类型对象实现了 __get__。</p>
<pre><code class="language-python">def func():
    pass

print(func.__get__)
&quot;&quot;&quot;
&lt;method-wrapper '__get__' of function object at 0x...&gt;
&quot;&quot;&quot;
</code></pre>
<p>同理，实例对象 g 在调用 get_info 之前，肯定要先获取 get_info。而在获取的时候，显然会执行 get_info 的 __get__。也就是说，g.get_info 会得到什么，取决于 get_info 的 __get__ 会返回什么。那么函数的 __get__ 会返回什么呢？显然这要去 func_descr_get 函数中一探究竟。</p>
<pre><code class="language-C">// Objects/funcobject.c
static PyObject *
func_descr_get(PyObject *func, PyObject *obj, PyObject *type)
{  
    // 如果是类获取函数：那么 obj 为 NULL，type 为类对象本身
    // 如果是实例获取函数：那么 obj 为实例，type 仍是类对象本身
    
    // 如果 obj 为空，说明是类获取
    // 那么直接返回 func 本身, 也就是原来的函数
    if (obj == Py_None || obj == NULL) {
        Py_INCREF(func);
        return func;
    }
    // 如果是实例对象，那么调用 PyMethod_New 
    // 将函数和实例绑定在一起，得到一个 PyMethodObject 对象 
    return PyMethod_New(func, obj);
}
</code></pre>
<p>函数对应的结构体是 PyFunctionObject，那么 PyMethodObject 是啥应该不需要我说了，显然就是方法对应的结构体。所以类里面定义的就是单纯的函数，通过类去调用的话，和调用一个普通函数并无区别。</p>
<p>但是实例调用就不一样了，实例在拿到类的成员函数时，会先调用 PyMethod_New 将函数包装成方法，然后再对方法进行调用。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def get_info(self):
        return f&quot;name = {self.name}, age = {self.age}&quot;

g = Girl(&quot;satori&quot;, 16)
print(Girl.get_info.__class__)
print(g.get_info.__class__)
&quot;&quot;&quot;
&lt;class 'function'&gt;
&lt;class 'method'&gt;
&quot;&quot;&quot;
</code></pre>
<p>在获取 get_info 时，会发现它被描述符代理了，而描述符就是成员函数本身。因为类型对象 PyFunction_Type 实现了 tp_descr_get，即 __get__，所以它的实例对象（函数）本质上就是个描述符。</p>
<p>因此无论是类还是实例，在调用时都会执行 func_descr_get。如果是类调用，那么实例 obj 为空，于是会将成员函数直接返回，因此类调用的就是函数本身。如果是实例调用，则执行 PyMethod_New，将 PyFunctionObject 包装成 PyMethodObject，然后调用，因此实例调用的是方法。</p>
<p>那么问题来了，方法在底层长什么样呢？可以肯定的是，方法也是一个对象，一个 PyObject。</p>
<pre><code class="language-C">// Include/classobject.h
typedef struct {
    PyObject_HEAD
    // 可调用的 PyFunctionObject 对象
    PyObject *im_func;  
    // self 参数，即实例对象
    PyObject *im_self;   
    // 弱引用列表，不做深入讨论
    PyObject *im_weakreflist;
    // 速度更快的矢量调用，因为方法和函数一样，肯定是要被调用的
    // 所以它们都自己实现了一套调用方式：vectorcallfunc
    // 而没有走类型对象的 tp_call
    vectorcallfunc vectorcall;
} PyMethodObject;
</code></pre>
<p>所以方法就是对函数的一个封装，我们用 Python 举例说明：</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age

    def get_info(self):
        return f&quot;name = {self.name}, age = {self.age}&quot;

g = Girl(&quot;satori&quot;, 16)

# 方法是对函数的封装
# 只不过里面不仅仅有函数，还有实例
method = g.get_info
# 拿到的是实例本身
print(method.__self__ is g)  # True
# 拿到的是成员函数，也就是 Girl.get_info
print(method.__func__ is Girl.get_info)  # True

print(
    method()
    == 
    Girl.get_info(g)
    ==
    method.__func__(method.__self__)
)  # True
</code></pre>
<p>而方法是在 PyMethod_New 中创建的，再来看看这个函数。</p>
<pre><code class="language-C">// Objects/classobjet.c
PyObject *
PyMethod_New(PyObject *func, PyObject *self)
{
    PyMethodObject *im;
    if (self == NULL) {
        PyErr_BadInternalCall();
        return NULL;
    }
    // 缓存池
    im = free_list;
    if (im != NULL) {
        free_list = (PyMethodObject *)(im-&gt;im_self);
        (void)PyObject_INIT(im, &amp;PyMethod_Type);
        numfree--;
    }
    // 缓冲池如果空了，直接创建 PyMethodObject 对象
    else {
        // 可以看到方法的类型在底层是 &amp;PyMethod_Type
        im = PyObject_GC_New(PyMethodObject, &amp;PyMethod_Type);
        if (im == NULL)
            return NULL;
    }
    im-&gt;im_weakreflist = NULL;
    Py_INCREF(func);
    // im_func 指向 PyFunctionObject 对象
    im-&gt;im_func = func;
    Py_XINCREF(self);
    // im_self 指向实例对象
    im-&gt;im_self = self;
    // 会通过 method_vectorcall 来对方法进行调用
    im-&gt;vectorcall = method_vectorcall;
    // 被 GC 跟踪
    _PyObject_GC_TRACK(im);
    return (PyObject *)im;
}
</code></pre>
<p>在 PyMethod_New 中，分别将 im_func，im_self 设置为函数、实例。因此通过 PyMethod_New 将函数、实例结合在一起，得到的 PyMethodObject 就是方法。并且我们还看到了 free_list，说明方法也使用了缓存池。</p>
<p>所以不管是类还是实例，获取成员函数时都会走描述符的 func_descr_get，然后在里面会判断是类获取还是实例获取。如果是类获取，直接返回函数本身；如果是实例获取，则通过 PyMethod_New 将函数和实例绑定起来得到方法，这个过程称为成员函数的绑定。</p>
<p><img src="./images/265.png" alt="" /></p>
<p>当然啦，调用方法本质上还是调用方法里面的 im_func，也就是函数。只不过会处理自动传参的逻辑，将内部的 im_self（实例）和我们传递的参数组合起来（如果没有传参，那么只有一个 im_self），然后整体传递给 im_func。</p>
<p>所以为什么实例调用方法的时候会自动传递第一个参数，此刻算是真相大白了。当然啦，以上只能说从概念上理解了，但是源码还没有看，下面就来看看具体的实现细节。</p>
<h2 id="方法调用"><a class="header" href="#方法调用">方法调用</a></h2>
<p>通过字节码，我们知道 LOAD_METHOD 指令结束之后，便开始执行 CALL_METHOD。它和 CALL_FUNCTION 之间最大的区别就是：</p>
<ul>
<li>CALL_METHOD 针对的是 PyMethodObject 对象；</li>
<li>CALL_FUNCTION 针对的是 PyFunctionObject 对象。</li>
</ul>
<p>但是这两个指令调用的都是 call_function 函数，然后内部执行的也都是 Girl.get_info。因为执行方法，本质上还是执行方法里面的 im_func，只不过会自动将 im_self 和我们传递的参数组合起来，一起传给 im_func。</p>
<blockquote>
<p><strong>假设 obj 是 cls 的实例对象，那么 obj.xxx() 在底层会被翻译成 cls.xxx(obj)，前者只是后者的语法糖。</strong></p>
</blockquote>
<p>然后在 PyMethod_New 中，我们看到虚拟机给 <code>im-&gt;vectorcall</code> 赋值为 method_vectorcall，而方法调用的秘密就隐藏在里面。</p>
<pre><code class="language-C">// Objects/classobject.c
static PyObject *
method_vectorcall(PyObject *method, PyObject *const *args,
                  size_t nargsf, PyObject *kwnames)
{
    assert(Py_TYPE(method) == &amp;PyMethod_Type);
    PyObject *self, *func, *result;
    // 实例对象 self
    self = PyMethod_GET_SELF(method);
    // 方法里的成员函数
    func = PyMethod_GET_FUNCTION(method);
    // 参数个数
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);

    //...   
        // 这里的代码比较有趣，一会单独说
        // 总之它的逻辑就是将 self 和我们传递的参数组合起来
        // 通过 _PyObject_Vectorcall 对 func 进行调用
        // 所以 method_vectorcall 只是负责组装参数
        // 真正执行的依旧是 PyFunctionObjec 的 _PyObject_Vectorcall 
        PyObject **newargs = (PyObject**)args - 1;
        nargs += 1;
        PyObject *tmp = newargs[0];
        newargs[0] = self;
        result = _PyObject_Vectorcall(func, newargs, nargs, kwnames);
        newargs[0] = tmp;
    //...
    return result;
}
</code></pre>
<p>再来说说里面的具体细节，假设我们调用的不是方法，而是一个普通的函数，并且依次传入了 name、age、gender 三个参数，那么此时的运行时栈如下：</p>
<p><img src="./images/266.png" alt="" /></p>
<p>_PyObject_Vectorcall 的第一个参数就是要调用的函数 func；第二个参数是 args，指向给函数 func 传递的首个参数，至于到底给 func 传了多少个，则由第三个参数 nargs 指定。</p>
<p>但如果调用的不是函数，而是方法呢？我们仍以传入 name、age、gender 三个参数为例，解释一下源码的具体细节。</p>
<p>首先是 <font color="blue">PyObject **newargs = (PyObject **)args - 1;</font> ，这意味着什么呢？</p>
<p><img src="./images/267.png" alt="" /></p>
<p>然后 <font color="blue">nargs += 1;</font> 表示参数个数加 1，这很好理解，因为多了一个 self。</p>
<p><font color="blue">PyObject *tmp = newargs[0];</font> 做的事情也很简单，相当于将 name 的前一个元素保存了起来，赋值为 tmp。</p>
<p>关键来了，<font color="blue">newargs[0] = self;</font> 会将 name 的前一个元素设置为实例 self，此时运行时栈如下：</p>
<p><img src="./images/268.png" alt="" /></p>
<p>然后调用 _PyObject_Vectorcall，显然第二个参数就变成了 newargs，因为 name 前面多了一个 self，所以现在是 newargs 指向函数 func 的首个参数。而从 Python 的角度来说，就是将<strong>实例</strong>和<strong>我们给 func 传入的参数</strong>组装了起来。</p>
<p>调用完之后拿到返回值，非常 Happy。但需要注意的是，从内存布局上来讲，<strong>参数 name</strong> 的前面是没有 self 的容身之处的。而 self 之所以能挤进去，是因为它把<strong>参数 name</strong> 的前一个元素给顶掉了，至于被顶掉的元素到底是啥我们不得而知，也无需关注，它有可能是 free 区域里面的某个元素。总之关键的是，函数 func 调用完之后，还要再换回来，否则在逻辑上就相当于越界了。</p>
<p>所以通过 <font color="blue">newargs[0] = tmp;</font> 将 name 的前一个元素再替换回来。</p>
<p>但相比上面这种做法， 其实还有一个更通用的办法。</p>
<p><img src="./images/269.png" alt="" /></p>
<p>将我们传递的参数都向后移动一个位置，然后空出来的第一个位置留给 self，这样也是可以的。但很明显，此做法的效率不高，因为这是一个 O(N) 操作，而源码中的做法是 O(1)。所以底层实现一定要讲究效率，采用各种手段极限优化。因为 Python 语言的设计模式就决定了它的运行效率注定不高，如果虚拟机源码再写的不好的话，那么运行速度就真的不能忍了。</p>
<p>总结一下上面的内容，函数调用和方法调用本质上是一样的。方法里面的 im_func 字段指向一个函数，调用方法的时候底层还是会调用函数，只不过在调用的时候会自动把方法里面的 im_self 作为第一个参数传到函数里面去。而类在调用的时候，所有的参数都需要手动传递。</p>
<blockquote>
<p>还是那句话：obj.xxx() 本质上就是 cls.xxx(obj)；而 cls.xxx() 仍是 cls.xxx()。</p>
</blockquote>
<p><strong>因此到了这里，我们可以在更高的层次俯视一下 Python 的运行模型了，最核心的模型非常简单，可以简化为两条规则：</strong></p>
<ul>
<li>1）在某个名字空间中寻找符号对应的对象</li>
<li>2）对得到的对象进行某些操作</li>
</ul>
<p>抛开面向对象这些花里胡哨的外表，其实我们发现自定义类对象就是一个名字空间，实例对象也是一个名字空间。只不过这些名字空间通过一些特殊的规则连接在一起，使得符号的搜索过程变得复杂，从而实现了面向对象这种编程模式。</p>
<h2 id="bound-method-和-unbound-method"><a class="header" href="#bound-method-和-unbound-method">bound method 和 unbound method</a></h2>
<p>当对成员函数进行引用时，会有两种形式：bound method 和 unbound method。</p>
<ul>
<li>bound method：被绑定的方法，说白了就是方法，PyMethodObject。比如实例获取成员函数，拿到的就是方法。</li>
<li>unbound method：未被绑定的方法，说白了就是成员函数本身。比如类获取成员函数，拿到的还是成员函数本身，只不过对应的指令也是 LOAD_METHOD，所以叫未被绑定的方法。</li>
</ul>
<p>因此 bound method 和 unbound method 的本质区别就在于成员函数有没有和实例绑定在一起，成为方法。前者完成了绑定动作，而后者没有完成绑定动作。</p>
<pre><code class="language-C">// Objects/funcobject.c
static PyObject *
func_descr_get(PyObject *func, PyObject *obj, PyObject *type)
{  
    // obj：相当于 __get__ 里面的 instance
    // type：相当于 __get__ 里面的 owner
    
    // 类获取成员函数，obj 为空，直接返回成员函数
    // 所以它也被称为是 &quot;未被绑定的方法&quot;
    if (obj == Py_None || obj == NULL) {
        Py_INCREF(func);
        return func;
    }
    // 实例获取，则会先通过 PyMethod_New 将成员函数 func 和实例 obj 绑定在一起 
    // 返回的结果被称为 &quot;被绑定的方法&quot;，简称方法 
    // 而 func 会交给方法的 im_func 字段保存，obj 则会交给方法的 im_self 字段保存 
    // im_func 和 im_self 对应 Python 里面的 __func__ 和 __self__ 
    return PyMethod_New(func, obj);
}
</code></pre>
<p>我们用 Python 演示一下：</p>
<pre><code class="language-Python">class Girl(object):

    def get_info(self):
        print(self)

g = Girl()
Girl.get_info(123)  # 123
# 我们看到即便传入一个 123 也是可以的
# 这是我们自己传递的，传递什么就是什么

g.get_info()  # &lt;__main__.A object at 0x00...&gt;
# 但 g.get_info() 就不一样了，它是 Girl.get_info(g) 的语法糖

# 被绑定的方法，说白了就是方法
# 方法的类型为 &lt;class 'method'&gt;，在底层对应 &amp;PyMethod_Type
print(g.get_info)  # &lt;bound method Girl.get_info of ...&gt;
print(g.get_info.__class__)  # &lt;class 'method'&gt;

# 未被绑定的方法，这个叫法只是为了和&quot;被绑定的方法&quot;形成呼应
# 说白了它就是个成员函数，类型为 &lt;class 'function'&gt;
print(Girl.get_info)  # &lt;function Girl.get_info at 0x00...&gt;
print(Girl.get_info.__class__)  # &lt;class 'function'&gt;
</code></pre>
<p>我们说成员函数和实例绑定，会得到方法，这是没错的。但是成员函数不仅仅可以和实例绑定，和类绑定也是可以的。</p>
<pre><code class="language-Python">class Girl(object):

    @classmethod
    def get_info(cls):
        print(cls)

print(Girl.get_info)  
print(Girl().get_info)
&quot;&quot;&quot;
&lt;bound method Girl.get_info of &lt;class '__main__.Girl'&gt;&gt;
&lt;bound method Girl.get_info of &lt;class '__main__.Girl'&gt;&gt;
&quot;&quot;&quot;

# 无论是实例调用还是类调用，第一个参数传进去的都是类
Girl.get_info()  
Girl().get_info()
&quot;&quot;&quot;
&lt;class '__main__.Girl'&gt;
&lt;class '__main__.Girl'&gt;
&quot;&quot;&quot;
</code></pre>
<p>此时通过类去调用得到的不再是一个函数，而是一个方法，这是因为我们加上了 classmethod 装饰器。加上装饰器之后，get_info 就不再是原来的函数了，而是 <strong>classmethod(get_info)</strong>，也就是 classmethod 的实例对象。</p>
<p>然后 classmethod 在 Python 里面是一个类，它在底层对应的是 &amp;PyClassMethod_Type，而 classmethod 的实例对象在底层对应的结构体也叫 classmethod。</p>
<pre><code class="language-C">// Objects/funcobject.c
typedef struct {
    PyObject_HEAD
    PyObject *cm_callable;
    PyObject *cm_dict;
} classmethod;
</code></pre>
<p>由于 &amp;PyClassMethod_Type 内部实现了 tp_descr_get，所以它的实例对象是一个描述符。</p>
<p><img src="./images/270.png" alt="" /></p>
<p>此时调用 get_info 会执行 &lt;class 'classmethod'&gt; 的 __get__，看一下 cm_descr_get 的具体实现：</p>
<pre><code class="language-C">// Objects/funcobject.c
static PyObject *
cm_descr_get(PyObject *self, PyObject *obj, PyObject *type)
{
    // 这里的 self 就是 Python 里面的类 classmethod 的实例
    // 只不过在虚拟机中，它的实例对应的结构体也叫 classmethod
    classmethod *cm = (classmethod *)self;

    if (cm-&gt;cm_callable == NULL) {
        PyErr_SetString(PyExc_RuntimeError,
                        &quot;uninitialized classmethod object&quot;);
        return NULL;
    }
    // 如果 type 为空，让 type = Py_TYPE(obj)
    // 所以不管是类调用还是实例调用，第一个参数都是类
    if (type == NULL)
        type = (PyObject *)(Py_TYPE(obj));
    return PyMethod_New(cm-&gt;cm_callable, type);
}
</code></pre>
<p>所以当类在调用的时候，类也和函数绑定起来了，因此也会得到一个方法。不过被 classmethod 装饰之后，即使是实例调用，第一个参数传递的还是类本身，因为和函数绑定的是类、而不是实例。</p>
<p>但不管和函数绑定的是类还是实例，绑定之后的结果都叫<strong>方法</strong>。所以得到的究竟是函数还是方法，就看这个函数有没有和某个对象进行绑定，只要绑定了，那么它就会变成方法。至于调用我们就不赘述了，上面已经说过了。不管和函数绑定的是类还是实例，调用方式不变，唯一的区别就是第一个参数不同。</p>
<h2 id="千变万化的描述符"><a class="header" href="#千变万化的描述符">千变万化的描述符</a></h2>
<p>当我们通过对象调用成员函数时，最关键的一个动作就是从 PyFunctionObject 对象到 PyMethodObject 对象的转变，而这个关键的转变就取决于描述符。当我们访问对象的被代理属性时，由于描述符的存在，这种转变自然而然地就发生了。</p>
<p>事实上，Python 的描述符很强大，我们可以使用它做很多事情。而在虚拟机层面，也存在各种各样的描述符，比如 property 实例、staticmethod 实例、classmethod 实例等等。这些描述符给 Python 的类机制赋予了强大的力量，具体源码就不分析了，可以参照上面介绍的 classmethod，我们直接在 Python 的层面，演示一下这三种描述符的具体用法。</p>
<h3 id="property"><a class="header" href="#property">property</a></h3>
<p>property 可以让我们像访问属性一样去调用一个方法，举个栗子：</p>
<pre><code class="language-Python">class Girl:

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    @property
    def get_info(self):
        return f&quot;name: {self.name}, age: {self.age}&quot;


g = Girl()
print(g.get_info)  # name: satori, age: 16
print(Girl.get_info)  # &lt;property object at 0x00...&gt;
</code></pre>
<p>我们并没有调用 get_info，结果它自动就调用了，就像访问属性一样。并且 property 是为实例对象准备的，如果是类调用，返回的就是描述符本身。那么这是怎么实现的呢？我们来演示一下。</p>
<pre><code class="language-Python">class MyProperty:

    def __init__(self, func):
        self.func = func

    def __get__(self, instance, owner):
        # 当实例访问 get_info 的时候，本来应该被包装成方法的
        # 但是现在被新的描述符代理了，所以会执行此处的 __get__
        if instance is None:
            # 如果 instance 为 None，证明是类调用，直接返回描述符本身
            return self
        # 否则调用 self.func，也就是 Girl 里面的 get_info
        # 等价于 Girl.get_info(g)
        self.func(instance)


class Girl:

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    # 等价于 get_info = MyProperty(get_info)
    # 所以此时的 get_info 就被描述符代理了
    @MyProperty
    def get_info(self):
        return f&quot;name: {self.name}, age: {self.age}&quot;

g = Girl()
print(g.get_info)  # name: satori, age: 16
print(Girl.get_info)  # &lt;__main__.MyProperty object at 0x00...&gt;
</code></pre>
<p>但是内置的 property 功能远不止这么简单。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self):
        self.__name = None

    def fget(self):
        return self.__name

    def fset(self, value):
        self.__name = value

    def fdelete(self):
        print(&quot;属性被删了&quot;)
        del self.__name

    user_name = property(fget, fset, fdelete, doc=&quot;这是 property&quot;)

    
g = Girl()
# 执行 fget
print(g.user_name)  # None
# 执行 fset
g.user_name = &quot;satori&quot;
print(g.user_name)  # satori
# 执行 fdelete
del g.user_name  # 属性被删了
</code></pre>
<p>如果我们也想实现这个功能，该怎么做呢？</p>
<pre><code class="language-Python">class MyProperty:

    def __init__(self, fget=None, fset=None,
                 fdelete=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdelete = fdelete
        self.doc = doc

    def __get__(self, instance, owner):
        # Girl.fget(g)
        if isinstance is None:
            return self
        return self.fget(instance)

    def __set__(self, instance, value):
        # Girl.fset(g, value)
        return self.fset(instance, value)

    def __delete__(self, instance):
        # Girl.fdelete(g)
        return self.fdelete(instance)


class Girl:

    def __init__(self):
        self.__name = None

    def fget(self):
        return self.__name

    def fset(self, value):
        self.__name = value

    def fdelete(self):
        print(&quot;属性被删了&quot;)
        del self.__name

    user_name = MyProperty(fget, fset, fdelete, doc=&quot;这是property&quot;)


g = Girl()
# 执行 fget
print(g.user_name)  # None
# 执行 fset
g.user_name = &quot;satori&quot;
print(g.user_name)  # satori
# 执行 fdelete
del g.user_name  # 属性被删了
</code></pre>
<p>可以看到，自定义的 MyProperty 和内置的 property 的表现是一致的。但是 property 还支持使用装饰器的方式。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self):
        self.__name = None

    @property
    def user_name(self):
        return self.__name

    @user_name.setter
    def user_name(self, value):
        self.__name = value

    @user_name.deleter
    def user_name(self):
        print(&quot;属性被删了&quot;)
        del self.__name


g = Girl()
print(g.user_name)  # None
g.user_name = &quot;satori&quot;
print(g.user_name)  # satori
del g.user_name  # 属性被删了
</code></pre>
<p>如果我们想实现这一点也很简单。</p>
<pre><code class="language-Python">class MyProperty:

    def __init__(self, fget=None, fset=None,
                 fdelete=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdelete = fdelete
        self.doc = doc

    def __get__(self, instance, owner):
        # 执行 @MyProperty 的时候
        # 被 MyProperty 装饰的 user_name 会赋值给 self.fget
        # 然后返回的 MyProperty(user_name) 会重新赋值给 user_name
        if instance is None:
            return self
        return self.fget(instance)

    def __set__(self, instance, value):
        return self.fset(instance, value)

    def __delete__(self, instance):
        return self.fdelete(instance)

    def setter(self, func):
        # 调用 @user_name.setter，创建一个新的描述符
        # 其它参数不变，但是第二个参数 fset 变为接收的 func
        return type(self)(self.fget, func, self.fdelete, self.doc)

    def deleter(self, func):
        # 调用 @user_name.deleter，创建一个新的描述符
        # 其它参数不变，但是第三个参数 fdelete 变为接收的 func
        return type(self)(self.fget, self.fset, func, self.doc)


class Girl:

    def __init__(self):
        self.__name = None

    # user_name = MyProperty(user_name)
    # 调用时会触发描述符的 __get__
    @MyProperty
    def user_name(self):
        return self.__name

    # 被一个新的描述符所代理，这个描述符实现了__set__
    # 给 g.user_name 赋值时，会触发 __set__
    @user_name.setter
    def user_name(self, value):
        self.__name = value

    # 被一个新的描述符所代理，这个描述符实现了 __delete__
    # 删除 g.user_name 时，会触发 __delete__
    @user_name.deleter
    def user_name(self):
        print(&quot;属性被删了&quot;)
        del self.__name


g = Girl()
print(g.user_name)  # None
g.user_name = &quot;satori&quot;
print(g.user_name)  # satori
del g.user_name  # 属性被删了

# 当然啦，user = MyProperty(...) 这种方式也是支持的
</code></pre>
<p>以上我们就手动实现了 property，虽然都知道怎么用，但当让你手动实现的时候，一瞬间是不是有点懵呢？</p>
<h3 id="staticmethod"><a class="header" href="#staticmethod">staticmethod</a></h3>
<p>实例在获取成员函数时，会将其包装成方法，并在调用时将自身作为第一个参数传进去。但如果函数被 staticmethod 装饰，那么实例和类一样，在获取的时候拿到的就是函数本身。</p>
<pre><code class="language-Python">class Girl:

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    # 被装饰之后，就是一个普通的函数
    @staticmethod
    def get_info():
        return &quot;info&quot;


g = Girl()
print(g.get_info is Girl.get_info)  # True
print(g.get_info)  # &lt;function Girl.get_info at 0x00...&gt;
print(g.get_info())  # info
</code></pre>
<p>并且实例在调用的时候也不会将自身传进去了。然后我们来看看如何手动实现 staticmethod。</p>
<pre><code class="language-Python">class StaticMethod:

    def __init__(self, func):
        self.func = func

    def __get__(self, instance, owner):
        # 静态方法的话，类和实例都可以用
        # 因此不管是实例还是类，调用时直接返回 self.func 即可
        # 这里的 self.func 就是 Girl.get_info
        return self.func


class Girl:

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    @StaticMethod
    def get_info():
        return &quot;info&quot;


g = Girl()
print(g.get_info is Girl.get_info)  # True
print(g.get_info)  # &lt;function Girl.get_info at 0x00...&gt;
print(g.get_info())  # info
</code></pre>
<p>如果不是静态方法的话，那么 g.get_info() 本质上就是 Girl.get_info(g)。但现在我们不希望实例调用时将自身传过去，那么就让 g 在获取 get_info 时，返回 Girl.get_info 即可。</p>
<p>由于静态方法在调用时不会自动传参，那么也就意味着不需要使用 self 内部的属性。换言之，如果一个方法里面没有使用 self，那么它应该被声明为静态的。</p>
<p><img src="./images/271.png" alt="" /></p>
<p>在 get_info 里面直接返回了一个字符串，没有用到 self，那么第一个参数就是个摆设。所以 PyCharm 提示你，这个方法可以考虑声明为静态的。当然啦，此时是否静态都不影响，都能够正常调用。</p>
<h3 id="classmethod"><a class="header" href="#classmethod">classmethod</a></h3>
<p>这个之前已经介绍过了，直接看代码吧。</p>
<pre><code class="language-Python">class Girl:
    name = &quot;koishi&quot;
    age = 15

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    @classmethod
    def get_info(cls):
        # 此时拿到的是类属性
        return f&quot;name: {cls.name}, age: {cls.age}&quot;


g = Girl()
print(g.get_info())  # name: koishi, age: 15
print(Girl.get_info())  # name: koishi, age: 15
</code></pre>
<p>一旦被 classmethod 装饰，那么就变成了类方法，此时无论是实例调用还是类调用，都会将类作为第一个参数传进去。由于传递的第一个参数是类，所以第一个参数的名称不再叫 self，而是叫 cls。当然，名字啥的都无所谓，没有影响，只是按照规范应该这么做。</p>
<p>然后我们用 Python 来模拟一下。</p>
<pre><code class="language-Python">from functools import wraps


class ClassMethod:

    def __init__(self, func):
        self.func = func

    def __get__(self, instance, owner):
        # 返回一个闭包，然后当调用的时候，接收参数
        @wraps(self.func)
        def inner(*args, **kwargs):
            # 调用的时候，手动将类、也就是 owner 传递进去
            # 所以我们看到，函数被 classmethod 装饰之后
            # 即使是实例调用，第一个参数传递的还是类本身
            return self.func(owner, *args, **kwargs)
        return inner


class Girl:
    name = &quot;koishi&quot;
    age = 15

    def __init__(self):
        self.name = &quot;satori&quot;
        self.age = 16

    @ClassMethod
    def get_info(cls):
        return f&quot;name: {cls.name}, age: {cls.age}&quot;


g = Girl()
print(g.get_info())  # name: koishi, age: 15
print(Girl.get_info())  # name: koishi, age: 15
</code></pre>
<p>类方法是为类准备的，但是实例也可以调用。</p>
<p>另外，类方法一般都用在初始化上面，举个栗子：</p>
<pre><code class="language-Python">class Girl:

    def __init__(self, name, age):
        self.name = name
        self.age = age

    @classmethod
    def create_girl(cls, name, age):
        return cls(name, age)

    def get_info(self):
        return f&quot;name: {self.name}, age: {self.age}&quot;


g1 = Girl(&quot;satori&quot;, 16)
g2 = Girl.create_girl(&quot;koishi&quot;, 15)
print(g1.get_info())  # name: satori, age: 16
print(g2.get_info())  # name: koishi, age: 15
</code></pre>
<p>然后静态方法和类方法在继承的时候，也会直接继承过来。比如在调用父类的方法时，发现这是一个静态方法，那么得到的也是静态方法；同理，类方法和 property 亦是如此。</p>
<h2 id="小结-64"><a class="header" href="#小结-64">小结</a></h2>
<p>以上我们就探讨了为什么实例调用方法时，会自动将自身传给 self，说白了就是因为描述符机制。像 property、staticmethod、classmethod 等等都是通过描述符来实现的，描述符在 Python 里面是一个很强大的机制，但使用的频率却不高，更多的是在一些框架的源码中出现。</p>
<p>到此，类相关的内容就算全部介绍完了，算是历经九九八十一难吧。当然啦，由于虚拟机是一个非常庞大的工程，这里无法涉及到边边角角的每一处细节。有兴趣的话，可以进入源码中自己探索一番，加深一遍印象。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-65"><a class="header" href="#楔子-65">楔子</a></h2>
<p>下面来聊一聊模块的导入机制，我们之前考察的所有内容都具有一个相同的特征，那就是它们都局限在一个 .py 文件中。然而现实中不可能只有一个 .py 文件，而是存在多个，而多个 .py 文件之间又存在引用和交互，这些也是程序的一个重要组成部分。那么这里我们就来分析一下，Python 中模块的导入机制。</p>
<p>首先在这里我们必须强调一点，一个单独的 .py 文件、或者 .pyc 文件、.pyd 文件，我们称之为一个<strong>模块</strong> ；而多个模块组合起来放在一个目录中，这个目录我们称之为<strong>包</strong>。但不管是模块，还是包，在虚拟机的眼中，它们都是 PyModuleObject 结构体实例，类型为 PyModule_Type，而在 Python 中则都是一个 <strong>&lt;class 'module'&gt;</strong> 对象。</p>
<pre><code class="language-C">// Objects/moduleobject.c
PyTypeObject PyModule_Type = {
    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)
    &quot;module&quot;,                                   /* tp_name */
    sizeof(PyModuleObject),                     /* tp_basicsize */
    0,                                          /* tp_itemsize */
    (destructor)module_dealloc,                 /* tp_dealloc */
    0,                                          /* tp_vectorcall_offset */
    0,                                          /* tp_getattr */
    0,                                          /* tp_setattr */
    0,                                          /* tp_as_async */
    (reprfunc)module_repr,                      /* tp_repr */
    0,                                          /* tp_as_number */
    0,                                          /* tp_as_sequence */
    0,                                          /* tp_as_mapping */
    0,                                          /* tp_hash */
    0,                                          /* tp_call */
    0,                                          /* tp_str */
    (getattrofunc)module_getattro,              /* tp_getattro */
    PyObject_GenericSetAttr,                    /* tp_setattro */
    0,                                          /* tp_as_buffer */
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC |
        Py_TPFLAGS_BASETYPE,                    /* tp_flags */
    module___init____doc__,                     /* tp_doc */
    (traverseproc)module_traverse,              /* tp_traverse */
    (inquiry)module_clear,                      /* tp_clear */
    0,                                          /* tp_richcompare */
    offsetof(PyModuleObject, md_weaklist),      /* tp_weaklistoffset */
    0,                                          /* tp_iter */
    0,                                          /* tp_iternext */
    module_methods,                             /* tp_methods */
    module_members,                             /* tp_members */
    0,                                          /* tp_getset */
    0,                                          /* tp_base */
    0,                                          /* tp_dict */
    0,                                          /* tp_descr_get */
    0,                                          /* tp_descr_set */
    offsetof(PyModuleObject, md_dict),          /* tp_dictoffset */
    module___init__,                            /* tp_init */
    PyType_GenericAlloc,                        /* tp_alloc */
    PyType_GenericNew,                          /* tp_new */
    PyObject_GC_Del,                            /* tp_free */
};
// Python 的 &lt;class 'module'&gt; 对应底层的 PyModule_Type
// 而导入进来的模块对象则对应底层的 PyModuleObject
</code></pre>
<p>所以模块和包导入进来之后也是一个对象，下面我们通过 Python 来演示一下。</p>
<pre><code class="language-python">import os
import pandas

print(os)  
print(pandas)  
&quot;&quot;&quot;
&lt;module 'os' from 'C:\\python38\\lib\\os.py'&gt;
&lt;module 'pandas' from 'C:\\python38\\lib\\site-packages\\pandas\\__init__.py'&gt;
&quot;&quot;&quot;

print(type(os))  # &lt;class 'module'&gt;
print(type(pandas))  # &lt;class 'module'&gt;
</code></pre>
<p>因此不管是模块还是包，在 Python 中都是一样的，我们后面会详细说。总之它们都是一个 PyModuleObject，只不过为了区分，我们把单独的文件叫做模块，把包含文件的目录叫做包。但是在底层则并没有区分那么明显，它们都是一样的。</p>
<p>所以为了后续不产生歧义，我们这里做一个约定，从现在开始本系列中出现的<strong>模块</strong>，指的是单独的可导入文件；出现的<strong>包</strong>，指的是目录。而模块和包，我们都可以称之为 module 对象，因为这两者本来就是 <strong>&lt;class 'module'&gt;</strong> 的实例对象。</p>
<h2 id="import-前奏曲"><a class="header" href="#import-前奏曲">import 前奏曲</a></h2>
<p>我们以一个简单的 import 为序幕，看看相应的字节码。</p>
<pre><code class="language-Python">import dis

code_string = &quot;import sys&quot;
dis.dis(compile(code_string, &quot;&lt;file&gt;&quot;, &quot;exec&quot;))
&quot;&quot;&quot;
  1           0 LOAD_CONST               0 (0)
              2 LOAD_CONST               1 (None)
              4 IMPORT_NAME              0 (sys)
              6 STORE_NAME               0 (sys)
              8 LOAD_CONST               1 (None)
             10 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>字节码非常简单，import sys 这行代码对应指令 IMPORT_NAME，可以类比之前的 LOAD_NAME，表示将名字为 &quot;sys&quot;  的 module 对象加载进来，然后用变量 sys 保存。</p>
<p>当我们访问 sys.path 的时候，虚拟机就能很轻松地通过 sys 来获取 path 这个属性对应的值了。因此就像我们之前说的那样，创建函数、类、导入模块等等，它们本质上和通过赋值语句创建一个变量是没有什么区别的。</p>
<p>关键就是这个 IMPORT_NAME，我们看看它的实现，还记得从哪里看吗？我们说所有指令的实现都在 ceval.c 的那个无限 for 循环的巨型 switch 中。</p>
<pre><code class="language-C">case TARGET(IMPORT_NAME): {
    // PyUnicodeObject 对象，比如 import sys，那么这个 name 就是字符串 &quot;sys&quot;
    PyObject *name = GETITEM(names, oparg);
    // 再看一下上面的字节码
    // 在 IMPORT_NAME 之前有两个 LOAD_CONST，将 0 和 None 压入了运行时栈
    // 因此这里会从运行时栈中获取到 None 和 0，然后分别赋值给 fromlist 和 level
    // 至于这两个是干啥的，我们后面说
    PyObject *fromlist = POP();
    PyObject *level = TOP();
    // 一个 PyModuleObject *，指向模块对象
    PyObject *res;
    // 调用 import_name，将该函数的返回值赋值给 res
    res = import_name(tstate, f, name, fromlist, level);
    Py_DECREF(level);
    Py_DECREF(fromlist);
    // 设置为栈顶元素，后续通过 STORE_NAME 将其弹出，交给变量 sys 保存
    SET_TOP(res);
    if (res == NULL)
        goto error;
    DISPATCH();
}
</code></pre>
<p>因此重点在 import_name 这个函数中，但是在此之前我们需要先关注一下 fromlist 和 level，而这一点可以从 Python 的层面来介绍。我们知道在 Python 里面导入一个模块直接通过 import 关键字即可， 但是除了 import，还可以使用内置函数 __import__ 来进行导入。这个 __import__ 是解释器使用的一个函数，不推荐我们直接使用，但 import os 在虚拟机看来就是 <font color="blue">os = __import__(&quot;os&quot;)</font>。</p>
<pre><code class="language-python">os = __import__(&quot;os&quot;)
SYS = __import__(&quot;sys&quot;)

print(os)  # &lt;module 'os' from 'C:\\python38\\lib\\os.py'&gt;
print(SYS.prefix)  # C:\python38
</code></pre>
<p>但是问题来了：</p>
<pre><code class="language-python">m1 = __import__(&quot;os.path&quot;)
print(m1)  # &lt;module 'os' from 'C:\\python38\\lib\\os.py'&gt;
# 我们惊奇地发现，返回的居然还是 os 模块
# 按理说应该是 os.path（windows 系统对应 ntpath）才对啊

m2 = __import__(&quot;os.path&quot;, fromlist=[&quot;&quot;])
print(m2)  # &lt;module 'ntpath' from 'C:\\python38\\lib\\ntpath.py'&gt;
# 你看到了什么，我们加上一个 fromlist，就能导入子模块
</code></pre>
<p>为什么会这样呢？我们来看看 __import__ 这个函数的解释，这个是 PyCharm 给抽象出来的。</p>
<p><img src="./images/272.png" alt="" /></p>
<p>大意就是，此函数会由 import 语句调用，当执行 import 的时候，解释器底层会调用 __import__。比如 import os 表示将 &quot;os&quot; 这个字符串传入 __import__ 函数中，从指定目录加载 os.py，当然也可能是 os.pyd、或者一个名为 os 的目录，然后得到一个 module 对象，并将返回值赋值给变量 os，也就是 <font color="blue">os = __import__(&quot;os&quot;)</font>。虽然可以通过这种方式来导入模块，但是 Python 不建议我们这么做。</p>
<p>然后 globals 参数则是确定 import 语句包的上下文，一般直接传 globals() 即可，而 locals 参数基本不用，不过一般情况下 globals 和 locals 我们都不用管。</p>
<p>总之 <font color="blue">__import__(&quot;os.path&quot;)</font> 导入的不是 os.path，而还是 os 这个外层模块。如果想导入 os.path，那么只需要给 fromlist 传入一个非空列表即可，当然不仅仅是非空列表，只要是一个非空的可迭代对象就行。然后是 level 参数，如果 level 是 0，那么表示仅执行绝对导入；如果是一个正整数，表示要搜索的父目录的数量，也就是相对导入。</p>
<p>因此当包名是一个动态字符串的时候，我们就没办法使用 import 关键字了，这时就可以使用 __import__ 手动导入。但是官方不推荐这么做，因为这是给解释器用的，官方推荐我们用 importlib。</p>
<pre><code class="language-python">import importlib

a = &quot;pandas&quot;
pd = importlib.import_module(a)
# 很方便地就导入了，直接通过字符串的方式导入一个 module 对象
print(pd)  
&quot;&quot;&quot;
&lt;module 'pandas' from 'C:\\python38\\lib\\site-packages\\pandas\\__init__.py'&gt;
&quot;&quot;&quot;

# 如果想导入 &quot;模块中导入的模块&quot;
# 比如: 模块 a 中导入了模块 b，我们希望导入 a.b
# 或者导入一个包下面的子模块，比如 pandas.core.frame
sub_mod = importlib.import_module(&quot;pandas.core.frame&quot;)
# 我们看到可以自动导入 pandas.core.frame
print(sub_mod)  
&quot;&quot;&quot;
&lt;module 'pandas.core.frame' from 'C:\\python38\\lib\\site-packages\\pandas\\core\\frame.py'&gt;
&quot;&quot;&quot;

# 但如果是 __import__，默认的话是不行的，导入的依旧是最外层的 pandas
print(__import__(&quot;pandas.core.frame&quot;))
&quot;&quot;&quot;
&lt;module 'pandas' from 'C:\\python38\\lib\\site-packages\\pandas\\__init__.py'&gt;
&quot;&quot;&quot;
# 可以通过给 fromlist 指定一个非空列表来实现
print(__import__(&quot;pandas.core.frame&quot;, fromlist=[&quot;&quot;]))
&quot;&quot;&quot;
&lt;module 'pandas.core.frame' from 'C:\\python38\\lib\\site-packages\\pandas\\core\\frame.py'&gt;
&quot;&quot;&quot;
</code></pre>
<p>上面的导入方式虽然很方便，但有一个要求，就是导入的模块必须位于搜索路径之下。举个栗子，假设我们的项目在 D 盘，但是有一个 test.py 模块位于 F 盘，这时候该怎么做呢？</p>
<pre><code class="language-Python"># 有一个文件 F:\mashiro\test.py，我们如何才能将它导入进来呢？
from importlib.machinery import SourceFileLoader

# 第一个参数是模块名，第二个参数是模块的路径
# 这样就可以实现导入了，所以这是基于文件路径进行加载的
# 这个做法能够保证无论文件在什么地方，都可以进行导入
test = SourceFileLoader(&quot;test&quot;, r&quot;F:\mashiro\test.py&quot;).load_module()

# 但有一点需要注意，如果是导入包的话，那么要导入包里面的 __init__.py 文件
pd = SourceFileLoader(
    &quot;我是 pandas 模块&quot;,
    r&quot;C:\python38\lib\site-packages\pandas\__init__.py&quot;
).load_module()
print(pd.DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [4, 5, 6]}))
&quot;&quot;&quot;
   a  b
0  1  4
1  2  5
2  3  6
&quot;&quot;&quot;
# 如果只写到 pandas，那么会抛出 PermissionError，因为我们不能把目录当成文件来读取
# 至于 import 一个包，本质上也是加载包内部的 __init__.py 

# 但上面这个类只能加载 py 文件，如果想加载 pyc、pyd 文件，需要用下面两个类
# 但需要注意的是，加载普通文件和 pyc 文件时，我们可以随便起名字，也就是第一个参数任意
# 但对于 pyd 文件，第一个参数必须和 pyd 文件的名字保持一致。
from importlib.machinery import SourcelessFileLoader  # pyc
from importlib.machinery import ExtensionFileLoader   # pyd
</code></pre>
<p>或者我们还可以通过 exec 的方式创建。</p>
<pre><code class="language-Python"># ModuleType = type(sys)
from types import ModuleType

print(ModuleType)  # &lt;class 'module'&gt;

# 类对象有了，下面就可以创建了，module 类接收两个参数
# 参数一：模块的名字，必须传递
# 参数二：模块的 doc，不传默认为 None
os = ModuleType(&quot;我是 os 模块&quot;)  # 此时的 os 里面啥也没有

with open(r&quot;C:\python38\Lib\os.py&quot;, encoding=&quot;utf-8&quot;) as f:
    source = f.read()

# 通过 exec 执行读取出来的字符串，然后将名字空间换成 os 的属性字典
exec(source, os.__dict__)
print(os.__name__)  # 我是 os 模块
print(os.path.join(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;))  # x\y\z

print(hasattr(os, &quot;嘿&quot;))  # False
exec(&quot;嘿 = '蛤'&quot;, os.__dict__)
print(os.嘿)  # 蛤
</code></pre>
<p>当然啦，也可以把一个自定义的类的实例变成模块，举个栗子：</p>
<pre><code class="language-Python">import sys
from types import ModuleType


class MyModule(ModuleType):

    def __init__(self, module_name):
        super().__init__(module_name)

    def __getattr__(self, item):
        return f&quot;不存在的属性: {item}&quot;

    def __setattr__(self, key, value):
        self.__dict__[key] = value

    def __str__(self):
        return f&quot;&lt;module '{self.__name__}' from '我来自于虚无'&gt;&quot;


m = MyModule(&quot;MyModule&quot;)
print(m)  # &lt;module 'MyModule' from '我来自于虚无'&gt;
print(m.__name__)  # MyModule
print(m.hello)  # 不存在的属性: hello
m.hello = &quot;world&quot;
print(m.hello)  # world

# 加入到 sys.modules 中
sys.modules[&quot;嘿嘿&quot;] = m
import 嘿嘿
print(嘿嘿.hello)  # world
print(嘿嘿.xxx)  # 不存在的属性: xxx

from 嘿嘿 import hello, a, b, c
print(hello)  # world
print(a)  # 不存在的属性: a
print(b)  # 不存在的属性: b
print(c)  # 不存在的属性: c
</code></pre>
<p>是不是很好玩呢？关于里面的一些细节，比如 sys.modules 是什么，后续会详细说。好了，扯了这么多，我们回到 IMPORT_NAME 这个指令，它是加载模块时对应的指令。在里面确定完参数之后，会调用 import_name，我们看看这个函数长什么样子。</p>
<pre><code class="language-C">// Python/ceval.c
static PyObject *
import_name(PyThreadState *tstate, PyFrameObject *f,
            PyObject *name, PyObject *fromlist, PyObject *level)
{
    _Py_IDENTIFIER(__import__);
    PyObject *import_func, *res;
    PyObject* stack[5];
    // 获取内置函数 __import__
    import_func = _PyDict_GetItemIdWithError(f-&gt;f_builtins, &amp;PyId___import__);
    // 为 NULL 表示获取失败，显然这些都是 Python 底层做的检测
    // 我们使用时不会出现，如果出现，只能说明解释器出问题了
    if (import_func == NULL) {
        if (!_PyErr_Occurred(tstate)) {
            _PyErr_SetString(tstate, PyExc_ImportError, &quot;__import__ not found&quot;);
        }
        return NULL;
    }

    // 判断 __import__ 是否被重载了
    if (import_func == tstate-&gt;interp-&gt;import_func) {
        int ilevel = _PyLong_AsInt(level);
        if (ilevel == -1 &amp;&amp; _PyErr_Occurred(tstate)) {
            return NULL;
        }
        // 未重载的话，调用 PyImport_ImportModuleLevelObject
        res = PyImport_ImportModuleLevelObject(
                        name,
                        f-&gt;f_globals,
                        f-&gt;f_locals == NULL ? Py_None : f-&gt;f_locals,
                        fromlist,
                        ilevel);
        return res;
    }

    Py_INCREF(import_func);
    // 否则调用重载后的 __import__
    stack[0] = name;
    stack[1] = f-&gt;f_globals;
    stack[2] = f-&gt;f_locals == NULL ? Py_None : f-&gt;f_locals;
    stack[3] = fromlist;
    stack[4] = level;
    res = _PyObject_FastCall(import_func, stack, 5);
    Py_DECREF(import_func);
    return res;
}
</code></pre>
<p>然后我们看到底层又调用了 PyImport_ImportModuleLevelObject ，显然核心隐藏在这里面，来看一下它的实现。</p>
<pre><code class="language-C">//Python/import.c
PyObject *
PyImport_ImportModuleLevelObject(PyObject *name, PyObject *globals,
                                 PyObject *locals, PyObject *fromlist,
                                 int level)
{
    _Py_IDENTIFIER(_handle_fromlist);
    PyObject *abs_name = NULL;
    PyObject *final_mod = NULL;
    PyObject *mod = NULL;
    PyObject *package = NULL;
    PyInterpreterState *interp = _PyInterpreterState_GET_UNSAFE();
    int has_from;
    // 名字不可以为空
    if (name == NULL) {
        PyErr_SetString(PyExc_ValueError, &quot;Empty module name&quot;);
        goto error;
    }
    // 名字必须是 PyUnicodeObject
    if (!PyUnicode_Check(name)) {
        PyErr_SetString(PyExc_TypeError, &quot;module name must be a string&quot;);
        goto error;
    }
    if (PyUnicode_READY(name) &lt; 0) {
        goto error;
    }
    // level 不可以小于 0
    if (level &lt; 0) {
        PyErr_SetString(PyExc_ValueError, &quot;level must be &gt;= 0&quot;);
        goto error;
    }
    // level 大于 0，在相应的父目录中寻找，得到 abs_name
    if (level &gt; 0) {
        abs_name = resolve_name(name, globals, level);
        if (abs_name == NULL)
            goto error;
    }
    else {
        // 否则的话，说明 level == 0，因为 level 要求是一个大于等于 0 的整数
        if (PyUnicode_GET_LENGTH(name) == 0) {
            PyErr_SetString(PyExc_ValueError, &quot;Empty module name&quot;);
            goto error;
        }
        // 直接将 name 赋值给 abs_name，说明此时是绝对导入
        abs_name = name;
        Py_INCREF(abs_name);
    }
    // 优先从 sys.modules 中获取
    mod = PyImport_GetModule(abs_name);
    if (mod == NULL &amp;&amp; PyErr_Occurred()) {
        goto error;
    }
    // ...
    // ...
    // ...
    else {
        _Py_IDENTIFIER(__path__);
        PyObject *path;
        if (_PyObject_LookupAttrId(mod, &amp;PyId___path__, &amp;path) &lt; 0) {
            goto error;
        }
        if (path) {
            Py_DECREF(path);
            // 调用函数，导入模块
            final_mod = _PyObject_CallMethodIdObjArgs(
                        interp-&gt;importlib, &amp;PyId__handle_fromlist,
                        mod, fromlist, interp-&gt;import_func, NULL);
        }
        else {
            final_mod = mod;
            Py_INCREF(mod);
        }
    }

  error:
    Py_XDECREF(abs_name);
    Py_XDECREF(mod);
    Py_XDECREF(package);
    if (final_mod == NULL) {
        remove_importlib_frames(interp);
    }
    return final_mod;
}
</code></pre>
<p>还是很好理解的，关于 module 对象的导入，Python 也提供了非常丰富的写法。</p>
<pre><code class="language-python">import numpy
import numpy as np
import numpy.random as _random

from numpy import random
from numpy import random as _random
from numpy import *
</code></pre>
<p>从 import 的目标来说，可以是<strong>包</strong>，也可以是<strong>模块</strong>。而模块可以通过 .py 文件作为载体，也可以通过 .pyc 或者 .pyd 等二进制文件作为载体。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-66"><a class="header" href="#楔子-66">楔子</a></h2>
<p>同 C++ 的 namespace，Python 通过模块和包来实现对系统复杂度的分解，以及保护名字空间不受污染。通过模块和包，我们可以将某个功能、某种抽象进行独立的实现和维护，在 module 对象的基础之上构建软件。这样不仅使得软件的架构清晰，而且也能很好地实现代码复用。</p>
<h2 id="标准-import"><a class="header" href="#标准-import">标准 import</a></h2>
<p>sys 这个模块恐怕是使用最频繁的 module 对象之一了，我们就从这位老铁入手。Python 有一个内置函数 dir，这个小工具是我们探测 import 的杀手锏。如果你在交互式环境下输入 dir()，那么会打印当前 local 名字空间里的所有符号，如果有参数，比如 dir(xx)，则输出 xx 指向对象的所有属性。我们先来看看 import 动作对当前名字空间的影响：</p>
<pre><code class="language-Python">&gt;&gt;&gt; dir()
['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__']
&gt;&gt;&gt; 
&gt;&gt;&gt; import sys
&gt;&gt;&gt; 
&gt;&gt;&gt; dir()
['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'sys']
</code></pre>
<p>我们看到进行了 import 动作之后，当前的 local 名字空间增加了一个 sys 符号。</p>
<pre><code class="language-python">&gt;&gt;&gt; type(sys)
&lt;class 'module'&gt;
</code></pre>
<p>而且通过 type 操作，我们看到这个 sys 符号指向一个 module对象，在底层它是一个 PyModuleObject。当然啦，虽然写着类型是 &lt;class 'module'&gt;，但是这个类无法直接使用，因为解释器没有将它暴露出来。不过它既然是一个 class，那么就一定继承 object，并且元类为 type。</p>
<pre><code class="language-python">&gt;&gt;&gt; sys.__class__.__class__
&lt;class 'type'&gt;
&gt;&gt;&gt; sys.__class__.__base__
&lt;class 'object'&gt;
</code></pre>
<p>这与我们的分析是一致的。言归正传，我们看到 import 机制影响了当前的 local 名字空间，使得加载的 module 对象在 local 空间成为可见的。而引用该 module 的方法正是通过 module 的名字，即这里的 sys。</p>
<p>实际上，这和我们创建一个变量是等价的，比如 a = 123，会先创建一个 PyLongObject，然后让变量 a 指向它。而上面的 import sys 也是同理，先创建一个 PyModuleObject，然后让变量 sys 指向它。</p>
<p>不过这里还有一个问题，来看一下：</p>
<pre><code class="language-Python">&gt;&gt;&gt; sys
&lt;module 'sys' (built-in)&gt;
</code></pre>
<p>我们看到 sys 是内置的，说明模块除了可以是真实存在的文件之外，还可以内嵌在解释器里面。但既然如此，那为什么不能直接使用，还需要导入呢？其实不光是 sys，在 Python 初始化的时候，就已经将一大批的 module 对象加载到了内存中。这些 module 对象都是使用 C 编写，并内嵌在解释器里面的，因为它们对性能的要求比较严苛，比如 _random、gc、_pickle 等等。</p>
<p>但是为了让当前 local 名字空间能够达到最干净的效果，Python 并没有将这些符号暴露在 local 名字空间中。而是需要开发者显式地通过 import 机制将符号引入到 local 名字空间之后，才能让程序使用符号背后的对象。</p>
<p><font color="blue">凡是加载进内存的 module 对象都会保存在 sys.modules 里面，尽管当前的 local 空间里面没有，但 sys.modules 里面是跑不掉的。</font></p>
<pre><code class="language-Python">import sys

# sys.modules 是一个字典，里面保存了 &quot;module 对象的名字&quot; 到 &quot;module 对象&quot; 的映射
# 里面有很多模块，这里就不打印了，但令我感到意外的是，居然把 numpy 也加载进来了
modules = sys.modules

np = modules[&quot;numpy&quot;]
arr = np.array([1, 2, 3, 4, 5])
print(np.sum(arr))  # 15


# os 模块我们没有导入，但是它已经在内存中了
# 虽然当前 local 空间没有，但它在 sys.modules 里面
os_ = modules[&quot;os&quot;]

# 手动导入，会从 sys.modules 里面加载
import os   
print(id(os) == id(os_))  # True
</code></pre>
<p>一开始这些 module 对象是不在 local 空间里面的，除非显式导入，但即便我们导入，这些 module 对象也不会被二次加载。因为在解释器启动后，它们就已经被加载到内存里面了，存放在 sys.modules 中。</p>
<p>因此对于已经在 sys.modules 里面的 module 对象来说，导入的时候只是将符号暴露到 local 空间里面去，所以代码中的 os 和 os_ 指向同一个 module对象。如果我们在 Python 启动之后，导入一个 sys.modules 中不存在的 module 对象，那么才会进行加载、然后同时进入 sys.modules 和 local 空间。</p>
<h3 id="自定义-module"><a class="header" href="#自定义-module">自定义 module</a></h3>
<p>对于那些内嵌在解释器里面的 module 对象，如果 import，只是将符号暴露在了 local 名字空间中。下面我们看看对那些在初始化的时候没有加载到内存的 module 对象进行 import 的时候，会出现什么样的动作。</p>
<p>这里就以模块为例，当然正如我们之前说的，一个模块的载体可以是 py 文件或者二进制文件，而 py 文件可以是自己编写的、也可以是标准库中的、或者第三方库中的。那么下面我们就自己编写一个 py 文件作为例子，探探路。</p>
<pre><code class="language-Python"># a.py
a = 1
b = 2
</code></pre>
<p>以上是 a.py，里面定义了两个变量，然后导入它。</p>
<pre><code class="language-Python">import sys

print(&quot;a&quot; in sys.modules)  # False

import a
print(&quot;a&quot; in sys.modules)  # True
print(dir())  # [..., 'a', 'sys']

print(id(a))  # 2653299804976
print(id(sys.modules[&quot;a&quot;]))  # 2653299804976

print(type(a))  # &lt;class 'module'&gt;
</code></pre>
<p>type(a) 的结果表明 import 机制确实创建了一个新的 module对象，而且也正如我们之前所说，解释器对 a 指向的 module 对象进行导入时，会同时将其引入到 sys.modules 和当前的 local 名字空间中，它们指向的是同一个 PyModuleObject。然后我们再来看看这个 module对象：</p>
<pre><code class="language-Python">import a

# 查看 a 里面的属性
print(dir(a))  
&quot;&quot;&quot;

['__builtins__', '__cached__', '__doc__', '__file__', '__loader__',
 '__name__', '__package__', '__spec__', 'a', 'b']
&quot;&quot;&quot;

print(a.__name__)  # a
print(a.__file__)  # D:\satori\a.py
</code></pre>
<p>可以看到，module 对象内部实际上是通过一个字典来维护所有的属性，里面有 module 的元信息（名字、文件路径）、以及 module 对象的内容。因为 module 对象本身就是 &lt;class 'module'&gt; 的实例对象，它有自己的属性字典，用来维护内部的属性。</p>
<blockquote>
<p>另外，如果此时你查看 a.py 所在目录的 __pycache__ 目录，会发现里面有一个 a.pyc，说明解释器在导入的时候先生成了 pyc，然后再导入 pyc。</p>
</blockquote>
<p>并且我们通过 dir(a) 查看的时候，发现里面有一个 __builtins__ 符号，那么这个 __builtins__ 和我们之前说的那个 __builtins__ 是一样的吗？</p>
<pre><code class="language-Python"># 获取 builtins 可以通过 import builtins 的方式导入
# 但其实也可以通过 __builtins__ 获取
print(
    id(__builtins__), type(__builtins__)
)  # 140265846506256 &lt;class 'module'&gt;

print(
    id(a.__dict__[&quot;__builtins__&quot;]), type(a.__dict__[&quot;__builtins__&quot;])
)  # 140265846500608 &lt;class 'dict'&gt;
</code></pre>
<p>尽管它们都叫 __builtins__，但一个是 module对象，一个是字典。直接访问 __builtins__ 获取的是一个 module 对象，int、str、globals 和 __builtins__.int，__builtins__.str，__builtins__.globals 是等价的。</p>
<p>但 a.__dict__[&quot;__builtins__&quot;] 是一个字典，这就说明两者从性质上就是不同的东西，但即便如此，就真的一点关系也没有吗？</p>
<pre><code class="language-Python">import a

print(id(__builtins__.__dict__))  # 2791398177216
print(id(a.__dict__[&quot;__builtins__&quot;]))  # 2791398177216
</code></pre>
<p>我们看到还是有一点关系的，和类、类的实例对象一样，每一个 module 对象也有自己的属性字典 __dict__，记录了自身的元信息、里面存放的内容等等。对于 <font color="blue">a.__dict__[&quot;__builtins__&quot;]</font> 来说，拿到的就是 <font color="blue">__builtins__.__dict__</font>。所以说 __builtins__ 是一个模块，但这个模块有一个属性字典，而这个字典可以通过 <font color="blue">module对象.__dict__[&quot;__builtins__&quot;]</font> 来获取。</p>
<p>因为任何一个模块都可以使用 __builtins__ 里面的内容，并且所有模块对应的 __builtins__ 都是一样的。所以当你直接打印 a.__dict__ 的时候会输出一大堆内容，因为输出的内容里面不仅有当前模块的内容，还有 __builtins__.__dict__。</p>
<pre><code class="language-python">import a

# a.__dict__[&quot;__builtins__&quot;] 就是 __builtins__.__dict__ 这个属性字典
# 而 __builtins__.__dict__[&quot;list&quot;] 又是 __builtins__.list
# 说白了，就是我们直接输入的 list
print(a.__dict__[&quot;__builtins__&quot;][&quot;list&quot;] is list)  # True
print(
    # 等价于 __builtins__.__dict__[&quot;list&quot;](&quot;abcd&quot;)
    # 等价于 __builtins__.list(&quot;abcd&quot;)
    # 等价于 list(&quot;abcd&quot;)
    a.__dict__[&quot;__builtins__&quot;][&quot;list&quot;](&quot;abcd&quot;),
)  # ['a', 'b', 'c', 'd']

# 回顾之前的内容
# 我们说，模块名是在模块的属性字典里面
print(a.__dict__[&quot;__name__&quot;] == a.__name__ == &quot;a&quot;)  # True

# __builtins__ 里面的 __name__ 就是 builtins
print(__builtins__.__dict__[&quot;__name__&quot;])  # builtins

# 对于当前文件来说也是一个模块，它的 local 空间也有 __name__
# 并且如果它做为启动文件，那么 __name__ 会等于 &quot;__main__&quot;
# 如果是被导入的，那么它的 __name__ 会等于文件名
print(__name__)   # __main__

# __main__ 也是一个模块
# 注意：如果这么做的话，那么该文件必须是启动文件
name = &quot;古明地觉&quot;
from __main__ import name as NAME
print(NAME)  # 古明地觉
</code></pre>
<p>所以可以把模块的属性字典，看成是 local 空间（也是 global空间）、内置空间的组合。</p>
<h2 id="嵌套-import"><a class="header" href="#嵌套-import">嵌套 import</a></h2>
<p>我们下面来看一下 import 的嵌套，所谓 import 的嵌套就是指 import a、但是在 a 中又 import b，我们来看看这个时候会发生什么有趣的动作。</p>
<pre><code class="language-python"># a.py
import tornado
</code></pre>
<p>在 a.py 中我们导入了 tornado 模块，然后再来导入 a。</p>
<pre><code class="language-python">import a
import sys
import tornado

print(
    a.tornado is tornado is sys.modules[&quot;tornado&quot;] is a.__dict__[&quot;tornado&quot;]
)  # True
</code></pre>
<p>首先 import a 之后，我们通过 a 这个符号是可以直接拿到其对应的模块的。但是在 a 中我们又 import tornado，那么通过 a.tornado 可以拿到 tornado 模块。</p>
<p>但第二次导入 tornado 的时候，会怎么样呢？首先在 a 中已经导入了 tornado，那么 tornado 就已经在 sys.modules 里面了。因此当再次导入 tornado 的时候，会直接从 sys.modules 里面查找，而不会二次加载。为了更直观的验证，我们再举一个例子：</p>
<pre><code class="language-python"># a.py
print(123)

# b.py
import a

# c.py
import a
</code></pre>
<p>以上是三个文件，每个文件只有一行代码，我们来导入 a、b、c。</p>
<pre><code class="language-Python">import a
import b
import c
&quot;&quot;&quot;
123
&quot;&quot;&quot;
</code></pre>
<p>当导入一个不在 sys.modules 里面的模块时，会先从硬盘中加载相应的文件，然后逐行解释执行里面的内容，构建 PyModuleObject 对象，最后加入到 sys.modules 和 local 空间中。当第二次导入的时候，对应的模块已经存在 sys.modules 当中了，因此直接将符号暴露到当前的 local 空间里面即可，不会再执行里面的内容。</p>
<p>所以我们可以把 sys.modules 看成是一个大仓库，里面保存了<strong>模块名</strong>到<strong>模块对象</strong>的映射，任何导入的模块都在这里面。如果导入时，发现 sys.modules 里面已存在，那么直接通过字典获取即可，这样可以避免重复加载。</p>
<p><img src="./images/273.png" alt="" /></p>
<h2 id="导入包"><a class="header" href="#导入包">导入包</a></h2>
<p>我们写的多个逻辑或者功能上相关的函数、类可以放在一个模块里面，那么多个模块是不是也可以组成一个包呢？如果说模块是管理 class、函数、变量的机制，那么包就是管理模块的机制。当然啦，多个小的包又可以聚合成一个更大的包。</p>
<p>因此在 Python 中，模块是由一个单独的文件来实现的，可以是 .py 文件、或者二进制文件。而对于包来说，则是一个目录，里面容纳了模块对应的文件，这种方式就是把多个模块聚合成一个包的具体实现。但不管是模块还是包，它们都是一个 module 对象，在虚拟机看来则都是 PyModuleObject 对象。关于这一点，一会儿会看的更加明显。</p>
<p>假设现在有一个名为 test_import 的包，里面有一个 a.py，内容如下。</p>
<pre><code class="language-Python">a = 123
b = 456
print(&quot;&gt;&gt;&gt;&quot;)
</code></pre>
<p>现在我们来导入它。</p>
<pre><code class="language-Python">import test_import
print(test_import)  # &lt;module 'test_import' (namespace)&gt;
</code></pre>
<p>在 Python2 中，这样是没办法导入的，因为如果一个目录要成为 Python 的包，那么里面必须要有一个 __init__.py 文件，但是在 Python3 中则没有此要求。而且我们发现 print 之后，显示的也是一个 module 对象，因此 Python 对模块和包的底层定义其实是很灵活的，并没有那么僵硬。</p>
<pre><code class="language-Python">import test_import

print(test_import.a)
&quot;&quot;&quot;
AttributeError: module 'test_import' has no attribute 'a'
&quot;&quot;&quot;
</code></pre>
<p>然而此时神奇的地方出现了，调用 test_import.a 的时候，告诉我们没有 a 这个属性。很奇怪，test_import 里面不是有 a.py 吗？</p>
<p>原因是 Python 导入一个包，等价于导入包里的 __init__.py，只有属性在 __init__.py 文件中被导入了，我们才可以通过包名来访问。如果这个包里面没有 __init__.py 文件，那么你导入这个包，是什么属性也用不了的。</p>
<p>光说可能比较难理解，我们来演示一下。我们在 test_import 里面创建一个 __init__.py 文件，但是文件里面什么也不写。</p>
<pre><code class="language-python">import test_import

print(test_import)
&quot;&quot;&quot;
&lt;module 'test_import' from 'D:\\satori\\test_import\\__init__.py'&gt;
&quot;&quot;&quot;
</code></pre>
<p>此时又看到了神奇的地方，我们在 test_import 目录里面创建了 __init__.py 之后，再打印 test_import，得到的结果又变了，告诉我们这个包来自于包里面的 __init__.py 文件。所以就像之前说的，Python 对包和模块的概念区分的不是很明显，我们就把包当做该包下面的  __init__.py 文件即可，__init__.py 中定义了什么，那么这个包里面就有什么。</p>
<p>我们往 __init__.py 里面写点内容：</p>
<pre><code class="language-python"># test_import/__init__.py

import sys
from . import a

name = &quot;satori&quot;
</code></pre>
<p>from . import a 表示在 __init__.py 的同级目录中导入 a.py，但是问题来了，直接像 import sys 那样 import a 不行吗？答案是不行的，至于为什么我们后面说。</p>
<p>总之我们在 __init__.py 中导入了 sys 模块、a 模块，定义了 name 变量，那么就等于将 sys、a、name 加入到 test_import 这个包的 local 空间里面了。因为 Python 的包等价于它里面的 __init__.py 文件，这个文件有什么，那么这个包就有什么。</p>
<p>既然在 __init__.py 中导入了 sys、a，定义了 name，那么这个文件的属性字典里面、或者也可以说 local 空间里面就多了三个 entry，key 分别为 &quot;sys&quot;、&quot;a&quot;、&quot;name&quot;。而 __init__.py 里面有什么，那么通过包名就能够获取什么。</p>
<pre><code class="language-python"># 导入一个包会执行内部的 __init__.py
# 而在 __init__.py 里面导入了 a
# a 里面有一个 print，所以会直接执行
import test_import
&quot;&quot;&quot;
&gt;&gt;&gt;
&quot;&quot;&quot;

print(test_import.a)
&quot;&quot;&quot;
&lt;module 'test_import.a' from 'D:\\satori\\test_import\\a.py'&gt;
&quot;&quot;&quot;
print(test_import.a.a)  # 123  
print(test_import.a.b)  # 456

print(test_import.sys)  # &lt;module 'sys' (built-in)&gt;
print(test_import.name)  # satori



# 二次导入
import test_import
# 我们看到 a 里面的 print 没有打印，证明模块、包不管以怎样的方式被导入
# 对应的文件只会被加载一遍，第二次导入只是从 sys.modules 里面进行了一次键值对查找
</code></pre>
<h3 id="相对导入与绝对导入"><a class="header" href="#相对导入与绝对导入">相对导入与绝对导入</a></h3>
<p>我们刚才使用了 from . import a 的方式导入模块 a，这个 <strong>.</strong> 表示当前文件所在的目录。因此这行代码的含义就是，我要导入 a 这个模块，不是从别的地方导入，而是从该文件所在的目录里面导入。如果是 <strong>..</strong> 就表示当前文件所在目录的上一层目录，<strong>...</strong> 和 <strong>....</strong> 依次类推。</p>
<p>另外模块 a 里面还有一个变量 a，那如果我想在 __init__.py 中导入这个变量该怎么办呢？很简单，直接 <font color="blue">from .a import a</font> 即可，表示导入当前目录里面的模块 a 里面的变量 a。</p>
<p>但如果我们导入的时候没有 <strong>.</strong> 的话，则表示绝对导入，虚拟机就会按照 sys.path 定义的路径进行查找。那么问题来了，假设我们在 __init__.py 中写的不是 <font color="blue">from . import a</font>，而是 <font color="blue">import a</font>，那么会发生什么后果呢？</p>
<pre><code class="language-Python">import test_import

&quot;&quot;&quot;
    import a
ModuleNotFoundError: No module named 'a'
&quot;&quot;&quot;
</code></pre>
<p>我们发现报错了，提示没有 a 这个模块，可是我们明明在包里面定义了呀。还记得之前说的导入一个模块、导入一个包会做哪些事情吗？导入一个模块，会将该模块里面的内容 &quot;拿过来&quot; 执行一遍，导入包会将该包里面的 __init__.py 文件 &quot;拿过来&quot; 执行一遍。注意：这里把 &quot;拿过来&quot; 三个字加上了引号。</p>
<p>我们在和 test_import 目录同级的 py 文件中导入了 test_import，那么就相当于把里面的 __init__ 拿过来执行一遍（当然只有第一次导入的时候才会这么做）。但是它们具有单独的空间，是被隔离的，访问时需要使用符号 test_import 来访问。</p>
<p>但是正如之前所说，是 &quot;拿过来&quot; 执行，所以这个 __init__.py 里面的内容是&quot;拿过来&quot;，在当前的 .py 文件（在哪里导入的就是哪里）中执行的。所以由于 import a 这行代码表示绝对导入，就相当于在当前模块里面导入，会从 sys.path 里面搜索，但模块 a 是在 test_import 包里面，那么此时还能找到这个 a 吗？显然是不能的，除非我们将 test_import 所在路径加入到 sys.path 中。</p>
<p>那 <font color="blue">from . import a</font> 为什么就好使呢？因为这种导入方式是相对导入，表示要在 __init__.py 所在目录里面找，那么不管在什么地方导入这个包，由于 __init__.py 的位置是不变的，所以 <font color="blue">from . import a</font> 这种相对导入的方式总能找到对应的 a。</p>
<p>至于标准库、第三方模块、第三方包，因为它们在 sys.path 里面，在哪儿都能找得到，所以直接绝对导入即可。并且我们知道每一个模块都有一个 __file__ 属性（除了内嵌在解释器里面的模块），当然包也是。如果你在一个模块里面 print(__file__)，那么不管在哪里导入这个模块，打印的永远是这个模块的路径；包的话，则是指向内部的 __init__.py 文件。</p>
<p>另外关于相对导入，一个很重要的一点，一旦一个模块出现了相对导入，那么这个模块就不能被执行了，它只可以被导入。</p>
<pre><code class="language-python">import sys
from . import a

name = &quot;satori&quot;
&quot;&quot;&quot;
    from . import a
ImportError: attempted relative import with no known parent package
&quot;&quot;&quot;
</code></pre>
<p>此时如果试图执行 __init__.py，那么就会报出这个错误，所以出现相对导入的模块不能被执行，只能被导入。此外，导入一个内部具有&quot;相对导入&quot;的模块，还要求<font color="blue">当前模块</font>和<font color="blue">被导入模块</font>不能在同一个包内，我们要执行的当前模块至少在<font color="blue">被导入模块</font>的上一级，否则执行当前模块也会报出这种错误。</p>
<p>因此出现相对导入的模块要在一个包里面，然后在包外面使用，所以<font color="blue">当前模块</font>和<font color="blue">出现相对导入的被导入模块</font>绝对不能在同一个包里面。</p>
<h3 id="import-的另一种方式"><a class="header" href="#import-的另一种方式">import 的另一种方式</a></h3>
<p>我们要导入 test_import 包里面的 a 模块，除了可以 import test_import（前提是 __init__.py 里面导入了 a）之外，还可以直接 <font color="blue">import test_import.a</font>。</p>
<p>另外如果是这种导入方式，那么包里面可以没有 __init__.py 文件。因为之前导入 test_import 包的时候，是通过 test_import 来获取 a，所以必须要有 __init__.py、并且里面导入 a。但是在导入 test_import.a 的时候，就是找 test_import.a，所以此时是可以没有 __init__.py文件的。</p>
<pre><code class="language-Python"># test_import/__init__.py
__version__ = &quot;1.0&quot;

# test_import/a.py
name = &quot;古明地觉&quot;
print(&quot;古明地恋&quot;)
</code></pre>
<p>此时 test_import 包的 __init__.py 里面只定义了一个变量，下面我们来通过 test_import.a 的形式导入。</p>
<pre><code class="language-Python">import test_import.a

print(test_import.a.name) 
&quot;&quot;&quot;
古明地恋
古明地觉
&quot;&quot;&quot;

# 当 import test_import.a 的时候，会执行里面的 print
# 然后可以通过 test_import.a 获取 a.py 里面的属性，这很好理解

# 但是，没错，我要说但是了
print(test_import.__version__)  # 1.0
</code></pre>
<p>惊了，我们在导入 test_import.a 的时候，也把 test_import 导入进来了，为了更直观地看到现象，我们在 __init__.py 里面打印一句话。</p>
<pre><code class="language-python">import test_import.a
&quot;&quot;&quot;
我是 test_import 下面的 __init__
古明地恋
&quot;&quot;&quot;
</code></pre>
<p>导入一个包等价于导入包里面的 __init__.py，而 __init__.py 里面的内容都可以通过包来获取。而打印结果显示在导入 test_import.a 时，会先把 test_import 导入进来。如果我们在 __init__.py 中也导入了 a 会怎么样？</p>
<pre><code class="language-python"># test_import/__init__.py
print(&quot;我是 test_import 下面的 __init__&quot;)
from . import a

# test_import/a.py
print(&quot;我是 test_import 下面的 a&quot;)
</code></pre>
<p>导入一下看看：</p>
<pre><code class="language-python">import test_import.a
&quot;&quot;&quot;
我是 test_import 下面的 __init__
我是 test_import 下面的 a
&quot;&quot;&quot;
</code></pre>
<p>我们看到 a.py 里面的内容只被打印了一次，说明没有进行二次加载，在 __init__.py 中将 a 导入进来之后，就加入到 sys.modules 里面了。再看一下 sys.modules：</p>
<pre><code class="language-python">import sys
import test_import.a
&quot;&quot;&quot;
我是 test_import 下面的 __init__
我是 test_import 下面的 a
&quot;&quot;&quot;

print(sys.modules[&quot;test_import&quot;])
print(sys.modules[&quot;test_import.a&quot;])
&quot;&quot;&quot;
&lt;module 'test_import' from 'D:\\satori\\test_import\\__init__.py'&gt;
&lt;module 'test_import.a' from 'D:\\satori\\test_import\\a.py'&gt;
&quot;&quot;&quot;
</code></pre>
<p>通过 test_import.a 的方式来导入，即使 test_import 里面没有 __init__.py 文件依旧可以访问。</p>
<p>不过问题来了，为什么在导入 test_import.a 的时候，会将 test_import 也导入进来呢？并且还可以直接使用 test_import，毕竟这不是我们期望的结果。因为导入 test_import.a 的话，那么我们只是想使用 test_import.a，不打算使用 test_import，那 Python 为什么要这么做呢？</p>
<p>事实上，这对 Python 而言是必须的，根据我们对虚拟机执行原理的了解，要想获取 test_import.a，那么肯定要先从 local 空间中找到 test_import，然后才能找到 a。如果不找到 test_import 的话，那么对 a 的查找也就无从谈起。</p>
<p>虽然 sys.modules 里面有一个 test_import.a，但并不是说有一个模块叫 test_import.a。准确的说 <font color="blue">import test_import.a</font> 表示先导入 test_import，然后再将 test_import 下面的 a 加入到 test_import 的属性字典里面。</p>
<p>我们说当包里面没有 __init__.py 的时候，那这个包是无法使用的，因为属性字典里面啥也没有。但是当 <font color="blue">import test_import.a</font> 的时候，虚拟机会先导入 test_import 这个包，然后再把 a 这个模块加入到包的属性字典里面。而 sys.modules 里面之所以会有 &quot;test_import.a&quot; 这个 key，显然也是为了解决重复导入的问题。</p>
<p>假设 test_import 里面有 a 和 b 两个 .py 文件，那么执行 <font color="blue">import test_import.a</font> 和 <font color="blue">import test_import.b</font> 会进行什么样的动作应该了如指掌了。</p>
<p>执行 <font color="blue">import test_import.a</font>，会先导入 test_import，然后把 a 加入到 test_import 的属性字典里面。执行 <font color="blue">import test_import.b</font>，还是会先导入包 test_import，但是 test_import 在上一步已经被导入了，所以此时会直接从 sys.modules 里面获取，然后再把 b 加入到 test_import 的属性字典里面。</p>
<p>所以如果 __init__.py 里面有一个 print 的话，那么两次导入显然只会 print 一次，这种现象是由 Python 对包内模块的动态加载机制决定的。还是那句话，一个包你就看成是里面的 __init__.py 文件即可，Python 对于包和模块的区分不是特别明显。</p>
<pre><code class="language-python"># test_import 目录下有 __init__.py 文件
import test_import

print(test_import.__file__) 
print(test_import) 
&quot;&quot;&quot;
D:\satori\test_import\__init__.py
&lt;module 'test_import' from 'D:\\satori\\test_import\\__init__.py'&gt;
&quot;&quot;&quot;

# test_import 目录下没有 __init__.py 文件
import test_import

print(test_import.__file__)  
print(test_import)  
&quot;&quot;&quot;
None
&lt;module 'test_import' (namespace)&gt;
&quot;&quot;&quot;
</code></pre>
<p>如果包里面有 __init__.py 文件，那么这个包的 __file__ 属性就是其内部的 __init__.py 文件的完整路径。如果没有 __init__.py 文件，那么这个包的 __file__ 就是 None。</p>
<p>一个模块（即使里面什么也不写）的属性字典里面肯定是有 __builtins__ 属性的，因此可以直接使用内置函数等等。而 __init__.py 也属于一个模块，所以它也有 __builtins__ 属性，由于一个包指向了内部的 __init__.py，所以这个包的属性字典也是有 __builtins__ 属性的。但如果这个包没有 __init__.py 文件，那么就没有 __builtins__ 属性了。</p>
<pre><code class="language-python"># 没有 __init__.py 文件
import test_import
print(
    test_import.__dict__.get(&quot;__builtins__&quot;)
)  # None


# 有 __init__.py 文件
import test_import
print(
    test_import.__dict__.get(&quot;__builtins__&quot;)[&quot;int&quot;]
)  # &lt;class 'int'&gt;
</code></pre>
<h3 id="路径搜索树"><a class="header" href="#路径搜索树">路径搜索树</a></h3>
<p>假设有这样一个目录结构：</p>
<p><img src="./images/274.png" alt="" /></p>
<p>那么 Python 会将这个结构进行分解，得到一个类似于树状的节点集合：</p>
<p><img src="./images/275.png" alt="" /></p>
<p>然后从左到右依次去 sys.modules 中查找每一个符号所对应的 module 对象是否已经被加载，如果一个包被加载了，比如说包 test_import 被加载了，那么在包 test_import 对应的 PyModuleObject 中会维护一个元信息 __path__，表示这个包的路径。比如搜索 A.a，当 A 加载进来之后，对 a 的搜索只会在 A.__path__ 中进行，而不会在 Python 的所有搜索路径中进行了。</p>
<pre><code class="language-Python">import test_import

print(test_import.__path__)  # ['D:\\satori\\test_import']

# 导入 sys 模块
try:
    import test_import.sys
except ImportError as e:
    print(e)  # No module named 'test_import.sys'
</code></pre>
<p>显然这样是错的，因为导入的是 test_import.sys，那么就将搜索范围只限定在 test_import 的 __path__ 下面了，而它下面没有 sys 模块，因此报错。</p>
<h2 id="from-与-import"><a class="header" href="#from-与-import">from 与 import</a></h2>
<p>在 Python 的 import 中，有一种方法可以精确控制所加载的对象，通过 from 和 import 的结合，可以只将我们期望的 module 对象、甚至是 module 对象中的某个符号，动态地加载到内存中。这种机制使得虚拟机在当前名字空间中引入的符号可以尽可能地少，从而更好地避免名字空间遭到污染。</p>
<p>按照我们之前所说，导入 test_import 下面的模块 a，可以使用 import test_import.a 的方式，但此时 a 是在 test_import 的名字空间中，不是在我们当前模块的名字空间中。也就是说我们希望能直接通过符号 a 来调用，而不是 test_import.a，此时通过 <font color="blue">from ... import ...</font> 联手就能完美解决。</p>
<pre><code class="language-python">import sys
# test_import 是一个目录，里面有一个 __init__.py 和一个 a.py
# 在 __init__.py 中导入了 a.py
from test_import import a

print(sys.modules.get(&quot;test_import&quot;) is not None)  # True
print(sys.modules.get(&quot;test_import.a&quot;) is not None)  # True
print(sys.modules.get(&quot;a&quot;) is not None)  # False
</code></pre>
<p>我们看到，确确实实将 a 这个符号加载到当前的名字空间里面了，但是在 sys.modules 里面却没有 a。还是之前说的，a 这个模块在 test_import 这个包里面，我们不可能不通过包就直接拿到包里面的模块，因此在 sys.modules 里面的形式其实还是 test_import.a。</p>
<p>只不过在当前模块的名字空间中是 a，并且 a 被映射到 sys.modules[&quot;test_import.a&quot;]。另外除了 test_import.a，test_import 也导入了，这个原因之前也说过了，不再赘述。所以我们发现即便是 <font color="blue">from ... import ...</font>，还是会触发整个包的导入，只不过包在导入之后，没有暴露在当前的 local 空间中。</p>
<p>所以我们导入谁，就把谁加入到了当前模块的 local 空间里面，假设从 a 导入 b，那么会把 b 加入到当前的 local 空间中。但是在 sys.modules 里面是没有 &quot;b&quot; 这个 key 的，key 应该是 &quot;a.b&quot;，这么做的原因就是为了防止模块重复加载。当然，此时名字空间中的符号 b，和 sys.modules[&quot;a.b&quot;] 都会指向同一个 module 对象。</p>
<p>此外我们 from test_import import a，导入的这个 a 是一个模块，但是模块 a 里面还有一个变量也叫 a。如果不加 from，只通过 import 的话，那么最深也只能 import 到一个模块，不可能说直接 import 模块里面的某个变量、函数什么的。但是 <font color="blue">from ... import ...</font> 的话，却是可以的，比如我们  <font color="blue">from test_import.a import a</font>，这就表示要导入 test_import.a 模块里面的变量 a。</p>
<pre><code class="language-Python">import sys
from test_import.a import a

modules = sys.modules
print(&quot;a&quot; in modules)  # False
print(&quot;test_import.a&quot; in modules)  # True
print(&quot;test_import&quot; in modules)  # True
</code></pre>
<p>此时导入的 a 是一个变量，并不是模块，所以 sys.modules 里面不会有 test_import.a.a 这样的东西存在。但是这个 a 毕竟是从 test_import.a 里面导入的，所以 test_import.a 会在 sys.modules 里面，同理 test_import.a 表示从 test_import 的属性字典里面查找 a，所以 test_import 也会进入 sys.modules 里面。</p>
<p>最后还可以使用 <font color="blue">from test_import.a import *</font> 这样的机制把一个模块里面所有的内容全部导入进来。但是在 Python 中还有一个特殊的机制，如果模块里面定义了 __all__，那么只会导入 __all__ 里面指定的属性。</p>
<pre><code class="language-Python"># test_import/a.py

a = 123
b = 456
c = 789
__all__ = [&quot;a&quot;, &quot;b&quot;]
</code></pre>
<p>我们注意到在 __all__ 里面只指定了 a 和 b，那么后续通过 <font color="blue">from test_import.a import *</font> 的时候，只会导入 a 和 b，而不会导入 c。</p>
<pre><code class="language-python">from test_import.a import *

print(&quot;a&quot; in locals() and &quot;b&quot; in locals())  # True
print(&quot;c&quot; in locals())  # False

from test_import.a import c
print(&quot;c&quot; in locals())  # True
</code></pre>
<p>通过 <font color="blue">from ... import *</font> 导入的时候，是无法导入 c 的，因为 c 没有在 __all__ 中。但即便如此，我们也可以通过单独导入的方式，把 c 导入进来。只是不推荐这么做，像 PyCharm 也会提示：'c' is not declared in __all__。因为既然没有在 __all__ 里面，就证明这个变量是不希望被导入的，但是一般导入了也没关系。</p>
<h2 id="符号重命名"><a class="header" href="#符号重命名">符号重命名</a></h2>
<p>导入模块的时候一般为了解决符号冲突，往往会起别名，或者说符号重命名。比如包 a 和包 b 下面都有一个模块叫做 m，如果是 <font color="blue">from a import m</font> 和 <font color="blue">from b import m</font> 的话，那么两者就冲突了，后面的 m 会把前面的 m 覆盖掉，不然 Python 怎么知道要找哪一个 m 呢。</p>
<p>所以这个时候我们会起别名，比如 <font color="blue">from a import m as m1</font>、<font color="blue">from b import m as m2</font>。所以符号重命名是一种通过 as 关键字控制包、模块、变量暴露给 local 空间的方式，但是 <font color="blue">from a import *</font> 是不支持 as 的。</p>
<pre><code class="language-python">import sys
import test_import.a as a

print(a)  # &lt;module 'test_import.a' from 'D:\\satori\\test_import\\a.py'&gt; 
print(&quot;test_import.a&quot; in sys.modules)  # True
print(&quot;test_import&quot; in sys.modules)  # True
print(&quot;test_import&quot; in locals())  # False
</code></pre>
<p>到这里我相信就应该心里有数了，不管我们有没有 as，既然 import test_import.a，那么 sys.modules 里面就一定有 test_import.a 和 test_import。其实理论上有 test_import 就够了，但 a 是一个模块，为了避免多次导入所以也要加到 sys.modules 里面，由于 a 在 test_import 下面，因此 sys.modules 里面还会有一个 key 叫 &quot;test_import.a&quot;。</p>
<p>而 import test_import.a 后面还有个 as a，那么 a 这个符号就暴露在了当前模块的 local 空间里面，而且这个 a 跟之前的 test_import.a 一样，都指向了 test_import 包下面的 a 模块，无非是名字不同罢了。</p>
<p>当然这不是重点，之前 import test_import.a 的时候，会自动把 test_import 也加入到当前模块的 local 空间里面，也就是说通过 <font color="blue">import test_import.a</font> 是可以直接使用 test_import 的。但是当我们加上了 as 之后，发现 test_import 已经不能访问了。尽管都在 sys.modules 里面，但是对于加了 as 来说，此时的 test_import 已经不在 local 空间里面了。</p>
<h2 id="符号的销毁和重载"><a class="header" href="#符号的销毁和重载">符号的销毁和重载</a></h2>
<p>为了使用一个模块，无论是内置的还是自己写的，都需要先通过 import 动态加载。使用之后，我们也可能会删除，删除的原因一般是释放内存啊等等。而在 Python 中，删除一个变量可以使用 del 关键字，遇事不决 del。</p>
<pre><code class="language-python">l = [1, 2, 3]
d = {&quot;a&quot;: 1, &quot;b&quot;: 2}

del l[0]
del d[&quot;a&quot;]

print(l)  # [2, 3]
print(d)  # {'b': 2}


class A:

    def foo(self):
        pass

print(&quot;foo&quot; in dir(A))  # True
del A.foo
print(&quot;foo&quot; in dir(A))  # False
</code></pre>
<p>不光是列表、字典，好多东西 del 都能删除，当然这里的删除不是直接删掉了，而是将对象的引用计数减一。或者说<font color="blue">符号的销毁</font>和<font color="blue">符号关联的对象的销毁</font>不是一个概念，del 只能删除某个符号，无法删除一个具体的对象，比如 <font color="blue">del 123</font> 就是非法的。而 import 本质上也是创建一个变量，所以它同样可以被删除，至于变量指向的模块对象是否被删除，则看它的引用计数是否为 0。</p>
<p>因此 Python 向我们隐藏了太多的动作，也采取了太多的缓存策略，当然对于使用者来说是好事情，因为把复杂的特性隐藏起来了。但是当我们想彻底地了解 Python 的行为时，则必须要把这些隐藏的东西挖掘出来。</p>
<pre><code class="language-python">import sys
import test_import.a as a

# 对于模块来说，dir()、locals()、globals() 的 keys 是一致的
print(&quot;a&quot; in dir())  # True
del a
print(&quot;a&quot; in locals())  # False

print(id(sys.modules[&quot;test_import.a&quot;]))  # 1576944838432
import test_import.a as 我不叫a了
print(id(我不叫a了))  # 1576944838432
</code></pre>
<p>在 del 之后，a 这个符号确实从 local 空间消失了，或者说 dir 已经看不到了。但是我们发现，消失的仅仅是 a 这个符号，至于指向的 PyModuleObject 依旧在 sys.modules 里面岿然不动。然而，尽管它还存在于 Python 系统中，但程序再也无法感知到。所以此时 Python 就成功地隐藏了这一切，我们的程序认为： test_import.a 已经不存在了。</p>
<p>不过为什么 Python 要采用这种看上去类似<strong>模块池</strong>的缓存机制呢？答案很简单，因为组成一个完整系统的多个 .py 文件可能都要对某个 module 对象进行 import 动作。所以要是从 sys.modules 里面删除了，那么就意味着需要重新从文件里面读取，如果不删除，那么只需要将其从 sys.modules 里面暴露给当前的 local 空间即可。</p>
<p>所以 import 实际上并不等同于我们所说的动态加载，它的真实含义是希望某个模块被感知，也就是<font color="blue">将这个模块以某个符号的形式引入到某个名字空间</font>。这些都是同一个模块，如果 import 等同于动态加载，那么就等于 Python 对同一个模块执行多次导入，并且内存中保存一个模块的多个镜像，这显然是非常愚蠢的。</p>
<p>为此 Python 引入了全局的 module 对象集合 sys.modules 作为<strong>模块池</strong>，保存了模块的唯一值。当通过 import 声明希望感知到某个 module 对象时，虚拟机将在这个池子里面查找，如果被导入的模块已经存在于池子中，那么就引入一个符号到当前模块的名字空间中，并将其关联到导入的模块，使得被导入的模块可以透过这个符号被当前模块感知到。而如果被导入的模块不在池子里，Python 这才执行动态加载的动作。</p>
<p>不过这就产生了一个问题，这不等于说一个模块在被加载之后，就不能改变了吗？假如在加载了模块 a 之后，我们修改了模块 a，难道 Python 程序只能先暂停再重启，然后才能使用修改之后的模块 a 吗？显然不是这样的，Python 的动态特性不止于此，它提供了一种重新加载的机制，使用 importlib 模块，通过 <font color="blue">importlib.reload(module)</font>，可以实现重新加载。并且这个函数是有返回值的，会返回加载之后的模块。</p>
<pre><code class="language-python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.path.append(r&quot;D:\satori&quot;)
&gt;&gt;&gt;
&gt;&gt;&gt; from test_import import a
&gt;&gt;&gt; a.name  # 不存在 name 属性
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
AttributeError: module 'test_import.a' has no attribute 'name'
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; import importlib
# 增加一个赋值语句 name = &quot;古明地觉&quot;
&gt;&gt;&gt; a = importlib.reload(a)  
&gt;&gt;&gt; a.name
'古明地觉'
&gt;&gt;&gt;
# 将 name = &quot;古明地觉&quot; 语句删除
&gt;&gt;&gt; a = importlib.reload(a)  
&gt;&gt;&gt; a.name
'古明地觉'
&gt;&gt;&gt;
</code></pre>
<p>首先模块 test_import.a 里面没有 name 变量，但之后在 a.py 里面增加了 name，然后重新加载模块，发现 a.name 正常打印。接着在 a.py 里面再删除 name，然后重新加载，但我们看到 name 还在里面，还可以被访问。</p>
<p>那么根据这个现象我们是不是可以大胆猜测，Python 在 reload 一个模块的时候，只是将模块里面新的符号加载进来，而删除的则不管了。那么这个猜测到底正不正确呢，别急我们下一篇文章就来揭晓，并通过源码来剖析 import 的实现机制。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-67"><a class="header" href="#楔子-67">楔子</a></h2>
<p>通过上一篇的 import 黑盒探测，我们已经对 import 机制有了一个非常清晰的认识，Python 的 import 机制基本上可以分为三个不同的功能。</p>
<ul>
<li>Python 运行时的全局模块池的维护和搜索；</li>
<li>解析与搜索模块路径的树状结构；</li>
<li>对不同文件格式的模块执行动态加载机制；</li>
</ul>
<p>尽管 import 的表现形式千变万化，但是都可以归结为：<strong>import x.y.z</strong> 的形式，当然 <strong>import sys</strong> 也可以看成是 x.y.z 的一种特殊形式。而诸如 from、as 与 import 的结合，实际上同样会进行 <strong>import x.y.z</strong> 的动作，只是最后在当前名字空间中引入的符号各有不同。</p>
<h2 id="__import__"><a class="header" href="#__import__">__import__</a></h2>
<p>导入模块，虚拟机会调用 __import__，那么我们就来看看这个函数长什么样子。</p>
<pre><code class="language-C">// Python/bitinmodule.c
static PyObject *
builtin___import__(PyObject *self, PyObject *args, PyObject *kwds)
{
    static char *kwlist[] = {&quot;name&quot;, &quot;globals&quot;, &quot;locals&quot;, &quot;fromlist&quot;,
                             &quot;level&quot;, 0};
    PyObject *name, *globals = NULL, *locals = NULL, *fromlist = NULL;
    int level = 0;  // 默认绝对导入
    // 从 PyTupleObject 和 PyDictObject 中解析出需要的信息
    if (!PyArg_ParseTupleAndKeywords(args, kwds, &quot;U|OOOi:__import__&quot;,
                    kwlist, &amp;name, &amp;globals, &amp;locals, &amp;fromlist, &amp;level))
        return NULL;
    // 导入模块
    return PyImport_ImportModuleLevelObject(name, globals, locals,
                                            fromlist, level);
}
</code></pre>
<p>里面有一个 PyArg_ParseTupleAndKeywords 函数，我们需要提一下，它在虚拟机中是一个被广泛使用的函数，原型如下：</p>
<pre><code class="language-C">// Python/getargs.c
int PyArg_ParseTupleAndKeywords(PyObject *, PyObject *,
                                const char *, char **, ...);
</code></pre>
<p>这个函数的作用是解析参数，负责将 args 和 kwds 中所包含的所有对象（指针）按指定的 format 解析成各种目标对象，可以是 Python 的对象，例如 PyListObject、PyLongObject，也可以是 C 的原生对象。我们知道 builtin__import__ 里面的参数 args 指向一个 PyTupleObject ，包含了 __import__ 函数运行所需要的参数和信息，它是虚拟机在执行 IMPORT_NAME 指令的时候打包产生的。</p>
<p>然而在这里虚拟机进行了一个逆动作，将打包后的 PyTupleObject 拆开，重新获得当初的参数。Python 在自身的实现中大量使用了这样的打包、拆包策略，使得可变数量的对象能够很容易地在函数之间传递。</p>
<p>而在完成了对参数的拆包动作之后，会进入 PyImport_ImportModuleLevelObject ，这个我们在 import_name 中已经看到了，当然它内部也是调用了 __import__。</p>
<p>另外每个包和模块都有一个 __name__ 和 __path__ 属性。</p>
<pre><code class="language-Python">import six
import numpy as np
import numpy.core

print(np.__name__, np.__path__) 
&quot;&quot;&quot;
numpy ['C:\\python38\\lib\\site-packages\\numpy']
&quot;&quot;&quot;

print(np.core.__name__, np.core.__path__)
&quot;&quot;&quot;
numpy.core ['C:\\python38\\lib\\site-packages\\numpy\\core']
&quot;&quot;&quot;

print(six.__name__, six.__path__) 
&quot;&quot;&quot;
six []
&quot;&quot;&quot;
</code></pre>
<p>__name__ 就是模块名或者包名，如果是包下面的包或者模块，那么就是<strong>包名.包名</strong>或者<strong>包名.模块名</strong>。至于 __path__ 则是导入包内模块时会搜索的目录列表，对于模块而言， __path__ 为空列表。</p>
<p>此外还有一个 __file__ 属性，对于模块而言就是其自身的完整路径；对于包而言则分两种情况，如果包内部存在 __init__.py 文件，那么得到的就是 __init__.py 文件的完整路径，没有则为 None。</p>
<p>下面来看一下不同的导入方式对应的字节码，然后在虚拟机的层面来理解这些导入方式。</p>
<h2 id="单模块导入"><a class="header" href="#单模块导入">单模块导入</a></h2>
<p>以一个简单的模块导入为例：</p>
<pre><code class="language-python">import sys
&quot;&quot;&quot;
  0 LOAD_CONST               0 (0)
  2 LOAD_CONST               1 (None)
  4 IMPORT_NAME              0 (sys)
  6 STORE_NAME               0 (sys)
  8 LOAD_CONST               1 (None)
 10 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>这是一开始考察的例子，现在我们已经很清楚地了解了 IMPORT_NAME 的行为。在 IMPORT_NAME 指令的最后，虚拟机会将 PyModuleObject 对象（指针）压入运行时栈，随后会将 <font color="blue">&quot;sys&quot;: &lt;PyModuleObject *&gt;</font> 存放到当前的 local 名字空间中。</p>
<h2 id="级联导入"><a class="header" href="#级联导入">级联导入</a></h2>
<p>级联导入就是类似于 import a.b.c 这种导入方式。</p>
<pre><code class="language-Python">import sklearn.linear_model.ridge
&quot;&quot;&quot;
  0 LOAD_CONST               0 (0)
  2 LOAD_CONST               1 (None)
  4 IMPORT_NAME              0 (sklearn.linear_model.ridge)
  6 STORE_NAME               1 (sklearn)
  8 LOAD_CONST               1 (None)
 10 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>如果是级联导入，那么 IMPORT_NAME 的指令参数则是完整的路径信息，该指令的内部将解析这个路径，并为 sklearn、sklearn.linear_model、sklearn.linear_model.ridge 都创建一个 PyModuleObject 对象，这三者都存在于 sys.modules 里面。</p>
<p>但我们看到 STORE_NAME 是 sklearn，表示只有 sklearn 这个符号暴露在了当前模块的 local 空间里面。可为什么是 sklearn 呢？难道不应该是 sklearn.linear_model.ridge 吗？</p>
<p>其实经过之前的分析这一点已经不再是问题了，因为 <font color="blue">import sklearn.linear_model.ridge</font> 并不是说导入一个模块或包叫做 sklearn.linear_model.ridge，而是先导入 sklearn，然后把 linear_model 放在 sklearn 的属性字典里面，再把 ridge 放在 linear_model 的属性字典里面。</p>
<p>同理 sklearn.linear_model.ridge 代表的是先从 local 空间里面找到 sklearn，再从 sklearn 的属性字典中找到 linear_model，然后在 linear_model 的属性字典中找到 ridge。因为 linear_model 和 ridge 已经在相应的属性字典里面，我们通过 sklearn 一级一级往下找是可以找到的，因此只需要将符号 skearn 暴露给 local 空间即可。</p>
<p>或者说暴露 sklearn.linear_model.ridge 本身就是不合理的，因为这表示导入一个名字就叫做 sklearn.linear_model.ridge 的模块或者包，但显然不存在。而即便我们创建了这样的一个模块或包，但由于 Python 的语法解析规则依旧不会得到想要的结果。不然的话，假设 <font color="blue">import test_import.a</font>，那是导入名为 test_import.a 的模块或包呢？还是导入 test_import 下的 a 呢？</p>
<p>也正如我们之前分析的 test_import.a，在导入 test_import.a 的时候，会把 test_import 加载进来，然后把 a 加到 test_import 的属性字典里面，最后只需要把 test_import 返回即可。因为通过 test_import 可以找到 a，或者说 test_import.a 代表的含义就是从 test_import 的属性字典里面获取 a，所以 <font color="blue">import test_import.a</font> 必须要返回 test_import，而且只需返回 test_import。</p>
<p>至于 sys.modules 里面虽然存在字符串为 &quot;test_import.a&quot; 的 key，但这是为了避免重复加载所采取的策略，它依旧表示从 test_import 的属性字典里面获取 a。</p>
<pre><code class="language-Python">import pandas.core

print(pandas.DataFrame({&quot;a&quot;: [1, 2, 3]}))
&quot;&quot;&quot;
   a
0  1
1  2
2  3
&quot;&quot;&quot;
# 显然 pandas.DataFrame 是可以调用的
</code></pre>
<p>导入 pandas.core 会先导入 pandas，也就是执行 pandas 内部的 __init__ 文件。虽然 sys.modules 里面同时有 &quot;pandas&quot; 和 &quot;pandas.core&quot;，但是暴露在 local 空间的只有 pandas，所以调用 pandas.DataFrame 是完全合理的。至于 pandas.core 显然它无法暴露，因为这不符合 Python 的变量命名规范，变量的名称里面不能出现小数点，它只是单纯地表示从 pandas 的属性字典中加载 core。</p>
<h2 id="from--import"><a class="header" href="#from--import">from &amp; import</a></h2>
<p>基于 from &amp; import 可以实现精确导入，看一下字节码。</p>
<pre><code class="language-python">from sklearn.linear_model import ridge
&quot;&quot;&quot;
  0 LOAD_CONST               0 (0)
  2 LOAD_CONST               1 (('ridge',))
  4 IMPORT_NAME              0 (sklearn.linear_model)
  6 IMPORT_FROM              1 (ridge)
  8 STORE_NAME               1 (ridge)
 10 POP_TOP
 12 LOAD_CONST               2 (None)
 14 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>注意此时的 2 LOAD_CONST 不再是 None 了，而是一个元组，虚拟机将 ridge 放到了当前模块的 local 空间中。并且 sklearn.linear_model 和 sklearn 都被导入了，存在 sys.modules 里面。</p>
<p>但是 sklearn 却并不在当前的 local 空间中，尽管它被创建了，但是又被隐藏了。IMPORT_NAME 的指令参数是 sklearn.linear_model，也表示导入 sklearn，然后把 sklearn 下面的 linear_model 加入到 sklearn 的属性字典里面。</p>
<p>而之所以 sklearn 没在 local 空间里面，可以这样理解。当只出现 import 的时候，由于必须从头开始一级一级向下调用，所以顶层的包必须加入到 local 空间里面。但这里通过 <font color="blue">from ... import ...</font> 把 ridge 导出了，此时 ridge 已经指向了 sklearn 下面的 linear_model 下面的 ridge，那么就不需要 sklearn 了，或者说 sklearn 就没必要暴露在 local 空间里面了，但它确实被导入进来了。</p>
<p>并且 sys.modules 里面也不存在 &quot;ridge&quot; 这个key，存在的是 &quot;sklearn.linear_model.ridge&quot;，暴露给 local 空间的符号是 ridge。所以正如上面所说，不管什么导入，都可以归结为 <font color="blue">import x.y.z</font> 的形式，只是暴露出来的符号不同罢了。</p>
<h2 id="import--as"><a class="header" href="#import--as">import &amp; as</a></h2>
<p>通过 import &amp; as 可以在导入的时候给模块起一个别名。</p>
<pre><code class="language-Python">import sklearn.linear_model.ridge as xxx
&quot;&quot;&quot;
  0 LOAD_CONST               0 (0)
  2 LOAD_CONST               1 (None)
  4 IMPORT_NAME              0 (sklearn.linear_model.ridge)
  6 IMPORT_FROM              1 (linear_model)
  8 ROT_TWO
 10 POP_TOP
 12 IMPORT_FROM              2 (ridge)
 14 STORE_NAME               3 (xxx)
 16 POP_TOP
 18 LOAD_CONST               1 (None)
 20 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>这个和上面的 from &amp; import 类似，&quot;sklearn&quot;、&quot;sklearn.linear_model&quot;、&quot;sklearn.linear_model.ridge&quot; 都在 sys.modules 里面。但是我们加上了 as xxx，那么这个 xxx 就直接指向了 sklearn 下面的 linear_model 下面的 ridge，此时就不需要 sklearn 了。</p>
<p>因此只有 xxx 暴露在了当前模块的 local 空间里面，而 sklearn 虽然也被导入了，但它只在 sys.modules 里面，没有暴露给当前模块的 local 空间。</p>
<h2 id="from--import--as"><a class="header" href="#from--import--as">from &amp; import &amp; as</a></h2>
<p>通过 from &amp; import &amp; as 可以在精确导入的同时起别名。</p>
<pre><code class="language-Python">from sklearn.linear_model import ridge as xxx
&quot;&quot;&quot;
  0 LOAD_CONST               0 (0)
  2 LOAD_CONST               1 (('ridge',))
  4 IMPORT_NAME              0 (sklearn.linear_model)
  6 IMPORT_FROM              1 (ridge)
  8 STORE_NAME               2 (xxx)
 10 POP_TOP
 12 LOAD_CONST               2 (None)
 14 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>这个和之前的 from &amp; import 一样，只是最后暴露给 local 空间的 ridge 变成了我们指定的 xxx。</p>
<h2 id="与-module-对象有关的名字空间问题"><a class="header" href="#与-module-对象有关的名字空间问题">与 module 对象有关的名字空间问题</a></h2>
<p>同函数、类一样，每个 PyModuleObject 也有自己的名字空间。一个模块不能直接访问另一个模块的内容，尽管模块内部的作用域比较复杂，比如 LEGB 规则，但是模块与模块之间的划分则是很明显的。</p>
<pre><code class="language-python"># test.py
name = &quot;古明地觉&quot;

def print_name():
    return name
  
# main.py
from test import name, print_name
name = &quot;古明地恋&quot;
print(print_name())  # 古明地觉  
</code></pre>
<p>执行 main.py 之后，发现打印的依旧是&quot;古明地觉&quot;。我们说 Python 是根据 LEGB 规则进行查找，而 print_name 函数里面没有 name，那么去外层找。可 main.py 里面的 name 是&quot;古明地恋&quot;，但打印的依旧是 test.py 里面的&quot;古明地觉&quot;。为什么？</p>
<p>还是那句话，模块与模块之间的作用域划分地非常明显，print_name 是 test.py 里面的函数，所以在返回 name 的时候，只会从 test.py 中搜索，无论如何都不会跳过 test.py、跑到 main.py 里面。</p>
<p>再来看个例子：</p>
<pre><code class="language-Python"># test.py
name = &quot;古明地觉&quot;
nicknames = [&quot;小五&quot;, &quot;少女觉&quot;]

# main.py
import test
test.name = &quot;❤古明地觉❤&quot;
test.nicknames = [&quot;觉大人&quot;]

from test import name, nicknames
print(name)  # ❤古明地觉❤
print(nicknames)  # ['觉大人']
</code></pre>
<p>此时打印的结果变了，很简单，这里是直接把 test.py 里面的变量修改了。因为这种方式，相当于直接修改 test.py 的属性字典。那么后续再导入的时候，打印的就是修改之后的值。</p>
<pre><code class="language-python"># test.py
name = &quot;古明地觉&quot;
nicknames = [&quot;小五&quot;, &quot;少女觉&quot;]

# main.py
from test import name, nicknames
name = &quot;古明地恋&quot;
nicknames.remove(&quot;小五&quot;)

from test import name, nicknames
print(name)  # 古明地觉
print(nicknames)  # [&quot;少女觉&quot;]
</code></pre>
<p>如果是 from test import name, nicknames，那么相当于在当前的 local 空间中新创建变量 name 和 nicknames，它们和 test.py 中的 name 和 nicknames 指向相同的对象。</p>
<p>而 name = &quot;古明地觉&quot; 相当于重新赋值了，所以不会影响 test.py 里的 name。而 nicknames.remove 则是在本地进行修改，所以会产生影响。</p>
<h2 id="模块的-reload-问题"><a class="header" href="#模块的-reload-问题">模块的 reload 问题</a></h2>
<p>在上一篇文章中我们说到，如果模块在导入之后，源文件被修改了，那么可以通过 importlib.reload 更新模块。但 reload 的行为和我们想的不太一样，reload 会重新执行模块的代码，但是它会<font color="blue">重用同一个模块对象</font>，而不是创建新的。</p>
<pre><code class="language-Python"># test.py
print(&quot;模块被加载&quot;)
x = 1
</code></pre>
<p>我们来导入 test.py 测试一下。</p>
<pre><code class="language-Python">&gt;&gt;&gt; import test
模块被加载
&gt;&gt;&gt; id(test)  # 记录模块对象的 id
140712834927872
&gt;&gt;&gt; test.x
1
&gt;&gt;&gt; test.y = 2  # 手动添加一个属性（但源文件里面是没有 y = 2 的）
&gt;&gt;&gt;
# 修改 test.py，将 x = 1 改成 x = 11
&gt;&gt;&gt; import importlib
&gt;&gt;&gt; test = importlib.reload(test)
模块被加载
&gt;&gt;&gt; id(test)  # reload 后是同一个对象
140712834927872
&gt;&gt;&gt; test.x  # 模块中定义的变量被更新了
11
&gt;&gt;&gt; test.y  # 手动添加的属性仍然存在
2
</code></pre>
<p>所以 reload 不会创建新的模块对象，它会重新执行模块代码，更新模块的 __dict__，但不会清除模块对象中已存在的属性。如果我们真的想完全重新加载一个模块（包括删除旧属性），需要先将模块从 sys.modules 中删掉，然后重新 import。</p>
<pre><code class="language-Python">&gt;&gt;&gt; import sys
&gt;&gt;&gt; del sys.modules['test']
&gt;&gt;&gt; import test  # 完全重新加载
模块被加载
&gt;&gt;&gt; test.y  # 之前手动添加的属性不存在了
AttributeError: module 'test' has no attribute 'y'
</code></pre>
<p>这种设计保持了模块级别的状态，可以避免破坏其它持有该模块引用的代码，但可能导致&quot;幽灵属性&quot;存在。所以实际开发中如果需要完全重新加载一个模块，最好使用删除 sys.modules[&quot;xxx&quot;] 的方式，而不是依赖 reload。当然啦，重新加载模块这个需求本身就不常见，大家了解一下就好。</p>
<h2 id="小结-65"><a class="header" href="#小结-65">小结</a></h2>
<p>以上就是模块（包）相关的内容，虽然一个项目可以有很多个文件，但是每个文件的执行原理是一致的。无论一个文件是作为模块被导入，还是直接作为启动文件被执行，虚拟机的执行流程都没有变化。</p>
<p>通过模块和包，我们便可以对项目进行功能上的划分，从而更好地组织项目。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-68"><a class="header" href="#楔子-68">楔子</a></h2>
<p>我们之前完成了 Python 的字节码、以及虚拟机的剖析工作，但这仅仅只是一部分，而其余的部分则被遮在了幕后。记得在分析虚拟机的时候，曾这么说过：</p>
<blockquote>
<p>解释器启动时，首先会进行 &quot;运行时环境&quot; 的初始化，关于 &quot;运行时环境&quot; 的初始化是一个非常复杂的过程。并且 &quot;运行时环境&quot; 和 &quot;执行环境&quot; 是不同的，&quot;运行时环境&quot; 是一个全局的概念，而 &quot;执行环境&quot; 是一个栈帧。关于 &quot;运行时环境&quot; 后面会单独分析，这里就假设初始化动作已经完成，我们已经站在了虚拟机的门槛外面，只需要轻轻推动第一张骨牌，整个执行过程就会像多米诺骨牌一样，一环扣一环地展开。</p>
</blockquote>
<p>所以这次，我们将回到时间的起点，从 Python 的应用程序被执行开始，一步一步紧紧跟随 Python 的轨迹，完整地展示解释器在启动之初的所有动作。当我们了解所有的初始化动作之后，也就能对 Python 引擎执行字节码指令时的整个运行环境了如指掌了。</p>
<h2 id="线程模型"><a class="header" href="#线程模型">线程模型</a></h2>
<p>我们知道线程是操作系统调度的最小单元，那么 Python 的线程又是怎样的呢？</p>
<p>启动一个 Python 线程，底层会启动一个 C 线程，然后启动操作系统的一个原生线程（OS 线程）。所以 Python 线程实际上是对 OS 线程的一个封装，因此 Python 的线程是货真价实的。</p>
<p>然后 Python 还提供了一个 PyThreadState 对象，也就是线程状态对象，维护 OS 线程执行的状态信息，相当于是 OS 线程的一个抽象描述。虽然真正用来执行的线程及其状态肯定是由操作系统进行维护的，但 Python 虚拟机在运行的时候总需要另外一些与线程相关的状态和信息，比如是否发生了异常等等，这些信息显然操作系统是没有办法提供的。</p>
<p>而 PyThreadState 对象正是为 OS 线程准备的、在虚拟机层面保存其状态信息的对象，也就是线程状态对象。在 Python 中，当前活动的 OS 线程对应的 PyThreadState 对象可以通过调用 PyThreadState_GET 函数获得，有了线程状态对象之后，就可以设置一些额外信息了。具体内容，我们后面会说。</p>
<p>当然除了线程状态对象之外，还有进程状态对象，我们来看看两者在底层的定义是什么？它们位于 Include/pystate.h 中。</p>
<pre><code class="language-c">// ts 是 thread state 的简写
typedef struct _ts PyThreadState;
// is 是 interpreter state 的简写
typedef struct _is PyInterpreterState;
</code></pre>
<p>里面的 PyThreadState 表示线程状态对象，PyInterpreterState 表示进程状态对象，但它们都是 typedef 起的一个别名。前者是 struct _ts 的别名，后者是 struct _is 的别名，来看一下它们长什么样。</p>
<pre><code class="language-C">// Include/cpython/pystate.h

// Python 的异常信息有三个属性
// exc_type：异常类型；exc_value：异常值，说白了就是异常本身；exc_traceback：异常的回溯栈
// 而 _PyErr_StackItem 相当于对这三个属性做了封装，并且还通过 previous_item 形成了一个链表
typedef struct _err_stackitem {
    PyObject *exc_type, *exc_value, *exc_traceback;
    struct _err_stackitem *previous_item;
} _PyErr_StackItem;

struct _ts {
    // 指向上一个线程状态对象
    struct _ts *prev;
    // 指向下一个线程状态对象    
    struct _ts *next;
    // 进程状态对象，因为每个线程都隶属于一个进程
    PyInterpreterState *interp;
    // 当前正在执行的栈桢
    struct _frame *frame;
    // 递归深度
    int recursion_depth;
    // 标记栈是否溢出，如果溢出，还允许 50 次调用来处理运行时错误
    char overflowed;
    // 标记当前调用不能导致栈溢出的标志位
    char recursion_critical;
    // 栈检查计数器
    int stackcheck_counter;
    // 追踪和性能分析时的执行深度计数器
    int tracing;
    // 是否启用追踪
    int use_tracing;
    // C 级性能分析的函数指针
    Py_tracefunc c_profilefunc;
    // C 级追踪函数指针
    Py_tracefunc c_tracefunc;
    // Python 级性能分析对象
    PyObject *c_profileobj;
    // Python 级追踪对象
    PyObject *c_traceobj;
    // 当前抛出的异常信息
    PyObject *curexc_type;
    PyObject *curexc_value;
    PyObject *curexc_traceback;
    // 当前正在处理的异常状态（如果没有协程/生成器）
    _PyErr_StackItem exc_state;
    // 指向当前正在处理的异常栈的栈顶
    // 估计有人好奇 exc_state 和 exc_info 啥区别，我们稍后说
    _PyErr_StackItem *exc_info;
    // 存储线程状态信息的字典
    PyObject *dict;
    // GIL 状态计数器
    int gilstate_counter;
    // 待抛出的异步异常
    PyObject *async_exc;
    // 创建该线程状态对象的线程 ID
    unsigned long thread_id;
    // 嵌套层级，用于延迟删除
    int trash_delete_nesting;
    // 延迟删除的对象，关于延迟删除，我们介绍列表的时候说过
    PyObject *trash_delete_later;
    // 线程状态正常删除时的回调函数
    void (*on_delete)(void *);
    // 回调函数的数据参数（实现为一个指向锁的弱引用）
    void *on_delete_data;
    // 协程起源追踪深度
    int coroutine_origin_tracking_depth;
    // 当异步生成器首次迭代时，用于存储相关状态和处理异常
    PyObject *async_gen_firstiter;
    // 当异步生成器被垃圾回收时，用于执行必要的清理工作
    PyObject *async_gen_finalizer;
    // 上下文对象
    PyObject *context;
    // 上下文版本号
    uint64_t context_ver;
    // 线程状态对象的唯一标识符
    uint64_t id;
};
</code></pre>
<p>以上是线程状态对象，然后我们再来看看进程状态对象。需要补充的是，struct _is、或者说 PyInterpreterState 在严格意义上应该叫做解释器状态对象。我们知道当解释器启动后会创建一个进程，但这两者并不是一对一的，因为 CPython 支持多解释器模式。也就是说可以在一个进程中启动多个解释器，这种模式一般应用在嵌入式 Python 或需要隔离环境的情况。</p>
<p>但是多解释器模式只能通过手动调用 Python/C API 实现，Python 代码层面无法直接创建和管理多个解释器，所以默认一个进程只会对应一个解释器实例。因此为了和线程对应，我们这里称 PyInterpreterState 为进程状态对象。</p>
<pre><code class="language-c">// Include/internal/pycore_pystate.h

struct _is {
    // Python 支持多进程，多个进程状态对象也会以链表的形式进行组织
    // next 字段会指向下一个进程状态对象
    struct _is *next;
    // 每个进程内部可以有很多个线程，那么自然就会有很多个线程状态对象
    // 这些线程状态对象会以链表的形式串起来，而 tstate_head 指向链表的头节点
    struct _ts *tstate_head;
    // 进程状态对象的 ID
    int64_t id;
    // 进程状态对象的引用计数
    int64_t id_refcount;
    // 指示解释器是否需要引用计数跟踪
    // 当多个子解释器共享同一个 ID 时，此标志用于确保 ID 的正确管理和清理
    int requires_idref;
    // ID 相关的互斥锁
    PyThread_type_lock id_mutex;
    // 终止标志
    int finalizing;
    // sys.modules，所以可以看出，多个线程共用一个 sys.modules
    PyObject *modules;
    // 按模块索引存储的缓存，它允许通过数字索引快速访问模块
    // 而不是每次都通过模块名在 modules 字典中查找，提高了模块访问性能
    PyObject *modules_by_index;
    // sys 模块的属性字典
    PyObject *sysdict;
    // 内置名称空间
    PyObject *builtins;
    // 导入机制
    PyObject *importlib;
    // 线程切换检查间隔
    int check_interval;
    // 进程内部的线程数量
    long num_threads;
    // 线程栈大小
    size_t pythread_stacksize;
    // 编解码器搜索路径
    PyObject *codec_search_path;
    // 编解码器缓存
    PyObject *codec_search_cache;
    // 存储自定义的编解码错误处理器
    // 允许通过 codecs.register_error() 注册新的错误处理策略，用于处理编解码过程中遇到的错误
    PyObject *codec_error_registry;
    // 表示编解码系统是否已经完成初始化，为 1 时表示已初始化，0 表示未初始化
    int codecs_initialized;
    // 文件系统编码设置
    struct {
        char *encoding;   /* Filesystem encoding (encoded to UTF-8) */
        char *errors;     /* Filesystem errors (encoded to UTF-8) */
        _Py_error_handler error_handler;
    } fs_codec;
    // 解释器的配置参数结构体
    // 包含：路径设置、命令行参数、环境变量设置、编码设置、性能和调试选项、内存分配器设置、隔离选项等
    PyConfig config;
    // 控制动态库加载行为的标志位，用于 dlopen() 函数调用
    // 这个标志决定了动态库加载时的符号解析策略和可见性
#ifdef HAVE_DLOPEN
    int dlopenflags;
#endif
    // 存储进程状态信息的字典
    PyObject *dict;
    // 内置名字空间的备份副本，用于在必要时恢复到内置名字空间的默认状态
    // 这是一个安全措施，防止内置名字空间被意外修改。
    PyObject *builtins_copy;
    // 存储当前解释器使用的导入函数，通常是 __import__ 函数
    // 因此解释器也允许自定义模块导入行为，用于实现特殊的导入逻辑
    PyObject *import_func;
    // 帧评估函数，默认是 _PyEval_EvalFrameDefault
    // 所以解释器也支持自定义帧评估函数，即自定义字节码执行逻辑
    _PyFrameEvalFunction eval_frame;
        Py_ssize_t co_extra_user_count;
    freefunc co_extra_freefuncs[MAX_CO_EXTRA_USERS];

#ifdef HAVE_FORK
    PyObject *before_forkers;
    PyObject *after_forkers_parent;
    PyObject *after_forkers_child;
#endif
    /* AtExit module */
    void (*pyexitfunc)(PyObject *);
    PyObject *pyexitmodule;

    uint64_t tstate_next_unique_id;

    struct _warnings_runtime_state warnings;

    PyObject *audit_hooks;
};
</code></pre>
<p>所以 PyInterpreterState 对象可以看成是对进程的模拟， PyThreadState 对象可以看成是对线程的模拟。我们之前分析虚拟机的时候说过执行环境，如果再将运行时环境加进去的话。</p>
<p><img src="./images/276.png" alt="" /></p>
<p>进程状态对象的 tstate_head 指向了线程状态对象，对应当前活跃的 Python 线程；而每个线程状态对象的 frame 都指向当前正在执行的栈帧对象。</p>
<h2 id="线程环境的初始化"><a class="header" href="#线程环境的初始化">线程环境的初始化</a></h2>
<p>在解释器启动之后，初始化的动作是从 Py_NewInterpreter 函数开始的，然后这个函数调用了 new_interpreter 函数完成初始化。至于这两个函数长什么样一会儿再聊，先往后看。</p>
<p>我们知道当操作系统在运行一个可执行文件时，首先会创建一个进程内核。同理在 Python 中亦是如此，会在 new_interpreter 中调用 PyInterpreterState_New 创建一个崭新的 PyInterpreterState 对象，该函数位于 Python/pystate.c 中。</p>
<pre><code class="language-C">PyInterpreterState *
PyInterpreterState_New(void)
{
    // 触发审计事件
    if (PySys_Audit(&quot;cpython.PyInterpreterState_New&quot;, NULL) &lt; 0) {
        return NULL;
    }
    // 为进程状态对象分配内存
    PyInterpreterState *interp = PyMem_RawMalloc(sizeof(PyInterpreterState));
    if (interp == NULL) {
        return NULL;
    }
    // 初始化内存
    memset(interp, 0, sizeof(*interp));
    interp-&gt;id_refcount = -1;
    // 每个线程执行 100 条字节码后进行切换
    interp-&gt;check_interval = 100;
    // 初始化 Python 配置
    PyConfig_InitPythonConfig(&amp;interp-&gt;config);
    // 设置帧评估函数，默认为 _PyEval_EvalFrameDefault
    interp-&gt;eval_frame = _PyEval_EvalFrameDefault;
    // 设置动态库加载标志
#ifdef HAVE_DLOPEN
#if HAVE_DECL_RTLD_NOW
    interp-&gt;dlopenflags = RTLD_NOW;
#else
    interp-&gt;dlopenflags = RTLD_LAZY;
#endif
#endif
    // _PyRuntimeState 是 Python 解释器的全局运行时状态结构体，管理以下内容
    // GIL 锁相关的状态、解释器链表、垃圾回收系统状态、核心模块和类型
    // 信号处理、内存分配器、线程状态追踪、全局审计钩子等
    // 注：每个进程只有一个全局运行时（_PyRuntime），它是最高级的运行时状态容器
    _PyRuntimeState *runtime = &amp;_PyRuntime;
    // struct pyinterpreters 内部有四个字段
    // PyThread_type_lock mutex：互斥锁
    // PyInterpreterState *head：进程状态对象的头结点
    // PyInterpreterState *main：主进程对应的进程状态对象
    // int64_t next_id：下一个可用的解释器 ID，注意：主解释器 ID、或者说主进程状态对象的 ID 永远是 0
    struct pyinterpreters *interpreters = &amp;runtime-&gt;interpreters;
    
    // 获取全局解释器锁，用于保护解释器链表的操作
    // 它确保在多线程环境下，解释器的创建和管理是线程安全的
    HEAD_LOCK(runtime);
    // next_id 必须大于等于 0
    if (interpreters-&gt;next_id &lt; 0) {
        PyErr_SetString(PyExc_RuntimeError,
                        &quot;failed to get an interpreter ID&quot;);
        PyMem_RawFree(interp);
        interp = NULL;
    }
    else {
        // 分配新 ID 并更新 next_id
        interp-&gt;id = interpreters-&gt;next_id;
        interpreters-&gt;next_id += 1;
        // 让新创建的进程状态对象 interp，成为进程状态对象链表的头结点
        // 所以它的 next 要等于 interpreters-&gt;head
        interp-&gt;next = interpreters-&gt;head;
        // 如果 interpreters-&gt;main 等于 NULL，说明当前的进程是第一个进程
        // 那么显然它就是主进程，而之后创建的进程就是子进程了
        if (interpreters-&gt;main == NULL) {
            interpreters-&gt;main = interp;
        }
        // 然后再让 interpreters-&gt;head 等于 interp
        interpreters-&gt;head = interp;
    }
    HEAD_UNLOCK(runtime);

    if (interp == NULL) {
        return NULL;
    }

    interp-&gt;tstate_next_unique_id = 0;
    interp-&gt;audit_hooks = NULL;
    return interp;
}
</code></pre>
<p>所以解释器在启动时，会创建一个 PyInterpreterState 对象。如果开启了多进程，那么内部会继续创建，然后通过 next 指针将多个 PyInterpreterState 串成一个链表结构。</p>
<p>在调用 PyInterpreterState_New 成功创建 PyInterpreterState 之后，会再接再厉，调用 PyThreadState_New 创建一个全新的线程状态对象，相关函数定义同样位于 Python/pystate.c 中。</p>
<pre><code class="language-C">PyThreadState *
PyThreadState_New(PyInterpreterState *interp)
{
    return new_threadstate(interp, 1);
}
</code></pre>
<p>我们注意到这个函数接收一个 PyInterpreterState，这说明线程是依赖进程的，因为需要进程给自己分配资源，然后这个函数又调用了 new_threadstate。除了传递 PyInterpreterState 之外，还传了一个 1，想也不用想这肯定是创建的线程数量。这里创建 1 个，也就是主线程（main thread）。</p>
<pre><code class="language-C">static PyThreadState *
new_threadstate(PyInterpreterState *interp, int init)
{
    _PyRuntimeState *runtime = &amp;_PyRuntime;
    // 为线程状态对象申请内存
    PyThreadState *tstate = (PyThreadState *)PyMem_RawMalloc(sizeof(PyThreadState));
    if (tstate == NULL) {
        return NULL;
    }
    // 设置从线程中获取函数调用栈的操作
    if (_PyThreadState_GetFrame == NULL) {
        _PyThreadState_GetFrame = threadstate_getframe;
    }
    // 下面就是设置内部的字段属性
    // 该线程所在的进程
    tstate-&gt;interp = interp;
    // 当前正在执行的栈桢，初始为 NULL
    tstate-&gt;frame = NULL;
    // 递归深度，初始为 0
    tstate-&gt;recursion_depth = 0;
    tstate-&gt;overflowed = 0;
    tstate-&gt;recursion_critical = 0;
    tstate-&gt;stackcheck_counter = 0;
    tstate-&gt;tracing = 0;
    tstate-&gt;use_tracing = 0;
    tstate-&gt;gilstate_counter = 0;
    tstate-&gt;async_exc = NULL;
    tstate-&gt;thread_id = PyThread_get_thread_ident();

    tstate-&gt;dict = NULL;

    tstate-&gt;curexc_type = NULL;
    tstate-&gt;curexc_value = NULL;
    tstate-&gt;curexc_traceback = NULL;

    tstate-&gt;exc_state.exc_type = NULL;
    tstate-&gt;exc_state.exc_value = NULL;
    tstate-&gt;exc_state.exc_traceback = NULL;
    tstate-&gt;exc_state.previous_item = NULL;
    tstate-&gt;exc_info = &amp;tstate-&gt;exc_state;

    tstate-&gt;c_profilefunc = NULL;
    tstate-&gt;c_tracefunc = NULL;
    tstate-&gt;c_profileobj = NULL;
    tstate-&gt;c_traceobj = NULL;

    tstate-&gt;trash_delete_nesting = 0;
    tstate-&gt;trash_delete_later = NULL;
    tstate-&gt;on_delete = NULL;
    tstate-&gt;on_delete_data = NULL;

    tstate-&gt;coroutine_origin_tracking_depth = 0;

    tstate-&gt;async_gen_firstiter = NULL;
    tstate-&gt;async_gen_finalizer = NULL;

    tstate-&gt;context = NULL;
    tstate-&gt;context_ver = 1;

    if (init) {
        _PyThreadState_Init(runtime, tstate);
    }

    HEAD_LOCK(runtime);
    tstate-&gt;id = ++interp-&gt;tstate_next_unique_id;
    tstate-&gt;prev = NULL;
    // 当前线程状态对象的 next，我们看到指向了线程状态对象链表的头结点
    tstate-&gt;next = interp-&gt;tstate_head;
    // 因为每个线程状态对象的 prev 指针都要指向上一个线程状态对象
    // 如果是头结点的话，那么 prev 就是 NULL
    // 但由于新的线程状态对象在插入之后变成了链表的新的头结点
    // 因此还需要将插入之前的头结点的 prev 指向新插入的线程状态对象
    if (tstate-&gt;next)
        tstate-&gt;next-&gt;prev = tstate;
    // 将 tstate 设置为线程状态对象链表的新的头结点
    interp-&gt;tstate_head = tstate;
    HEAD_UNLOCK(runtime);
    // 返回线程状态对象
    return tstate;
}
</code></pre>
<p>和 PyInterpreterState_New 相同， PyThreadState_New 会申请内存，创建线程状态对象，并且对每个字段进行初始化。其中 prev 指针和 next 指针分别指向了上一个线程状态对象和下一个线程状态对象。而且也肯定会存在某一时刻，会有多个 PyThreadState 对象组成一个链表，那什么时刻会发生这种情况呢？显然用鼻子想也知道这是在启动多线程的时候。</p>
<blockquote>
<p>Python 在插入线程状态对象的时候采用的是头插法。</p>
</blockquote>
<p>从源码中我们看到，虚拟机设置了从线程中获取函数调用栈的操作，所谓函数调用栈就是前面说的 PyFrameObject 对象链表。而且在源码中，PyThreadState 关联了 PyInterpreterState，PyInterpreterState 也关联了 PyInterpreterState 。</p>
<p>到目前为止，仅有的两个对象建立起了联系。而对应到操作系统，就是进程和线程建立了联系。</p>
<p>而在两者建立了联系之后，那么就很容易在 PyInterpreterState 和 PyThreadState 之间穿梭。并且在 Python 运行时环境中，会有一个变量（先卖个关子）一直维护着当前活动的线程，更准确的说是当前活动线程（OS 线程）对应的 PyThreadState 对象。初始时，该变量为 NULL，在 Python 启动并创建了第一个 PyThreadState 之后，会调用 PyThreadState_Swap 函数来设置这个变量。</p>
<pre><code class="language-C">// Python/pystate.c
PyThreadState *
PyThreadState_Swap(PyThreadState *newts)
{
    // 调用了 _PyThreadState_Swap，里面传入了两个参数
    // 第一个我们后面说，从名字上看显然这是和 GIL 相关的
    // 第二个参数就是新创建的线程状态对象
    return _PyThreadState_Swap(&amp;_PyRuntime.gilstate, newts);
}

PyThreadState *
_PyThreadState_Swap(struct _gilstate_runtime_state *gilstate, PyThreadState *newts)
{
    // 获取当前的线程状态对象，并且保证线程的安全
    PyThreadState *oldts = _PyRuntimeGILState_GetThreadState(gilstate);
    // 将 GIL 交给 newts，也就是新创建、即将获取执行权的线程状态对象
    _PyRuntimeGILState_SetThreadState(gilstate, newts);
    // ...
    return oldts;
}
</code></pre>
<p>所以逻辑很容易理解，有一个<strong>变量</strong>始终维护着当前活跃线程对应的线程状态对象，初始时它是个 NULL。而一旦解释器启动，并创建了第一个线程状态对象（显然对应主线程），那么就会将创建的线程状态对象交给这个<strong>变量</strong>保存。</p>
<p>如果调用 _PyThreadState_Swap 的时候，发现保存线程状态对象的<strong>变量</strong>不为 NULL，那么说明开启了多线程。<strong>变量</strong>保存的就是代码中的 oldts，也就是当前活动线程对应的线程状态对象，可由于它的时间片耗尽，解释器会剥夺它的执行权，然后交给 newts。那么 newts 就成为了新的当前活跃线程对应的线程状态对象，那么它也要交给<strong>变量</strong>进行保存。</p>
<p>而通过 _PyThreadState_Swap 可以看到，想要实现这一点，主要依赖两个宏。</p>
<pre><code class="language-c">// 通过 &amp;(gilstate)-&gt;tstate_current 获取当前活动线程（的线程状态对象）
#define _PyRuntimeGILState_GetThreadState(gilstate) \
    ((PyThreadState*)_Py_atomic_load_relaxed(&amp;(gilstate)-&gt;tstate_current))

// 将 newts 设置为新的活跃线程，可以理解为发生了线程切换
#define _PyRuntimeGILState_SetThreadState(gilstate, value) \
    _Py_atomic_store_relaxed(&amp;(gilstate)-&gt;tstate_current, \
                             (uintptr_t)(value))
</code></pre>
<p>然后这两个宏里面出现了 _Py_atomic_load_relaxed、_Py_atomic_store_relaxed 和 &amp;(gilstate)-&gt;tstate_current ，这些又是什么呢？还有到底是哪个变量在维护着当前活动线程对应的线程状态对象呢？其实那两个宏已经告诉你了。</p>
<pre><code class="language-C">//Include/internal/pycore_pystate.h
struct _gilstate_runtime_state {
    // GIL 检查是否启用
    int check_enabled;
    // 持有 GIL 的活动线程对应的线程状态对象
    _Py_atomic_address tstate_current;
    // 函数指针，用于获取栈桢
    PyThreadFrameGetter getframe;
    PyInterpreterState *autoInterpreterState;
    Py_tss_t autoTSSkey;
};

//Include/internal/pycore_atomic.h
#define _Py_atomic_store_relaxed(ATOMIC_VAL, NEW_VAL) \
    _Py_atomic_store_explicit((ATOMIC_VAL), (NEW_VAL), _Py_memory_order_relaxed)
#define _Py_atomic_load_relaxed(ATOMIC_VAL) \
    _Py_atomic_load_explicit((ATOMIC_VAL), _Py_memory_order_relaxed)

#define _Py_atomic_store_explicit(ATOMIC_VAL, NEW_VAL, ORDER) \
    atomic_store_explicit(&amp;((ATOMIC_VAL)-&gt;_value), NEW_VAL, ORDER)
#define _Py_atomic_load_explicit(ATOMIC_VAL, ORDER) \
    atomic_load_explicit(&amp;((ATOMIC_VAL)-&gt;_value), ORDER)
</code></pre>
<p>不难发现：</p>
<ul>
<li>_Py_atomic_load_relaxed 调用了 _Py_atomic_load_explicit，_Py_atomic_load_explicit 又调用了 atomic_load_explicit。</li>
<li>_Py_atomic_store_relaxed 调用了 _Py_atomic_store_explicit，_Py_atomic_store_explicit 调用了 atomic_store_explicit。</li>
</ul>
<p>而 atomic_load_explicit 和 atomic_store_explicit 是系统头文件 stdatomic.h 中定义的 api，这是在系统的 api 中修改的，所以说是线程安全的。</p>
<p>介绍完中间部分的内容，那么我们可以从头开始分析 Python 运行时环境的初始化了，我们说它是从 Py_NewInterpreter 开始的。</p>
<pre><code class="language-C">// Python/pylifecycle.c
PyThreadState *
Py_NewInterpreter(void)
{   
    // 线程状态对象
    PyThreadState *tstate = NULL;
    // 传入线程状态对象，调用 new_interpreter
    PyStatus status = new_interpreter(&amp;tstate);
    if (_PyStatus_EXCEPTION(status)) {
        Py_ExitStatusException(status);
    }
    // 返回线程状态对象
    return tstate;
}
</code></pre>
<p>然后我们的重点是 new_interpreter 函数，进程状态对象的创建就是在这个函数里面发生的。</p>
<pre><code class="language-C">// Include/cpython/initconfig.h
// 程序执行的状态
typedef struct {
    enum {
        _PyStatus_TYPE_OK=0,     // 正常
        _PyStatus_TYPE_ERROR=1,  // 错误
        _PyStatus_TYPE_EXIT=2    // 退出
    } _type;
    const char *func;     // 发生错误的函数名
    const char *err_msg;  // 错误消息
    int exitcode;         // 退出码
} PyStatus;


// Python/pylifecycle.c
static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    PyStatus status;
    // 运行时初始化，如果出现异常直接返回
    status = _PyRuntime_Initialize();
    if (_PyStatus_EXCEPTION(status)) {
        return status;
    }
    // 获取运行时
    _PyRuntimeState *runtime = &amp;_PyRuntime;
    if (!runtime-&gt;initialized) {
        return _PyStatus_ERR(&quot;Py_Initialize must be called first&quot;);
    }
    // GIL API 在多解释器环境下存在问题，无法正常工作，因此需要禁用 PyGILState_Check() 来避免问题
    _PyGILState_check_enabled = 0;
    // 创建进程状态对象
    PyInterpreterState *interp = PyInterpreterState_New();
    if (interp == NULL) {
        *tstate_p = NULL;
        return _PyStatus_OK();
    }
    // 根据进程状态对象创建线程状态对象，维护对应的 OS 线程的状态
    PyThreadState *tstate = PyThreadState_New(interp);
    if (tstate == NULL) {
        PyInterpreterState_Delete(interp);
        *tstate_p = NULL;
        return _PyStatus_OK();
    }
    // 将 GIL 的控制权交给创建的线程
    PyThreadState *save_tstate = PyThreadState_Swap(tstate);

    // 从当前或主进程状态对象复制配置到新的进程状态对象
    PyConfig *config;
    if (save_tstate != NULL) {
        config = &amp;save_tstate-&gt;interp-&gt;config;
    } else {
        PyInterpreterState *main_interp = PyInterpreterState_Main();
        config = &amp;main_interp-&gt;config;
    }
    status = _PyConfig_Copy(&amp;interp-&gt;config, config);
    if (_PyStatus_EXCEPTION(status)) {
        return status;
    }
    config = &amp;interp-&gt;config;
    
    // 异常系统初始化
    status = _PyExc_Init();
    if (_PyStatus_EXCEPTION(status)) {
        return status;
    }
    status = _PyErr_Init();
    if (_PyStatus_EXCEPTION(status)) {
        return status;
    }

    // 创建模块字典
    PyObject *modules = PyDict_New();
    if (modules == NULL) {
        return _PyStatus_ERR(&quot;can't make modules dictionary&quot;);
    }
    interp-&gt;modules = modules;
    
    // 初始化 sys 模块
    PyObject *sysmod = _PyImport_FindBuiltin(&quot;sys&quot;, modules);
    if (sysmod != NULL) {
        interp-&gt;sysdict = PyModule_GetDict(sysmod);
        if (interp-&gt;sysdict == NULL) {
            goto handle_error;
        }
        Py_INCREF(interp-&gt;sysdict);
        PyDict_SetItemString(interp-&gt;sysdict, &quot;modules&quot;, modules);
        if (_PySys_InitMain(runtime, interp) &lt; 0) {
            return _PyStatus_ERR(&quot;can't finish initializing sys&quot;);
        }
    }
    else if (PyErr_Occurred()) {
        goto handle_error;
    }
    
    // 初始化 builtins 模块
    PyObject *bimod = _PyImport_FindBuiltin(&quot;builtins&quot;, modules);
    if (bimod != NULL) {
        interp-&gt;builtins = PyModule_GetDict(bimod);
        if (interp-&gt;builtins == NULL)
            goto handle_error;
        Py_INCREF(interp-&gt;builtins);
    }
    else if (PyErr_Occurred()) {
        goto handle_error;
    }
    
    if (bimod != NULL &amp;&amp; sysmod != NULL) {
        // 添加内置异常
        status = _PyBuiltins_AddExceptions(bimod);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        status = _PySys_SetPreliminaryStderr(interp-&gt;sysdict);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        status = _PyImportHooks_Init();
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        // 初始化导入系统
        status = init_importlib(interp, sysmod);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }

        status = init_importlib_external(interp);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        // 初始化编码
        status = _PyUnicode_InitEncodings(tstate);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        // 设置标准流
        status = init_sys_streams(interp);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        // 添加 main 模块
        status = add_main_module(interp);
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
        
        // 初始化 site 导入
        if (config-&gt;site_import) {
            status = init_import_size();
            if (_PyStatus_EXCEPTION(status)) {
                return status;
            }
        }
    }

    if (PyErr_Occurred()) {
        goto handle_error;
    }

    *tstate_p = tstate;
    return _PyStatus_OK();

handle_error:
    // 错误处理，如果失败则清理所有资源并恢复原状态
    PyErr_PrintEx(0);
    PyThreadState_Clear(tstate);
    PyThreadState_Swap(save_tstate);
    PyThreadState_Delete(tstate);
    PyInterpreterState_Delete(interp);

    *tstate_p = NULL;
    return _PyStatus_OK();
}
</code></pre>
<p>Python 在初始化运行时环境时，肯定也要对类型系统进行初始化等等，整体是一个非常庞大的过程。</p>
<p>到这里，我们对 new_interpreter 的探索算是有了一个阶段性的成功，我们创建了代表进程和线程概念的 PyInterpreterState 和 PyThreadState 对象，并在它们之间建立了联系。下面 new_interpreter 将进入另一个环节，设置系统 module。</p>
<h2 id="创建-builtins-模块"><a class="header" href="#创建-builtins-模块">创建 builtins 模块</a></h2>
<p>在 new_interpreter 中创建了 PyInterpreterState 和 PyThreadState 对象之后，就会开始设置系统的 builtins 了。</p>
<pre><code class="language-C">static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    // ...
    // 申请一个 PyDictObject 对象，用于 sys.modules
    PyObject *modules = PyDict_New();
    if (modules == NULL) {
        return _PyStatus_ERR(&quot;can't make modules dictionary&quot;);
    }
    // 然后让 interp -&gt; modules 维护 modules
    // 由于 interp 表示的是进程状态对象，这说明什么? 
    // 显然是该进程内的多个线程共享同一个 sys.modules
    interp-&gt;modules = modules;
    // 加载 sys 模块，所有的 module 对象都在 sys.modules 中
    PyObject *sysmod = _PyImport_FindBuiltin(&quot;sys&quot;, modules);
    if (sysmod != NULL) {
        interp-&gt;sysdict = PyModule_GetDict(sysmod);
        if (interp-&gt;sysdict == NULL) {
            goto handle_error;
        }
        Py_INCREF(interp-&gt;sysdict);
        PyDict_SetItemString(interp-&gt;sysdict, &quot;modules&quot;, modules);
        if (_PySys_InitMain(runtime, interp) &lt; 0) {
            return _PyStatus_ERR(&quot;can't finish initializing sys&quot;);
        }
    }
    else if (PyErr_Occurred()) {
        goto handle_error;
    }
    // 加载内置模块 builtins
    PyObject *bimod = _PyImport_FindBuiltin(&quot;builtins&quot;, modules);
    if (bimod != NULL) {
        // 设置内置名字空间
        interp-&gt;builtins = PyModule_GetDict(bimod);
        if (interp-&gt;builtins == NULL)
            goto handle_error;
        Py_INCREF(interp-&gt;builtins);
    }
    // ...
}  
</code></pre>
<p>整体还是比较清晰和直观的，另外我们说内置名字空间是由进程来维护的，因为进程就是用来为线程提供资源的。但是也能看出，一个进程内的多个线程共享同一个内置名字空间。显然这是非常合理的，不可能每开启一个线程，就为其创建一个 builtins。我们来从 Python 的角度证明这一点：</p>
<pre><code class="language-Python">import threading
import builtins

def foo1():
    builtins.list, builtins.tuple = builtins.tuple, builtins.list

def foo2():
    print(f&quot;猜猜下面代码会输出什么：&quot;)
    print(&quot;list:&quot;, list([1, 2, 3, 4, 5]))
    print(&quot;tuple:&quot;, tuple([1, 2, 3, 4, 5]))

f1 = threading.Thread(target=foo1)
f1.start()
f1.join()
threading.Thread(target=foo2).start()
&quot;&quot;&quot;
猜猜下面代码会输出什么：
list: (1, 2, 3, 4, 5)
tuple: [1, 2, 3, 4, 5]
&quot;&quot;&quot;
</code></pre>
<p>所有的内置对象和内置函数都在内置名字空间里面，可以通过 import builtins 获取、也可以直接通过 __builtins__ 这个变量来获取，当然这种方式拿到的是模块，再获取模块的 __dict__ 就是内置名字空间了。</p>
<p>我们在 foo1 中把 list 和 tuple 互换了，而这个结果显然也影响了 foo2 函数，这也说明了 builtins 模块是属于进程级别的，它被多个线程共享。当然不止内置名字空间，所有的 module 对象都是被多个线程共享的，所以是 <code>interp-&gt;modules = modules</code>。</p>
<p>至于对 builtins 模块的初始化是在 _PyBuiltin_Init 函数中进行的。</p>
<pre><code class="language-C">// Python/bltinmodule.c

PyObject *
_PyBuiltin_Init(void)
{
    PyObject *mod, *dict, *debug;

    const PyConfig *config = &amp;_PyInterpreterState_GET_UNSAFE()-&gt;config;

    if (PyType_Ready(&amp;PyFilter_Type) &lt; 0 ||
        PyType_Ready(&amp;PyMap_Type) &lt; 0 ||
        PyType_Ready(&amp;PyZip_Type) &lt; 0)
        return NULL;
    // 获取 builtins 模块
    mod = _PyModule_CreateInitialized(&amp;builtinsmodule, PYTHON_API_VERSION);
    if (mod == NULL)
        return NULL;
    // 拿到模块内部的属性字典
    dict = PyModule_GetDict(mod);

    // ...
    // 将所有内置对象加入到 builtins 模块的属性字典中，下面这些东西应该不陌生吧
    SETBUILTIN(&quot;None&quot;,                  Py_None);
    SETBUILTIN(&quot;Ellipsis&quot;,              Py_Ellipsis);
    SETBUILTIN(&quot;NotImplemented&quot;,        Py_NotImplemented);
    SETBUILTIN(&quot;False&quot;,                 Py_False);
    SETBUILTIN(&quot;True&quot;,                  Py_True);
    SETBUILTIN(&quot;bool&quot;,                  &amp;PyBool_Type);
    SETBUILTIN(&quot;memoryview&quot;,        &amp;PyMemoryView_Type);
    SETBUILTIN(&quot;bytearray&quot;,             &amp;PyByteArray_Type);
    SETBUILTIN(&quot;bytes&quot;,                 &amp;PyBytes_Type);
    SETBUILTIN(&quot;classmethod&quot;,           &amp;PyClassMethod_Type);
    SETBUILTIN(&quot;complex&quot;,               &amp;PyComplex_Type);
    SETBUILTIN(&quot;dict&quot;,                  &amp;PyDict_Type);
    SETBUILTIN(&quot;enumerate&quot;,             &amp;PyEnum_Type);
    SETBUILTIN(&quot;filter&quot;,                &amp;PyFilter_Type);
    SETBUILTIN(&quot;float&quot;,                 &amp;PyFloat_Type);
    SETBUILTIN(&quot;frozenset&quot;,             &amp;PyFrozenSet_Type);
    SETBUILTIN(&quot;property&quot;,              &amp;PyProperty_Type);
    SETBUILTIN(&quot;int&quot;,                   &amp;PyLong_Type);
    SETBUILTIN(&quot;list&quot;,                  &amp;PyList_Type);
    SETBUILTIN(&quot;map&quot;,                   &amp;PyMap_Type);
    SETBUILTIN(&quot;object&quot;,                &amp;PyBaseObject_Type);
    SETBUILTIN(&quot;range&quot;,                 &amp;PyRange_Type);
    SETBUILTIN(&quot;reversed&quot;,              &amp;PyReversed_Type);
    SETBUILTIN(&quot;set&quot;,                   &amp;PySet_Type);
    SETBUILTIN(&quot;slice&quot;,                 &amp;PySlice_Type);
    SETBUILTIN(&quot;staticmethod&quot;,          &amp;PyStaticMethod_Type);
    SETBUILTIN(&quot;str&quot;,                   &amp;PyUnicode_Type);
    SETBUILTIN(&quot;super&quot;,                 &amp;PySuper_Type);
    SETBUILTIN(&quot;tuple&quot;,                 &amp;PyTuple_Type);
    SETBUILTIN(&quot;type&quot;,                  &amp;PyType_Type);
    SETBUILTIN(&quot;zip&quot;,                   &amp;PyZip_Type);
    debug = PyBool_FromLong(config-&gt;optimization_level == 0);
    if (PyDict_SetItemString(dict, &quot;__debug__&quot;, debug) &lt; 0) {
        Py_DECREF(debug);
        return NULL;
    }
    Py_DECREF(debug);

    return mod;
#undef ADD_TO_ALL
#undef SETBUILTIN
}
</code></pre>
<p>整个 _PyBuiltin__Init 函数的功能就是设置内置名字空间，不过设置的东西似乎少了很多，比如 dir、hasattr、setattr 等等，这些明显也是内置的，但是它们到哪里去了呢。其实，设置内置名字空间这个过程是分为两步的：</p>
<ul>
<li>通过 _PyModule_CreateInitialized 函数创建 PyModuleObject 对象，即 builtins 模块。</li>
<li>获取 builtins 模块的属性字典（即内置名字空间），将 Python 的内置对象塞到里面。</li>
</ul>
<p>我们上面只看到了第二步，其实在第一步创建 builtins 模块时就已经完成了大部分的属性设置工作。</p>
<pre><code class="language-C">// Include/moduleobject.h

// 包含了模块的核心信息
typedef struct PyModuleDef{
    PyModuleDef_Base m_base;
    // 模块名称
    const char* m_name;
    // 模块的文档字符串
    const char* m_doc;
    // 模块的额外内存大小，用于单进程多解释器
    // 如果不是多解释器模式，那么写 -1 即可
    Py_ssize_t m_size;
    // 模块内部定义的函数
    PyMethodDef *m_methods;
    // 用于定义模块导入时的特殊行为，比如多阶段初始化等高级特性
    struct PyModuleDef_Slot* m_slots;
    // 用于垃圾回收，负责遍历模块引用的对象
    traverseproc m_traverse;
    // 用于垃圾回收，负责清理模块状态
    inquiry m_clear;
    // 模块被销毁时调用的清理函数
    freefunc m_free;
} PyModuleDef;

// Object/moduleobject.c
PyObject *
_PyModule_CreateInitialized(struct PyModuleDef* module, int module_api_version)
{
    const char* name;
    PyModuleObject *m;
    // 初始化
    if (!PyModuleDef_Init(module))
        return NULL;
    // 拿到 module 的 name，对于当前来说就是 builtins
    name = module-&gt;m_name;
    // 这里比较有意思，这是检测模块版本的，针对的是需要被导入的 py 文件
    // 解释器在导入 py 文件时，会优先从当前目录的 __pycache__ 里面加载 pyc
    // 而 pyc 文件包含了编译时解释器的 MAGIC NUMBER，所以要比较是否一致
    // 如果不一致，说明解释器版本不对，则不导入 pyc 文件，而是会重新编译 py 文件    
    if (!check_api_version(name, module_api_version)) {
        return NULL;
    }
    if (module-&gt;m_slots) {
        PyErr_Format(
            PyExc_SystemError,
            &quot;module %s: PyModule_Create is incompatible with m_slots&quot;, name);
        return NULL;
    }
    // ...
    // 创建一个 PyModuleObject 实例
    if ((m = (PyModuleObject*)PyModule_New(name)) == NULL)
        return NULL;
    // 如果 m_size &gt; 0，说明当前是多解释器模式，这个不需要关注
    // 因为多解释器模式只能手动调用 Python/C API 开启（用得也很少）
    // 像我们平时在使用 Python 时，都是一个进程对应一个解释器
    if (module-&gt;m_size &gt; 0) {
        m-&gt;md_state = PyMem_MALLOC(module-&gt;m_size);
        if (!m-&gt;md_state) {
            PyErr_NoMemory();
            Py_DECREF(m);
            return NULL;
        }
        memset(m-&gt;md_state, 0, module-&gt;m_size);
    }
    // 这里的变量 module 指向 PyModuleDef，它包含了模块的核心信息
    // 而变量 m 指向的 PyModuleObject 才是模块对象，它是基于 PyModuleDef 构建的
    if (module-&gt;m_methods != NULL) {
        // module-&gt;m_methods 指向 builtin_methods 数组，该数组中包含了大量的内置函数
        // 调用 PyModule_AddFunctions 将它们添加到模块中
        if (PyModule_AddFunctions((PyObject *) m, module-&gt;m_methods) != 0) {
            Py_DECREF(m);
            return NULL;
        }
    }
    if (module-&gt;m_doc != NULL) {
        // 设置 docstring
        if (PyModule_SetDocString((PyObject *) m, module-&gt;m_doc) != 0) {
            Py_DECREF(m);
            return NULL;
        }
    }
    m-&gt;md_def = module;
    return (PyObject*)m;
}
</code></pre>
<p>所以在创建模块之后，就已经将大量的内置函数添加到 builtins 模块里面了。然后来看一下模块的具体创建过程。</p>
<h3 id="创建-module-对象"><a class="header" href="#创建-module-对象">创建 module 对象</a></h3>
<p>Python 的 module 对象在底层对应 PyModuleObject 结构体，来看看它长什么样子。</p>
<pre><code class="language-c">// Objects/moduleobject.c
typedef struct {
    // 头部信息
    PyObject_HEAD
    // 属性字典，所有的属性和值都在里面
    PyObject *md_dict;
    // module 对象的核心信息
    struct PyModuleDef *md_def;
    void *md_state;
    PyObject *md_weaklist;
    PyObject *md_name;
} PyModuleObject;
</code></pre>
<p>而这个对象是通过 PyModule_New 创建的。</p>
<pre><code class="language-C">// Objects/moduleobject.c
PyObject *
PyModule_New(const char *name)
{
    PyObject *nameobj, *module;
    // 模块的名称
    nameobj = PyUnicode_FromString(name);
    if (nameobj == NULL)
        return NULL;
    // 创建 PyModuleObject
    module = PyModule_NewObject(nameobj);
    Py_DECREF(nameobj);
    return module;
}

PyObject *
PyModule_NewObject(PyObject *name)
{
    PyModuleObject *m;
    // 为模块对象申请内存空间
    m = PyObject_GC_New(PyModuleObject, &amp;PyModule_Type);
    if (m == NULL)
        return NULL;
    // 初始化内部字段
    m-&gt;md_def = NULL;
    m-&gt;md_state = NULL;
    m-&gt;md_weaklist = NULL;
    m-&gt;md_name = NULL;
    // 属性字典
    m-&gt;md_dict = PyDict_New();
    // 调用 module_init_dict 初始化属性字典
    if (module_init_dict(m, m-&gt;md_dict, name, NULL) != 0)
        goto fail;
    PyObject_GC_Track(m);
    return (PyObject *)m;

 fail:
    Py_DECREF(m);
    return NULL;
}

static int
module_init_dict(PyModuleObject *mod, PyObject *md_dict,
                 PyObject *name, PyObject *doc)
{
    _Py_IDENTIFIER(__name__);
    _Py_IDENTIFIER(__doc__);
    _Py_IDENTIFIER(__package__);
    _Py_IDENTIFIER(__loader__);
    _Py_IDENTIFIER(__spec__);

    if (md_dict == NULL)
        return -1;
    if (doc == NULL)
        doc = Py_None;
    // 模块的一些属性，如 __name__、__doc__等等
    if (_PyDict_SetItemId(md_dict, &amp;PyId___name__, name) != 0)
        return -1;
    if (_PyDict_SetItemId(md_dict, &amp;PyId___doc__, doc) != 0)
        return -1;
    if (_PyDict_SetItemId(md_dict, &amp;PyId___package__, Py_None) != 0)
        return -1;
    if (_PyDict_SetItemId(md_dict, &amp;PyId___loader__, Py_None) != 0)
        return -1;
    if (_PyDict_SetItemId(md_dict, &amp;PyId___spec__, Py_None) != 0)
        return -1;
    if (PyUnicode_CheckExact(name)) {
        Py_INCREF(name);
        Py_XSETREF(mod-&gt;md_name, name);
    }

    return 0;
}
</code></pre>
<p>这里虽然创建了一个 module 对象，但这仅仅是一个空的 module 对象，并没有包含相应的操作和数据。我们看到只设置了 name 和 doc 等属性。</p>
<h3 id="设置-module-对象的属性"><a class="header" href="#设置-module-对象的属性">设置 module 对象的属性</a></h3>
<p>在 _PyModule_CreateInitialized 函数中调用 PyModule_New 创建了一个模块，然后通过 PyModule_AddFunctions 完成了对 builtins 大部分属性的设置。这个设置的属性依赖于第二个参数 <code>module-&gt;m_methods</code>，在这里为 builtin_methods。</p>
<pre><code class="language-C">// Python/bltinmodule.c
static PyMethodDef builtin_methods[] = {
    {&quot;__build_class__&quot;, (PyCFunction)(void(*)(void))builtin___build_class__,
     METH_FASTCALL | METH_KEYWORDS, build_class_doc},
    {&quot;__import__&quot;,      (PyCFunction)(void(*)(void))builtin___import__, METH_VARARGS | METH_KEYWORDS, import_doc},
    BUILTIN_ABS_METHODDEF
    BUILTIN_ALL_METHODDEF
    BUILTIN_ANY_METHODDEF
    BUILTIN_ASCII_METHODDEF
    BUILTIN_BIN_METHODDEF
    {&quot;breakpoint&quot;,      (PyCFunction)(void(*)(void))builtin_breakpoint, METH_FASTCALL | METH_KEYWORDS, breakpoint_doc},
    BUILTIN_CALLABLE_METHODDEF
    BUILTIN_CHR_METHODDEF
    BUILTIN_COMPILE_METHODDEF
    BUILTIN_DELATTR_METHODDEF
    {&quot;dir&quot;,             builtin_dir,        METH_VARARGS, dir_doc},
    BUILTIN_DIVMOD_METHODDEF
    BUILTIN_EVAL_METHODDEF
    BUILTIN_EXEC_METHODDEF
    BUILTIN_FORMAT_METHODDEF
    {&quot;getattr&quot;,         (PyCFunction)(void(*)(void))builtin_getattr, METH_FASTCALL, getattr_doc},
    BUILTIN_GLOBALS_METHODDEF
    BUILTIN_HASATTR_METHODDEF
    BUILTIN_HASH_METHODDEF
    BUILTIN_HEX_METHODDEF
    BUILTIN_ID_METHODDEF
    BUILTIN_INPUT_METHODDEF
    BUILTIN_ISINSTANCE_METHODDEF
    BUILTIN_ISSUBCLASS_METHODDEF
    {&quot;iter&quot;,            (PyCFunction)(void(*)(void))builtin_iter,       METH_FASTCALL, iter_doc},
    BUILTIN_LEN_METHODDEF
    BUILTIN_LOCALS_METHODDEF
    {&quot;max&quot;,             (PyCFunction)(void(*)(void))builtin_max,        METH_VARARGS | METH_KEYWORDS, max_doc},
    {&quot;min&quot;,             (PyCFunction)(void(*)(void))builtin_min,        METH_VARARGS | METH_KEYWORDS, min_doc},
    {&quot;next&quot;,            (PyCFunction)(void(*)(void))builtin_next,       METH_FASTCALL, next_doc},
    BUILTIN_OCT_METHODDEF
    BUILTIN_ORD_METHODDEF
    BUILTIN_POW_METHODDEF
    {&quot;print&quot;,           (PyCFunction)(void(*)(void))builtin_print,      METH_FASTCALL | METH_KEYWORDS, print_doc},
    BUILTIN_REPR_METHODDEF
    BUILTIN_ROUND_METHODDEF
    BUILTIN_SETATTR_METHODDEF
    BUILTIN_SORTED_METHODDEF
    BUILTIN_SUM_METHODDEF
    {&quot;vars&quot;,            builtin_vars,       METH_VARARGS, vars_doc},
    {NULL,              NULL},
};
</code></pre>
<p>怎么样，是不是看到了玄机。</p>
<p>总结一下就是：在 Py_NewInterpreter 里面调用 new_interpreter 函数，然后在 new_interpreter 函数里面，通过 PyInterpreterState_New 创建 PyInterpreterState 对象，然后以 PyInterpreterState 对象为参数，调用 PyThreadState_New 函数创建 PyThreadState 对象。</p>
<p>接着就是执行各种初始化动作，然后调用 _PyBuiltin_Init 设置内置属性。然而在 _PyBuiltin_Init 函数的最后设置的都是一些内置的类对象，而内置函数（比如 getattr、exec 等）却没有设置。</p>
<p>所以 _PyBuiltin_Init 函数中间调用的 _PyModule_CreateInitialized 不仅仅是初始化一个 module 对象，还会在初始化之后将我们没有看到的一些属性设置进去。在里面先使用 PyModule_New 创建一个 PyModuleObject，此时它内部只有 __name__ 和 __doc__ 等属性，之后再通过 PyModule_AddFunctions 设置 builtin_methods，在 builtin_methods 里面我们看到了 dir、getattr 等内置函数。当这些属性设置完之后，退回到 _PyBuiltin_Init 函数中，再设置剩余的部分属性（内置的类对象和一些常量）。之后，builtins 模块就完成了。</p>
<p><img src="./images/277.png" alt="" /></p>
<p>另外 builtin_methods 是一个 PyMethodDef 类型的数组，里面是一个个的 PyMethodDef 结构体实例。</p>
<pre><code class="language-C">// Include/methodobject.h

typedef PyObject *(*PyCFunction)(PyObject *, PyObject *);
typedef PyObject *(*_PyCFunctionFast) (PyObject *, PyObject *const *, Py_ssize_t);
typedef PyObject *(*PyCFunctionWithKeywords)(PyObject *, PyObject *, PyObject *);

struct PyMethodDef {
    // 内置函数的名称
    const char  *ml_name;
    // 具体实现对应的 C 函数
    PyCFunction ml_meth;
    // 函数类型
    /* #define METH_VARARGS  0x0001  支持扩展位置参数
     * #define METH_KEYWORDS 0x0002  支持扩展关键字参数
     * #define METH_NOARGS   0x0004  不需要参数
     * #define METH_O        0x0008  精确接收一个位置参数
     * #define METH_CLASS    0x0010  被 classmethod 装饰的类方法
     * #define METH_STATIC   0x0020  被 staticmethod 装饰的静态方法
     */
    int         ml_flags;
    // 函数的 __doc__
    const char  *ml_doc;
};
typedef struct PyMethodDef PyMethodDef;
</code></pre>
<p>对于这里面每一个 PyMethodDef 实例，_PyModule_CreateInitialized 都会基于它创建一个 PyCFunctionObject 对象，我们说过内置函数以及内置实例对象的方法在底层会对应 PyCFunctionObject。</p>
<pre><code class="language-C">// Include/methodobject.h

typedef struct {
    // 头部信息
    PyObject_HEAD
    // PyMethodDef 实例
    PyMethodDef *m_ml;
    // self 
    PyObject    *m_self;
    // __module__
    PyObject    *m_module;
    // 弱引用列表，不讨论
    PyObject    *m_weakreflist;
    // 为了效率而单独实现的矢量调用函数
    vectorcallfunc vectorcall;
} PyCFunctionObject;
</code></pre>
<p>然后 PyCFunctionObject 的创建则是通过 PyCFunction_New 完成的。</p>
<pre><code class="language-C">// Objects/methodobject.c
PyObject *
PyCFunction_New(PyMethodDef *ml, PyObject *self)
{
    return PyCFunction_NewEx(ml, self, NULL);
}

PyObject *
PyCFunction_NewEx(PyMethodDef *ml, PyObject *self, PyObject *module)
{
    vectorcallfunc vectorcall;
    // 判断参数类型，决定调用方式
    switch (ml-&gt;ml_flags &amp; (METH_VARARGS | METH_FASTCALL | METH_NOARGS | METH_O | METH_KEYWORDS))
    {
        case METH_VARARGS:
        case METH_VARARGS | METH_KEYWORDS:
            /* For METH_VARARGS functions, it's more efficient to use tp_call
             * instead of vectorcall. */
            vectorcall = NULL;
            break;
        case METH_FASTCALL:
            vectorcall = cfunction_vectorcall_FASTCALL;
            break;
        case METH_FASTCALL | METH_KEYWORDS:
            vectorcall = cfunction_vectorcall_FASTCALL_KEYWORDS;
            break;
        case METH_NOARGS:
            vectorcall = cfunction_vectorcall_NOARGS;
            break;
        case METH_O:
            vectorcall = cfunction_vectorcall_O;
            break;
        default:
            PyErr_Format(PyExc_SystemError,
                         &quot;%s() method: bad call flags&quot;, ml-&gt;ml_name);
            return NULL;
    }

    PyCFunctionObject *op;
    // 我们看到 PyCFunctionObject 也采用了缓存池
    op = free_list;
    if (op != NULL) {
        free_list = (PyCFunctionObject *)(op-&gt;m_self);
        (void)PyObject_INIT(op, &amp;PyCFunction_Type);
        numfree--;
    }
    else {
        op = PyObject_GC_New(PyCFunctionObject, &amp;PyCFunction_Type);
        if (op == NULL)
            return NULL;
    }
    // 设置属性
    op-&gt;m_weakreflist = NULL;
    op-&gt;m_ml = ml;
    Py_XINCREF(self);
    op-&gt;m_self = self;
    Py_XINCREF(module);
    op-&gt;m_module = module;
    op-&gt;vectorcall = vectorcall;
    _PyObject_GC_TRACK(op);
    return (PyObject *)op;
}
</code></pre>
<p>以上就是 _PyBuiltin__Init 所做的事情，再之后虚拟机会把 PyModuleObject 对象的属性字典抽取出来，赋值给 <code>interp -&gt; builtins</code>。</p>
<pre><code class="language-C">// Python/pylifecycle.c
static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    // ...
    PyObject *bimod = _PyImport_FindBuiltin(&quot;builtins&quot;, modules);
    if (bimod != NULL) {
        // 通过 PyModule_GetDict 获取属性字典，赋值给 builtins
        interp-&gt;builtins = PyModule_GetDict(bimod);
        if (interp-&gt;builtins == NULL)
            goto handle_error;
        Py_INCREF(interp-&gt;builtins);
    }
    else if (PyErr_Occurred()) {
        goto handle_error;
    }
    // ...
}
</code></pre>
<p>以后 Python 在访问内置名字空间时，直接访问 <code>interp-&gt;builtins</code> 就可以了，因为内置属性的使用会很频繁，所以这种加速机制是很有效的。</p>
<h2 id="创建-sys-模块"><a class="header" href="#创建-sys-模块">创建 sys 模块</a></h2>
<p>Python 在创建 builtins 模块、设置内置名字空间之前，会先创建 sys 模块，流程是一样的，只是我们将介绍的顺序颠倒了一下。</p>
<pre><code class="language-C">static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    // ...
    // 创建 sys 模块
    PyObject *sysmod = _PyImport_FindBuiltin(&quot;sys&quot;, modules);
    if (sysmod != NULL) {
        // 获取 sys 模块的属性字典，并赋值给 interp-&gt;sysdict
        interp-&gt;sysdict = PyModule_GetDict(sysmod);
        if (interp-&gt;sysdict == NULL) {
            goto handle_error;
        }
        Py_INCREF(interp-&gt;sysdict);
        // 将 &quot;modules&quot;: modules 添加到 sys 模块的属性字典中
        // 在 Python 里面便可通过 sys.modules 拿到所有的模块
        PyDict_SetItemString(interp-&gt;sysdict, &quot;modules&quot;, modules);
        if (_PySys_InitMain(runtime, interp) &lt; 0) {
            return _PyStatus_ERR(&quot;can't finish initializing sys&quot;);
        }
    }
    else if (PyErr_Occurred()) {
        goto handle_error;
    }
    // ...
}
</code></pre>
<p>创建 sys module 之后，还会额外添加一个 __main__ 模块。</p>
<pre><code class="language-C">static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    // ...
    status = add_main_module(interp);
    if (_PyStatus_EXCEPTION(status)) {
        return status;
    }  
    // ...
}  

static PyStatus
add_main_module(PyInterpreterState *interp)
{
    PyObject *m, *d, *loader, *ann_dict;
    // 将 __main__ 添加进 sys.modules 中
    m = PyImport_AddModule(&quot;__main__&quot;);
    if (m == NULL)
        return _PyStatus_ERR(&quot;can't create __main__ module&quot;);

    d = PyModule_GetDict(m);
    ann_dict = PyDict_New();
    if ((ann_dict == NULL) ||
        (PyDict_SetItemString(d, &quot;__annotations__&quot;, ann_dict) &lt; 0)) {
        return _PyStatus_ERR(&quot;Failed to initialize __main__.__annotations__&quot;);
    }
    Py_DECREF(ann_dict);

    if (PyDict_GetItemString(d, &quot;__builtins__&quot;) == NULL) {
        PyObject *bimod = PyImport_ImportModule(&quot;builtins&quot;);
        if (bimod == NULL) {
            return _PyStatus_ERR(&quot;Failed to retrieve builtins module&quot;);
        }
        if (PyDict_SetItemString(d, &quot;__builtins__&quot;, bimod) &lt; 0) {
            return _PyStatus_ERR(&quot;Failed to initialize __main__.__builtins__&quot;);
        }
        Py_DECREF(bimod);
    }
  
    loader = PyDict_GetItemString(d, &quot;__loader__&quot;);
    if (loader == NULL || loader == Py_None) {
        PyObject *loader = PyObject_GetAttrString(interp-&gt;importlib,
                                                  &quot;BuiltinImporter&quot;);
        if (loader == NULL) {
            return _PyStatus_ERR(&quot;Failed to retrieve BuiltinImporter&quot;);
        }
        if (PyDict_SetItemString(d, &quot;__loader__&quot;, loader) &lt; 0) {
            return _PyStatus_ERR(&quot;Failed to initialize __main__.__loader__&quot;);
        }
        Py_DECREF(loader);
    }
    return _PyStatus_OK();
}
</code></pre>
<p>这个 __main__ 估计不用我多说了。之前在 PyModule_New 中，创建一个 PyModuleObject 对象之后，会在其属性字典中插入一个名为 &quot;__name__&quot; 的 key，value 就是 &quot;__main__&quot;。但是对于当前模块来说，这个模块也叫做 __main__。</p>
<pre><code class="language-Python">name = &quot;古明地觉&quot;

import __main__
print(__main__.name)  # 古明地觉

import sys
print(sys.modules[&quot;__main__&quot;] is __main__)  # True
</code></pre>
<p>因此我们算是知道了，为什么执行 python xxx.py 的时候，__name__ 是 &quot;__main__&quot; 了，因为这里设置了。而 Python 沿着名字空间寻找的时候，最终会在 __main__ 的 local 空间中发现 __name__，且值为字符串 &quot;__main__&quot;。但如果是以 import 的方式加载的，那么 __name__ 则不是 &quot;__main__&quot;，而是模块名。</p>
<p>其实这个 __main__ 我们再熟悉不过了，当输入 dir() 的时候，就会显示 __main__ 的内容。dir 可以不加参数，如果不加参数，那么默认访问当前的 local 空间，也就是 __main__。</p>
<pre><code class="language-python">&gt;&gt;&gt; __name__
'__main__'
&gt;&gt;&gt; 
&gt;&gt;&gt; __builtins__.__name__
'builtins'
&gt;&gt;&gt;
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; np.__name__
'numpy'
</code></pre>
<p>所以说，访问模块就类似访问变量一样，modules 里面存放了所有的 &lt;模块名, 模块对象&gt;。当我们访问 np 的时候，会找到 name 为 &quot;numpy&quot; 的模块，然后这个值里面也维护了一个字典，其中也有一个 key 为 &quot;__name__&quot; 的 entry，value 为 &quot;numpy&quot;。</p>
<h2 id="设置-site-specific-的-module-搜索路径"><a class="header" href="#设置-site-specific-的-module-搜索路径">设置 site-specific 的 module 搜索路径</a></h2>
<p>Python 是一个非常开放的体系，它的强大来源于丰富的第三方库，这些库由外部的 py 文件来提供。当使用这些第三方库的时候，只需要简单地进行 import 即可。一般来说，这些第三方库都放在 Lib/site-packages 中，如果程序想使用这些库，直接导入即可。</p>
<p>但是到目前为止，我们好像也没看到 Python 将 site-packages 路径设置到搜索路径里面去啊。其实在完成了 __main__ 的创建之后，Python 才腾出手来收拾这个 site-package。这个关键的动作在于 Python 的一个标准库：site.py。</p>
<p>我们先将 Lib 目录下的 site.py 删掉，然后导入一个第三方模块，看看会有什么后果。</p>
<p><img src="./images/278.png" alt="" /></p>
<p>因此 Python 在初始化的过程中确实导入了 site.py，所以才有了如下的输出。而这个 site.py 也正是 Python 能正确加载位于 site-packages 目录下第三方包的关键所在。我们可以猜测，应该就是这个 site.py 将 site-packages 目录加入到了 sys.path 中，而这个动作是由 init_import_size 完成的。</p>
<pre><code class="language-C">static PyStatus
new_interpreter(PyThreadState **tstate_p)
{
    // ...
    if (config-&gt;site_import) {
        status = init_import_size();
        if (_PyStatus_EXCEPTION(status)) {
            return status;
        }
    }
    // ...
}

static PyStatus
init_import_size(void)
{
    PyObject *m;
    // 导入 site 模块，在 site 模块里面会将 site-packages 加入到 sys.path 中
    m = PyImport_ImportModule(&quot;site&quot;);
    // 如果导入失败，抛出异常
    if (m == NULL) {
        // 这里的报错信息是不是和上图中显示的一样呢？
        return _PyStatus_ERR(&quot;Failed to import the site module&quot;);
    }
    Py_DECREF(m);
    return _PyStatus_OK();
}
</code></pre>
<p>在 init_import_size 中，只调用了 PyImport_ImportModule 函数，这个函数是 import 机制的核心所在。比如 PyImport_ImportModule(&quot;numpy&quot;) 就等价于 <font color="blue">import numpy</font>。</p>
<h2 id="小结-66"><a class="header" href="#小结-66">小结</a></h2>
<p>以上就是运行时环境的初始化所做的事情，但需要注意：此时虚拟机还没有完全启动。对，上面的那些工作都只是前戏，是虚拟机启动之前所做的一些准备工作。而在准备工作做完之后，虚拟机就会正式启动。那么怎么启动呢？我们下一篇文章再聊。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-69"><a class="header" href="#楔子-69">楔子</a></h2>
<p>Python 的运行方式有两种，一种是在命令行中输入 python 进入交互式环境，另一种则是以 <font color="blue">python xxx.py</font> 的方式运行脚本文件。尽管方式不同，但最终殊途同归，进入相同的处理逻辑。</p>
<p>而 Python 在初始化（Py_Initialize）完成之后，会执行 pymain_run_file。</p>
<pre><code class="language-C">// Modules/main.c
static int
pymain_run_file(PyConfig *config, PyCompilerFlags *cf)
{
    // 获取文件名
    const wchar_t *filename = config-&gt;run_filename;
    if (PySys_Audit(&quot;cpython.run_file&quot;, &quot;u&quot;, filename) &lt; 0) {
        return pymain_exit_err_print();
    }
    // 打开文件
    FILE *fp = _Py_wfopen(filename, L&quot;rb&quot;);
    // 如果 fp 为 NULL，证明文件打开失败
    if (fp == NULL) {
        char *cfilename_buffer;
        const char *cfilename;
        int err = errno;
        cfilename_buffer = _Py_EncodeLocaleRaw(filename, NULL);
        if (cfilename_buffer != NULL)
            cfilename = cfilename_buffer;
        else
            cfilename = &quot;&lt;unprintable file name&gt;&quot;;
        fprintf(stderr, &quot;%ls: can't open file '%s': [Errno %d] %s\n&quot;,
                config-&gt;program_name, cfilename, err, strerror(err));
        PyMem_RawFree(cfilename_buffer);
        return 2;
    }
    // ...
    // 调用 PyRun_AnyFileExFlags
    int run = PyRun_AnyFileExFlags(fp, filename_str, 1, cf);
    Py_XDECREF(bytes);
    return (run != 0);
}

// Python/pythonrun.c
int
PyRun_AnyFileExFlags(FILE *fp, const char *filename, int closeit,
                     PyCompilerFlags *flags)
{
    if (filename == NULL)
        filename = &quot;???&quot;;
    // 根据 fp 是否代表交互式环境，对程序进行流程控制
    if (Py_FdIsInteractive(fp, filename)) {
        // 如果是交互环境，调用 PyRun_InteractiveLoopFlags
        int err = PyRun_InteractiveLoopFlags(fp, filename, flags);
        if (closeit)
            fclose(fp);
        return err;
    }
    else
        // 否则说明是一个普通的 python 脚本，执行 PyRun_SimpleFileExFlags
        return PyRun_SimpleFileExFlags(fp, filename, closeit, flags);
}
</code></pre>
<p>我们看到<font color="blue">交互式</font>和<font color="blue">执行 py 脚本方式</font>调用的是两个不同的函数，但是别着急，最终你会看到它们又分久必合、走到一起。</p>
<h2 id="交互式环境"><a class="header" href="#交互式环境">交互式环境</a></h2>
<p>看看交互式运行时候的情形，不过在此之前先来看一下提示符。</p>
<pre><code class="language-Python">&gt;&gt;&gt; name = &quot;satori&quot;
&gt;&gt;&gt; if name == &quot;satori&quot;:
...     pass
... 
&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.ps1 = &quot;+++ &quot;
+++ sys.ps2 = &quot;--- &quot;
+++ 
+++ if name == &quot;satori&quot;:
---     pass
--- 
+++ 
</code></pre>
<p>我们每输入一行，开头都是 <code>&gt;&gt;&gt;</code>，这个是 sys.ps1。而输入语句块，没输入完的时候，那么显示 <code>...</code>，这个是 sys.ps2。而这两者都支持修改，如果修改了，那么就是我们自己定义的了。</p>
<p>交互式环境会执行 PyRun_InteractiveLoopFlags 函数。</p>
<pre><code class="language-c">// Python/pythonrun.c
int
PyRun_InteractiveLoopFlags(FILE *fp, const char *filename_str, PyCompilerFlags *flags)
{
    // ...
    // 创建交互式提示符，sys.ps1
    v = _PySys_GetObjectId(&amp;PyId_ps1);
    if (v == NULL) {
        _PySys_SetObjectId(&amp;PyId_ps1, v = PyUnicode_FromString(&quot;&gt;&gt;&gt; &quot;));
        Py_XDECREF(v);
    }
    // 同理这个也是一样，sys.ps2
    v = _PySys_GetObjectId(&amp;PyId_ps2);
    if (v == NULL) {
        _PySys_SetObjectId(&amp;PyId_ps2, v = PyUnicode_FromString(&quot;... &quot;));
        Py_XDECREF(v);
    }
    err = 0;
    do {
        // 这里就进入了交互式环境
        // 我们看到每次都调用了 PyRun_InteractiveOneObjectEx
        // 直到下面的 ret != E_EOF 不成立，停止循环，一般情况就是我们输入 exit() 退出了
        ret = PyRun_InteractiveOneObjectEx(fp, filename, flags);
        if (ret == -1 &amp;&amp; PyErr_Occurred()) {
            if (PyErr_ExceptionMatches(PyExc_MemoryError)) {
                if (++nomem_count &gt; 16) {
                    PyErr_Clear();
                    err = -1;
                    break;
                }
            } else {
                nomem_count = 0;
            }
            PyErr_Print();
            flush_io();
        } else {
            nomem_count = 0;
        }
#ifdef Py_REF_DEBUG
        if (show_ref_count) {
            _PyDebug_PrintTotalRefs();
        }
#endif
    } while (ret != E_EOF);
    Py_DECREF(filename);
    return err;
}

static int
PyRun_InteractiveOneObjectEx(FILE *fp, PyObject *filename,
                             PyCompilerFlags *flags)
{
    PyObject *m, *d, *v, *w, *oenc = NULL, *mod_name;
    mod_ty mod;
    PyArena *arena;
    const char *ps1 = &quot;&quot;, *ps2 = &quot;&quot;, *enc = NULL;
    int errcode = 0;
    _Py_IDENTIFIER(encoding);
    _Py_IDENTIFIER(__main__);

    mod_name = _PyUnicode_FromId(&amp;PyId___main__); /* borrowed */
    if (mod_name == NULL) {
        return -1;
    }

    if (fp == stdin) {
        // ...
    }
    v = _PySys_GetObjectId(&amp;PyId_ps1);
    if (v != NULL) {
        // ...
    }
    w = _PySys_GetObjectId(&amp;PyId_ps2);
    if (w != NULL) {
        // ...
    }
    arena = PyArena_New();
    if (arena == NULL) {
        Py_XDECREF(v);
        Py_XDECREF(w);
        Py_XDECREF(oenc);
        return -1;
    }
    // 编译用户在交互式环境下输入的 Python 语句，生成抽象语法树
    mod = PyParser_ASTFromFileObject(fp, filename, enc,
                                     Py_single_input, ps1, ps2,
                                     flags, &amp;errcode, arena);
    Py_XDECREF(v);
    Py_XDECREF(w);
    Py_XDECREF(oenc);
    if (mod == NULL) {
        PyArena_Free(arena);
        if (errcode == E_EOF) {
            PyErr_Clear();
            return E_EOF;
        }
        return -1;
    }
    // 获取 &lt;module '__main__'&gt; 中维护的 dict
    m = PyImport_AddModuleObject(mod_name);
    if (m == NULL) {
        PyArena_Free(arena);
        return -1;
    }
    d = PyModule_GetDict(m);
    // 执行用户输入的 Python 语句
    v = run_mod(mod, filename, d, d, flags, arena);
    PyArena_Free(arena);
    if (v == NULL) {
        return -1;
    }
    Py_DECREF(v);
    flush_io();
    return 0;
}
</code></pre>
<p>在 run_mod 之前，Python 会将 __main__ 中维护的 PyDictObject 对象取出，作为参数传递给 run_mod 函数。</p>
<h2 id="脚本文件运行方式"><a class="header" href="#脚本文件运行方式">脚本文件运行方式</a></h2>
<p>然后是脚本文件运行方式。</p>
<pre><code class="language-c">// Python/pythonrun.c
int
PyRun_SimpleFileExFlags(FILE *fp, const char *filename, int closeit,
                        PyCompilerFlags *flags)
{
    PyObject *filename_obj = PyUnicode_DecodeFSDefault(filename);
    if (filename_obj == NULL) {
        return -1;
    }
    // 调用了 pyrun_simple_file
    int res = pyrun_simple_file(fp, filename_obj, closeit, flags);
    Py_DECREF(filename_obj);
    return res;
}

static int
pyrun_simple_file(FILE *fp, PyObject *filename, int closeit,
                  PyCompilerFlags *flags)
{
    PyObject *m, *d, *v;
    int set_file_name = 0, ret = -1;
    // __main__ 就是当前文件
    m = PyImport_AddModule(&quot;__main__&quot;);
    if (m == NULL)
        return -1;
    Py_INCREF(m);
    // 模块的属性字典，同时也作为 local 空间和 global 空间
    d = PyModule_GetDict(m);
    // 在 __main__ 中设置 __file__ 属性
    if (PyDict_GetItemString(d, &quot;__file__&quot;) == NULL) {
        if (PyDict_SetItemString(d, &quot;__file__&quot;, filename) &lt; 0) {
            goto done;
        }
        if (PyDict_SetItemString(d, &quot;__cached__&quot;, Py_None) &lt; 0) {
            goto done;
        }
        set_file_name = 1;
    }
    
    int pyc = maybe_pyc_file(fp, filename, closeit);
    if (pyc &lt; 0) {
        goto done;
    }
    // 如果是 pyc，那么以二进制模式打开
    if (pyc) {
        FILE *pyc_fp;
        /* Try to run a pyc file. First, re-open in binary */
        if (closeit) {
            fclose(fp);
        }

        pyc_fp = _Py_fopen_obj(filename, &quot;rb&quot;);
        if (pyc_fp == NULL) {
            fprintf(stderr, &quot;python: Can't reopen .pyc file\n&quot;);
            goto done;
        }

        if (set_main_loader(d, filename, &quot;SourcelessFileLoader&quot;) &lt; 0) {
            fprintf(stderr, &quot;python: failed to set __main__.__loader__\n&quot;);
            ret = -1;
            fclose(pyc_fp);
            goto done;
        }
        v = run_pyc_file(pyc_fp, d, d, flags);
    } else {
        if (PyUnicode_CompareWithASCIIString(filename, &quot;&lt;stdin&gt;&quot;) != 0 &amp;&amp;
            set_main_loader(d, filename, &quot;SourceFileLoader&quot;) &lt; 0) {
            fprintf(stderr, &quot;python: failed to set __main__.__loader__\n&quot;);
            ret = -1;
            goto done;
        }
        // 执行脚本文件
        v = pyrun_file(fp, filename, Py_file_input, d, d,
                       closeit, flags);
    }
    // ...
    return ret;
}

static PyObject *
pyrun_file(FILE *fp, PyObject *filename, int start, PyObject *globals,
           PyObject *locals, int closeit, PyCompilerFlags *flags)
{
    PyArena *arena = PyArena_New();
    if (arena == NULL) {
        return NULL;
    }

    mod_ty mod;
    // 编译文件
    mod = PyParser_ASTFromFileObject(fp, filename, NULL, start, 0, 0,
                                     flags, NULL, arena);
    if (closeit) {
        fclose(fp);
    }

    PyObject *ret;
    if (mod != NULL) {
        // 执行，依旧是调用了 run_mod
        ret = run_mod(mod, filename, globals, locals, flags, arena);
    }
    else {
        ret = NULL;
    }
    PyArena_Free(arena);

    return ret;
}
</code></pre>
<p>很显然，脚本文件和交互式之间的执行流程是不同的，但最终都进入了 run_mod，而且同样将 __main__ 中维护的 PyDictObject 对象作为 local 名字空间和 global 名字空间传给了 run_mod。</p>
<h2 id="启动虚拟机"><a class="header" href="#启动虚拟机">启动虚拟机</a></h2>
<p>前面的都是准备工作，到这里才算是真正开始启动虚拟机。</p>
<pre><code class="language-C">// Python/pythonrun.c
static PyObject *
run_mod(mod_ty mod, PyObject *filename, PyObject *globals, PyObject *locals,
            PyCompilerFlags *flags, PyArena *arena)
{
    PyCodeObject *co;
    PyObject *v;
    // 基于 ast 编译字节码指令序列，创建 PyCodeObject 对象
    co = PyAST_CompileObject(mod, filename, flags, -1, arena);
    if (co == NULL)
        return NULL;

    if (PySys_Audit(&quot;exec&quot;, &quot;O&quot;, co) &lt; 0) {
        Py_DECREF(co);
        return NULL;
    }
    // 创建 PyFrameObject，执行 PyCodeObject 对象中的字节码指令序列
    v = run_eval_code_obj(co, globals, locals);
    Py_DECREF(co);
    return v;
}
</code></pre>
<p>run_mod 接手传来的 ast，然后再传到 PyAST_CompileObject 中，创建了一个我们已经非常熟悉的 PyCodeObject 对象。此时，Python 已经做好一切工作，于是开始通过 run_eval_code_obj 着手唤醒虚拟机。</p>
<pre><code class="language-c">static PyObject *
run_eval_code_obj(PyCodeObject *co, PyObject *globals, PyObject *locals)
{
    PyObject *v;
    // ...
    v = PyEval_EvalCode((PyObject*)co, globals, locals);
    if (!v &amp;&amp; PyErr_Occurred() == PyExc_KeyboardInterrupt) {
        _Py_UnhandledKeyboardInterrupt = 1;
    }
    return v;
}
</code></pre>
<p>函数中调用了 PyEval_EvalCode，根据前面的介绍，我们知道最终一定会调用 _PyEval_EvalFrameDefault，然后进入那个拥有巨型 switch 的 for 循环，不停地执行字节码指令，而运行时栈就是参数的容身之所。</p>
<p>所以整个流程就是先创建进程，进程创建线程，设置 builtins（包括设置 __name__、内置对象、内置函数等等)、设置缓存池，然后各种初始化，设置搜索路径。最后分词、编译、激活虚拟机执行。而执行方式就是调用曾经与我们朝夕相处的帧评估函数 ，掌控 Python 世界中无数对象的生生灭灭。参数 f 就是 PyFrameObject 对象，我们曾经探索了很久，现在一下子就回到了当初，有种梦回栈帧对象的感觉。</p>
<p>目前的话，Python 的骨架我们已经看清了，虽然还有很多细节隐藏在幕后，至少神秘的面纱已经被撤掉了。</p>
<h2 id="小结-67"><a class="header" href="#小结-67">小结</a></h2>
<p>当我们在控制台输入 python 的那一刻，背后真的是做了大量的工作。因为 Python 是动态语言，很多操作都要发生在运行时。关于运行时环境的初始化和虚拟机的启动就说到这里，接下来我们就要介绍 Python 的多线程了，以及被称为万恶之源的 GIL。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="楔子-70"><a class="header" href="#楔子-70">楔子</a></h2>
<p>这次我们来说一下 Python 的多线程，上篇文章提到了 Python 线程是对 OS 线程的一个封装，并提供了相应的线程状态对象 PyThreadState，来记录 OS 线程的一些状态信息。</p>
<p>那什么是多线程呢？首先线程是操作系统调度 CPU 工作的最小单元，进程则是操作系统资源分配的最小单元，线程是需要依赖于进程的，并且每一个进程内部至少有一个线程，这个线程我们称之为主线程。然后主线程可以创建子线程，而一个进程中如果有多个线程在工作，我们就称之为多线程。</p>
<p>开发一个多线程应用程序是很常见的事情，很多语言都支持多线程，有的是原生支持，有的是通过库来支持。而 Python 毫无疑问也支持多线程，并且它是通过标准库 threading 实现的。</p>
<p>当然标准库 threading 底层依赖了 _thread，而 _thread 是一个用 C 实现的库，位于 Modules/_threadmodule.c 中。还记得这个 Modules 目录是做什么的吗？它也是 CPython 源码的一部分，里面存放的都是一些用 C 实现、并且对性能要求较为苛刻的库，编译之后就内嵌在解释器里面了。</p>
<p>另外提到多线程，总会让人想到 GIL（global interpreter lock）这个万恶之源，我们后面会详细介绍。目前我们知道 Python 多线程是不能利用多核的，因为虚拟机使用一个全局解释器锁（GIL）来控制线程对程序的执行，这个结果就使得无论你的 CPU 有多少核，但是同时被线程调度的 CPU 只有一个。不过底层是怎么做的呢？我们下面就来分析一下。</p>
<h2 id="gil-与线程调度"><a class="header" href="#gil-与线程调度">GIL 与线程调度</a></h2>
<p>如果讨论基于线程的并⾏，那么全局解释器锁（GIL）是⼀个绕不开的话题。我们知道 GIL 是⼀个施加在解释器之上的互斥锁，⽤于防⽌本机多个线程同时执⾏字节码。换句话说 ，GIL 确保解释器在程序执⾏期间，同⼀时刻只会使⽤操作系统的⼀个线程。不管你的 CPU 是多少核，以及你开了多少个线程，同⼀时刻只会使⽤操作系统的⼀个线程、去调度⼀个 CPU。⽽且 GIL 不仅影响 Python 代码，也会影响 Python/C API。</p>
<p>⾸先我们来分析⼀下为什么会有 GIL 这个东⻄存在？举个例⼦：</p>
<pre><code class="language-Python">import dis

dis.dis(&quot;del obj&quot;)
&quot;&quot;&quot;
 0 DELETE_NAME              0 (obj)
 2 LOAD_CONST               0 (None)
 4 RETURN_VALUE
&quot;&quot;&quot;
</code></pre>
<p>当使⽤ del 删除⼀个变量的时候，对应的指令是 DELETE_NAME，这条指令做的事情⾮常简单：通过宏 Py_DECREF 将对象的引⽤计数减 1，并且判断减少之后其引⽤计数是否为 0，如果为 0 就进⾏回收。伪代码如下:</p>
<pre><code class="language-C">--obj-&gt;ob_refcnt
if (obj -&gt; ob_refcnt == 0){
    销毁obj
}
</code></pre>
<p>所以总共是两步：第⼀步先将对象的引⽤计数减 1；第⼆步判断引⽤计数是否为 0，为 0 则进⾏销毁。那么问题来了，假设有两个线程 A 和 B，内部都引⽤了某个变量 obj，此时 obj 指向的对象的引⽤计数为 2，然后让两个线程都执⾏ del obj 这⾏代码。</p>
<p>其中 A 线程先执⾏，A 线程在执⾏完 <code>--obj -&gt; ob_refcnt</code> 之后，会将对象的引⽤计数减⼀，但不幸的是，这个时候调度机制将 A 挂起了，唤醒了 B。⽽ B 也执⾏ del obj，但它⽐较幸运，将两步⼀块执⾏完了。⽽由于之前 A 已经将引⽤计数减 1，所以 B 再减 1 之后会发现对象的引⽤计数为 0，从⽽执⾏了对象的销毁动作（tp_dealloc），内存被释放。</p>
<p>然后 A ⼜被唤醒了，此时开始执⾏第⼆个步骤，但由于 <code>obj-&gt;ob_refcnt</code> 已经被减少到 0，所以条件满⾜，那么 A 依旧会对 obj 指向的对象进⾏释放。但问题是这个对象所占的内存已经被释放了，所以 obj 此时就成了悬空指针。如果再对 obj 指向的对象进⾏释放，最终会引发什么后果，只有天知道，这也是臭名昭著的⼆次释放。</p>
<p>关键来了，所以 CPython 引⼊了 GIL，GIL 是解释器层⾯上的⼀把超级⼤锁，它是字节码级别的互斥锁。作⽤就是：在同时⼀刻，只让⼀个线程执⾏字节码，并且保证每⼀条字节码在执⾏的时候都不会被打断。</p>
<p>因此由于 GIL 的存在，会使得线程只有把当前的某条字节码指令执⾏完毕之后才有可能发⽣调度。所以⽆论是 A 还是 B，线程调度时，要么发⽣在 DELETE_NAME 这条指令执⾏之前，要么发⽣在 DELETE_NAME 这条指令执⾏完毕之后，但是不存在指令（不仅是 DELETE_NAME，⽽是所有指令）执⾏到⼀半的时候发⽣调度。</p>
<p>所以 GIL 才被称之为是字节码级别的互斥锁，它保护每条字节码指令只有在执⾏完毕之后才会发⽣线程调度，或者说线程切换。</p>
<p>回到上⾯那个 del obj 的例⼦当中，由于引⼊了 GIL，所以就不存在我们之前说的：在 A 将引⽤计数减⼀之后，挂起 A、唤醒 B 这⼀过程。因为 A 已经开始了 DELETE_NAME 这条指令的执⾏，⽽在没执⾏完之前是不会发⽣线程调度的，所以此时不会出现悬空指针的问题。</p>
<p>因此 Python 的⼀条字节码指令会对应多⾏ C 代码，这其中可能会涉及很多个 C 函数的调⽤，我们举个例⼦：</p>
<p><img src="./images/279.png" alt="" /></p>
<p>这是 FOR_ITER 指令，Python 的 for 循环对应的就是这条指令。可以看到⾥⾯的逻辑⾮常多，当然也涉及了多个函数调⽤，⽽且函数内部⼜会调⽤其它的函数。如果没有 GIL，那么这些逻辑在执⾏的时候，任何⼀处都可能被打断，发⽣线程调度。</p>
<p>但是有了 GIL 就不同了，它是施加在字节码层⾯上的互斥锁，保证每次只有⼀个线程执⾏字节码指令。并且不允许指令执⾏到⼀半时发⽣调度，因此 GIL 就保证了每条指令内部的 C 逻辑整体都是原⼦的。⽽如果没有 GIL，那么即使是简单的引⽤计数，在计算上都有可能出问题。事实上，GIL 最初的⽬的就是为了解决引⽤计数的安全性问题。</p>
<p>因此 GIL 对于 Python 对象的内存管理来说是不可或缺的，但是还有⼀点需要注意，GIL 和 Python 语⾔本身没有什么关系，它只是官⽅在实现 CPython 时，为了⽅便管理内存所引⼊的⼀个实现。⽽其它种类的 Python 解释器则不⼀定需要 GIL，⽐如 JPython。</p>
<h2 id="gil-有没有可能被移除"><a class="header" href="#gil-有没有可能被移除">GIL 有没有可能被移除</a></h2>
<p>那么 CPython 中的 GIL 将来是否会被移除呢？因为对于现在的多核 CPU 来说，GIL ⽆疑是进⾏了限制。关于能否移除 GIL，就我本⼈来看短时间内不可能（针对 CPython），这都⼏⼗年了，能移除早就移除了。事实上在 Python 诞⽣没多久，就有⼈发现了这⼀诡异之处，因为当时的⼈发现使⽤多线程在计算上居然没有任何的性能提升，反⽽还⽐单线程慢了⼀点。</p>
<p>⽽ Python 的官⽅⼈员回复的是：不要使⽤多线程，去使⽤多进程。此时站在上帝视⻆的我们知道，因为 GIL 的存在使得同⼀时刻只有⼀个核被使⽤，所以对于纯计算的代码来说，理论上多线程和单线程是没有区别的。但由于多线程涉及上下⽂的切换，会有⼀些额外开销，反⽽还慢⼀些。</p>
<p>因此在得知 GIL 的存在之后，有两位勇⼠站了出来表示要移除 GIL，当时 Python 还是 1.5 的版本，⾮常古⽼了。当他们在去掉 GIL 之后，发现多线程的效率相⽐之前确实提升了，但是单线程的效率只有原来的⼀半，这显然是不能接受的。因为把 GIL 去掉了，就意味着需要更细粒度的锁来解决共享数据的安全问题，这就会导致⼤量的加锁、解锁。⽽加锁、解锁对于操作系统来说是⼀个⽐较重量级的操作，所以 GIL 的移除是极其困难的。</p>
<p>另外还有⼀个关键，就是当 GIL 被移除之后，会使得扩展模块的编写难度⼤⼤增加。因为 GIL 保护的不仅仅是解释器，还有 Python/C API。像很多现有的 C 扩展，在很⼤程度上都依赖 GIL 提供的解决⽅案，如果要移除 GIL，就需要重新解决这些库的线程安全问题。</p>
<p>⽐如我们熟知的 numpy，numpy 的速度之所以这么快，就是因为底层是 C 写的，然后封装成 Python 的扩展模块。⽽其它的库，像 pandas、scipy、sklearn 都是在 numpy 之上开发的，如果把 GIL 移除了，那么这些库就都不能⽤了。还有深度学习，像 tensorflow、pytorch 等框架所使⽤的底层算法也都不是 Python 编写的，⽽是 C 和 C++，Python 只是起到了⼀个包装器的作⽤。Python 在深度学习领域很⽕，主要是它可以和 C ⽆缝结合，如果 GIL 被移除，那么这些框架也没法⽤了。</p>
<p>因此在 2024 年的今天，⽣态如此成熟的 Python，⼏乎是不可能摆脱 GIL 了。否则这些知名的科学计算相关的库就要重新洗牌了，可想⽽知这是⼀个什么样的⼯作量。</p>
<p>补充：这⾥我说 GIL ⽆法被移除其实有⼀些过于绝对，如果在移除 GIL 之后能够保证以下三点，那么 GIL 的移除就是成功的。</p>
<ul>
<li>GIL 移除之后不能影响单线程的运⾏速度；</li>
<li>GIL 移除之后不能影响 IO 密集场景下的多线程运⾏速度；</li>
<li>GIL 移除之后不能破坏现有的 C 扩展；</li>
</ul>
<p>如果这三点能够保证的话，那么 GIL 是可以被移除的，⽽只要有⼀点⽆法保证，那么就⽆法移除 GIL。⽽关于移除 GIL 的尝试，也从来都没有停⽌，但⽆⼀例外都失败了，原因也都是因为在移除 GIL 之后会有性能问题、以及要改变很多的 C API。</p>
<h2 id="图解-gil"><a class="header" href="#图解-gil">图解 GIL</a></h2>
<p>Python 启动⼀个线程，底层会启动⼀个 C 线程，最终启动⼀个操作系统的线程。所以 Python 的线程实际上是封装了 C 的线程，进⽽封装了 OS 线程，⼀个 Python 线程对应⼀个 OS 线程。</p>
<p>实际执⾏的肯定是 OS 线程，⽽ OS 线程 Python 解释器是没有权限控制的，它能控制的只有 Python 线程。假设有 4 个 Python 线程，那么肯定对应 4 个 OS 线程，但是解释器每次只让⼀个 Python 线程调⽤ OS 线程去执⾏，其它的线程只能⼲等着，只有当前的 Python 线程将 GIL 释放了，其它的某个线程在拿到 GIL 时，才可以调⽤相应的 OS 线程去执⾏。</p>
<p>总结⼀下就是，没有拿到 GIL 的 Python 线程，对应的 OS 线程会处于休眠状态。拿到 GIL 的 Python 线程，对应的 OS 线程会从休眠状态被唤醒。</p>
<p><img src="./images/280.png" alt="" /></p>
<p>所以 Python 线程是调⽤ C 的线程、进⽽调⽤操作系统的 OS 线程，⽽ OS 线程在执⾏过程中解释器是控制不了的。因为解释器的控制范围只有 Python 线程，它⽆权⼲预 C 的线程、更⽆权⼲预 OS 线程。</p>
<p>再次强调：GIL 并不是 Python 语⾔的特性，它是 CPython 开发⼈员为了⽅便内存管理才加上去的。只不过解释器我们⼤部分⽤的都是 CPython，所以很多⼈认为 GIL 是 Python 语⾔本身的⼀个特性，但其实不是的。</p>
<p>Python 是⼀⻔语⾔，⽽ CPython 是对使⽤ Python 语⾔编写的源代码进⾏解释执⾏的⼀个解释器。⽽解释器不⽌ CPython ⼀种，还有 JPython，但 JPython 就没有 GIL。因此 Python 语⾔本身是和 GIL ⽆关的，只不过我们平时在说 Python 的 GIL 的时候，指的都是 CPython ⾥⾯的 GIL，这⼀点要注意。</p>
<p><img src="./images/281.png" alt="" /></p>
<p>所以就类似于上图，⼀个线程执⾏⼀会⼉，另⼀个线程执⾏⼀会⼉，⾄于线程怎么切换、什么时候切换，我们后⾯会说。</p>
<p>对于 Python ⽽⾔，解释执⾏字节码是其核⼼所在，所以通过 GIL 来互斥不同线程执⾏字节码。如果⼀个线程想要执⾏，就必须拿到 GIL，⽽⼀旦拿到 GIL，其它线程就⽆法执⾏了，如果想执⾏，那么只能等 GIL 释放、被⾃⼰获取之后才可以。并且我们说 GIL 保护的不仅仅是 Python 解释器，还有 Python 的 C API，在使⽤ C/C++ 和 Python 混合开发，涉及到原⽣线程和 Python 线程相互合作时，也需要通过 GIL 进⾏互斥。</p>
<p>那么问题来了，有了 GIL，在编写多线程代码的时候是不是就意味着不需要加锁了呢？</p>
<p>答案显然不是的，因为 GIL 保护的是每条字节码不会被打断，⽽很多代码都是⼀⾏对应多条字节码，所以每⾏代码是可以被打断的。⽐如：<font color="blue">a = a + 1</font> 这样⼀条语句，它对应 4 条字节码：LOAD_NAME、LOAD_CONST、BINARY_ADD、STORE_NAME。</p>
<p>假设此时 a = 8，两个线程 A 和 B 同时执⾏ a = a + 1，线程 A 执⾏的时候已经将 a 和 1 压⼊运⾏时栈，栈⾥⾯的 a 指向的是 8。但还没有执⾏ BINARY_ADD 的时候，发⽣线程切换，轮到线程 B 执⾏，此时 B 得到的 a 显然还是指向 8，因为线程 A 还没有对变量 a 做加法操作。然后 B ⽐较幸运，它⼀次性将这 4 条字节码全部执⾏完了，所以 a 会指向 9。</p>
<p>然后线程调度再切换回 A，此时会执⾏ BINARY_ADD，不过注意：栈⾥⾯的 a ⽬前指向的还是 8，因此加完之后是 9。所以问题就出现了，本来 a 应该指向10，但是却指向 9，就是因为在执⾏的时候发⽣了线程调度。</p>
<p>所以我们在编写多线程代码的时候还是需要加锁的，GIL 只是保证每条字节码执⾏的时候不会被打断，但是⼀⾏代码往往对应多条字节码，所以我们会通过 threading.Lock() 再加上⼀把锁。这样即便发⽣了线程调度，但由于在 Python 的层⾯上⼜加了⼀把锁，别的线程依旧⽆法执⾏，这样就保证了数据的安全。</p>
<h2 id="gil-何时被释放"><a class="header" href="#gil-何时被释放">GIL 何时被释放</a></h2>
<p>那么问题来了，GIL 啥时候会被释放呢？关于这⼀点，Python 有⼀个⾃⼰的调度机制：</p>
<ul>
<li>当遇⻅ IO 阻塞的时候会释放，因为 IO 阻塞是不耗费 CPU 的，所以此时虚拟机会把该线程的锁释放；</li>
<li>即便是耗费 CPU 的运算，也不会⼀直执⾏，会在执⾏⼀⼩段时间之后释放锁，为了保证其它线程都有机会执⾏，就类似于 CPU 时间⽚轮转的⽅式；</li>
</ul>
<p>调度机制虽然简单，但是这背后还隐藏着两个问题：</p>
<ul>
<li>在何时挂起线程，选择处于等待状态的下⼀个线程？</li>
<li>在众多处于等待状态的候选线程中，选择激活哪⼀个线程？</li>
</ul>
<p>在 Python 的多线程机制中，这两个问题分别是由不同的层次解决的。对于何时进⾏线程调度的问题，是由 Python ⾃身决定的。思考⼀下操作系统是如何进⾏进程切换的，当⼀个进程运⾏了⼀段时间之后，发⽣了时钟中断，操作系统响应时钟，并开始进⾏进程的调度。</p>
<p>同样，Python 也是模拟了这样的时钟中断，来激活线程的调度。解释器内部维护着⼀个数值，这个数值就是 Python 内部的时钟，在 Python2 中如果⼀个线程执⾏的字节码指令数达到了这个值，那么会进⾏线程切换，并且这个值在 Python3 中仍然存在。</p>
<pre><code class="language-Python">import sys

# 默认执⾏ 100 条字节码之后，启动线程调度机制，进⾏切换
print(sys.getcheckinterval())  # 100

# 但是在 Python3 中，改成了时间间隔
# 表示⼀个线程在执⾏ 0.005s 之后进⾏切换
print(sys.getswitchinterval())  # 0.005
# 上⾯的⽅法我们都可以⼿动设置
# sys.setcheckinterval(N) # sys.setswitchinterval(N)
</code></pre>
<p>sys.getcheckinterval 和 sys.setcheckinterval 在 Python3.8 的时候已经废弃了，因为线程发⽣调度不再取决于执⾏的字节码条数，⽽是时间间隔。</p>
<p>除了执⾏时间之外，还有就是之前说的遇⻅ IO 阻塞的时候会进⾏切换，所以多线程在 IO 密集型的场景下还是很有⽤处的。说实话如果 IO 都不会⾃动切换的话，那么 Python 的多线程才是真的没有⽤。</p>
<p>然后⼀个问题就是，Python 在切换的时候会从等待的线程中选择哪⼀个呢？很简单，Python 直接借⽤了底层操作系统提供的调度机制来决定下⼀个获取 GIL 的线程究竟是谁。</p>
<p>所以⽬前为⽌可以得到如下结论：</p>
<ul>
<li>GIL 对于 Python 对象的内存管理来说是不可或缺的；</li>
<li>GIL 和 Python 语⾔本身没有什么关系，它只是 CPython 为了⽅便管理内存所引⼊的⼀个实现，只不过 CPython 是使⽤最为⼴泛的⼀种 Python 解释器，我们默认指的就是它。但是别的 Python 解释器则不⼀定需要 GIL，⽐如 JPython；</li>
</ul>
<p>关于 GIL 到底是个什么东⻄（底层就是⼀个结构体实例），以及为什么要有 GIL，我们已经清楚了。那么重点来了，我们能不能⼿动释放 GIL 呢？</p>
<p>在 Python ⾥⾯不可以，但在 C ⾥⾯是可以的。因为 GIL 是为了解决 Python 的内存管理⽽引⼊的，但如果是那些不需要和 Python 代码⼀起⼯作的纯 C 代码，那么是可以在没有 GIL 的情况下运⾏的。</p>
<p>因为 GIL 是字节码级别的互斥锁，显然这是在解释执⾏字节码的时候所施加的。⽽且不仅是 GIL，还有 Python 的动态性，都是在解释字节码的时候动态赋予的。⽽ C 代码经过编译之后直接就是⼆进制码了，所以它相当于绕过了解释执⾏这⼀步，因此也就失去了相应的动态性（换来的是速度的提升）。那么同理，既然能绕过解释执⾏这⼀步，那么就意味着也能绕过 GIL 的限制，因为 GIL 也是在解释执⾏字节码的时候施加的。</p>
<p>因此当我们在 C 中创建了不绑定任何 Python 对象的 C 级结构时，也就是在处理 C-Only 部分时，可以将全局解释器锁给释放掉。换句话说，我们可以使⽤ C 绕过 GIL，实现基于线程的并⾏。</p>
<p>注意：GIL 是为了保护 Python 对象的内存管理⽽设置的，如果我们要释放 GIL，那么⼀定⼀定⼀定不能和 Python 对象发⽣任何的交互，必须是纯 C 的数据结构。</p>
<h2 id="gil-在-c-的层要如何释放"><a class="header" href="#gil-在-c-的层要如何释放">GIL 在 C 的层⾯要如何释放</a></h2>
<p>⾸先必须澄清⼀点，GIL 只有在多线程的情况下才会出现，如果是单线程，那么 CPython 是不会创建 GIL 的。⽽⼀旦我们启动了多线程，那么 GIL 就被创建了。线程如果想安全地访问 Python 对象，就必须要持有全局解释器锁（GIL），如果没有这个锁，那么多线程基本上算是废了，即便是最简单的操作都有可能发⽣问题。例如两个线程同时引⽤了⼀个对象，那么这个对象的引⽤计数应该增加 2，但可能出现只增加 1 的情况。</p>
<p>因此存在⼀个铁打不动的规则：单线程除外，如果是多线程，只有获得了 GIL 的线程才能操作 Python 对象或者调⽤ Python / C API。⽽为了保证每个线程都能有机会执⾏，解释器有着⾃⼰的⼀套规则，可以定期迫使线程释放 GIL，让其它线程也有机会执⾏，因为线程都是抢占式的。但当出现了 IO 阻塞，会⽴即强制释放。</p>
<p>那么问题来了，如果在 C 里面有一段 Python 无关的逻辑，那么这段逻辑完全可以并行执行，此时便可主动释放 GIL，该怎么做呢？用大白话解释就是：</p>
<p><img src="./images/282.png" alt="" /></p>
<p>以上在编写扩展模块的时候⾮常常⽤，因此 Python 底层提供了两个宏：</p>
<pre><code class="language-C">// 从名字上来看，直译就是开始允许多线程（并⾏执⾏）
// 这⼀步就是释放 GIL，表示这 GIL 不要也罢
Py_BEGIN_ALLOW_THREADS
 
/* 做⼀些耗时的纯 C 操作，当然 IO 操作也是如此
   ⽽我们使⽤这两个宏很明显是为了耗时的 C 操作 */ 
// 执⾏完毕之后，如果要和 Python 对象进⾏交互
// 那么必须要再度获取 GIL，相当于结束多线程的并⾏执⾏
Py_END_ALLOW_THREADS
 
// 除了上⾯这两个宏之外，还可以使⽤下⾯这两个宏，效果是⼀样的
// Py_UNBLOCK_THREADS、Py_BLOCK_THREADS 
</code></pre>
<p>我们来看⼀下这两个宏在底层是怎么定义的？</p>
<pre><code class="language-C">// Include/ceval.h
#define Py_BEGIN_ALLOW_THREADS { \
                        PyThreadState *_save; \
                        _save = PyEval_SaveThread();
#define Py_END_ALLOW_THREADS    PyEval_RestoreThread(_save); \
                 }
</code></pre>
<p>所以，如果将这两个宏展开的话，那么就是下⾯这个样⼦。</p>
<p><img src="./images/283.png" alt="" /></p>
<p>浅蓝⾊的部分就是 Py_BEGIN_ALLOW_THREADS，⻩⾊的部分则是 Py_END_ALLOW_THREADS，它们组成了⼀个新的代码块，我们的纯 C 逻辑也会写在⾥⾯。很明显，这两者必须同时出现，如果只出现⼀个，那么编译时就会出现语法错误，因为⼤括号没有成对出现。</p>
<ul>
<li>所以 Py_BEGIN_ALLOW_THREADS 宏会打开⼀个新的代码块（⼤括号的左半部分），并定义⼀个隐藏的局部变量；</li>
<li>Py_END_ALLOW_THREADS 宏则是关闭这个代码块（⼤括号的右半部分）。</li>
</ul>
<p>如果 Python 编译为不⽀持线程的版本（⼏乎没⻅过），它们定义为空。如果⽀持线程，那么代码块会进⾏展开，⽽展开的结果就是上图展示的样⼦。</p>
<pre><code class="language-C">{
    PyThreadState *_save;
    _save = PyEval_SaveThread();
    // ... ...
    PyEval_RestoreThread(_save);
}
</code></pre>
<p>我们也可以使⽤更低级的 API 来实现这⼀点：</p>
<pre><code class="language-c">{
    PyThreadState *_save;
    _save = PyThreadState_Swap(NULL); 
    PyEval_ReleaseLock();
    // ... ...
    PyEval_AcquireLock(); 
    PyThreadState_Swap(_save);
}
</code></pre>
<p>当然低级的 API 会有⼀些微妙的差异，因为锁操作不⼀定保持变量的⼀致性，⽽ PyEval_RestoreThread 可以对这个变量进⾏保存和恢复。同样，如果是不⽀持线程的解释器，那么 PyEval_SaveThread 和 PyEval_RestoreThread 就会不操作锁，然后让 PyEval_ReleaseLock 和 PyEval_AcquireLock 不可⽤，这就使得不⽀持线程的解释器可以动态加载⽀持线程的扩展。</p>
<p>如果不是很理解没有关系，我们梳理⼀下整个过程。⾸先有⼀个全局变量，它保存了当前活跃线程的线程状态对象（指针），这⾥的活跃线程显然就是获取到 GIL 的线程。换句话说，这个关键的全局变量保存的是谁的状态对象，那么获取到 GIL 的活跃线程就是谁。</p>
<p>然后是释放 GIL：</p>
<pre><code class="language-C">{
    PyThreadState *_save;
    // PyThreadState_Swap(NULL) 会将保存线程状态对象指针的全局变量设置为 NULL
    // 也就是不让全局变量再保存⾃身的线程状态对象，因为要释放 GIL 了
    // 并且该函数设置的时候，还会返回之前保存的线程状态对象（显然对应当前线程）
    // 这⾥⽤局部变量 _save 保存起来
    _save = PyThreadState_Swap(NULL);

    // 释放锁，⽽锁⼀旦释放，就会⽴刻被其它线程获取
    // 其它线程在获取之后，还会将⾃身的线程状态对象设置给那个关键的全局变量
    // 设置的⽅式依旧是通过 PyThreadState_Swap 函数
    PyEval_ReleaseLock(); 
  
    // ... 当前线程在释放锁之后，就可以和其它线程并⾏执⾏了 ...
    // ... 但当前线程执⾏的操作，⼀定是不涉及 Python/C API 的纯 C 操作 ... 
  
    // 当 C 级操作执⾏完毕之后，需要使⽤ Python/C API 了，那么显然要再度获取锁
    // 此处会等待获取全局锁 
    PyEval_AcquireLock();
    // ⼀旦获取到锁，还要将⾃身的线程状态对象设置给专⻔负责保存的全局变量 
    PyThreadState_Swap(_save);
}
</code></pre>
<p>所以过程就是这个样⼦，简化⼀下就是五个步骤，⽤⼤⽩话解释就是：</p>
<ul>
<li>通过 PyThreadState_Swap 获取当前活跃线程的线程状态对象，同时将保存线程状态对象的全局变量设置为 NULL；</li>
<li>释放全局锁；</li>
<li>做⼀些需要并⾏的纯 C 操作；</li>
<li>获取全局锁；</li>
<li>调⽤ PyThreadState_Swap 再将全局变量设置为⾃身的线程状态对象；</li>
</ul>
<p>以上就是全局解释器锁的释放逻辑，它⽤于保护当前的线程状态对象。但需要注意的是，1 和 2 两个步骤不能颠倒，当然 4 和 5 也是如此。也就是说，我们必须在拿到当前线程状态对象并⽤局部变量保存之后，才能释放锁（因为另⼀个线程会获取锁，全局变量会保存新的线程状态对象）。同理在重新获取锁时，锁必须要先获取，然后才能恢复线程状态对象（将其设置给全局变量）。</p>
<h2 id="小结-68"><a class="header" href="#小结-68">小结</a></h2>
<p>到目前为止，我们算是以高维的视角理解了什么是 GIL，以及线程切换又是怎么一回事。那么下一篇文章，我们就从源代码的角度，来分析 GIL 到底是如何实现的。</p>
<hr />
<p> </p>
<p><strong>欢迎大家关注我的公众号：古明地觉的编程教室。</strong></p>
<p><img src="./images/qrcode_for_gh.jpg" alt="" /></p>
<p><strong>如果觉得文章对你有所帮助，也可以请作者吃个馒头，Thanks♪(･ω･)ﾉ。</strong></p>
<p><img src="./images/supports.png" alt="" /></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="theme/custom.js"></script>
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
